["```py\npyspark  \n```", "```py\nfrom pyspark import SparkContext\nsc = SparkContext.getOrCreate()\n\nlines = sc.textFile(\"B05238_04 Spark Total Line Lengths.ipynb\")\nlineLengths = lines.map(lambda s: len(s))\ntotalLength = lineLengths.reduce(lambda a, b: a + b)\nprint(totalLength)  \n```", "```py\nimport pyspark\nif not 'sc' in globals():\n sc = pyspark.SparkContext()\n\ntext_file = sc.textFile(\"Spark File Words.ipynb\")\ncounts = text_file.flatMap(lambda line: line.split(\" \")) \\\n .map(lambda word: (word, 1)) \\\n .reduceByKey(lambda a, b: a + b)\nfor x in counts.collect():\n print x  \n```", "```py\nfrom pyspark.sql import SparkSession \nspark = SparkSession(sc) \n\ndf = spark.read.format(\"csv\") \\\n .option(\"header\", \"true\") \\\n .load(\"productsales.csv\");\ndf.show()  \n```", "```py\ndf.groupBy(\"PRODUCT\").count().show()  \n```", "```py\ndf.filter(df['ACTUAL'] > df['PREDICT']).show()  \n```", "```py\n#register dataframe as temporary SQL table\ndf.createOrReplaceTempView(\"sales\")\n# pull the values by the difference calculated\nsqlDF = spark.sql(\"SELECT *, ACTUAL-PREDICT as DIFF FROM sales ORDER BY DIFF desc\")\nsqlDF.show()  \n```", "```py\nfrom pyspark import SparkContext\nfrom pyspark.sql import SparkSession\n\nsc = SparkContext.getOrCreate()\nspark = SparkSession(sc) \n\n# load product set\nproductDF = spark.read.format(\"csv\") \\\n .option(\"header\", \"true\") \\\n .load(\"product.csv\");\nproductDF.show()\nproductDF.createOrReplaceTempView(\"product\")\n\n# load order set\norderDF = spark.read.format(\"csv\") \\\n .option(\"header\", \"true\") \\\n .load(\"order.csv\");\norderDF.show()\norderDF.createOrReplaceTempView(\"order\")\n\n# load order/product set\norderproductDF = spark.read.format(\"csv\") \\\n .option(\"header\", \"true\") \\\n .load(\"orderproduct.csv\");\norderproductDF.show()\norderproductDF.createOrReplaceTempView(\"orderproduct\")  \n```", "```py\n# join the tables\njoinedDF = spark.sql(\"SELECT * \" \\\n \"FROM orderproduct \" \\\n \"JOIN order ON order.orderid = orderproduct.orderid \" \\\n \"ORDER BY order.orderid\")\njoinedDF.show()  \n```", "```py\nfrom pyspark import SparkContext\nfrom pyspark.sql import SparkSession \nsc = SparkContext.getOrCreate()\nspark = SparkSession(sc)  \n```", "```py\n#using some data from file from https://gist.github.com/marktyers/678711152b8dd33f6346\ndf = spark.read.json(\"people.json\")\ndf.show()  \n```", "```py\ndf.printSchema()  \n```", "```py\ndf.registerTempTable(\"people\")\nspark.sql(\"select name from people\").show()  \n```", "```py\nfrom pyspark import SparkContext\nfrom pyspark.sql import SparkSession\nfrom pyspark.sql import functions as func\n\nsc = SparkContext.getOrCreate()\nspark = SparkSession(sc)\n\n# load product set\npivotDF = spark.read.format(\"csv\") \\\n .option(\"header\", \"true\") \\\n .load(\"pivot.csv\");\npivotDF.show()\npivotDF.createOrReplaceTempView(\"pivot\")\n\n# pivot data per the year to get average prices per stock per year\npivotDF \\\n .groupBy(\"stock\") \\\n .pivot(\"year\",[2012,2013]) \\\n .agg(func.avg(\"price\")) \\\n .show()  \n```"]