["```py\n# import genfromtxt function\nfrom numpy import genfromtxt\n\n# Read comma separated file\nproduct_data = genfromtxt('demo.csv', delimiter=',')\n\n# display initial 5 records\nprint(product_data)\n```", "```py\n[[14\\. 32\\. 33.]\n [24\\. 45\\. 26.]\n [27\\. 38\\. 39.]]\n```", "```py\n# import numpy\nimport numpy as np\n\n# Create a sample array\nsample_array = np.asarray([ [1,2,3], [4,5,6], [7,8,9] ])\n\n# Write sample array to CSV file\nnp.savetxt(\"my_first_demo.csv\", sample_array, delimiter=\",\")\n```", "```py\n# import pandas\nimport pandas as pd\n\n# Read CSV file\nsample_df=pd.read_csv('demo.csv', sep=',' , header=None)\n\n# display initial 5 records\nsample_df.head()\n```", "```py\n# Save DataFrame to CSV file\nsample_df.to_csv('demo_sample_df.csv')\n```", "```py\n# Read excel file\ndf=pd.read_excel('employee.xlsx',sheet_name='performance')\n\n# display initial 5 records\ndf.head()\n```", "```py\ndf.to_excel('employee_performance.xlsx')\n```", "```py\n# Read excel file\nemp_df=pd.read_excel('employee.xlsx',sheet_name='employee_details')\n\n# write multiple dataframes to single excel file\nwith pd.ExcelWriter('new_employee_details.xlsx') as writer:\n    emp_df.to_excel(writer, sheet_name='employee')\n    df.to_excel(writer, sheet_name='perfromance')\n```", "```py\n# Reading JSON file\ndf=pd.read_json('employee.json')\n\n# display initial 5 records\ndf.head()\n```", "```py\n# Writing DataFrame to JSON file\ndf.to_json('employee_demo.json',orient=\"columns\")\n```", "```py\n# Write DataFrame to hdf5\ndf.to_hdf('employee.h5', 'table', append=True)\n```", "```py\n# Read a hdf5 file\ndf=pd.read_hdf('employee.h5', 'table')\n\n# display initial 5 records\ndf.head()\n```", "```py\n# Reading HTML table from given URL\ntable_url = 'https://en.wikipedia.org/wiki/List_of_sovereign_states_and_dependent_territories_in_North_America'\ndf_list = pd.read_html(table_url)\n\nprint(\"Number of DataFrames:\",len(df_list))\n```", "```py\nNumber of DataFrames: 7\n```", "```py\n# Check first DataFrame\ndf_list[0].head()\n```", "```py\n# Write DataFrame to raw HTML\ndf_list[1].to_html('country.html')\n```", "```py\npip install pyarrow\n```", "```py\n!pip install pyarrow\n```", "```py\n# Write to a parquet file.\ndf.to_parquet('employee.parquet', engine='pyarrow')\n```", "```py\n# Read parquet file\nemployee_df = pd.read_parquet('employee.parquet', engine='pyarrow')\n\n# display initial 5 records\nemployee_df.head()\n```", "```py\n# import pandas\nimport pandas as pd\n\n# Read CSV file\ndf=pd.read_csv('demo.csv', sep=',' , header=None)\n\n# Save DataFrame object in pickle file\ndf.to_pickle('demo_obj.pkl')\n```", "```py\n#Read DataFrame object from pickle file\npickle_obj=pd.read_pickle('demo_obj.pkl')\n\n# display initial 5 records\npickle_obj.head()\n```", "```py\n# Import sqlite3\nimport sqlite3\n\n# Create connection. This will create the connection with employee database. If the database does not exist it will create the database\nconn = sqlite3.connect('employee.db')\n\n# Create cursor\ncur = conn.cursor()\n\n# Execute SQL query and create the database table\ncur.execute(\"create table emp(eid int,salary int)\")\n\n# Execute SQL query and Write the data into database\ncur.execute(\"insert into emp values(105, 57000)\")\n\n# commit the transaction\ncon.commit()\n\n# Execute SQL query and Read the data from the database\ncur.execute('select * from emp')\n\n# Fetch records\nprint(cur.fetchall())\n\n# Close the Database connection\nconn.close()\n\nOutput: [(105, 57000)]\n```", "```py\npip install pymysql\n```", "```py\n>> create database employee\n```", "```py\n>> use employee\n```", "```py\n>> create table emp(eid int, salary int);\n```", "```py\n# import pymysql connector module\nimport pymysql\n\n# Create a connection object using connect() method \nconnection = pymysql.connect(host='localhost', # IP address of the MySQL database server\n                             user='root', # user name\n                             password='root',# password\n                             db='emp', # database name\n                             charset='utf8mb4', # character set\n                             cursorclass=pymysql.cursors.DictCursor) # cursor type\n\ntry:\n    with connection.cursor() as cur:\n        # Inject a record in database\n        sql_query = \"INSERT INTO `emp` (`eid`, `salary`) VALUES (%s, %s)\"\n        cur.execute(sql_query, (104,43000))\n\n    # Commit the record insertion explicitly.\n    connection.commit()\n\n    with connection.cursor() as cur:\n        # Read records from employee table\n        sql_query = \"SELECT * FROM `emp`\"\n        cur.execute(sql_query )\n        table_data = cur.fetchall()\n        print(table_data)\nexcept:\n    print(\"Exception Occurred\")\nfinally:\n    connection.close()\n```", "```py\npip install mysql-connector-python\n```", "```py\n# Import the required connector\nimport mysql.connector\nimport pandas as pd\n\n# Establish a database connection to mysql\nconnection=mysql.connector.connect(user='root',password='root',host='localhost',database='emp')\n\n# Create a cursor\ncur=connection.cursor()\n\n# Running sql query\ncur.execute(\"select * from emp\")\n\n# Fetch all the records and print it one by one\nrecords=cur.fetchall()\nfor i in records:\n    print(i)\n\n# Create a DataFrame from fetched records.\ndf = pd.DataFrame(records)\n\n# Assign column names to DataFrame\ndf.columns = [i[0] for i in cur.description]\n\n# close the connection\nconnection.close()\n```", "```py\n# Import the sqlalchemy engine\nfrom sqlalchemy import create_engine\n\n# Instantiate engine object\nen = create_engine(\"mysql+pymysql://{user}:{pw}@localhost/{db}\"\n                .format(user=\"root\", \n                        pw=\"root\", \n                        db=\"emp\"))\n\n# Insert the whole dataframe into the database\ndf.to_sql('emp', con=en, if_exists='append',chunksize=1000, index= False)\n```", "```py\npip install pymongo\n```", "```py\n# Import pymongo\nimport pymongo\n\n# Create mongo client\nclient = pymongo.MongoClient()\n\n# Get database\ndb = client.employee\n\n# Get the collection from database\ncollection = db.emp\n\n# Write the data using insert_one() method\nemployee_salary = {\"eid\":114, \"salary\":25000}\ncollection.insert_one(employee_salary)\n\n# Create a dataframe with fetched data\ndata = pd.DataFrame(list(collection.find()))\n```", "```py\npip install cassandra-driver\n```", "```py\n# Import the cluster\nfrom cassandra.cluster import Cluster\n\n# Creating a cluster object\ncluster = Cluster()\n\n# Create connections by calling Cluster.connect():\nconn = cluster.connect()\n\n# Execute the insert query\nconn.execute(\"\"\"INSERT INTO employee.emp_details (eid, ename, age) VALUES (%(eid)s, %(ename)s, %(age)s)\"\"\", {'eid':101, 'ename': \"Steve Smith\", 'age': 42})\n\n# Execute the select query\nrows = conn.execute('SELECT * FROM employee.emp_details')\n\n# Print the results\nfor emp_row in rows:\n    print(emp_row.eid, emp_row.ename, emp_row.age)\n\n# Create a dataframe with fetched data\ndata = pd.DataFrame(rows)\n```", "```py\npip install redis\n```", "```py\n# Import module\nimport redis\n\n# Create connection\nr = redis.Redis(host='localhost', port=6379, db=0)\n\n# Setting key-value pair\nr.set('eid', '101')\n\n# Get value for given key\nvalue=r.get('eid')\n\n# Print the value\nprint(value)\n```", "```py\n$ pip install pony\n```", "```py\n# Import pony module\nfrom pony.orm import *\n\n# Create database\ndb = Database()\n\n# Define entities\nclass Emp(db.Entity):\n    eid = PrimaryKey(int,auto=True)\n    salary = Required(int)\n\n# Check entity definition\nshow(Emp)\n\n# Bind entities to MySQL database\ndb.bind('mysql', host='localhost', user='root', passwd='12345', db='employee')\n\n# Generate required mappings for entities\ndb.generate_mapping(create_tables=True)\n\n# turn on the debug mode\nsql_debug(True)\n\n# Select the records from Emp entities or emp table\nselect(e for e in Emp)[:]\n\n# Show the values of all the attribute\nselect(e for e in Emp)[:].show()\n\nOutput:\neid|salary\n---+------\n104|43000 \n104|43000 \n```"]