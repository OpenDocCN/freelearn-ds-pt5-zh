<html><head></head><body><div id="sbo-rt-content"><div id="_idContainer110" class="Content">
			<h1 id="_idParaDest-62"><em class="italics"><a id="_idTextAnchor065"/>Chapter 3</em></h1>
		</div>
		<div id="_idContainer111" class="Content">
			<h1 id="_idParaDest-63"><a id="_idTextAnchor066"/>Introduction to Machine Learning via Scikit-Learn</h1>
		</div>
		<div id="_idContainer112" class="Content">
			<h2>Learning Objectives</h2>
			<p>By the end of this chapter, you will be able to:</p>
			<ul>
				<li class="bullets">Prepare data for different types of supervised learning models.</li>
				<li class="bullets">Tune model hyperparameters using a grid search.</li>
				<li class="bullets">Extract feature importance from a tuned model.</li>
				<li class="bullets">Evaluate performance of classification and regression models.</li>
			</ul>
			<p>In this chapter, we will be covering the important concepts of handling data and making the data ready for analysis.</p>
		</div>
		<div id="_idContainer145" class="Content">
			<h2 id="_idParaDest-64"><a id="_idTextAnchor067"/>Introduction</h2>
			<p><strong class="bold">scikit-learn</strong> is a free, open source library built for Python that contains an assortment of supervised and unsupervised machine learning algorithms. Additionally, scikit-learn provides functions for data preprocessing, hyperparameter tuning, and model evaluation, which we will be covering in the upcoming chapters. It streamlines the model-building process and is easy to install on a wide variety of platforms. scikit-learn started in 2007 as a Google Summer of Code project by David Corneapeau, and after a series of developments and releases, scikit-learn has evolved into one of the premier tools used by academics and professionals for machine learning.</p>
			<p>In this chapter, we will learn to build a variety of widely used modeling algorithms, namely, linear and logistic regression, support vector machines (SVMs), decision trees, and random forests. First, we will cover linear and logistic regression.</p>
			<h2 id="_idParaDest-65"><a id="_idTextAnchor068"/>Introduction to Linear and Logistic Regression</h2>
			<p>In regression, a single dependent, or outcome variable is predicted using one or more independent variables. Use cases for regression are included, but are not limited to predicting:</p>
			<ul>
				<li>The win percentage of a team, given a variety of team statistics</li>
				<li>The risk of heart disease, given family history and a number of physical and psychological characteristics</li>
				<li>The likelihood of snowfall, given several climate measurements</li>
			</ul>
			<p>Linear and logistic regression are popular choices for predicting such outcomes due to the ease and transparency of interpretability, as well as the ability to extrapolate to values not seen in the training data. The end goal of linear regression is to draw a straight line through the observations that minimizes the absolute distance between the line and observations (that is, the line of best fit). Therefore, in linear regression, it is assumed that the relationship between the feature(s) and the continuous dependent variable follows a straight line. Lines are defined in slope-intercept form (that is, <em class="italics">y = a + bx</em>), where <em class="italics">a</em> is the intercept (that is, the value of <em class="italics">y</em> when <em class="italics">x</em> is 0), <em class="italics">b</em> is the slope, and <em class="italics">x</em> is the independent variable. There are two types of linear regression that will be covered in this chapter: simple linear regression and multiple linear regression.</p>
			<h3 id="_idParaDest-66"><a id="_idTextAnchor069"/>Simple Linear Regression</h3>
			<p>Simple linear regression models define the relationship between one feature and the continuous outcome variable using <em class="italics">y = </em><em class="italics">α</em><em class="italics"> + </em><em class="italics">β</em><em class="italics">x</em>. This equation is like the slope-intercept form, where <em class="italics">y</em> denotes the predicted value of the dependent variable, <em class="italics">α</em> denotes the intercept, <em class="italics">β</em> (beta) represents the slope, and <em class="italics">x</em> is the value of the independent variable. Given <em class="italics">x</em>, regression models compute the values for <em class="italics">α</em> and <em class="italics">β</em> that minimize the absolute difference between predicted <em class="italics">y</em> values (that is, <em class="italics">ŷ</em>) and actual <em class="italics">y</em> values. </p>
			<p>For example, if we are predicting the weight of an individual in kilograms (kg) using height in meters (m) as the lone predictor variable, and the simple linear regression model computes 1.5 as the value for <em class="italics">α</em> and 50 as the coefficient for <em class="italics">β</em>, this model can be interpreted as for every 1 m increase in height, weight increases by 50 kg. Thus, we can predict that the weight of an individual who is 1.8 m is 91.5 kg using y = 1.5 + (50 x 1.8). In the following exercises, we will demonstrate simple linear regression using scikit-learn.</p>
			<h3 id="_idParaDest-67"><a id="_idTextAnchor070"/>Exercise 21: Preparing Data for a Linear Regression Model</h3>
			<p>To prepare our data for a simple linear regression model, we will use a random subset of the Weather in Szeged 2006-2016 dataset, which consists of hourly weather measurements from April 1, 2006, to September 9, 2016, in Szeged, Hungary. The adapted data is provided as a <strong class="inline">.csv</strong> file (<a href="">https://github.com/TrainingByPackt/Data-Science-with-Python/blob/master/Chapter02/weather.csv</a>) and consists of 10,000 observations of 8 variables:</p>
			<ul>
				<li><strong class="inline">Temperature_c</strong>: <a id="_idTextAnchor071"/>The temperature in Celsius</li>
				<li><strong class="inline">Humidity</strong>: The proportion of humidity</li>
				<li><strong class="inline">Wind_Speed_kmh</strong>: The wind speed in kilometers per hour</li>
				<li><strong class="inline">Wind_Bearing_Degrees</strong>: The wind direction in degrees clockwise from due north</li>
				<li><strong class="inline">Visibility_km</strong>: The visibility in kilometers</li>
				<li><strong class="inline">Pressure_millibars</strong>: The atmospheric pressure as measured in millibars</li>
				<li><strong class="inline">Rain</strong>: rain = 1, snow = 0</li>
				<li><strong class="inline">Description</strong>: Warm, normal, or cold</li>
			</ul>
			<ol>
				<li>Import the <strong class="inline">weather.csv</strong> dataset using the following code:<p class="snippet">import pandas as pd</p><p class="snippet">df = pd.read_csv('weather.csv')</p></li>
				<li>Explore the data using <strong class="inline">df.info()</strong>:<div id="_idContainer113" class="IMG---Figure"><img src="Images/C13322_03_01.jpg" alt="Figure 3.1: Information describing df&#13;&#10;" width="549" height="195"/></div><h6>Figure 3.1: Information describing df</h6></li>
				<li>The <strong class="inline">Description</strong> column is the lone categorical variable in <strong class="inline">df</strong>. Check the number of levels in <strong class="inline">Description</strong> as follows:<p class="snippet">levels = len(pd.value_counts(df['Description']))</p><p class="snippet">print('There are {} levels in the Description column'.format(levels))</p><p>The number of levels is shown in the following screenshot:</p><div id="_idContainer114" class="IMG---Figure"><img src="Images/C13322_03_02.jpg" alt="Figure 3.2: Number of levels in the 'Description' column" width="483" height="15"/></div><h6>Figure 3.2: Number of levels in the 'Description' column</h6><h4>Note</h4><p class="callout">Multi-class, categorical variables must be converted into dummy variables via a process termed "dummy coding." Dummy coding a multi-class, categorical variable creates n-1 new binary features, which correspond to the levels within the categorical variable. For example, a multi-class, categorical variable with three levels will create two binary features. After the multi-class, categorical feature has been dummy coded, the original feature must be dropped.</p></li>
				<li>To dummy code all multi-class, categorical variables, refer to the following code:<p class="snippet">import pandas as pd</p><p class="snippet">df_dummies = pd.get_dummies(df, drop_first=True)</p><h4>Note</h4><p class="callout">The original DataFrame, <strong class="inline">df</strong>, consisted of eight columns, one of which (that is, Description) was a multi-class, categorical variable with three levels.</p></li>
				<li>In step 4, we transformed this feature into n-1 (that is, 2), separated dummy variables, and dropped the original feature, <strong class="inline">Description</strong>. Thus, <strong class="inline">df_dummies</strong> should now contain one more column than df (that is, 9 columns). Check this out using the following code:<p class="snippet">print('There are {} columns in df_dummies'	.format(df_dummies.shape[1]))</p><div id="_idContainer115" class="IMG---Figure"><img src="Images/C13322_03_03.jpg" alt="Figure 3.3: Number of columns after dummy coding&#13;&#10;" width="520" height="18"/></div><h6>Figure 3.3: Number of columns after dummy coding</h6></li>
				<li>To remove any possible order effects in the data, it is good practice to first shuffle the rows of the data prior to splitting the data into features (<strong class="inline">X</strong>) and outcome (<strong class="inline">y</strong>). To shuffle the rows in <strong class="inline">df_dummies</strong>, refer to the code here:<p class="snippet">from sklearn.utils import shuffle</p><p class="snippet">df_shuffled = shuffle(df_dummies, random_state=42)</p></li>
				<li>Now that the data has been shuffled, we will split the rows in our data into features (<strong class="inline">X</strong>) and the dependent variable (<strong class="inline">y</strong>).<h4>Note</h4><p class="callout">Linear regression is used for predicting a continuous outcome. Thus, in this exercise, we will pretend that the continuous variable <strong class="inline">Temperature_c</strong> (the temperature in Celsius) is the dependent variable, and that we are preparing data to fit a linear regression model. </p></li>
				<li>Split <strong class="inline">df_shuffled</strong> into <strong class="inline">X</strong> and <strong class="inline">y</strong> as follows:<p class="snippet">DV = 'Temperature_c'</p><p class="snippet">X = df_shuffled.drop(DV, axis=1)</p><p class="snippet">y = df_shuffled[DV]</p></li>
				<li>Split <strong class="inline">X</strong> and <strong class="inline">y</strong> into testing and training data using the code here:<p class="snippet">from sklearn.model_selection import train_test_split</p><p class="snippet">X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)</p><p>Now that the data has been dummy coded, shuffled, split into <strong class="inline">X</strong> and <strong class="inline">y</strong>, and further divided into testing and training datasets, it is ready to be used in a linear or logistic regression model.</p><p>The screenshot here shows the first five rows of <strong class="inline">X_train</strong>:</p></li>
			</ol>
			<div>
				<div id="_idContainer116" class="IMG---Figure">
					<img src="Images/C13322_03_04.jpg" alt="Figure 3.4: The first five rows of X_train&#13;&#10;" width="871" height="208"/>
				</div>
			</div>
			<h6>Figure 3.4: The first five rows of X_train</h6>
			<h3 id="_idParaDest-68"><a id="_idTextAnchor072"/>Exercise 22: Fitting a Simple Linear Regression Model and Determining the Intercept and Coefficient</h3>
			<p>In this exercise, we will continue using the data we prepared in Exercise 21 to fit a simple linear regression model to predict the temperature in Celsius from the humidity.</p>
			<p>Continuing from Exercise 21, perform the following steps:</p>
			<ol>
				<li value="1">To instantiate a linear regression model, refer to the code here:<p class="snippet">from sklearn.linear_model import LinearRegression</p><p class="snippet">model = LinearRegression()</p></li>
				<li>Fit the model to the <strong class="inline">Humidity</strong> column in the training data using this code:<p class="snippet"><strong class="inline">model.fit(X_train[['Humidity']], y_train)</strong></p><div id="_idContainer117" class="IMG---Figure"><img src="Images/C13322_03_05.jpg" alt="Figure 3.5: The output from fitting the simple linear regression model&#13;&#10;" width="504" height="32"/></div><h6>Figure 3.5: The output from fitting the simple linear regression model</h6></li>
				<li>Extract the value for the intercept using the following code:<p class="snippet">intercept = model.intercept_</p></li>
				<li>Extract the value for the <strong class="inline">coefficient</strong> as follows:<p class="snippet">coefficient = model.coef_</p></li>
				<li>Now, we can print a message with the formula for predicting temperature in Celsius using the code here:<p class="snippet">print('Temperature = {0:0.2f} + ({1:0.2f} x Humidity)'.format(intercept, coefficient[0]))</p><div id="_idContainer118" class="IMG---Figure"><img src="Images/C13322_03_06.jpg" alt="Figure 3.6: A formula to predict temperature in Celsius from humidity using simple linear regression&#13;&#10;" width="579" height="18"/></div></li>
			</ol>
			<h6> </h6>
			<h6>Figure 3.6: A formula to predict temperature in Celsius from humidity using simple linear regression</h6>
			<p>Great work! According to this simple linear regression model, a day with a 0.78 humidity value has a predicted a temperature of 10.56 degrees Celsius. Now that we are familiar with extracting the intercept and coefficients of our simple linear regression model, it is time to generate predictions and subsequently evaluate how the model performs on unseen, test data.</p>
			<h4>Teaching tip</h4>
			<p class="callout">Practice calculating temperature at various levels of humidity.</p>
			<h3 id="_idParaDest-69"><a id="_idTextAnchor073"/>Exercise 23: Generating Predictions and Evaluating the Performance of a Simple Linear Regression Model</h3>
			<p>The very purpose of supervised learning is to use existing, labeled data to generate predictions. Thus, this exercise will demonstrate how to generate predictions on the test feature and generate model performance metrics by comparing the predictions to the actual values.</p>
			<p>Continuing from <em class="italics">Exercise 22</em>, perform the following steps:</p>
			<ol>
				<li value="1">Generate predictions on the test data using the following:<p class="snippet">predictions = model.predict(X_test[['Humidity']])</p><h4>Note</h4><p class="callout">A common way to evaluate model performance is to examine the correlation between the predicted and actual values using a scatterplot. The scatterplot displays the relationship between the actual and predicted values. A perfect regression model will display a straight, diagonal line between predicted and actual values. The relationship between the predicted and actual values can be quantified using the Pearson r correlation coefficient. In the following step, we will create a scatterplot of the predicted and actual values.</p></li>
				<li>It is helpful if the correlation coefficient is displayed in the plot's title. The following code will show us how to do this:<p class="snippet">import matplotlib.pyplot as plt</p><p class="snippet">from scipy.stats import pearsonr</p><p class="snippet">plt.scatter(y_test, predictions)</p><p class="snippet">plt.xlabel('Y Test (True Values)')</p><p class="snippet">plt.ylabel('Predicted Values')</p><p class="snippet">plt.title('Predicted vs. Actual Values (r = {0:0.2f})'.format(pearsonr(y_test, predictions)[0], 2))</p><p class="snippet">plt.show()</p><p>Here is the resultant output:</p><div id="_idContainer119" class="IMG---Figure"><img src="Images/C13322_03_07.jpg" alt="Figure 3.7: Predicted versus actual values from a simple linear regression model&#13;&#10;" width="512" height="273"/></div><h6>Figure 3.7: Predicted versus actual values from a simple linear regression model</h6><h4>Note</h4><p class="callout">With a Pearson r value of 0.62, there is a moderate, positive, linear correlation between the predicted and actual values. A perfect model would have all points on the plot in a straight line and an r value of 1.0.</p></li>
				<li>A model that fits the data very well will have normally distributed residuals. To create a density plot of the residuals, refer to the following code:<p class="snippet">import seaborn as sns</p><p class="snippet">from scipy.stats import shapiro</p><p class="snippet">sns.distplot((y_test - predictions), bins = 50)</p><p class="snippet">plt.xlabel('Residuals')</p><p class="snippet">plt.ylabel('Density')</p><p class="snippet">plt.title('Histogram of Residuals (Shapiro W p-value = {0:0.3f})'.format(shapiro(y_test - predictions)[1]))</p><p class="snippet">plt.show()</p><p>Refer to the resultant output here:</p><div id="_idContainer120" class="IMG---Figure"><img src="Images/C13322_03_08.jpg" alt="Figure 3.8: A histogram of residuals from a simple linear regression model&#13;&#10;" width="589" height="276"/></div><h6>  </h6><h6>Figure 3.8: A histogram of residuals from a simple linear regression model</h6><h4>Note</h4><p class="callout">The histogram shows us that the residuals are negatively skewed and the value of the Shapiro W p-value in the title tells us that the distribution is not normal. This gives us further evidence that our model has room for improvement.</p></li>
				<li>Lastly, we will compute metrics for mean absolute error, mean squared error, root mean squared error, and R-squared, and put them into a DataFrame using the code here:<p class="snippet">from sklearn import metrics</p><p class="snippet">import numpy as np</p><p class="snippet">metrics_df = pd.DataFrame({'Metric': ['MAE', </p><p class="snippet">                                      'MSE', </p><p class="snippet">                                      'RMSE', </p><p class="snippet">                                      'R-Squared'],</p><p class="snippet">                          'Value': [metrics.mean_absolute_error(y_test, predictions),</p><p class="snippet">                                    metrics.mean_squared_error(y_test, predictions),</p><p class="snippet">                                    np.sqrt(metrics.mean_squared_error(y_test, predictions)),</p><p class="snippet">                                    metrics.explained_variance_score(y_test, predictions)]}).round(3)</p><p class="snippet">print(metrics_df)</p><p>Please refer to the resultant output:</p></li>
			</ol>
			<div>
				<div id="_idContainer121" class="IMG---Figure">
					<img src="Images/C13322_03_09.jpg" alt="Figure 3.9: Model evaluation metrics from a simple linear regression model&#13;&#10;" width="519" height="75"/>
				</div>
			</div>
			<h6>Figure 3.9: Model evaluation metrics from a simple linear regression model</h6>
			<p><strong class="keyword">Mean absolute error</strong> (<strong class="keyword">MAE</strong>) is the average absolute difference between the predicted values and the actual values. <strong class="keyword">Mean squared error</strong> (<strong class="keyword">MSE</strong>) is the average of the squared differences between the predicted and actual values. <strong class="keyword">Root mean squared error</strong> (<strong class="keyword">RMSE</strong>) is the square root of the MSE. R-squared tells us the proportion of variance in the dependent variable that can be explained by the model. Thus, in this simple linear regression model, humidity explained only 38.9% of the variance in temperature. Additionally, our predictions were within ± 6.052 degrees Celsius.</p>
			<p>Here, we have successfully used scikit-learn to fit and evaluate a simple linear regression model. This is the first step in a very exciting journey to becoming a machine learning guru. Next, we will continue expanding our knowledge of regression and improving this model by exploring multiple linear regression.</p>
			<h2 id="_idParaDest-70"><a id="_idTextAnchor074"/>Multiple Linear Regression</h2>
			<p>Multiple linear regression models define the relationship between two or more features and the continuous outcome variable using <em class="italics">y = </em><em class="italics">α</em><em class="italics"> + </em><em class="italics">β</em><em class="italics">1</em><em class="italics">x</em><em class="italics">i1</em><em class="italics"> + </em><em class="italics">β</em><em class="italics">2</em><em class="italics">x</em><em class="italics">i2</em><em class="italics"> + … + </em><em class="italics">β</em><em class="italics">p-1</em><em class="italics">x</em><em class="italics">i,p-1</em>. Again, <em class="italics">α</em> represents the intercept and <em class="italics">β</em> denotes the slope for each feature (<em class="italics">x</em>) in the model. Thus, if we are predicting the weight of an individual in kg using height in <em class="italics">m</em>, total cholesterol in milligrams per deciliter (<em class="italics">mg/dL)</em>, and minutes of cardiovascular exercise per day, and the multiple linear regression model computes 1.5 as the value for <em class="italics">α</em>, 50 as the coefficient for <em class="italics">β</em><em class="italics">1</em>, 0.1 as the coefficient for <em class="italics">β</em><em class="italics">2</em>, and -0.4 as the coefficient for <em class="italics">β</em><em class="italics">3</em>, this model can be interpreted as for every 1 <em class="italics">m</em> increase in height, weight increases by 50 kg, controlling for all other features in the model. Additionally, for every 1 mg/dL increase in total cholesterol, weight increases by 0.1 kg, controlling for all other features in the model. Lastly, for every minute of cardiovascular exercise per day, weight decreases by 0.4 kg, controlling for all other features in the model. Thus, we can predict the weight of an individual who is 1.8 m tall, with total cholesterol of 200 mg/dL, and completes 30 minutes of cardiovascular exercise per day as 99.5 kg using <em class="italics">y = 1.5 + (0.1 x 50) + (200 x 0.5) + (30 x -0.4)</em>. In the following exercise, we will demonstrate conducting multiple linear regression using scikit-learn.</p>
			<h3 id="_idParaDest-71"><a id="_idTextAnchor075"/>Exercise 24: Fitting a Multiple Linear Regression Model and Determining the Intercept and Coefficients</h3>
			<p>In this exercise, we will continue using the data we prepared in <em class="italics">Exercise 21</em>, <em class="italics">Preparing Data for a Linear Regression Model</em>, to fit a multiple linear regression model to predict the temperature in Celsius from all the features in the data.</p>
			<p>Continuing from Exercise 23, perform the following steps:</p>
			<ol>
				<li value="1">To instantiate a linear regression model, refer to the code here:<p class="snippet">from sklearn.linear_model import LinearRegression</p><p class="snippet">model = LinearRegression()</p></li>
				<li>Fit the model to the training data using this code:<p class="snippet">model.fit(X_train, y_train) </p><div id="_idContainer122" class="IMG---Figure"><img src="Images/C13322_03_10.jpg" alt="Figure 3.10: The output from fitting the multiple linear regression model&#13;&#10;" width="438" height="32"/></div><h6>Figure 3.10: The output from fitting the multiple linear regression model</h6></li>
				<li>Extract the value for the intercept using the following code:<p class="snippet">intercept = model.intercept_</p></li>
				<li>Extract the value for the coefficients as follows:<p class="snippet">coefficients = model.coef_</p></li>
				<li>Now, we can print a message with the formula for predicting temperature in Celsius using the code here:<p class="snippet">print('Temperature = {0:0.2f} + ({1:0.2f} x Humidity) + ({2:0.2f} x Wind Speed) + ({3:0.2f} x Wind Bearing Degrees) + ({4:0.2f} x Visibility) + ({5:0.2f} x Pressure) + ({6:0.2f} x Rain) + ({7:0.2f} x Normal Weather) + ({8:0.2f} x Warm Weather)'.format(intercept,</p><p class="snippet">coefficients[0],</p><p class="snippet">coefficients[1],</p><p class="snippet">coefficients[2],</p><p class="snippet">coefficients[3],</p><p class="snippet">coefficients[4],</p><p class="snippet">coefficients[5],</p><p class="snippet">coefficients[6],</p><p class="snippet">coefficients[7]))</p><p>Our output should look like this:</p><div id="_idContainer123" class="IMG---Figure"><img src="Images/C13322_03_11.jpg" alt="Figure 3.11: A formula to predict temperature in Celsius from humidity using multiple linear regression&#13;&#10;" width="710" height="48"/></div></li>
			</ol>
			<h6> </h6>
			<h6>Figure 3.11: A formula to predict temperature in Celsius from humidity using multiple linear regression</h6>
			<p>Nice job! According to this multiple regression model, a day with 0.78 humidity, 5.0 km/h wind speed, wind direction at 81 degrees clockwise from due north, 3 km of visibility, 1000 millibars of pressure, no rain, and is described as normal, has a predicted temperature in Celsius of 5.72 degrees. Now that we are familiar with extracting the intercept and coefficients of our multiple linear regression model, we can generate predictions and evaluate how the model performs on the test data.</p>
			<h3 id="_idParaDest-72"><a id="_idTextAnchor076"/>Activity 5: Generating Predictions and Evaluating the Performance of a Multiple Linear Regression Model</h3>
			<p>In <em class="italics">Exercise 23</em>, <em class="italics">Generating Predictions and Evaluating the Performance of a Simple Linear Regression Model</em>, we learned how to generate predictions and evaluate the performance of a simple linear regression model using a variety of methods. To reduce the code redundancy, we will evaluate the performance of our multiple linear regression model using the metrics in <em class="italics">step 4</em> of <em class="italics">Exercise 23</em>, and we will determine if the multiple linear regression model performed better or worse in relation to the simple linear regression model.</p>
			<p>Continuing from Exercise 24, perform the following steps:</p>
			<ol>
				<li value="1">Generate predictions on the test data using all the features.</li>
				<li>Plot predictions versus actual using a scatterplot.</li>
				<li>Plot the distribution of the residuals.</li>
				<li>Calculate the metrics for mean absolute error, mean squared error, root mean squared error, and R-squared and put them into a DataFrame.</li>
				<li>Determine if the multiple linear regression model performed better or worse in relation to the simple linear regression model.<h4>Note </h4><p class="callout">The solution for this activity can be found on page 343.</p></li>
			</ol>
			<p>You should find that the multiple linear regression model performed better on every metric relative to the simple linear regression model. Most notably, in the simple linear regression model, only 38.9% of the variance in temperature was described by the model. However, in the multiple linear regression model, 86.6% of the variance in temperature was explained by the combination of features. Additionally, our simple linear regression model predicted temperatures, on average, within ± 6.052 degrees, while our multiple linear regression model predicted temperatures, on average, within ± 2.861 degrees.</p>
			<p>The transparent nature of the intercept and beta coefficients make linear regression models very easy to interpret. In business, it is commonly requested that data scientists explain the effect of a certain feature on an outcome. Thus, linear regression provides metrics allowing a reasonable response to the business inquiry earlier. </p>
			<p>However, much of the time, a problem requires the data scientist to predict an outcome measure that is not continuous, but categorical. For example, in insurance, given certain features of a customer, what is the probability that this customer will not renew their policy? In this case, there is not a linear relationship between the features in the data and the outcome variable, so linear regression will falter. A viable option for conducting regression analysis on a categorical dependent variable is logistic regression.</p>
			<h2 id="_idParaDest-73"><a id="_idTextAnchor077"/>Logistic Regression</h2>
			<p>Logistic regression uses categorical and continuous variables to predict a categorical outcome. When the dependent variable of choice has two categorical outcomes, the analysis is termed binary logistic regression. However, if the outcome variable consists of more than two levels, the analysis is referred to as multinomial logistic regression. For the purposes of this chapter, we will focus our learning on the former.</p>
			<p>When predicting a binary outcome, we do not have a linear relationship between the features and the outcome variable; an assumption of linear regression. Thus, to express a nonlinear relationship in a linear way, we must transform the data using logarithmic transformation. As a result, logistic regression allows us to predict the probability of the binary outcome occurring given the feature(s) in the model.</p>
			<p>For logistic regression with 1 predictor, the logistic regression equation is shown here:</p>
			<div>
				<div id="_idContainer124" class="IMG---Figure">
					<img src="Images/C13322_03_12.jpg" alt="Figure 3.12: Logistic regression formula with 1 predictor&#13;&#10;" width="826" height="87"/>
				</div>
			</div>
			<h6>Figure 3.12: Logistic regression formula with 1 predictor</h6>
			<p>In the preceding figure, <em class="italics">P(Y)</em> is the probability of the outcome occurring, <em class="italics">e</em> is the base of natural logarithms, <em class="italics">α</em> is the intercept, <em class="italics">β</em> is the beta coefficient, and <em class="italics">x</em> is the value of the predictor. This equation can be extended to multiple predictors using the formula here:</p>
			<div>
				<div id="_idContainer125" class="IMG---Figure">
					<img src="Images/C13322_03_13.jpg" alt="Figure 3.13: Logistic regression formula with more than one predictor&#13;&#10;" width="726" height="65"/>
				</div>
			</div>
			<h6>Figure 3.13: Logistic regression formula with more than one predictor</h6>
			<p>Thus, using logistic regression to model the probability of an event occurring is the same as fitting a linear regression model, except the continuous outcome variable has been replaced by the log odds (an alternate way of expressing probabilities) of success for a binary outcome variable. In linear regression, we assumed a linear relationship between the predictor variable(s) and the outcome variable. Logistic regression, on the other hand, assumes a linear relationship between the predictor variable(s) and the natural log of <em class="italics">p/(1-p)</em>, where <em class="italics">p</em> is the probability of the event occurring.</p>
			<p>In the following exercise, we will use the <strong class="inline">weather.csv</strong> dataset to demonstrate building a logistic regression model to predict the probability of rain using all the features in our data.</p>
			<h3 id="_idParaDest-74"><a id="_idTextAnchor078"/>Exercise 25: Fitting a Logistic Regression Model and Determining the Intercept and Coefficients</h3>
			<p>To model the probability of rain (as opposed to snow) using all the features in our data, we will use the <strong class="inline">weather.csv</strong> file and store the dichotomous variable <strong class="inline">Rain</strong> as the outcome measure.</p>
			<ol>
				<li value="1">Import data using the following code:<p class="snippet">import pandas as pd</p><p class="snippet">df = pd.read_csv('weather.csv')</p></li>
				<li>Dummy code the <strong class="inline">Description</strong> variable as follows:<p class="snippet">import pandas as pd</p><p class="snippet">df_dummies = pd.get_dummies(df, drop_first=True)</p></li>
				<li>Shuffle <strong class="inline">df_dummies</strong> using the code here:<p class="snippet">from sklearn.utils import shuffle</p><p class="snippet">df_shuffled = shuffle(df_dummies, random_state=42)</p></li>
				<li>Split the features and outcome into <strong class="inline">X</strong> and <strong class="inline">y</strong>, respectively, as follows:<p class="snippet">DV = 'Rain' </p><p class="snippet">X = df_shuffled.drop(DV, axis=1) </p><p class="snippet">y = df_shuffled[DV] </p></li>
				<li>Split the features and outcome into training and testing data using the code here:<p class="snippet">from sklearn.model_selection import train_test_split</p><p class="snippet">X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)</p></li>
				<li>Instantiate a logistic regression model using this code:<p class="snippet">from sklearn.linear_model import LogisticRegression</p><p class="snippet">model = LogisticRegression()</p></li>
				<li>Fit the logistic regression model to the training data using <strong class="inline">model.fit(X_train, y_train</strong>). We should get the following output:<div id="_idContainer126" class="IMG---Figure"><img src="Images/C13322_03_14.jpg" alt="Figure 3.14: The output from fitting a logistic regression model&#13;&#10;" width="538" height="66"/></div><h6>Figure 3.14: The output from fitting a logistic regression model</h6></li>
				<li>Get the intercept using the following:<p class="snippet">intercept = model.intercept_</p></li>
				<li>Extract the coefficients using the following:<p class="snippet">coefficients = model.coef_</p></li>
				<li>Place the coefficients into a list as follows:<p class="snippet">coef_list = list(coefficients[0,:])</p></li>
				<li>Match features to their coefficients, place them in a DataFrame, and print the DataFrame to the console as follows:<p class="snippet">coef_df = pd.DataFrame({'Feature': list(X_train.columns),</p><p class="snippet">                        'Coefficient': coef_list})</p><p class="snippet">print(coef_df)</p><p>Refer to the resultant output here:</p></li>
			</ol>
			<div>
				<div id="_idContainer127" class="IMG---Figure">
					<img src="Images/C13322_03_15.jpg" alt="Figure 3.15: Features and their coefficients from the logistic regression model&#13;&#10;" width="495" height="137"/>
				</div>
			</div>
			<h6>Figure 3.15: Features and their coefficients from the logistic regression model</h6>
			<p>The coefficient for temperature can be interpreted as for every 1-degree increase in temperature, the log odds of rain increase by 5.69, controlling for all other features in the model. To generate predictions, we could convert the log odds to odds and the odds to probability. However, scikit-learn has functionality to generate predicted probability, as well as predicted classes.</p>
			<h3 id="_idParaDest-75"><a id="_idTextAnchor079"/>Exercise 26: Generating Predictions and Evaluating the Performance of a Logistic Regression Model</h3>
			<p>In <em class="italics">Exercise 25</em>, we learned how to fit a logistic regression model and extract the elements necessary to generate predictions. However, scikit-learn makes our lives much easier by providing us with functions to predict the probability of an outcome, as well as the classes of an outcome. In this exercise, we will learn to generate predicted probabilities and classes, as well as evaluating a model performance using a confusion matrix and a classification report.</p>
			<p>Continuing from Exercise 25, perform the following steps:</p>
			<ol>
				<li value="1">Generate predicted probabilities using the following code:<p class="snippet"><strong class="inline">predicted_prob = model.predict_proba(X_test)[:,1]</strong></p></li>
				<li>Generate predicted classes using the following:<p class="snippet"><strong class="inline">predicted_class = model.predict(X_test)</strong></p></li>
				<li>Evaluate a performance using a confusion matrix as follows:<p class="snippet">from sklearn.metrics import confusion_matrix</p><p class="snippet">import numpy as np</p><p class="snippet">cm = pd.DataFrame(confusion_matrix(y_test, predicted_class))</p><p class="snippet">cm['Total'] = np.sum(cm, axis=1)</p><p class="snippet">cm = cm.append(np.sum(cm, axis=0), ignore_index=True)</p><p class="snippet">cm.columns = ['Predicted No', 'Predicted Yes', 'Total']</p><p class="snippet">cm = cm.set_index([['Actual No', 'Actual Yes', 'Total']])</p><p class="snippet">print(cm)</p><p>Refer to the resultant output here:</p><div id="_idContainer128" class="IMG---Figure"><img src="Images/C13322_03_16.jpg" alt="Figure 3.16: The confusion matrix from our logistic regression model&#13;&#10;" width="509" height="61"/></div><h6>Figure 3.16: The confusion matrix from our logistic regression model</h6><h4>Note</h4><p class="callout">From the confusion matrix, we can see that, of the 383 observations that were not classified as rainy, 377 of them were correctly classified, and of the 2917 observations that were classified as rainy, 2907 of them were correctly classified. To further inspect our model's performance using metrics such as precision, recall, and f1-score, we will generate a classification report.</p></li>
				<li>Generate a classification report using the following code:<p class="snippet">from sklearn.metrics import classification_report</p><p class="snippet">print(classification_report(y_test, predicted_class))</p><p>Refer to the resultant output:</p></li>
			</ol>
			<div>
				<div id="_idContainer129" class="IMG---Figure">
					<img src="Images/C13322_03_17.jpg" alt="Figure 3.17: The classification report generated from our logistic regression model&#13;&#10;" width="472" height="123"/>
				</div>
			</div>
			<h6>Figure 3.17: The classification report generated from our logistic regression model</h6>
			<p>As we can see from our confusion matrix and classification report, our model is performing very well and may be difficult to improve upon. However, machine learning models including logistic regression consist of numerous hyperparameters that can be adjusted to further improve model performance. In the next exercise, we will learn to find the optimal combination of hyperparameters to maximize model performance.</p>
			<h3 id="_idParaDest-76"><a id="_idTextAnchor080"/>Exercise 27: Tuning the Hyperparameters of a Multiple Logistic Regression Model</h3>
			<p>In <em class="italics">step 7</em> of <em class="italics">Exercise 25</em>, we fit a logistic regression model and the subsequent output from that model is displayed in Figure 3.14. Each of those arguments inside the <strong class="inline">LogisticRegression()</strong> function is set to a default hyperparameter. To tune the model, we will use scikit-learn's grid search function, which fits a model for every combination of possible hyperparameter values and determines the value for each hyperparameter resulting in the best model. In this exercise, we will learn how to use grid search to tune models.</p>
			<p>Continuing from <em class="italics">Exercise 26</em>:</p>
			<ol>
				<li value="1">The data has already been prepared for us (see Exercise 26); thus, we can jump right into instantiating a grid of possible hyperparameter values as follows:<p class="snippet">import numpy as np</p><p class="snippet">grid = {'penalty': ['l1', 'l2'],</p><p class="snippet">        'C': np.linspace(1, 10, 10),</p><p class="snippet">        'solver': ['liblinear']}</p></li>
				<li>Instantiate a grid search model to find the model with the greatest <strong class="inline">f1</strong> score (that is, the harmonic average of precision and recall) as follows:<p class="snippet">from sklearn.model_selection import GridSearchCV</p><p class="snippet">from sklearn.linear_model import LogisticRegression</p><p class="snippet">model = GridSearchCV(LogisticRegression(solver='liblinear'), grid, scoring='f1', cv=5)</p></li>
				<li>Fit the model on the training using <strong class="inline">model.fit(X_train, y_train)</strong> (keep in mind, this may take a while) and find the resultant output here:<p class="Normal" lang="en-US" xml:lang="en-US"> </p><div id="_idContainer130" class="IMG---Figure"><img src="Images/C13322_03_18.jpg" alt="Figure 3.18: The output from our logistic regression grid search model&#13;&#10;" width="758" height="138"/></div><h6>Figure 3.18: The output from our logistic regression grid search model</h6></li>
				<li>We can return the optimal combination of hyperparameters as a dictionary as follows:<p class="snippet">best_parameters = model.best_params_</p><p class="snippet">print(best_parameters)</p><p>Refer to the resultant output here:</p></li>
			</ol>
			<h6> </h6>
			<div>
				<div id="_idContainer131" class="IMG---Figure">
					<img src="Images/C13322_03_19.jpg" alt="Figure 3.19: The tuned hyperparameters from our logistic regression grid search model&#13;&#10;" width="549" height="19"/>
				</div>
			</div>
			<h6>Figure 3.19: The tuned hyperparameters from our logistic regression grid search model</h6>
			<p>We have found the combination of hyperparameters that maximizes the <strong class="inline">f1</strong> score. Remember, simply using the default hyperparameters in <em class="italics">Exercise 25</em> resulted in a model that performed very well on the test data. Thus, in the following activity, we will evaluate how the model with tuned hyperparameters performed on the test data.</p>
			<h3 id="_idParaDest-77"><a id="_idTextAnchor081"/>Activity 6: Generating Predictions and Evaluating Performance of a Tuned Logistic Regression Model</h3>
			<p>Once the best combination of hyperparameters has been converged upon, we need to evaluate model performance much like we did in <em class="italics">Exercise 25</em>.</p>
			<p>Continuing from Exercise 27:</p>
			<ol>
				<li value="1">Generate the predicted probabilities of rain.</li>
				<li>Generate the predicted class of rain.</li>
				<li>Evaluate performance with a confusion matrix and store it as a DataFrame.</li>
				<li>Print a classification report.<h4>Note </h4><p class="callout">The solution for this activity can be found on page 346.</p></li>
			</ol>
			<p>By tuning the hyperparameters of the logistic regression model, we were able to improve upon a logistic regression model that was already performing very well. We will continue to expand upon tuning different types of models in the following exercises and activities.</p>
			<h2 id="_idParaDest-78"><a id="_idTextAnchor082"/>Max Margin Classification Using SVMs</h2>
			<p>SVM is an algorithm for supervised learning that solves both classification and regression problems. However, SVM is most commonly used in classification problems, so, for the purposes of this chapter, we will focus on SVM as a binary classifier. The goal of SVM is to determine the best location of a hyperplane that create a class boundary between data points plotted on a multidimensional space. To help clarify this concept, refer to Figure 3.20.</p>
			<div>
				<div id="_idContainer132" class="IMG---Figure">
					<img src="Images/C13322_03_20.jpg" alt="Figure 3.20: Hyperplane (blue) separating the circles from the squares in three dimensions&#13;&#10;" width="1800" height="743"/>
				</div>
			</div>
			<h6>Figure 3.20: Hyperplane (blue) separating the circles from the squares in three dimensions</h6>
			<p>In Figure 3.20, the squares and circles are observations in the same DataFrame that represent different classes. In this figure, the hyperplane is depicted by a semi-transparent blue boundary lying between the circles and squares that separate the observations into two distinct classes. In this example, the observations are said to be linearly separable.</p>
			<p>The location of the hyperplane is determined by finding the position that creates the maximum separation (that is, margin) between the two classes. Thus, this is referred to as the <strong class="keyword">Maximum Margin Hyperplane</strong> (MMH) and improves the likelihood that the points will remain on the correct side of the hyperplane boundary. It is possible to express the MMH using the points from each class that are closest to the MMH. These points are termed support vectors and each class has at least 1. Figure 3.21 visually depicts the support vectors in relation to the MMH in 2 dimensions:</p>
			<div>
				<div id="_idContainer133" class="IMG---Figure">
					<img src="Images/C13322_03_21.jpg" alt="Figure 3.21: Support vectors in relation to the MMH&#13;&#10;" width="1221" height="662"/>
				</div>
			</div>
			<h6>Figure 3.21: Support vectors in relation to the MMH</h6>
			<p>In reality, most data is not linearly separable. In this case, SVM makes use of a slack variable, which creates a soft margin (as opposed to a maximum margin), allowing some observations to fall on the incorrect side of the line. See the following plot:</p>
			<div>
				<div id="_idContainer134" class="IMG---Figure">
					<img src="Images/C13322_03_22.jpg" alt="Figure 3.22: 2 observations (as denoted with grey shading and the Greek letter Χi) fall on the incorrect side of the soft margin line&#13;&#10;" width="868" height="436"/>
				</div>
			</div>
			<h6>Figure 3.22: 2 observations (as denoted with grey shading and the Greek letter Χi) fall on the incorrect side of the soft margin line</h6>
			<p>A cost value is applied to the misclassified data points and, instead of finding the maximum margin, the algorithm minimizes the total cost. As the cost parameter increases, a harder SVM optimization will go for 100% separation and may overfit the training data. Conversely, lower cost parameters emphasize a wider margin and may underfit the training data. Thus, to create SVM models that perform well on the test data, it is important to determine a cost parameter that balances overfitting and underfitting.</p>
			<p>Additionally, data that is not linearly separable can be transformed into a higher-dimension space using the kernel trick. After this mapping to a higher-dimensional space, a nonlinear relationship can appear linear. By transforming the original data, SVM can discover associations not explicitly apparent in the original features. scikit-learn uses the Gaussian RBF kernel by default, but comes equipped with common kernels such as linear, polynomial, and sigmoid as well. In order to maximize the performance of an SVM classifier model, the optimal combination of the kernel and cost function must be determined. Luckily, this can be easily achieved using grid search hyperparameter tuning, as introduced in Exercise 27. In the following exercises and activities, we will learn how this feat is accomplished.</p>
			<h3 id="_idParaDest-79"><a id="_idTextAnchor083"/>Exercise 28: Preparing Data for the Support Vector Classifier (SVC) Model</h3>
			<p>Before fitting an SVM classifier model to predict a binary outcome variable; in this case, rain or snow, we must prepare our data. Since SVM is a black box, meaning the processes between input and output are not explicit, we do not need to worry about interpretability. Thus, we will transform the features in our data into z-scores prior to fitting the model. The following steps will show how to do this:</p>
			<ol>
				<li value="1">Import <strong class="inline">weather.csv</strong> using the following code:<p class="snippet">import pandas as pd</p><p class="snippet">df = pd.read_csv('weather.csv')</p></li>
				<li>Dummy code the categorical feature, <strong class="inline">Description</strong>, as follows:<p class="snippet">import pandas as pd</p><p class="snippet">df_dummies = pd.get_dummies(df, drop_first=True)</p></li>
				<li>Shuffle <strong class="inline">df_dummies</strong> to remove any ordering effects using the code here:<p class="snippet">from sklearn.utils import shuffle</p><p class="snippet">df_shuffled = shuffle(df_dummies, random_state=42)</p></li>
				<li>Split <strong class="inline">df_shuffled</strong> into <strong class="inline">X</strong> and <strong class="inline">y</strong> using the following code:<p class="snippet">DV = 'Rain'</p><p class="snippet">X = df_shuffled.drop(DV, axis=1) </p><p class="snippet">y = df_shuffled[DV]</p></li>
				<li>Split <strong class="inline">X</strong> and <strong class="inline">y</strong> into testing and training data using the code here:<p class="snippet">from sklearn.model_selection import train_test_split</p><p class="snippet">X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)</p></li>
				<li>To prevent any data leakage, scale <strong class="inline">X_train</strong> and <strong class="inline">X_test</strong> by fitting a scaler model to <strong class="inline">X_train</strong> and transforming them to z-scores separately, as follows:<p class="snippet">from sklearn.preprocessing import StandardScaler</p><p class="snippet">model = StandardScaler() </p><p class="snippet">X_train_scaled = model.fit_transform(X_train)</p><p class="snippet">X_test_scaled = model.transform(X_test)</p></li>
			</ol>
			<p>Now that our data has been properly divided into features and outcome variables, split into testing and training data, and scaled separately, we can tune the hyperparameters of our SVC model using a grid search.</p>
			<h3 id="_idParaDest-80"><a id="_idTextAnchor084"/>Exercise 29: Tuning the SVC Model Using Grid Search</h3>
			<p>Previously, we discussed the importance of determining the optimal cost function and kernel for SVM classifier models. In Exercise 27, we learned how to find the optimal combination of hyperparameters using scikit-learn's grid search function. In this exercise, we will demonstrate using grid search to find the best combination of the cost function and kernel.</p>
			<p>Continuing from <em class="italics">Exercise 28</em>:</p>
			<ol>
				<li value="1">Instantiate the grid for which to search using the following code:<p class="snippet">import numpy as np</p><p class="snippet">grid = {'C': np.linspace(1, 10, 10),</p><p class="snippet">        'kernel': ['linear', 'poly', 'rbf', 'sigmoid']}</p></li>
				<li>Instantiate the <strong class="inline">GridSearchCV</strong> model with the <strong class="inline">gamma</strong> hyperparameter set to <strong class="inline">auto</strong> to avoid warnings, and set probability to <strong class="inline">True</strong> so we can extract probability of rain as follows:<p class="snippet">from sklearn.model_selection import GridSearchCV</p><p class="snippet">from sklearn.svm import SVC</p><p class="snippet">model = GridSearchCV(SVC(gamma='auto'), grid, scoring='f1', cv=5)</p></li>
				<li>Fit the grid search model using <strong class="inline">model.fit(X_train_scaled, y_train)</strong>:<div id="_idContainer135" class="IMG---Figure"><img src="Images/C13322_03_23.jpg" alt="Figure 3.23: The output from fitting the SVC grid search model&#13;&#10;" width="830" height="153"/></div><h6>Figure 3.23: The output from fitting the SVC grid search model</h6></li>
				<li>Print the best parameters using the following code:<p class="snippet">best_parameters = model.best_params_</p><p class="snippet">print(best_parameters)</p><p>See the resultant output below:</p></li>
			</ol>
			<div>
				<div id="_idContainer136" class="IMG---Figure">
					<img src="Images/C13322_03_24.jpg" alt="Figure 3.24: Tuned hyperparameters for our SVC grid search model&#13;&#10;" width="565" height="19"/>
				</div>
			</div>
			<h6>Figure 3.24: Tuned hyperparameters for our SVC grid search model</h6>
			<p>Once the optimal combination of hyperparameters has been determined, it is time to generate predictions and subsequently evaluate how our model performed on the unseen test data.</p>
			<h3 id="_idParaDest-81"><a id="_idTextAnchor085"/>Activity 7: Generating Predictions and Evaluating the Performance of the SVC Grid Search Model</h3>
			<p>In previous exercises/activities, we learned to generate predictions and evaluate classifier model performance. In this activity we will, again, evaluate the performance of our model by generating predictions, creating a confusion matrix, and printing a classification report.</p>
			<p>Continuing from Exercise 29:</p>
			<ol>
				<li value="1">Extract the predicted classes.</li>
				<li>Create and print a confusion matrix.</li>
				<li>Generate and print a classification report.<h4>Note </h4><p class="callout">The solution for this activity can be found on page 348.</p></li>
			</ol>
			<p>Here, we demonstrated how to tune the hyperparameters of an SVC model using grid search. After tuning the SVC model, it did not perform as well as the tuned logistic regression model in predicting rain/snow. Additionally, SVC models are a <strong class="bold">black box</strong> in that they do not provide insight into the contribution of features on the outcome measure. In the upcoming <em class="italics">Decision Trees</em> section, we will introduce a different algorithm known as a decision tree, which uses a "<em class="italics">divide and conquer</em>" approach to generate predictions and offers a feature importance attribute for determining the importance of each feature on the outcome.</p>
			<h2 id="_idParaDest-82"><a id="_idTextAnchor086"/>Decision Trees</h2>
			<p>Imagine we are considering changing jobs. We are weighing the pros and cons of prospective job opportunities and, after a few years of being in our current position, we start to realize the things that are important to us. However, not all aspects of a career are of equal importance. In fact, after being in the job for a few years, we decide that the most important aspect of a position is our interest in the projects we will be doing, followed by compensation, then work-related stress, trailed by commute time, and, lastly, benefits. We have just created the scaffolding of a cognitive decision tree. We can go into further detail by saying that we want a job where we are very interested in the allocated projects, paying at least $55k/year, with low work-related stress, a commute of under 30 minutes, and good dental insurance. Creating mental decision trees is a decision-making process we all utilize by nature and is one of the reasons why decision trees are one of the most widely used machine learning algorithms today.</p>
			<p>In machine learning, decision trees use either <em class="italics">gini</em> impurity or <em class="italics">entropy</em> information gain as the criterion to measure the quality of a split. First, the decision tree algorithm determines the feature that maximizes the value indicating quality of a split. This becomes referred to as the root node, as it is the most important feature in the data. In the job offer mentioned earlier, being very interested in the prospective projects would be considered the root node. Taking into consideration the root node, the job opportunities are divided into those with very interesting projects and those without very interesting projects. </p>
			<p>Next, each of these two categories are divided into the next most important feature, given the previous feature(s), and so on and so forth, until the potential jobs are identified as being of interest or not.</p>
			<p>This approach is termed recursive partitioning, or "<em class="italics">divide and conquer</em>", because it continues the process of splitting and subsetting the data until the algorithm determines the subsets in the data as sufficiently homogenous, or:</p>
			<ul>
				<li>Nearly all the observations at the corresponding node have the same class (that is, purity).</li>
				<li>There are no further features in the data for which to split.</li>
				<li>The tree has reached the size limit decided upon a priori.</li>
			</ul>
			<p>For example, if purity is determined by entropy, we must understand that entropy is a measure of randomness within a set of values. Decision trees operate by choosing the splits that minimize entropy (randomness) and, in turn, maximize information gain. Information gain is calculated as the difference in entropy between the split and all other following splits. The total entropy is then computed by taking the sum of the entropy in each partition, weighted by the proportion of observations in the partition. Luckily, scikit-learn provides us with a function that does all of this for us. In the following exercises and activities, we will implement the decision tree classifier model to predict whether it is raining or snowing, using the familiar <strong class="inline">weather.csv</strong> dataset.</p>
			<h3 id="_idParaDest-83"><a id="_idTextAnchor087"/>Activity 8: Preparing Data for a Decision Tree Classifier</h3>
			<p>In this activity, we will prepare our data for a decision tree classifier model. Perform the following steps to complete the activity:</p>
			<ol>
				<li value="1">Import <strong class="inline">weather.csv</strong> and store it as a DataFrame</li>
				<li>Dummy code the multi-level, categorical feature <strong class="inline">Summary</strong></li>
				<li>Shuffle the data to remove any possible order effects</li>
				<li>Split the data into features and outcome</li>
				<li>Further divide the features and outcome into testing and training data</li>
				<li>Scale <strong class="inline">X_train</strong> and <strong class="inline">X_test</strong> using the following code:<p class="snippet">from sklearn.preprocessing import StandardScaler</p><p class="snippet">model = StandardScaler()</p><p class="snippet">X_train_scaled = model.fit_transform(X_train)</p><p class="snippet">X_test_scaled = model.transform(X_test)</p><h4>Note </h4><p class="callout">The solution for this activity can be found on page 349</p></li>
			</ol>
			<p>In the following exercise, we will learn to tune and fit a decision tree classifier model..</p>
			<h3 id="_idParaDest-84"><a id="_idTextAnchor088"/>Exercise 30: Tuning a Decision Tree Classifier Using Grid Search</h3>
			<p>In the current exercise, we will instantiate a hyperparameter space and tune the hyperparameters of a decision tree classifier using a grid search.</p>
			<p>Continuing from <em class="italics">Activity 8</em>, perform the following steps:</p>
			<ol>
				<li value="1">Specify the hyperparameter space as follows:<p class="snippet">import numpy as np</p><p class="snippet">grid = {'criterion': ['gini', 'entropy'],</p><p class="snippet">        'min_weight_fraction_leaf': np.linspace(0.0, 0.5, 10),</p><p class="snippet">        'min_impurity_decrease': np.linspace(0.0, 1.0, 10),</p><p class="snippet">        'class_weight': [None, 'balanced'],</p><p class="snippet">'presort': [True, False]}Instantiate the GridSearchCV model</p></li>
				<li>Instantiate a grid search model using the code here:<p class="snippet">from sklearn.model_selection import GridSearchCV</p><p class="snippet">from sklearn.tree import DecisionTreeClassifier</p><p class="snippet">model = GridSearchCV(DecisionTreeClassifier(), grid, scoring='f1', cv=5)</p></li>
				<li>Fit to the training set using the following:<p class="snippet">model.fit(X_train_scaled, y_train)</p><p>See the resultant output displayed here:</p><p class="Normal" lang="en-US" xml:lang="en-US"> </p><div id="_idContainer137" class="IMG---Figure"><img src="Images/C13322_03_25.jpg" alt="Figure 3.25: The output from fitting our decision tree classifier grid search model&#13;&#10;" width="804" height="226"/></div><h6>Figure 3.25: The output from fitting our decision tree classifier grid search model</h6></li>
				<li>Print the tuned parameters:<p class="snippet">best_parameters = model.best_params_</p><p class="snippet">print(best_parameters)</p><p>See the resultant output below:</p></li>
			</ol>
			<div>
				<div id="_idContainer138" class="IMG---Figure">
					<img src="Images/C13322_03_26.jpg" alt="" width="866" height="18"/>
				</div>
			</div>
			<h6>Figure 3.26: The tuned hyperparameters for our decision tree classifier grid search model</h6>
			<p>We can see from Figure 3.26 that it used <strong class="bold">gini</strong> impurity as the criterion to measure the quality of a split. Further explanations of the hyperparameters are outside the scope of this chapter but can be found in the decision tree classifier scikit-learn documentation.</p>
			<p>Remember, in practice, it is common for decision makers to ask how various features are affecting the predictions. In linear and logistic regression, the intercept and coefficient(s) make model predictions very transparent.</p>
			<h4>Note</h4>
			<p class="callout">Decision trees can also be very easy to interpret, as we can see where the decisions were made, but this requires an installation and proper configuration of Graphviz, as well as unscaled features. </p>
			<p>Instead of plotting the tree in the following exercise, we will explore an attribute found in scitkit-learn's tree-based model algorithms, '<strong class="inline">feature_importances_</strong>', which returns an array containing values of relative feature importance for each feature. It is important to note that this attribute is unavailable from a grid search model. As a result, in the next exercise, we will learn to programmatically extract values from the <strong class="inline">best_parameters</strong> dictionary and re-fit the tuned decision tree model, allowing us to access the attributes provided by the decision tree classifier function.</p>
			<h3 id="_idParaDest-85"><a id="_idTextAnchor089"/>Exercise 31: Programmatically Extracting Tuned Hyperparameters from a Decision Tree Classifier Grid Search Model</h3>
			<p>In the previous exercise, we saved the tuned hyperparameters as key value pairs in the <strong class="inline">best_parameters</strong> dictionary. This allows us to programmatically access the values and assign them to the appropriate hyperparameters of a decision tree classifier model. By fitting the tuned decision tree model, we will be able to access the attributes made available from the scikit-learn decision tree classifier function.</p>
			<p>Continuing from <em class="italics">Exercise 30</em>, perform the following steps:</p>
			<ol>
				<li value="1">Prove that we can access the value for '<strong class="inline">Tree_criterion</strong>' using:<p class="snippet">print(best_parameters['criterion'])</p><p>See the resultant output here:</p><div id="_idContainer139" class="IMG---Figure"><img src="Images/C13322_03_27.jpg" alt="Figure 3.27: The value assigned to the ‘Tree_criterion’ key in the best_parameters dictionary&#13;&#10;" width="376" height="15"/></div><h6>Figure 3.27: The value assigned to the 'Tree_criterion' key in the best_parameters dictionary</h6></li>
				<li>Instantiate decision tree classifier model and assign the values to the corresponding hyperparameters as follows:<p class="snippet">from sklearn.tree import DecisionTreeClassifier</p><p class="snippet">model = DecisionTreeClassifier(class_weight=best_parameters['class_weight'],</p><p class="snippet">                               criterion=best_parameters['criterion'],</p><p class="snippet">                      min_impurity_decrease=best_parameters['min_impurity_decrease'],</p><p class="snippet">               min_weight_fraction_leaf=best_parameters['min_weight_fraction_leaf'],</p><p class="snippet">                               presort=best_parameters['presort'])</p></li>
				<li>Fit the grid search model to the scaled training data using the following:<p class="snippet">model.fit(X_train_scaled, y_train)</p><div id="_idContainer140" class="IMG---Figure"><img src="Images/C13322_03_28.jpg" alt="Figure 3.28: The output from fitting the decision tree classifier model with tuned hyperparameters&#13;&#10;" width="529" height="94"/></div><h6>Figure 3.28: The output from fitting the decision tree classifier model with tuned hyperparameters</h6></li>
				<li>Extract <strong class="inline">feature_importances</strong> attribute using:<p class="snippet">print(model.feature_importances_)</p><p class="snippet">The resultant output is shown below:</p><div id="_idContainer141" class="IMG---Figure"><img src="Images/C13322_03_29.jpg" alt="Figure 3.29: An array of feature importance from our tuned decision tree classifier model&#13;&#10;" width="401" height="16"/></div><h6>Figure 3.29: An array of feature importance from our tuned decision tree classifier model</h6><p>From the array in Figure 3.29, we can see that the first feature completely dominated the other variables in terms of feature importance.</p></li>
				<li>Visualize this using the following code:<p class="snippet">import pandas as pd</p><p class="snippet">import matplotlib.pyplot as plt</p><p class="snippet">df_imp = pd.DataFrame({'Importance': list(model.feature_importances_)}, index=X.columns)</p><p class="snippet">df_imp_sorted = df_imp.sort_values(by=('Importance'), ascending=True)</p><p class="snippet">df_imp_sorted.plot.barh(figsize=(5,5))</p><p class="snippet">plt.title('Relative Feature Importance')</p><p class="snippet">plt.xlabel('Relative Importance')</p><p class="snippet">plt.ylabel('Variable')</p><p class="snippet">plt.legend(loc=4)</p><p class="snippet">plt.show()</p><p>See the resultant output here:</p></li>
			</ol>
			<div>
				<div id="_idContainer142" class="IMG---Figure">
					<img src="Images/C13322_03_30.jpg" alt="Figure 3.30: Feature importance from a tuned decision tree classifier model&#13;&#10;" width="629" height="327"/>
				</div>
			</div>
			<h6>Figure 3.30: Feature importance from a tuned decision tree classifier model</h6>
			<p>It looks like temperature in Celsius was the sole driver in this classification problem. With the outcome measure being <strong class="inline">rain ('Rain'=1)</strong> or <strong class="inline">snow ('Rain'=0)</strong> and the way in which decision trees make split decisions via "<em class="italics">divide and conquer</em>," it makes sense that the algorithm used temperature to determine if there was rainfall or snowfall at the time of measurement. In the upcoming activity, we will evaluate how the model performed.</p>
			<h3 id="_idParaDest-86"><a id="_idTextAnchor090"/>Activity 9: Generating Predictions and Evaluating the Performance of a Decision Tree Classifier Model</h3>
			<p>We have generated predictions and evaluated the model performance in previous exercises and activities. We will be taking the same approach in this activity to evaluate the performance of our tuned decision tree classifier model.</p>
			<p>Continuing from Exercise 31, perform the following steps:</p>
			<ol>
				<li value="1">Generate the predicted probabilities of rain.</li>
				<li>Generate the predicted classes of rain.</li>
				<li>Generate and print a confusion matrix.</li>
				<li>Print a classification report.<h4>Note</h4><p class="callout">The solution for this activity can be found on page 350.</p></li>
			</ol>
			<p>You should find that there was only one misclassified observation. Thus, by tuning a decision tree classifier model on our <strong class="inline">weather.csv</strong> dataset, we were able to predict rain (or snow) with great accuracy. We can see that the sole driving feature was temperature in Celsius. This makes sense due to the way in which decision trees use recursive partitioning to make predictions.</p>
			<p>Sometimes, after evaluation, a single model is a weak learner and does not perform well. However, by combining weak learners, we create a stronger learner. The approach of combining numerous weak learners to create a stronger learner is termed ensemble. Random forest models combine numerous decision tree models to create a stronger ensemble model. Random forests can be used for classification or regression problems.</p>
			<h2 id="_idParaDest-87"><a id="_idTextAnchor091"/>Random Forests</h2>
			<p>As briefly mentioned earlier, random forests are ensembles of decision trees that can be used to solve classification or regression problems. Random forests use a small portion of the data to fit each tree, so they can handle very large datasets, and they are less prone to the "<em class="italics">curse of dimensionality</em>" relative to other algorithms. The curse of dimensionality is a situation in which an abundance of features in the data diminishes the performance of the model. Predictions of the random forest are then determined by combining the predictions of each tree. Like SVM, random forests are a <strong class="bold">black box</strong> with inputs and outputs which cannot be interpreted.</p>
			<p>In the upcoming exercises and activities, we will tune and fit a random forest regressor using grid search to predict the temperature in Celsius. Then, we will evaluate the performance of the model.</p>
			<h3 id="_idParaDest-88"><a id="_idTextAnchor092"/>Exercise 32: Preparing Data for a Random Forest Regressor</h3>
			<p>First, we will prepare the data for the random forest regressor with '<strong class="inline">Temperature_c</strong>' as the dependent variable, just as we did in Exercise 21:</p>
			<ol>
				<li value="1">Import '<strong class="inline">weather.csv</strong>' and save it as <strong class="inline">df</strong> using the following code:<p class="snippet">import pandas as pd</p><p class="snippet">df = pd.read_csv('weather.csv')</p></li>
				<li>Dummy code the multi-class, categorical variable, Description, as follows:<p class="snippet">import pandas as pd</p><p class="snippet">df_dummies = pd.get_dummies(df, drop_first=True)</p></li>
				<li>Remove any possible ordering effects by shuffling <strong class="inline">df_dummies</strong> using the following code:<p class="snippet">from sklearn.utils import shuffle</p><p class="snippet">df_shuffled = shuffle(df_dummies, random_state=42)</p></li>
				<li>Split <strong class="inline">df_shuffled</strong> into <strong class="inline">X</strong> and <strong class="inline">y</strong> using the following code:<p class="snippet">DV = 'Temperature_c'</p><p class="snippet">X = df_shuffled.drop(DV, axis=1)</p><p class="snippet">y = df_shuffled[DV]</p></li>
				<li>Split <strong class="inline">X</strong> and <strong class="inline">y</strong> into testing and training data as follows:<p class="snippet">from sklearn.model_selection import train_test_split</p><p class="snippet">X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)</p></li>
				<li>Scale <strong class="inline">X_train</strong> and <strong class="inline">X_test</strong> using the code here:<p class="snippet">from sklearn.preprocessing import StandardScaler</p><p class="snippet">scaler = StandardScaler()</p><p class="snippet">X_train_scaled = scaler.fit_transform(X_train)</p><p class="snippet">X_test_scaled = scaler.transform(X_test)</p></li>
			</ol>
			<p>Now that we have imported, shuffled, separated our data into features (<strong class="inline">X</strong>) and dependent variable (<strong class="inline">y</strong>), split <strong class="inline">X</strong> and <strong class="inline">y</strong> into testing and training data, and scaled <strong class="inline">X_train</strong> and <strong class="inline">X_test</strong>, we will tune a random forest regressor model using grid search.</p>
			<h3 id="_idParaDest-89"><a id="_idTextAnchor093"/>Activity 10: Tuning a Random Forest Regressor</h3>
			<p>The data has been prepared for inclusion in a random forest regressor. Now, we must set up the hyperparameter space and find the optimal combination of hyperparameters using a grid search.</p>
			<p>Continuing from Exercise 32, perform the following steps:</p>
			<ol>
				<li value="1">Specify the hyperparameter space.</li>
				<li>Instantiate the <strong class="inline">GridSearchCV</strong> model optimizing the explained variance.</li>
				<li>Fit the grid search model to the training set.</li>
				<li>Print the tuned parameters.<h4>Note</h4><p class="callout">The solution for this activity can be found on page 351.</p></li>
			</ol>
			<p>After performing a grid search of our random forest regressor hyperparameters, we need to fit a random forest regressor model with the tuned hyperparameters. We will programmatically extract the values in the <strong class="inline">best_parameters</strong> dictionary and assign them to the corresponding hyperparameters in the random forest regressor function, so we can access the attributes from the random forest regressor function.</p>
			<h3 id="_idParaDest-90"><a id="_idTextAnchor094"/>Exercise 33: Programmatically Extracting Tuned Hyperparameters and Determining Feature Importance from a Random Forest Regressor Grid Search Model</h3>
			<p>By extracting the value from the key-value pairs in the <strong class="inline">best_parameters</strong> dictionary, we eliminate the possibility of manual errors, as well as make our code more automated. In this exercise, we will replicate the steps from <em class="italics">Exercise 31</em>, but will adapt our code for the random forest regressor model.</p>
			<p>Continuing from <em class="italics">Activity 10</em>, perform the following steps:</p>
			<ol>
				<li value="1">Instantiate a random forest regressor model with the values for each key from the <strong class="inline">best_parameters</strong> dictionary assigned to the corresponding hyperparameter:<p class="snippet">from sklearn.ensemble import RandomForestRegressor</p><p class="snippet">model = RandomForestRegressor(criterion=best_parameters['criterion'],</p><p class="snippet">                              max_features=best_parameters['max_features'],</p><p class="snippet">                              min_impurity_decrease=best_parameters['min_impurity_decrease'],</p><p class="snippet">                              bootstrap=best_parameters['bootstrap'],</p><p class="snippet">                              warm_start=best_parameters['warm_start'])</p></li>
				<li>Fit the model on the training data using the following:<p class="snippet"><strong class="inline">model.fit(X_train_scaled, y_train)</strong></p><p>Find the resultant output here:</p><div id="_idContainer143" class="IMG---Figure"><img src="Images/C13322_03_31.jpg" alt="Figure 3.31: The output from fitting the random forest regressor model with tuned hyperparameters&#13;&#10;" width="523" height="92"/></div><h6>Figure 3.31: The output from fitting the random forest regressor model with tuned hyperparameters</h6></li>
				<li>Plot feature importance in descending order using the following code:<p class="snippet">import pandas as pd</p><p class="snippet">import matplotlib.pyplot as plt</p><p class="snippet">df_imp = pd.DataFrame({'Importance': list(model.feature_importances_)}, index=X.columns)</p><p class="snippet">df_imp_sorted = df_imp.sort_values(by=('Importance'), ascending=True)</p><p class="snippet">df_imp_sorted.plot.barh(figsize=(5,5))</p><p class="snippet">plt.title('Relative Feature Importance')</p><p class="snippet">plt.xlabel('Relative Importance')</p><p class="snippet">plt.ylabel('Variable')</p><p class="snippet">plt.legend(loc=4)</p><p class="snippet">plt.show()</p><p>See the resultant output here:</p></li>
			</ol>
			<h6> </h6>
			<div>
				<div id="_idContainer144" class="IMG---Figure">
					<img src="Images/C13322_03_32.jpg" alt="Figure 3.32: Feature importance from a random forest regressor model with tuned hyperparameters&#13;&#10;" width="501" height="328"/>
				</div>
			</div>
			<h6>Figure 3.32: Feature importance from a random forest regressor model with tuned hyperparameters</h6>
			<p>From Figure 3.32, we can see that the '<strong class="inline">Description_Warm</strong>' dummy variable and '<strong class="inline">Humidity</strong>' are the main drivers of temperature in Celsius. Meanwhile, '<strong class="inline">Visibility_km</strong>' and '<strong class="inline">Wind_Bearing_degrees</strong>' have a small effect on the temperature. Let's now check to see how our model performs on the test data.</p>
			<h3 id="_idParaDest-91"><a id="_idTextAnchor095"/>Activity 11: Generating Predictions and Evaluating the Performance of a Tuned Random Forest Regressor Model</h3>
			<p>In <em class="italics">Exercise 23</em> and <em class="italics">Activity 5</em>, we learned to generate predictions and evaluate the performance of regression models that predict a continuous outcome. In this activity, we will be taking the same approach to evaluate the performance of our random forest regressor model to predict temperature in Celsius.</p>
			<p>Continuing from <em class="italics">Exercise 33</em>, perform the following steps:</p>
			<ol>
				<li value="1">Generate predictions on the test data.</li>
				<li>Plot the correlation of predicted and actual values.</li>
				<li>Plot the distribution of residuals.</li>
				<li>Compute metrics, then place them in a DataFrame and print it.<h4>Note</h4><p class="callout">The solution for this activity can be found on page 352.</p></li>
			</ol>
			<p>The random forest regressor mode<a id="_idTextAnchor096"/>l seems to underperform compared to the multiple linear regression, as evidenced by greater MAE, MSE, and RMSE values, as well as less explained variance. Additionally, there was a weaker correlation between the predicted and actual values, and the residuals were further from being normally distributed. Nevertheless, by leveraging ensemble methods using a random forest regressor, we constructed a model that explains 75.8% of the variance in -temperature and predicts temperature in Celsius ± 3.781 degrees.</p>
			<h2 id="_idParaDest-92"><a id="_idTextAnchor097"/>Summary</h2>
			<p>In this chapter, we were introdu<a id="_idTextAnchor098"/>ced to the open source machine learning library for Python, scikit-learn. You learned to preprocess data, as well as how to tune and fit a few different regression and classification algorithms. Lastly, you learned how to quickly and effectively evaluate the performance of classification and regression models. This was a very comprehensive introduction to the scikit-learn library, and the strategies employed here can be applied to building numerous additional algorithms provided by scikit-learn.</p>
			<p>In the next chapter, you will learn about dimensionality reduction and unsupervised learning.</p>
		</div>
	</div></body></html>