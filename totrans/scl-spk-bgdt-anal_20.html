<html><head></head><body>
        <section id="HLGTI1-21aec46d8593429cacea59dbdcd64e1c">

                            <header>
                    </header><h1 class="header-title" id="calibre_pb_0">Accelerating Spark with Alluxio</h1>
                
            
            <article>
                
<div class="book-info-bottom-author-body">"It has become appallingly obvious that our technology has exceeded our humanity."</div>
<p class="cdpalignright">- Albert Einstein</p>
<p class="mce-root">Here, you will learn how to use Alluxio with Spark to accelerate the speed of processing. Alluxio is an open source distributed memory storage system, useful in accelerating the speed of many applications across platforms, including Apache Spark.<br class="title-page-name"/>
<span>In a nutshell, the following topics will be covered throughout this chapter:</span></p>
<ul class="calibre9">
<li class="mce-root1">The need for Alluxio</li>
<li class="mce-root1">Getting started with Alluxio</li>
<li class="mce-root1">Integration with YARN</li>
<li class="mce-root1">Using Alluxio in Spark</li>
</ul>


            </article>

            
        </section>
    

        <section id="HMFE41-21aec46d8593429cacea59dbdcd64e1c">

                            <header>
                    </header><h1 class="header-title" id="calibre_pb_0">The need for Alluxio</h1>
                
            
            <article>
                
<p class="mce-root">We have seen Apache Spark and the various functionalities around Spark core, Streaming, GraphX, Spark SQL, and Spark machine learning. We also looked at many use cases and operations surrounding data manipulations and processing. The key steps in any processing task are data input, data processing, and data output.</p>
<p class="mce-root">Shown here is an illustration of a Spark job:</p>
<div class="cdpaligncenter"><img class="image-border287" src="../images/00323.jpeg"/></div>
<p class="mce-root">As seen here, the input and output of a job are often dependent on slower storage options based on disk, while the processing usually is done using the memory/RAM. Since the memory is 100x faster than disk access, the performance of a job can clearly improve significantly if we can reduce the disk usage and use memory more. It is not necessary or even possible that we do not use any disk at all in any job; rather, we just intend to use memory as much as possible.</p>
<p class="mce-root">As a start, we can try to cache as much data as possible in the memory in order to accelerate the processing using executors. While this might work for some jobs, it's not possible to have so much memory in GBs or TBs for large jobs running in a distributed cluster running Spark. Moreover, even if there is a big cluster for your usage, there will be many users in the environment, thus making it difficult to use so many resources for all jobs.</p>
<p class="mce-root">We know of distributed storage systems such as HDFS, S3, and NFS. Similarly, if we had a distributed memory system, we could use this as a storage system for all the jobs to reduce the I/O needed for a job or intermediate jobs in a pipeline. Alluxio provides exactly that by implementing a distributed in-memory filesystem that can be used by Spark for all input/output needs.</p>


            </article>

            
        </section>
    

        <section id="HNDUM1-21aec46d8593429cacea59dbdcd64e1c">

                            <header>
                    </header><h1 class="header-title" id="calibre_pb_0">Getting started with Alluxio</h1>
                
            
            <article>
                
<p class="mce-root"><span>Alluxio, formerly known as Tachyon, unifies data access and bridges computation frameworks and the underlying storage systems. Alluxio's memory-centric architecture enables data access orders of magnitude faster than the existing solutions. Alluxio is also Hadoop compatible, thus providing seamless integration into the existing infrastructure. The existing data analytics applications, such as Spark and MapReduce programs, can run on top of Alluxio without any code change, which means that the transition time is insignificant with the benefit of better performance:</span></p>
<div class="cdpaligncenter"><img class="image-border288" src="../images/00326.jpeg"/></div>


            </article>

            
        </section>
    

        <section id="HOCF81-21aec46d8593429cacea59dbdcd64e1c">

                            <header>
                    </header><h1 class="header-title" id="calibre_pb_0">Downloading Alluxio</h1>
                
            
            <article>
                
<p class="mce-root">You can download Alluxio by registering your name and email address using the <a href="http://www.alluxio.org/download" class="calibre10">http://www.alluxio.org/download</a> website:</p>
<div class="cdpaligncenter"><img class="image-border289" src="../images/00207.jpeg"/></div>
<p class="mce-root">Alternatively, you can also just go to <a href="http://downloads.alluxio.org/downloads/files" class="calibre10">http://downloads.alluxio.org/downloads/files</a> and download the latest version:</p>
<div class="cdpaligncenter"><img class="image-border290" src="../images/00216.jpeg"/></div>


            </article>

            
        </section>
    

        <section id="HPAVQ1-21aec46d8593429cacea59dbdcd64e1c">

                            <header>
                    </header><h1 class="header-title" id="calibre_pb_0">Installing and running Alluxio locally</h1>
                
            
            <article>
                
<p class="mce-root">We will install and run 1.5.0 locally. You can do the same with any other version. If you downloaded version 1.5.0, you will see a file like <kbd class="calibre11">alluxio-1.5.0-hadoop2.7-bin.tar.gz</kbd>.</p>
<div class="packt_infobox"><br class="calibre23"/>
A prerequisite for Alluxio is to have JDK 7 or higher installed.</div>
<p class="mce-root">Unzip the downloaded <kbd class="calibre11">alluxio-1.5.0-hadoop2.7-bin.tar.gz</kbd> file:</p>
<pre class="calibre19">
<strong class="calibre1">tar -xvzf alluxio-1.5.0-hadoop2.7-bin.tar.gz</strong><br class="title-page-name"/><strong class="calibre1">cd alluxio-1.5.0-hadoop-2.7</strong>
</pre>
<p class="mce-root">Also, if running locally, Alluxio will need an environment variable to properly bind to the host, so run the following command:</p>
<pre class="calibre19">
<strong class="calibre1">export ALLUXIO_MASTER_HOSTNAME=localhost</strong>
</pre>
<p class="mce-root">Format the Alluxio filesystem using the <kbd class="calibre11">/bin/alluxio</kbd> command.</p>
<div class="packt_tip">This step is only required when you run Alluxio for the first time and, when run, all the previously stored data and metadata in the Alluxio filesystem will be erased.</div>
<p class="mce-root">Run the <kbd class="calibre11">/bin/alluxio</kbd> format command to format the filesystem:</p>
<pre class="calibre19">
<strong class="calibre1">falcon:alluxio-1.5.0-hadoop-2.7 salla$ ./bin/alluxio format</strong><br class="title-page-name"/>Waiting for tasks to finish...<br class="title-page-name"/>All tasks finished, please analyze the log at /Users/salla/alluxio-1.5.0-hadoop-2.7/bin/../logs/task.log.<br class="title-page-name"/>Formatting Alluxio Master @ falcon
</pre>
<p class="mce-root">Start the Alluxio filesystem locally:</p>
<pre class="calibre19">
<strong class="calibre1">falcon:alluxio-1.5.0-hadoop-2.7 salla$ ./bin/alluxio-start.sh local</strong><br class="title-page-name"/>Waiting for tasks to finish...<br class="title-page-name"/>All tasks finished, please analyze the log at /Users/salla/alluxio-1.5.0-hadoop-2.7/bin/../logs/task.log.<br class="title-page-name"/>Waiting for tasks to finish...<br class="title-page-name"/>All tasks finished, please analyze the log at /Users/salla/alluxio-1.5.0-hadoop-2.7/bin/../logs/task.log.<br class="title-page-name"/>Killed 0 processes on falcon<br class="title-page-name"/>Killed 0 processes on falcon<br class="title-page-name"/>Starting master @ falcon. Logging to /Users/salla/alluxio-1.5.0-hadoop-2.7/logs<br class="title-page-name"/>Formatting RamFS: ramdisk 2142792 sectors (1gb).<br class="title-page-name"/>Started erase on disk2<br class="title-page-name"/>Unmounting disk<br class="title-page-name"/>Erasing<br class="title-page-name"/>Initialized /dev/rdisk2 as a 1 GB case-insensitive HFS Plus volume<br class="title-page-name"/>Mounting disk<br class="title-page-name"/>Finished erase on disk2 ramdisk<br class="title-page-name"/>Starting worker @ falcon. Logging to /Users/salla/alluxio-1.5.0-hadoop-2.7/logs<br class="title-page-name"/>Starting proxy @ falcon. Logging to /Users/salla/alluxio-1.5.0-hadoop-2.7/logs
</pre>
<p class="mce-root">You can stop Alluxio by using a similar syntax.</p>
<div class="packt_tip">You can stop Alluxio by running <kbd class="calibre22">./bin/alluxio-stop.sh</kbd> local.</div>
<p class="mce-root">Verify that Alluxio is running by running the Alluxio script with the <kbd class="calibre11">runTests</kbd> argument:</p>
<pre class="calibre19">
<strong class="calibre1">falcon:alluxio-1.5.0-hadoop-2.7 salla$ ./bin/alluxio runTests</strong><br class="title-page-name"/>2017-06-11 10:31:13,997 INFO type (MetricsSystem.java:startSinksFromConfig) - Starting sinks with config: {}.<br class="title-page-name"/>2017-06-11 10:31:14,256 INFO type (AbstractClient.java:connect) - Alluxio client (version 1.5.0) is trying to connect with FileSystemMasterClient master @ localhost/127.0.0.1:19998<br class="title-page-name"/>2017-06-11 10:31:14,280 INFO type (AbstractClient.java:connect) - Client registered with FileSystemMasterClient master @ localhost/127.0.0.1:19998<br class="title-page-name"/>runTest Basic CACHE_PROMOTE MUST_CACHE<br class="title-page-name"/>2017-06-11 10:31:14,585 INFO type (AbstractClient.java:connect) - Alluxio client (version 1.5.0) is trying to connect with BlockMasterClient master @ localhost/127.0.0.1:19998<br class="title-page-name"/>2017-06-11 10:31:14,587 INFO type (AbstractClient.java:connect) - Client registered with BlockMasterClient master @ localhost/127.0.0.1:19998<br class="title-page-name"/>2017-06-11 10:31:14,633 INFO type (ThriftClientPool.java:createNewResource) - Created a new thrift client alluxio.thrift.BlockWorkerClientService$Client@36b4cef0<br class="title-page-name"/>2017-06-11 10:31:14,651 INFO type (ThriftClientPool.java:createNewResource) - Created a new thrift client alluxio.thrift.BlockWorkerClientService$Client@4eb7f003<br class="title-page-name"/>2017-06-11 10:31:14,779 INFO type (BasicOperations.java:writeFile) - writeFile to file /default_tests_files/Basic_CACHE_PROMOTE_MUST_CACHE took 411 ms.<br class="title-page-name"/>2017-06-11 10:31:14,852 INFO type (BasicOperations.java:readFile) - readFile file /default_tests_files/Basic_CACHE_PROMOTE_MUST_CACHE took 73 ms.<br class="title-page-name"/>Passed the test!
</pre>
<div class="packt_tip">Refer to <a href="http://www.alluxio.org/docs/master/en/Running-Alluxio-Locally.html" class="calibre21">http://www.alluxio.org/docs/master/en/Running-Alluxio-Locally.html</a> for additional options and details.</div>
<p class="mce-root">You can also use the web UI to look at the Alluxio process by opening a browser and typing in <kbd class="calibre11">http://localhost:19999/</kbd>.</p>


            </article>

            
        </section>
    

        <section id="HQ9GC1-21aec46d8593429cacea59dbdcd64e1c">

                            <header>
                    </header><h1 class="header-title" id="calibre_pb_0">Overview</h1>
                
            
            <article>
                
<p class="mce-root">The <span>Overview</span> tab shows summary information, such as <span>Master Address</span>, <span>Running Workers</span>, <span>Version</span>, and <span>Uptime</span> of the cluster. Also shown is the cluster usage summary, which shows the workers capacity and filesystem <span>UnderFS Capacity</span>. Then, the storage usage summary is also seen, which shows the space capacity and the used space:</p>
<div class="cdpaligncenter"><img class="image-border291" src="../images/00219.jpeg"/></div>


            </article>

            
        </section>
    

        <section id="HR80U1-21aec46d8593429cacea59dbdcd64e1c">

                            <header>
                    </header><h1 class="header-title" id="calibre_pb_0">Browse</h1>
                
            
            <article>
                
<p class="mce-root">The <span>Browse</span> tab allows you to look at the current content of the in-memory filesystem. This tab shows what is in the filesystem, the name of the file, size, and block size, whether we loaded the data into memory, and the ACLs and permissions on the file, specifying who can access it and perform operations such as read and write. You will see all the files managed in Alluxio in the <span>Browse</span> tab:</p>
<div class="cdpaligncenter"><img class="image-border292" src="../images/00225.jpeg"/></div>


            </article>

            
        </section>
    

        <section id="HS6HG1-21aec46d8593429cacea59dbdcd64e1c">

                            <header>
                    </header><h1 class="header-title" id="calibre_pb_0">Configuration</h1>
                
            
            <article>
                
<p class="mce-root">The <span>Configuration</span> tab shows all the configuration parameters used. Some of the most important parameters are the configuration directory used, CPU resources, and memory resource allocations to the master as well as the workers. Also seen are the filesystem name, path, JDK settings, and so on. All these can be overridden to customize Alluxio for your use cases. Any changes here will also need a restart of the cluster:</p>
<div class="cdpaligncenter"><img class="image-border293" src="../images/00231.jpeg"/></div>


            </article>

            
        </section>
    

        <section id="HT5221-21aec46d8593429cacea59dbdcd64e1c">

                            <header>
                    </header><h1 class="header-title" id="calibre_pb_0">Workers</h1>
                
            
            <article>
                
<p class="mce-root">The <strong class="calibre1">Workers</strong> tab simply shows the workers in the Alluxio cluster. This will just show the local machine in our case of local setup, but in a typical cluster of many workers, you will see all the worker nodes along with the state of the node, the worker's capacity, the space used, and the last heartbeat received, which shows whether a worker is alive and participating in the cluster operations or not:</p>
<div class="cdpaligncenter"><img class="image-border294" src="../images/00234.jpeg"/></div>


            </article>

            
        </section>
    

        <section id="HU3IK1-21aec46d8593429cacea59dbdcd64e1c">

                            <header>
                    </header><h1 class="header-title" id="calibre_pb_0">In-Memory Data</h1>
                
            
            <article>
                
<p class="mce-root">The <span>In-Memory Data</span> tab shows the current data in the memory of the Alluxio filesystem. This shows the content in the memory of the cluster memory. Typical information shown for each of the dataset in memory includes the permissions, ownership, creation, and modification times:</p>
<div class="cdpaligncenter"><img class="image-border295" src="../images/00243.jpeg"/></div>


            </article>

            
        </section>
    

        <section id="HV2361-21aec46d8593429cacea59dbdcd64e1c">

                            <header>
                    </header><h1 class="header-title" id="calibre_pb_0">Logs</h1>
                
            
            <article>
                
<p class="mce-root">The <span>Logs</span> tab allows you to look at various log files for debugging and monitoring purpose. You will see the log file named <kbd class="calibre11">master.log</kbd> for the master node, the log file named <kbd class="calibre11">worker.log</kbd> for the worker nodes, <kbd class="calibre11">task.log</kbd>, <kbd class="calibre11">proxy.log</kbd>, and a user log too. Each of the log files grows independently and can be very useful in diagnosing problems or just monitoring the health of the cluster:</p>
<div class="cdpaligncenter"><img class="image-border296" src="../images/00252.jpeg"/></div>


            </article>

            
        </section>
    

        <section id="I00JO1-21aec46d8593429cacea59dbdcd64e1c">

                            <header>
                    </header><h1 class="header-title" id="calibre_pb_0">Metrics</h1>
                
            
            <article>
                
<p class="mce-root">The <span>Metric</span><span>s</span> tab shows metrics useful to monitor the current state of the Alluxio filesystem. The main information here includes the capacity of the master node and the filesystem capacity. Also shown are the counters of various operations, such as logical operations of files created and deleted, and directories created and deleted. Another section shows the RPC invocations that you can use to monitor the <span>CreateFile</span>, <span>DeleteFile</span>, and <span>GetFileBlockInfo</span> operations, among others:</p>
<div class="cdpaligncenter"><img class="image-border31" src="../images/00255.jpeg"/></div>


            </article>

            
        </section>
    

        <section id="I0V4A1-21aec46d8593429cacea59dbdcd64e1c">

                            <header>
                    </header><h1 class="header-title" id="calibre_pb_0">Current features</h1>
                
            
            <article>
                
<p class="mce-root">As seen earlier, Alluxio provides a lot of functionalities to support a high-speed in-memory filesystem, significantly accelerating Spark or many other computing systems. The current release has many features, and some of the main features can be described as in the following list:</p>
<ul class="calibre9">
<li class="mce-root1">
<p class="calibre32"><strong class="calibre1">Flexible file API</strong> provides a Hadoop compatible filesystem, allowing Hadoop MapReduce and Spark to use Alluxio.</p>
</li>
<li class="mce-root1">
<p class="calibre32"><strong class="calibre1">Pluggable under storage</strong> checkpoints in-memory data to the underlying storage system, which supports Amazon S3, Google Cloud Storage, OpenStack Swift, HDFS, and so on.</p>
</li>
<li class="mce-root1">
<p class="calibre32"><strong class="calibre1">Tiered storage</strong> can manage SSDs and HDDs in addition to memory, allowing for larger datasets to be stored in Alluxio.</p>
</li>
<li class="mce-root1">
<p class="calibre32"><strong class="calibre1">Unified namespace</strong> enables effective data management across different storage systems through the mount feature. In addition, transparent naming ensures that filenames and the directory hierarchy for objects created in Alluxio are preserved when persisting these objects to the underlying storage system.</p>
</li>
<li class="mce-root1">
<p class="calibre32"><strong class="calibre1">Lineage</strong> can achieve high throughput writes without compromising fault-tolerance using lineage, where lost output is recovered by reexecuting the jobs that created the output, just like the DAGs in Apache Spark.</p>
</li>
<li class="mce-root1">
<p class="calibre32"><strong class="calibre1">Web UI and command line</strong> allows users to browse the filesystem easily through the web UI. Under the debug mode, administrators can view detailed information of each file, including locations and checkpoint paths. Users can also use <kbd class="calibre11">./bin/alluxio fs</kbd> to interact with Alluxio, for example, copy data in and out of the filesystem.</p>
</li>
</ul>
<div class="packt_tip">Refer to <a href="http://www.alluxio.org/" class="calibre21">http://www.alluxio.org/</a> for the latest features and more up-to-date information.</div>
<p class="mce-root">This is all good enough to get Alluxio started locally. Next, we will see how to integrate with a cluster manager, such as YARN.</p>


            </article>

            
        </section>
    

        <section id="I1TKS1-21aec46d8593429cacea59dbdcd64e1c">

                            <header>
                    </header><h1 class="header-title" id="calibre_pb_0">Integration with YARN</h1>
                
            
            <article>
                
<p class="mce-root">YARN is one of the most used cluster managers, followed by Mesos. If you can recollect from <a href="part0148.html#4D4J81-21aec46d8593429cacea59dbdcd64e1c" class="calibre10">Chapter 5</a>, <em class="calibre8">Tackle Big Data - Spark Comes to The Party</em>, YARN can manage the resources of a Hadoop cluster and allow hundreds of applications to share the cluster resources. We can run long-running Spark jobs to process real-time credit card transactions, for example, using YARN and Spark integration.</p>
<p class="mce-root">However, it is not recommended to try running Alluxio as a YARN application; rather, Alluxio should be run as a standalone cluster alongside YARN. Alluxio should be run alongside YARN so that all the YARN nodes have access to a local Alluxio worker. For YARN and Alluxio to coexist, we must inform YARN of the resources used by Alluxio. For instance, YARN needs to know how much memory and CPU to leave for Alluxio.</p>


            </article>

            
        </section>
    

        <section id="I2S5E1-21aec46d8593429cacea59dbdcd64e1c">

                            <header>
                    </header><h1 class="header-title" id="calibre_pb_0">Alluxio worker memory</h1>
                
            
            <article>
                
<p class="mce-root">The Alluxio worker requires some memory for its JVM process and some memory for its RAM disk; 1 GB is generally fine for the JVM memory since this memory is only used for buffering and metadata.</p>
<p class="mce-root">The RAM disk memory can be configured by setting <kbd class="calibre11">alluxio.worker.memory.size</kbd>.</p>
<div class="packt_tip">Data stored in non-memory tiers, such as SSD or HDD, does not need to be included in the memory-size calculation.</div>


            </article>

            
        </section>
    

        <section id="I3QM01-21aec46d8593429cacea59dbdcd64e1c">

                            <header>
                    </header><h1 class="header-title" id="calibre_pb_0">Alluxio master memory</h1>
                
            
            <article>
                
<p class="mce-root">The Alluxio master stores metadata about every file in Alluxio, so it should be at least 1 GB and up to 32 GB for larger cluster deployment.</p>


            </article>

            
        </section>
    

        <section id="I4P6I1-21aec46d8593429cacea59dbdcd64e1c">

                            <header>
                    </header><h1 class="header-title" id="calibre_pb_0">CPU vcores</h1>
                
            
            <article>
                
<p class="mce-root">Each Alluxio worker should have one vcore as a minimum, and Alluxio master can use at least one and up to four vcores in production deployments.</p>
<p class="mce-root">To inform YARN of the resources to reserve for Alluxio on each node, modify the YARN configuration parameters in <kbd class="calibre11">yarn-site.xml</kbd>.<br class="title-page-name"/>
Change <kbd class="calibre11">yarn.nodemanager.resource.memory-mb</kbd> to reserve some memory for the Alluxio worker.</p>
<div class="packt_tip">After determining how much memory to allocate to Alluxio on the node, subtract this from <kbd class="calibre22">yarn.nodemanager.resource.memory-mb</kbd> and update the parameter with the new value.</div>
<p class="mce-root">Change <kbd class="calibre11">yarn.nodemanager.resource.cpu-vcores</kbd> to reserve CPU vcores for the Alluxio worker.</p>
<div class="packt_tip"><span class="field">After determining how much memory to allocate to Alluxio on the node, subtract this from</span> <span class="field"><kbd class="calibre22">yarn.nodemanager.resource.cpu-vcores</kbd> and update the parameter with the new value.</span></div>
<p class="mce-root">After updating the YARN configuration, restart YARN so that it picks up the changes.</p>


            </article>

            
        </section>
    

        <section id="I5NN41-21aec46d8593429cacea59dbdcd64e1c">

                            <header>
                    </header><h1 class="header-title" id="calibre_pb_0">Using Alluxio with Spark</h1>
                
            
            <article>
                
<p class="mce-root">In order to use Alluxio with Spark, you will need a couple of dependency JARs. This is to enable Spark to connect to the Alluxio filesystem and to read/write data. Once we start Spark with Alluxio integration, most of the Spark code remains exactly the same, with changes only to the reading and writing portions of the code as now you have to use <kbd class="calibre11">alluxio://</kbd> to denote the Alluxio filesystem.</p>
<p class="mce-root">However, once the Alluxio cluster is set up, Spark jobs (executors) will connect to Alluxio master for metadata and the Alluxio workers for the actual data read/write operations.</p>
<p class="mce-root">Shown here is an illustration of an Alluxio cluster used from a Spark job:</p>
<div class="cdpaligncenter"><img class="image-border297" src="../images/00261.jpeg"/></div>
<p class="mce-root">The following are the steps on how to start Spark-shell with Alluxio and run some code:</p>
<p class="mce-root"><strong class="calibre1">Step 1</strong>, Change the directory into the directory where Spark was extracted:</p>
<pre class="calibre19">
<strong class="calibre1">      cd spark-2.2.0-bin-hadoop2.7</strong>
</pre>
<p class="mce-root"><strong class="calibre1">Step 2</strong>, Copy the JARs from Alluxio to Spark:</p>
<pre class="calibre19">
<strong class="calibre1">cp ../alluxio-1.5.0-hadoop-2.7/core/common/target/alluxio-core-common-1.5.0.jar .<br class="title-page-name"/>cp ../alluxio-1.5.0-hadoop-2.7/core/client/hdfs/target/alluxio-core-client-hdfs-1.5.0.jar .<br class="title-page-name"/>cp ../alluxio-1.5.0-hadoop-2.7/core/client/fs/target/alluxio-core-client-fs-1.5.0.jar .<br class="title-page-name"/>cp ../alluxio-1.5.0-hadoop-2.7/core/protobuf/target/alluxio-core-protobuf-1.5.0.jar .<br class="title-page-name"/></strong>
</pre>
<p class="mce-root">Â </p>
<p class="mce-root"><strong class="calibre1">Step 3</strong>, Start Spark-shell with the Alluxio JARs:</p>
<pre class="calibre19">
<strong class="calibre1">./bin/spark-shell --master local[2] --jars alluxio-core-common-1.5.0.jar,alluxio-core-client-fs-1.5.0.jar,alluxio-core-client-hdfs-1.5.0.jar,alluxio-otobuf-1.5.0.jar</strong>
</pre>
<p class="mce-root">Step 4, Copy a sample dataset into the Alluxio filesystem:</p>
<pre class="calibre19">
<strong class="calibre1">$ ./bin/alluxio fs copyFromLocal ../spark-2.1.1-bin-hadoop2.7/Sentiment_Analysis_Dataset10k.csv /Sentiment_Analysis_Dataset10k.csv</strong><br class="title-page-name"/>Copied ../spark-2.1.1-bin-hadoop2.7/Sentiment_Analysis_Dataset10k.csv to /Sentiment_Analysis_Dataset10k.csv
</pre>
<p class="mce-root">You can verify the file in Alluxio using the Browse tab; it is the Sentiment_Analysis_Dataset10k.csv of size 801.29KB file:</p>
<p class="mce-root"><img class="image-border158" src="../images/00053.jpeg"/></p>
<p class="mce-root">Step 4. Access the file with and without Alluxio.</p>
<p class="mce-root">First, set the Alluxio filesystem configuration in the shell:</p>
<pre class="calibre19">
<strong class="calibre1">scala&gt; sc.hadoopConfiguration.set("fs.alluxio.impl", "alluxio.hadoop.FileSystem")</strong>
</pre>
<p class="mce-root">Load the text file from Alluxio:</p>
<pre class="calibre19">
<strong class="calibre1">scala&gt; val alluxioFile = sc.textFile("alluxio://localhost:19998/Sentiment_Analysis_Dataset10k.csv")</strong><br class="title-page-name"/>alluxioFile: org.apache.spark.rdd.RDD[String] = alluxio://localhost:19998/Sentiment_Analysis_Dataset10k.csv MapPartitionsRDD[39] at textFile at &lt;console&gt;:24<br class="title-page-name"/><br class="title-page-name"/><strong class="calibre1">scala&gt; alluxioFile.count</strong><br class="title-page-name"/>res24: Long = 9999
</pre>
<p class="mce-root">Load the same text file from the local filesystem:</p>
<pre class="calibre19">
<strong class="calibre1">scala&gt; val localFile = sc.textFile("Sentiment_Analysis_Dataset10k.csv")</strong><br class="title-page-name"/>localFile: org.apache.spark.rdd.RDD[String] = Sentiment_Analysis_Dataset10k.csv MapPartitionsRDD[41] at textFile at &lt;console&gt;:24<br class="title-page-name"/><br class="title-page-name"/><strong class="calibre1">scala&gt; localFile.count</strong><br class="title-page-name"/>res23: Long = 9999
</pre>
<p class="mce-root">If you can load Alluxio with a lot of data, Alluxio integration will provide greater performance without needing to cache the data. This yields several advantages, including removal of the need to cache large datasets by every user who is using the Spark cluster.</p>


            </article>

            
        </section>
    

        <section id="I6M7M1-21aec46d8593429cacea59dbdcd64e1c">

                            <header>
                    </header><h1 class="header-title" id="calibre_pb_0">Summary</h1>
                
            
            <article>
                
<p class="mce-root">In this appendix, we explored the use of <span>Alluxio</span> as a way of accelerating Spark applications using the in-memory filesystem capabilities of Alluxio. <span>This yields several advantages, including removal of the need to cache large datasets by every user who is using the Spark cluster.</span></p>
<p class="mce-root">In the next appendix, we will explore how to use Apache Zeppelin, a web-based notebook to perform interactive data analysis.</p>


            </article>

            
        </section>
    </body></html>