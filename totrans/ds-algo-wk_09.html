<html><head></head><body><div><h1 class="header-title">Statistics</h1>
                
            
            
                


            

            
        
    </div>



  
<div><h1 class="header-title">Basic concepts</h1>
                
            
            
                
<p class="mce-root"><strong class="calibre8">Notation</strong></p>
<p class="mce-root">A set intersection of two sets, <em class="calibre18">A</em> and <em class="calibre18">B</em>, denoted by <em class="calibre18">A ∩ B</em>, is a subset of A or B that contains all elements that are in both <em class="calibre18">A</em> and <em class="calibre18">B</em>. In other words, <em class="calibre18">A ∩</em> <em class="calibre18">B</em> :<em class="calibre18">= { x :</em> <em class="calibre18">x in A and x in B}</em>.</p>
<p class="mce-root">A set union of two sets, <em class="calibre18">A</em> and B, denoted by <em class="calibre18">A ∪ B</em>, is a set that contains precisely the elements that are in <em class="calibre18">A</em> or in <em class="calibre18">B</em>. In other words, <em class="calibre18">A ∪ B := { x : x in A or x in B}</em>.</p>
<p class="mce-root">A set difference of two sets, <em class="calibre18">A</em> and <em class="calibre18">B</em>, denoted by <em class="calibre18">A – B</em> or <em class="calibre18">A\B</em>, is a subset of <em class="calibre18">A</em> that contains all elements in <em class="calibre18">A</em> that are not in <em class="calibre18">B</em>. In other words, <em class="calibre18">A – B := { x : x in A and x not in B}</em>.</p>
<p class="mce-root">The summation symbol, ∑, represents the sum of all members over the set, for example:</p>
<p class="calibre75"><img src="img/56c8332f-77a9-4a01-b18c-865fdab4ad0d.png" width="2190" height="540" class="calibre76"/></p>
<p class="mce-root"><strong class="calibre8">Definitions and terms</strong></p>
<ul class="calibre14">
<li class="calibre15"><strong class="calibre3">Population</strong>: A set of similar data or items subject to analysis.</li>
<li class="calibre15"><strong class="calibre3">Sample</strong>: A subset of the population.</li>
<li class="calibre15"><strong class="calibre3">Arithmetic mean (average) of a set</strong>: The sum of all the values in the set divided by the size of the set.</li>
<li class="calibre15"><strong class="calibre3">Median</strong>: The middle value in an ordered set, for example, the median of the set <em class="calibre5">{x1, …, x2k+1},</em> where <em class="calibre5">x1 &lt;…&lt; x2k+1</em> is the value <em class="calibre5">xk+1</em>.</li>
<li class="calibre15"><strong class="calibre3">Random variable</strong>: A function from a set of possible outcomes (for example, heads or tails) to a set of values (for example, 0 for heads and 1 for tails).</li>
<li class="calibre15"><strong class="calibre3">Expectation</strong>: An expectation of a random variable is the limit of the average values of the increasing sets of the values given by the random variable.</li>
<li class="calibre15"><strong class="calibre3">Variance</strong>: Measures the dispersion of the population from its mean. Mathematically, the variance of a random variable, <em class="calibre5">X</em>, is the expected value of the square of the difference between the random variable and the mean <em class="calibre5">μ</em> of <em class="calibre5">X</em>, that is,  <img src="img/1756b292-2e96-4c8a-96ea-cb65738957fe.png" width="1850" height="240" class="calibre77"/>.</li>
</ul>
<ul class="calibre14">
<li class="calibre15"><strong class="calibre3">Standard deviation</strong>: The deviation in the random variable, <em class="calibre5">X</em>, is the square root of the variation in the <em class="calibre5">X</em> variable, that is, <img src="img/d13c3d36-c49f-4be8-bcc6-d070ab372d16.png" width="1920" height="220" class="calibre78"/>.</li>
<li class="calibre15"><strong class="calibre3">Correlation</strong>: The measure of the dependency between the random variables. Mathematically, for the random variables <em class="calibre5">X</em> and <em class="calibre5">Y</em>, the correlation is defined as <img src="img/9a5119ff-c88c-44b2-a405-a09dc684cd34.png" width="4600" height="220" class="calibre79"/>.</li>
<li class="calibre15"><strong class="calibre3">Causation</strong>: A dependence relation explaining the occurrence of one phenomenon through the occurrence of another phenomenon. Causation implies correlation, but not vice versa!</li>
<li class="calibre15"><strong class="calibre3">Slope</strong>: The <em class="calibre5">a</em> variable in the linear equation <em class="calibre5">y=a*x+b</em>.</li>
<li class="calibre15"><strong class="calibre3">Intercept</strong>: The <em class="calibre5">b</em> variable in the linear equation <em class="calibre5">y=a*x+b</em>.</li>
</ul>


            

            
        
    </div>



  
<div><h1 class="header-title">Bayesian inference</h1>
                
            
            
                
<p class="mce-root">Let <em class="calibre18">P(A)</em>, and <em class="calibre18">P(B)</em> be the probabilities of <em class="calibre18">A</em> and <em class="calibre18">B</em> respectively. Let <em class="calibre18">P(A|B)</em> be the conditional probability of <em class="calibre18">A</em> given <em class="calibre18">B,</em> and let <em class="calibre18">P(B|A)</em> be the probability of <em class="calibre18">B</em> given <em class="calibre18">A</em>.</p>
<p class="mce-root">Then, Bayes' theorem states the following:</p>
<p class="cdpaligncenter"><em class="calibre18">P(A|B)=(P(B|A) * P(A))/P(B)</em></p>


            

            
        
    </div>



  
<div><h1 class="header-title">Distributions</h1>
                
            
            
                
<p class="mce-root">The probability distribution is a function from a set of possible outcomes (for example, heads and tails) to a set of probabilities of those outcomes (that is, 50% for both heads and tails).</p>


            

            
        
    </div>



  
<div><h1 class="header-title">Normal distribution</h1>
                
            
            
                
<p class="mce-root">Random variables of many natural phenomena are modeled by a normal distribution. A normal distribution has the following probability density:</p>
<p class="cdpaligncenter"><img class="fm-editor-equation218" src="img/c8112696-6cad-400f-b969-7b35bc619a0e.png" width="1800" height="680"/></p>
<div><p class="mce-root">Here, μ is the mean of the distribution and <img class="fm-editor-equation219" src="img/e51a2c42-41d1-49b1-a8a4-6d2873446a0e.png" width="190" height="190"/> is the variation of the distribution. A normal distribution graph has the shape of a bell curve; for example, refer to the following graph of a normal distribution with a mean of 10 and a standard deviation of 2:</p>
<div><img src="img/51a4faaf-3071-444d-a400-dc63d2c52b3a.png" width="700" height="700" class="calibre81"/></div>
<p>Normal distribution with a mean of 10 and a standard deviation of 2</p>


            

            
        
    </div>



  
<div><h1 class="header-title">Cross-validation</h1>
                
            
            
                
<p class="mce-root">Cross-validation is a method of validating a hypothesis about data. At the beginning of the analysis process, the data is split into learning data and testing data. A hypothesis is fit to the learning data, and then its actual error is measured on the testing data. This way, we can estimate how well a hypothesis may perform on future data. Reducing the amount of learning data can also be beneficial as it reduces the chance of hypothesis over-fitting. This is where a hypothesis is trained to a particularly narrow subset of the data.</p>


            

            
        
    </div>



  
<div><h1 class="header-title">K-fold cross-validation</h1>
                
            
            
                
<p class="mce-root">The original data is partitioned randomly into <em class="calibre18">k</em> folds. One fold is used for validation, while <em class="calibre18">k</em>-1 folds of data are used for hypothesis training.</p>


            

            
        
    </div>



  
<div><h1 class="header-title">A/B testing</h1>
                
            
            
                
<p class="mce-root">A/B testing is the validation of two hypotheses about data—usually on real data. Then, the hypothesis with the superior outcome (lower estimation error) is chosen as an estimator for future data.</p>


            

            
        
    </div>



  </body></html>