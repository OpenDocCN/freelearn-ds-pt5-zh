["```py\n!pip install tensorflow\n\n```", "```py\nimport tensorflow as tf\nx_input = tf.placeholder(tf.float32)\ny_output = tf.placeholder(tf.float32)\n```", "```py\neps = 0.01\nW1 = tf.Variable(tf.random_uniform([2,2], -eps, eps))\nW2 = tf.Variable(tf.random_uniform([2,1], -eps, eps))\n```", "```py\nlayer1 = tf.sigmoid(tf.matmul(x_input, W1))\noutput_layer = tf.sigmoid(tf.matmul(layer1, W2))\n```", "```py\ncost = tf.reduce_mean(tf.square(y_output - output_layer))\n```", "```py\ntrain = tf.train.GradientDescentOptimizer(0.05).minimize(cost)\ntraining_data = ([[0,0],[0,1],[1,0],[1,1]], [[0],[1],[1],[0]])\nwith tf.Session() as sess:\n    sess.run(tf.global_variables_initializer())\n    for i in range(5000):\n        sess.run(train,\n            feed_dict={x_input: training_data[0], y_output: training_data[1]})\n```", "```py\nwith tf.Session() as sess:\n    with-block statement with TensorFlow operations\n```", "```py\nimport pixiedust\npixiedust.sampleData()\n```", "```py\nimport pixiedust\ncrimes = pixiedust.sampleData(7, forcePandas=True)\n```", "```py\ndisplay(crimes)\n```", "```py\ndef do_training(train, train_labels, test, test_labels, num_classes):\n    #set TensorFlow logging level to INFO\n    tf.logging.set_verbosity(tf.logging.INFO)\n\n    # Build 2 hidden layer DNN with 10, 10 units respectively.\n    classifier = tf.estimator.DNNClassifier(\n        # Compute feature_columns from dataframe keys using a list comprehension\n        feature_columns =\n            [tf.feature_column.numeric_column(key=key) for key in train.keys()],\n        hidden_units=[10, 10],\n        n_classes=num_classes)\n\n    # Train the Model\n    classifier.train(\n        input_fn=lambda:train_input_fn(train, train_labels,100),\n        steps=1000\n    )\n\n    # Evaluate the model\n    eval_result = classifier.evaluate(\n        input_fn=lambda:eval_input_fn(test, test_labels,100)\n    )\n\n    return (classifier, eval_result)\n```", "```py\ndef input_fn(features, labels, batch_size, train):\n    # Convert the inputs to a Dataset and shuffle.\n    dataset = tf.data.Dataset.from_tensor_slices((dict(features), labels)).shuffle(1000)\n    if train:\n        #repeat only for training\n dataset = dataset.repeat()\n    # Return the dataset in batch\n    return dataset.batch(batch_size)\n\ndef train_input_fn(features, labels, batch_size):\n    return input_fn(features, labels, batch_size, train=True)\n\ndef eval_input_fn(features, labels, batch_size):\n    return input_fn(features, labels, batch_size, train=False)\n```", "```py\n[[SimpleClassificationDNN]]\nfrom pixiedust.display.app import *\n@PixieApp\nclass SimpleClassificationDNN():\n    @route()\n    def main_screen(self):\n        return \"\"\"\n<h1 style=\"margin:40px\">\n    <center>The classificiation model will be trained on all the numeric columns of the dataset</center>\n</h1>\n<style>\n    div.outer-wrapper {\n        display: table;width:100%;height:300px;\n    }\n    div.inner-wrapper {\n        display: table-cell;vertical-align: middle;height: 100%;width: 100%;\n    }\n</style>\n<div class=\"outer-wrapper\">\n    <div class=\"inner-wrapper\">\n        <div class=\"col-sm-3\"></div>\n        <div class=\"input-group col-sm-6\">\n          <select id=\"cols{{prefix}}\" style=\"width:100%;height:30px\" pd_options=\"predictor=$val(cols{{prefix}})\">\n              <option value=\"0\">Select a predictor column</option>\n              {%for col in this.pixieapp_entity.columns.values.tolist()%}\n <option value=\"{{col}}\">{{col}}</option>\n {%endfor%}\n          </select>\n        </div>\n    </div>\n</div>     \n        \"\"\"\n```", "```py\napp = SimpleClassificationDNN()\napp.run(crimes)\n```", "```py\n[[SimpleClassificationDNN]]\n@route(predictor=\"*\")\n@templateArgs\ndef prepare_training(self, predictor):\n        #select only numerical columns\n        self.dataset = self.pixieapp_entity.dropna(axis=1).select_dtypes(\n            include=['int16', 'int32', 'int64', 'float16', 'float32', 'float64']\n        )\n        #Compute the number of classed by counting the groups\n        self.num_classes = self.dataset.groupby(predictor).size().shape[0]\n        #Create the train and test feature and labels\n        self.train_x=self.dataset.sample(frac=0.8)\n        self.full_train = self.train_x.copy()\n        self.train_y = self.train_x.pop(predictor)\n        self.test_x=self.dataset.drop(self.train_x.index)\n        self.full_test = self.test_x.copy()\n        self.test_y=self.test_x.pop(predictor)\n\n        bar_chart_options = {\n          \"rowCount\": \"100\",\n          \"keyFields\": predictor,\n          \"handlerId\": \"barChart\",\n          \"noChartCache\": \"true\"\n        }\n\n        return \"\"\"\n<div class=\"container\" style=\"margin-top:20px\">\n    <div class=\"row\">\n        <div class=\"col-sm-5\">\n            <h3><center>Train set class distribution</center></h3>\n            <div pd_entity=\"full_train\" pd_render_onload>\n                <pd_options>{{bar_chart_options|tojson}}</pd_options>\n            </div>\n        </div>\n        <div class=\"col-sm-5\">\n            <h3><center>Test set class distribution</center></h3>\n            <div pd_entity=\"full_test\" pd_render_onload>\n                <pd_options>{{bar_chart_options|tojson}}</pd_options>\n            </div>\n        </div>\n    </div>\n</div>\n\n<div style=\"text-align:center\">\n <button class=\"btn btn-default\" type=\"submit\" pd_options=\"do_training=true\">\n Start Training\n </button>\n</div>\n\"\"\"\n```", "```py\n[[SimpleClassificationDNN]]\n@route(do_training=\"*\")\n   @captureOutput\ndef do_training_screen(self):\n self.classifier, self.eval_results = \\\n do_training(\nself.train_x, self.train_y, self.test_x, self.test_y, self.num_classes\n )\n        return \"\"\"\n<h2>Training completed successfully</h2>\n<table>\n    <thead>\n        <th>Metric</th>\n        <th>Value</th>\n    </thead>\n    <tbody>\n{%for key,value in this.eval_results.items()%}\n<tr>\n    <td>{{key}}</td>\n    <td>{{value}}</td>\n</tr>\n{%endfor%}\n    </tbody>\n</table>\n        \"\"\"\n```", "```py\napp = SimpleClassificationDNN()\napp.run(crimes)\n```", "```py\nmodels = {\n    \"mobilenet\": {\n        \"base_url\":\"https://github.com/DTAIEB/Thoughtful-Data-Science/raw/master/chapter%206/Visual%20Recognition/mobilenet_v1_0.50_224\",\n        \"model_file_url\": \"frozen_graph.pb\",\n        \"label_file\": \"labels.txt\",\n        \"output_layer\": \"MobilenetV1/Predictions/Softmax\"\n    }\n}\n```", "```py\n# helper method for reading attributes from the model metadata\ndef get_model_attribute(model, key, default_value = None):\n    if key not in model:\n        if default_value is None:\n            raise Exception(\"Require model attribute {} not found\".format(key))\n        return default_value\n    return model[key]\n```", "```py\nimport tensorflow as tf\nimport requests\n# Helper method for resolving url relative to the selected model\ndef get_url(model, path):\n    return model[\"base_url\"] + \"/\" + path\n\n# Download the serialized model and create a TensorFlow graph\ndef load_graph(model):\n    graph = tf.Graph()\n    graph_def = tf.GraphDef()\n    graph_def.ParseFromString(\n        requests.get( get_url( model, model[\"model_file_url\"] ) ).content\n    )\n    with graph.as_default():\n        tf.import_graph_def(graph_def)\n    return graph\n```", "```py\n# Load the labels\ndef load_labels(model, as_json = False):\n    labels = [line.rstrip() \\\n      for line in requests.get(get_url(model, model[\"label_file\"]) ).text.split(\"\\n\") if line != \"\"]\n    if as_json:\n        return [{\"index\": item.split(\":\")[0],\"label\":item.split(\":\")[1]} for item in labels]\n    return labels\n```", "```py\n!pip install beautifulsoup4\n\n```", "```py\nfrom bs4 import BeautifulSoup as BS\nimport re\n\n# return an array of all the images scraped from an html page\ndef get_image_urls(url):\n    # Instantiate a BeautifulSoup parser\n    soup = BS(requests.get(url).text, \"html.parser\")\n\n    # Local helper method for extracting url\n    def extract_url(val):\n        m = re.match(r\"url\\((.*)\\)\", val)\n        val = m.group(1) if m is not None else val\n        return \"http:\" + val if val.startswith(\"//\") else val\n\n    # List comprehension that look for <img> elements and backgroud-image styles\n    return [extract_url(imgtag['src']) for imgtag in soup.find_all('img')] + [ \\\n        extract_url(val.strip()) for key,val in \\\n        [tuple(selector.split(\":\")) for elt in soup.select(\"[style]\") \\\n            for selector in elt[\"style\"].strip(\" ;\").split(\";\")] \\\n            if key.strip().lower()=='background-image' \\\n        ]\n```", "```py\nimport tempfile\ndef download_image(url):\n   response = requests.get(url, stream=True)\n   if response.status_code == 200:\n      with tempfile.NamedTemporaryFile(delete=False) as f:\n for chunk in response.iter_content(2048):\n f.write(chunk)\n         return f.name\n   else:\n      raise Exception(\"Unable to download image: {}\".format(response.status_code))\n```", "```py\n# decode a given image into a tensor\ndef read_tensor_from_image_file(model, file_name):\n    file_reader = tf.read_file(file_name, \"file_reader\")\n    if file_name.endswith(\".png\"):\n        image_reader = tf.image.decode_png(file_reader, channels = 3,name='png_reader')\n    elif file_name.endswith(\".gif\"):\n        image_reader = tf.squeeze(tf.image.decode_gif(file_reader,name='gif_reader'))\n    elif file_name.endswith(\".bmp\"):\n        image_reader = tf.image.decode_bmp(file_reader, name='bmp_reader')\n    else:\n        image_reader = tf.image.decode_jpeg(file_reader, channels = 3, name='jpeg_reader')\n    float_caster = tf.cast(image_reader, tf.float32)\n    dims_expander = tf.expand_dims(float_caster, 0);\n\n    # Read some info from the model metadata, providing default values\n    input_height = get_model_attribute(model, \"input_height\", 224)\n    input_width = get_model_attribute(model, \"input_width\", 224)\n    input_mean = get_model_attribute(model, \"input_mean\", 0)\n    input_std = get_model_attribute(model, \"input_std\", 255)\n\n    resized = tf.image.resize_bilinear(dims_expander, [input_height, input_width])\n    normalized = tf.divide(tf.subtract(resized, [input_mean]), [input_std])\n    sess = tf.Session()\n    result = sess.run(normalized)\n    return result\n```", "```py\nimport numpy as np\n\n# classify an image given its url\ndef score_image(graph, model, url):\n    # Get the input and output layer from the model\n    input_layer = get_model_attribute(model, \"input_layer\", \"input\")\n    output_layer = get_model_attribute(model, \"output_layer\")\n\n    # Download the image and build a tensor from its data\n    t = read_tensor_from_image_file(model, download_image(url))\n\n    # Retrieve the tensors corresponding to the input and output layers\n    input_tensor = graph.get_tensor_by_name(\"import/\" + input_layer + \":0\");\n    output_tensor = graph.get_tensor_by_name(\"import/\" + output_layer + \":0\");\n\n    with tf.Session(graph=graph) as sess:\n        results = sess.run(output_tensor, {input_tensor: t})\n    results = np.squeeze(results)\n    # select the top 5 candidate and match them to the labels\n    top_k = results.argsort()[-5:][::-1]\n labels = load_labels(model)\n return [(labels[i].split(\":\")[1], results[i]) for i in top_k]\n\n```", "```py\nmodel = models['mobilenet']\ngraph = load_graph(model)\nimage_urls = get_image_urls(\"https://www.flickr.com/search/?text=cats\")\nfor url in image_urls:\n    results = score_image(graph, model, url)\n    print(\"Result for {}: \\n\\t{}\".format(url, results))\n```", "```py\nfrom pixiedust.display.app import *\n\n@PixieApp\nclass ScoreImageApp():\n    def setup(self):\n        self.model = models[\"mobilenet\"]\n        self.graph = load_graph( self.model )\n    ...\n```", "```py\n[[ScoreImageApp]]\n@route()\ndef main_screen(self):\n   return \"\"\"\n<style>\n    div.outer-wrapper {\n        display: table;width:100%;height:300px;\n    }\n    div.inner-wrapper {\n        display: table-cell;vertical-align: middle;height: 100%;width: 100%;\n    }\n</style>\n<div class=\"outer-wrapper\">\n    <div class=\"inner-wrapper\">\n        <div class=\"col-sm-3\"></div>\n        <div class=\"input-group col-sm-6\">\n          <input id=\"url{{prefix}}\" type=\"text\" class=\"form-control\"\n              value=\"https://www.flickr.com/search/?text=cats\"\n              placeholder=\"Enter a url that contains images\">\n          <span class=\"input-group-btn\">\n            <button class=\"btn btn-default\" type=\"button\" pd_options=\"image_url=$val(url{{prefix}})\">Go</button>\n          </span>\n        </div>\n    </div>\n</div>\n\"\"\"\n```", "```py\napp = ScoreImageApp()\napp.run()\n```", "```py\n[[ScoreImageApp]]\n@route(image_url=\"*\")\n@templateArgs\ndef do_process_url(self, image_url):\n    image_urls = get_image_urls(image_url)\n    return \"\"\"\n<div>\n{%for url in image_urls%}\n<div style=\"float: left; font-size: 9pt; text-align: center; width: 30%; margin-right: 1%; margin-bottom: 0.5em;\">\n<img src=\"img/{{url}}\" style=\"width: 100%\">\n  <div style=\"display:inline-block\" pd_render_onload pd_options=\"score_url={{url}}\">\n  </div>\n</div>\n{%endfor%}\n<p style=\"clear: both;\">\n</div>\n        \"\"\"\n```", "```py\n[[ScoreImageApp]]\n@route(score_url=\"*\")\n@templateArgs\ndef do_score_url(self, score_url):\n    results = score_image(self.graph, self.model, score_url)\n    return \"\"\"\n<ul style=\"text-align:left\">\n{%for label, confidence in results%}\n<li><b>{{label}}</b>: {{confidence}}</li>\n{%endfor%}\n</ul>\n\"\"\"\n```", "```py\n[[ImageRecoApp]]\nfrom pixiedust.apps.template import TemplateTabbedApp\n@PixieApp\nclass ImageRecoApp(TemplateTabbedApp):\n    def setup(self):\n        self.apps = [\n            {\"title\": \"Score\", \"app_class\": \"ScoreImageApp\"},\n            {\"title\": \"Model\", \"app_class\": \"TensorGraphApp\"},\n            {\"title\": \"Labels\", \"app_class\": \"LabelsApp\"}\n        ]\n        self.model = models[\"mobilenet\"]\n        self.graph = self.load_graph(self.model)\n\napp = ImageRecoApp()\napp.run()\n```", "```py\n@PixieApp\nclass TensorGraphApp():\n    \"\"\"Visualize TensorFlow graph.\"\"\"\n    def setup(self):\n        self.graph = self.parent_pixieapp.graph\n\n    @route()\n    @templateArgs\n    def main_screen(self):\n        strip_def = self.strip_consts(self.graph.as_graph_def())\n        code = \"\"\"\n            <script>\n              function load() {{\n                document.getElementById(\"{id}\").pbtxt = {data};\n              }}\n            </script>\n            <link rel=\"import\" href=\"https://tensorboard.appspot.com/tf-graph-basic.build.html\" onload=load()>\n            <div style=\"height:600px\">\n              <tf-graph-basic id=\"{id}\"></tf-graph-basic>\n            </div>\n        \"\"\".format(data=repr(str(strip_def)), id='graph'+ self.getPrefix()).replace('\"', '&quot;')\n\n        return \"\"\"\n<iframe seamless style=\"width:1200px;height:620px;border:0\" srcdoc=\"{{code}}\"></iframe>\n\"\"\"\n\n    def strip_consts(self, graph_def, max_const_size=32):\n        \"\"\"Strip large constant values from graph_def.\"\"\"\n        strip_def = tf.GraphDef()\n        for n0 in graph_def.node:\n            n = strip_def.node.add() \n            n.MergeFrom(n0)\n            if n.op == 'Const':\n                tensor = n.attr['value'].tensor\n                size = len(tensor.tensor_content)\n                if size > max_const_size:\n                    tensor.tensor_content = \"<stripped {} bytes>\".format(size).encode(\"UTF-8\")\n        return strip_def\n```", "```py\n[[LabelsApp]]\n@PixieApp\nclass LabelsApp():\n    def setup(self):\n        self.labels = self.parent_pixieapp.load_labels(\n            self.parent_pixieapp.model, as_json=True\n        )\n\n    @route()\n    def main_screen(self):\n        return \"\"\"\n<div pd_render_onload pd_entity=\"labels\">\n    <pd_options>\n    {\n        \"table_noschema\": \"true\",\n \"handlerId\": \"tableView\",\n        \"rowCount\": \"10000\"\n    }\n    </pd_options>\n</div>\n        \"\"\"\n```", "```py\nimport pandas\nwnid_to_urls = pandas.read_csv('/Users/dtaieb/Downloads/fall11_urls.txt',\n                sep='\\t', names=[\"wnid\", \"url\"],\n                header=0, error_bad_lines=False,\n                warn_bad_lines=False, encoding=\"ISO-8859-1\")\nwnid_to_urls['wnid'] = wnid_to_urls['wnid'].apply(lambda x: x.split(\"_\")[0])\nwnid_to_urls = wnid_to_urls.dropna()\n\nwnid_to_words = pandas.read_csv('/Users/dtaieb/Downloads/words.txt',\n                sep='\\t', names=[\"wnid\", \"description\"],\n                header=0, error_bad_lines=False,\n                warn_bad_lines=False, encoding=\"ISO-8859-1\")\nwnid_to_words = wnid_to_words.dropna()\n```", "```py\ndef get_url_for_keywords(keywords):\n    results = {}\n    for keyword in keywords:\n        df = wnid_to_words.loc[wnid_to_words['description'] == keyword]\n        row_list = df['wnid'].values.tolist()\n        descriptions = df['description'].values.tolist()\n        if len(row_list) > 0:\n            results[descriptions[0]] = \\\n            wnid_to_urls.loc[wnid_to_urls['wnid'] == \\\n            row_list[0]][\"url\"].values.tolist()\n    return results\n```", "```py\nfrom pixiedust.utils.environment import Environment\nroot_dir = ensure_dir_exists(os.path.join(Environment.pixiedustHome, \"imageRecoApp\")\nimage_dir = root_dir\nimage_dict = get_url_for_keywords([\"apple\", \"orange\", \"pear\", \"banana\"])\nwith open(os.path.join(image_dir, \"retrained_label.txt\"), \"w\") as f_label:\n    for key in image_dict:\n        f_label.write(key + \"\\n\")\n        path = ensure_dir_exists(os.path.join(image_dir, key))\n        count = 0\n        for url in image_dict[key]:\n            download_image_into_dir(url, path)\n            count += 1\n            if count > 500:\n                break;\n```", "```py\n    def add_jpeg_decoding(model):\n        input_height = get_model_attribute(model,\n                       \"input_height\")\n        input_width = get_model_attribute(model, \"input_width\")\n        input_depth = get_model_attribute(model, \"input_depth\")\n        input_mean = get_model_attribute(model, \"input_mean\",\n                     0)\n        input_std = get_model_attribute(model, \"input_std\",\n                    255)\n\n        jpeg_data = tf.placeholder(tf.string,\n                    name='DecodeJPGInput')\n        decoded_image = tf.image.decode_jpeg(jpeg_data,\n                        channels=input_depth)\n        decoded_image_as_float = tf.cast(decoded_image,\n                                 dtype=tf.float32)\n        decoded_image_4d =  tf.expand_dims(\n                           decoded_image_as_float,\n                           0)\n        resize_shape = tf.stack([input_height, input_width])\n        resize_shape_as_int = tf.cast(resize_shape,\n                              dtype=tf.int32)\n        resized_image = tf.image.resize_bilinear(\n                        decoded_image_4d,\n                        resize_shape_as_int)\n        offset_image = tf.subtract(resized_image, input_mean)\n        mul_image = tf.multiply(offset_image, 1.0 / input_std)\n        return jpeg_data, mul_image\n    ```", "```py\n    def run_bottleneck_on_image(sess, image_data,\n        image_data_tensor,decoded_image_tensor,\n        resized_input_tensor,bottleneck_tensor):\n        # First decode the JPEG image, resize it, and rescale the pixel values.\n        resized_input_values = sess.run(decoded_image_tensor,\n            {image_data_tensor: image_data})\n        # Then run it through the recognition network.\n        bottleneck_values = sess.run(\n            bottleneck_tensor,\n            {resized_input_tensor: resized_input_values})\n        bottleneck_values = np.squeeze(bottleneck_values)\n        return bottleneck_values\n    ```", "```py\n              initial_value = tf.truncated_normal(\n                  [bottleneck_tensor_size, class_count],\n                  stddev=0.001)\n                  layer_weights = tf.Variable(\n                      initial_value, name='final_weights')\n        ```", "```py\n              layer_biases = tf.Variable(tf.zeros([class_count]),\n                  name='final_biases')\n        ```", "```py\n              logits = tf.matmul(bottleneck_input, layer_weights) +\n                  layer_biases\n        ```", "```py\n              cross_entropy =\n                  tf.nn.softmax_cross_entropy_with_logits(\n                  labels=ground_truth_input, logits=logits)\n              with tf.name_scope('total'):\n                  cross_entropy_mean = tf.reduce_mean(\n                  cross_entropy)\n        ```", "```py\n              optimizer = tf.train.GradientDescentOptimizer(\n                  learning_rate)\n              train_step = optimizer.minimize(cross_entropy_mean)\n        ```", "```py\n[[TensorGraphApp]]\nreturn \"\"\"\n{%if this.custom_graph%}\n<div style=\"margin-top:10px\" pd_refresh>\n    <pd_script>\nself.graph = self.custom_graph if self.graph is not self.custom_graph else self.parent_pixieapp.graph\n    </pd_script>\n    <span style=\"font-weight:bold\">Select a model to display:</span>\n    <select>\n <option {%if this.graph!=this.custom_graph%}selected{%endif%} value=\"main\">MobileNet</option>\n <option {%if this.graph==this.custom_graph%}selected{%endif%} value=\"custom\">Custom</options>\n    </select>\n{%endif%}\n<iframe seamless style=\"width:1200px;height:620px;border:0\" srcdoc=\"{{code}}\"></iframe>\n\"\"\"\n```", "```py\nwith tf.name_scope('cross_entropy'):\n    cross_entropy = tf.nn.softmax_cross_entropy_with_logits(\n        labels=ground_truth_input, logits=logits)\n    with tf.name_scope('total'):\n        cross_entropy_mean = tf.reduce_mean(cross_entropy)\n\n```", "```py\n[[LabelsApp]]\n@PixieApp\nclass LabelsApp():\n    def setup(self):\n        ...\n\n    @route()\n    def main_screen(self):\n        return \"\"\"\n{%if this.custom_labels%}\n<div style=\"margin-top:10px\" pd_refresh>\n    <pd_script>\nself.current_labels = self.custom_labels if self.current_labels is not self.custom_labels else self.labels\n    </pd_script>\n    <span style=\"font-weight:bold\">\n        Select a model to display:</span>\n    <select>\n        <option {%if this.current_labels!=this.labels%}selected{%endif%} value=\"main\">MobileNet</option>\n        <option {%if this.current_labels==this.custom_labels%}selected{%endif%} value=\"custom\">Custom</options>\n    </select>\n{%endif%}\n<div pd_render_onload pd_entity=\"current_labels\">\n    <pd_options>\n    {\n        \"table_noschema\": \"true\",\n        \"handlerId\": \"tableView\",\n        \"rowCount\": \"10000\",\n        \"noChartCache\": \"true\"\n\n    }\n    </pd_options>\n</div>\n        \"\"\"\n```", "```py\n# classify an image given its url\ndef score_image(graph, model, url):\n    # Download the image and build a tensor from its data\n    t = read_tensor_from_image_file(model, download_image(url))\n\n    def do_score_image(graph, output_layer, labels):\n        # Retrieve the tensors corresponding to the input and output layers\n        input_tensor = graph.get_tensor_by_name(\"import/\" +\n            input_layer + \":0\");\n        output_tensor = graph.get_tensor_by_name( output_layer +\n            \":0\");\n\n        with tf.Session(graph=graph) as sess:\n            # Initialize the variables\n            sess.run(tf.global_variables_initializer())\n            results = sess.run(output_tensor, {input_tensor: t})\n        results = np.squeeze(results)\n        # select the top 5 candidates and match them to the labels\n        top_k = results.argsort()[-5:][::-1]\n        return [(labels[i].split(\":\")[1], results[i]) for i in top_k]\n\n    results = {}\n    input_layer = get_model_attribute(model, \"input_layer\",\n        \"input\")\n    labels = load_labels(model)\n    results[\"mobilenet\"] = do_score_image(graph, \"import/\" +\n        get_model_attribute(model, \"output_layer\"), labels)\n    if \"custom_graph\" in model and \"custom_labels\" in model:\n        with open(model[\"custom_labels\"]) as f:\n            labels = [line.rstrip() for line in f.readlines() if line != \"\"]\n            custom_labels = [\"{}:{}\".format(i, label) for i,label in zip(range(len(labels)), labels)]\n        results[\"custom\"] = do_score_image(model[\"custom_graph\"],\n            \"final_result\", custom_labels)\n    return results\n```", "```py\n@route(score_url=\"*\")\n@templateArgs\ndef do_score_url(self, score_url):\n    scores_dict = score_image(self.graph, self.model, score_url)\n    return \"\"\"\n{%for model, results in scores_dict.items()%}\n<div style=\"font-weight:bold\">{{model}}</div>\n<ul style=\"text-align:left\">\n{%for label, confidence in results%}\n<li><b>{{label}}</b>: {{confidence}}</li>\n{%endfor%}\n</ul>\n{%endfor%}\n    \"\"\"\n```"]