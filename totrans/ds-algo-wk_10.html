<html><head></head><body><div id="sbo-rt-content" class="calibre1"><section class="calibre2">

                            <header class="calibre2">
                    <h1 class="header-title">Glossary of Algorithms and Methods in Data Science</h1>
                </header>
            
            <article class="calibre2">
                
<ul class="calibre14">
<li class="calibre15"><strong class="calibre3"><em class="calibre5">k</em>-nearest neighbors algorithm</strong>: An algorithm that estimates an unknown data item as being like the majority of the<span class="calibre4"> </span><em class="calibre5">k</em>-closest neighbors to that item.</li>
<li class="calibre15"><strong class="calibre3">Naive Bayes classifier</strong>: A way to classify a data item using Bayes' theorem concerning the conditional probabilities <em class="calibre5">P(A|B)=(P(B|A) * P(A))/P(B)</em>. It also assumes that variables in the data are independent, which means that no variable affects the probability of the remaining variables attaining a certain value.</li>
<li class="calibre15"><strong class="calibre3">Decision tree</strong>: A model classifying a data item into one of the classes at the leaf node, based on matching properties between the branches on the tree and the actual data item.</li>
<li class="calibre15"><strong class="calibre3">Random decision tree</strong>: A decision tree in which every branch is formed using only a random subset of the available variables during its construction.</li>
<li class="calibre15"><strong class="calibre3">Random forest</strong>: An ensemble of random decision trees constructed on a random subset of the data with replacement, where a data item is<span class="calibre4"> </span>classified<span class="calibre4"> </span>to the class with the majority vote from its trees.</li>
<li class="calibre15"><strong class="calibre3"><em class="calibre5">K</em>-means algorithm</strong>: The clustering algorithm that divides a dataset into<span class="calibre4"> </span><em class="calibre5">k</em><span class="calibre4"> </span>groups such that the members in each group are as similar as possible, that is, closest to one another.</li>
<li class="calibre15"><strong class="calibre3">Regression analysis</strong>: A method for estimating the unknown parameters in a functional model that predicts the output variable from the input variables, for example, to estimate<span class="calibre4"> </span><em class="calibre5">a</em><span class="calibre4"> </span>and<span class="calibre4"> </span><em class="calibre5">b</em><span class="calibre4"> </span>in the linear model<span class="calibre4"> </span><em class="calibre5">y=a*x+b</em>.</li>
<li class="calibre15"><strong class="calibre3">Time series analysis</strong>: The analysis of data dependent on time; it mainly includes the analysis of trends and seasonality.</li>
<li class="calibre15"><strong class="calibre3">Support vector machines</strong>: A classification algorithm that finds the hyperplane dividing the training data into given classes. This division by the hyperplane is then used to classify the data further.</li>
<li class="calibre15"><strong class="calibre3">Principal component analysis</strong>: The preprocessing of individual components of given data in order to achieve better accuracy, for example, rescaling of the variables in the input vector depending on how much impact they have on the end result.</li>
</ul>
<ul class="calibre14">
<li class="calibre15"><strong class="calibre3">Text mining</strong>: The search and extraction of text, and its possible conversion to numerical data that is used for data analysis.</li>
<li class="calibre15"><strong class="calibre3">Neural networks</strong>: A machine learning algorithm consisting of a network of simple classifiers that make decisions based on the input or the results of the other classifiers in the network.</li>
<li class="calibre15"><strong class="calibre3">Deep learning</strong>: The ability of a neural network to improve its learning process.</li>
<li class="calibre15"><strong class="calibre3"><em class="calibre5">A priori</em><span class="calibre4"> </span>association rules</strong>: The rules that can be observed in training data and, on the basis of which, a classification of the future data can be made.</li>
<li class="calibre15"><strong class="calibre3">PageRank</strong>: A search algorithm that assigns the greatest relevance to the search result that has the greatest number of incoming web links from the most relevant search results for a given search term. In mathematical terms, PageRank calculates a certain eigenvector representing these measures of relevance.</li>
<li class="calibre15"><strong class="calibre3">Ensemble learning</strong>: A method of learning where different learning algorithms are used to reach a final conclusion.</li>
<li class="calibre15"><strong class="calibre3">Bagging</strong>: A method of classifying a data item by the majority vote of the classifiers trained on random subsets of the training data.</li>
<li class="calibre15"><strong class="calibre3">Genetic algorithms</strong>: Machine learning algorithms inspired by genetic processes, for example, an evolution where classifiers with the greatest accuracy are trained further.</li>
<li class="calibre15"><strong class="calibre3">Inductive inference</strong>: A machine learning method for learning the rules that produced the actual data.</li>
<li class="calibre15"><strong class="calibre3">Bayesian networks</strong>: A graph model representing random variables with their conditional dependencies.</li>
<li class="calibre15"><strong class="calibre3">Singular value decomposition</strong>: The factorization of a matrix, a generalization of<span class="calibre4"> </span>eigendecomposition, used in the least squares methods.</li>
<li class="calibre15"><strong class="calibre3">Boosting</strong>: A machine learning meta-algorithm that decreases the variance in an estimation by making a prediction based on the ensembles of the classifiers.</li>
<li class="calibre15"><strong class="calibre3">Expectation maximization</strong>: An iterative method for searching the parameters in the model that maximize the accuracy of the prediction of the model.</li>
</ul>


            </article>

            
        </section>
    </div>



  </body></html>