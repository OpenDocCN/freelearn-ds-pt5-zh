<html><head></head><body>
        <section>

                            <header>
                    <h1 class="header-title">Healthcare Predictive Models – A Review</h1>
                </header>
            
            <article>
                
<p>This chapter is intended for all audiences and marries the traditional risk score model commonly used in healthcare with the theory and features underlying machine learning models similar to those developed in <a href="d029d858-9c6e-4bf0-b793-87cdc4395e86.xhtml" target="_blank">Chapter 7</a>, <em>Making Predictive Models in Healthcare</em>. If you come from a data science background, this chapter will be a good introduction to some of the widely used clinical risk scores and will indicate which features should be included in your models, whether general or disease-specific. If you come from a healthcare background, this chapter will be a review of some of the clinical risk scores and will explain how machine learning algorithms can enhance traditional risk assessment.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Predictive healthcare analytics – state of the art</h1>
                </header>
            
            <article>
                
<p>As we touched upon in <a href="46c83498-cb6e-45b4-ac39-6875a8d32400.xhtml" target="_blank">Chapter 3</a>, <em>Machine Learning Foundations</em>, healthcare is no stranger to complex risk factor assessments. For almost every major disease, one can find several risk-scoring models that are used widely by physicians to assess the risk of having a disease or suffering morbidity/mortality from that disease. When we use the term "risk score," we are largely referring to criterion tables, in which risk factors are allotted point values, and the points for all of the risk factors are summed to give an overall risk based on the total. These scoring systems are used widely in medicine; interestingly, many of them are based on research involving logistic regression models (similar to the one developed in <a href="d029d858-9c6e-4bf0-b793-87cdc4395e86.xhtml" target="_blank">Chapter 7</a>, <em>Making Predictive Models in Healthcare</em>). The crucial question of the last several decades is whether machine learning can improve our ability to predict whether an individual has or will have a disease, how much care that disease will require, and whether the patient will die from the disease in a certain time period.</p>
<p>That question is addressed in this chapter. We organize this chapter by having sections on several leading causes of morbidity and mortality in developed countries for which risk scores have been developed. The covered entities include overall cardiovascular risk, congestive heart failure, cancer, and all-cause readmission. The first three entities are leading causes of mortality, and the fourth entity is a common way to measure quality in healthcare. We then explore the subsequent machine learning literature to see whether machine learning has improved the traditional risk assessment used for that disease. By the end of this chapter, you should have a thorough understanding of how machine learning can be used to improve disease prediction.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Overall cardiovascular risk</h1>
                </header>
            
            <article>
                
<p>We start with overall cardiovascular risk assessment since it is one of the most important areas in personal health and the exploration of cardiovascular risk factors has such a long and storied history.</p>
<p>Cardiovascular risk refers to the risk of developing a subset of the cardiac disease known as cardiovascular disease. <strong>Cardiovascular disease</strong> (<strong>CVD</strong>) refers to dysfunction of the circulatory system caused by a narrowing and/or clogging of the arteries that supply blood to tissues, a process known as atherosclerosis. It encompasses a broad set of cardiac diseases, which include the following:</p>
<ul>
<li><strong>Coronary artery disease</strong> (<strong>CAD</strong>): This occurs when the blood vessels that supply blood to the heart become narrowed due to atherosclerosis. CAD is deadly because it can lead to sudden occlusion of the coronary arteries, which is known as a myocardial infarction (or a heart attack).</li>
<li><strong>Congestive heart failure</strong> (<strong>CHF</strong>): This is the failure of the heart to pump blood to the rest of the body. It is caused by the long-term effects of CAD on the heart. It has an onset that is more gradual than myocardial infarction, however, its course is often characterized by sudden exacerbations and hospitalizations before ultimately leading to death.</li>
<li><strong>Peripheral vascular disease</strong> (<strong>PVD</strong>): This is when arteries that supply blood to the arms or legs become narrowed and occluded, which can lead to problematic symptoms such as pain (known as <strong>claudication</strong>) and may result in amputations.</li>
<li><strong>Cerebrovascular disease</strong>, or atherosclerosis of the vessels supplying the brain: This puts individuals at higher risk for ischemic and hemorrhagic stroke. Stroke is when the blood supply to the brain is cut off, which can lead to death and also can lead to devastating sequelae.</li>
</ul>
<p class="mce-root"/>
<p>Now that you know what CVD is, you should also know its devastating effects on humans. Globally, it is the leading cause of morbidity and mortality (Weng et al., 2017). CHF alone is related to 3-5% of hospital admissions and is the leading cause of hospital admissions for healthcare professionals and accounts for up to 2% of total healthcare expenditures in developed countries (Tripoliti et al., 2016).</p>
<p>Although CVD had been a prominent cause of disability and death in the United States since the beginning of the twentieth century, in the 1940s, people still had no idea what caused it. In fact, during that time, little was understood about the risk and prevention of CVDs (and disease in general). At the time, it was believed that CVD was the destiny of whomever it affected, independent of lifestyle decisions.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">The Framingham Risk Score</h1>
                </header>
            
            <article>
                
<p>In 1948, the National Heart Institute embarked on an ambitious project in conjunction with Boston University, called the Framingham Heart Study. Its goal: to find which factors cause CVD. In 1948, 5,209 men and women were recruited from the town of Framingham, Massachusetts that had not yet been affected visibly by CVD (Framingham Heart Study, 2018a). Every 2 years, these individuals underwent a detailed medical history, physical examination, and laboratory testing. Over the years, new generations of patients were recruited and subjects have continued to return every 2 years for assessment, until today.</p>
<p>It was through this long-term, prospective study that the risk factors for CVD were first identified. The link between smoking and CVD was first reported in 1960 (Framingham Heart Study, 2018b). After that, cholesterol, high blood pressure, and diabetes were eventually linked to CVD as well. Starting in the 1990s, risk scores for developing specific types of CVD (for example, myocardial infarction, PVD, CHF) began being published. In 2008, the general Framingham Risk Score was published. The Framingham Risk Score assigns individuals a risk score for experiencing CVD events within a 10-year period based on five major CVD risk factors: age, high blood pressure, cholesterol levels, smoking status, and diabetes. The following is a summary of the general cardiovascular risk-scoring criteria for women (D'Agostino et al., 2008).</p>
<p class="mce-root"/>
<p>Men have similar criteria with slightly different point values:</p>
<table border="1" style="border-collapse: collapse;width: 100%">
<tbody>
<tr>
<td><strong>Points</strong></td>
<td><strong>Age (y)</strong></td>
<td><strong>HDL cholesterol</strong></td>
<td><strong>Total cholesterol</strong></td>
<td><strong>SBP not treated</strong></td>
<td><strong>SBP treated</strong></td>
<td><strong>Smoker</strong></td>
<td><strong>Diabetic</strong></td>
</tr>
<tr>
<td>-3</td>
<td/>
<td/>
<td/>
<td>&lt;120</td>
<td/>
<td/>
<td/>
</tr>
<tr>
<td>-2</td>
<td/>
<td>60+</td>
<td/>
<td/>
<td/>
<td/>
<td/>
</tr>
<tr>
<td>-1</td>
<td/>
<td>50-59</td>
<td/>
<td/>
<td>&lt;120</td>
<td/>
<td/>
</tr>
<tr>
<td>0</td>
<td>30-34</td>
<td>45-49</td>
<td>&lt;160</td>
<td>120-129</td>
<td/>
<td>No</td>
<td>No</td>
</tr>
<tr>
<td>1</td>
<td/>
<td>35-44</td>
<td>160-190</td>
<td>130-139</td>
<td/>
<td/>
<td/>
</tr>
<tr>
<td>2</td>
<td>35-39</td>
<td>&lt;35</td>
<td/>
<td>140-149</td>
<td>120-129</td>
<td/>
<td/>
</tr>
<tr>
<td>3</td>
<td/>
<td/>
<td>200-239</td>
<td/>
<td>130-139</td>
<td>Yes</td>
<td/>
</tr>
<tr>
<td>4</td>
<td>40-44</td>
<td/>
<td>240-279</td>
<td>150-159</td>
<td/>
<td/>
<td>Yes</td>
</tr>
<tr>
<td>5</td>
<td>45-49</td>
<td/>
<td>280+</td>
<td>160+</td>
<td>140-149</td>
<td/>
<td/>
</tr>
<tr>
<td>6</td>
<td/>
<td/>
<td/>
<td/>
<td>150-159</td>
<td/>
<td/>
</tr>
<tr>
<td>7</td>
<td>50-54</td>
<td/>
<td/>
<td/>
<td>160+</td>
<td/>
<td/>
</tr>
<tr>
<td>8</td>
<td>55-59</td>
<td/>
<td/>
<td/>
<td/>
<td/>
<td/>
</tr>
<tr>
<td>9</td>
<td>60-64</td>
<td/>
<td/>
<td/>
<td/>
<td/>
<td/>
</tr>
<tr>
<td>10</td>
<td>65-69</td>
<td/>
<td/>
<td/>
<td/>
<td/>
<td/>
</tr>
<tr>
<td>11</td>
<td>70-74</td>
<td/>
<td/>
<td/>
<td/>
<td/>
<td/>
</tr>
<tr>
<td>12</td>
<td>75+</td>
<td/>
<td/>
<td/>
<td/>
<td/>
<td/>
</tr>
</tbody>
</table>
<p> </p>
<p>Today, these same five risk factors (four of them being preventable) are continuously expounded by our doctors when we visit their offices.</p>
<p>To calculate the total score, the values for each of the six risk factors (age, HDL level, total cholesterol, SBP not treated, SBP treated, smoker, diabetic) are added. The following table shows how point values correspond to 10-year risk scores (D'Agostino et al., 2008):</p>
<table border="1" style="border-collapse: collapse;width: 100%">
<tbody>
<tr>
<td>Points</td>
<td>Risk (%)</td>
<td>Points</td>
<td>Risk (%)</td>
<td>Points</td>
<td>Risk (%)</td>
</tr>
<tr>
<td>&lt;-2</td>
<td>&lt;1</td>
<td>6</td>
<td>3.3</td>
<td>14</td>
<td>11.7</td>
</tr>
<tr>
<td>-1</td>
<td>1.0</td>
<td>7</td>
<td>3.9</td>
<td>15</td>
<td>13.7</td>
</tr>
<tr>
<td>0</td>
<td>1.2</td>
<td>8</td>
<td>4.5</td>
<td>16</td>
<td>15.9</td>
</tr>
<tr>
<td>1</td>
<td>1.5</td>
<td>9</td>
<td>5.3</td>
<td>17</td>
<td>18.5</td>
</tr>
<tr>
<td>2</td>
<td>1.7</td>
<td>10</td>
<td>6.3</td>
<td>18</td>
<td>21.5</td>
</tr>
<tr>
<td>3</td>
<td>2.0</td>
<td>11</td>
<td>7.3</td>
<td>19</td>
<td>24.8</td>
</tr>
<tr>
<td>4</td>
<td>2.4</td>
<td>12</td>
<td>8.6</td>
<td>20</td>
<td>28.5</td>
</tr>
<tr>
<td>5</td>
<td>2.8</td>
<td>13</td>
<td>10.0</td>
<td>21 +</td>
<td>&gt; 30</td>
</tr>
</tbody>
</table>
<p> </p>
<p class="mce-root"/>
<p>You may be wondering, "What is the method behind the madness?" To develop these scores, the study's authors used the Cox proportional hazards regression, which is similar to logistic regression, except that instead of determining how variables are associated with a binary outcome, it determines how variables are related to the quantity of time before an event occurs. They even calculated the <em>C</em>-statistic of their risk score (analogous to the area under the curve, discussed in <a href="46c83498-cb6e-45b4-ac39-6875a8d32400.xhtml" target="_blank">Chapter 3</a>, <em>Machine Learning Foundations</em>) which was 0.76 to 0.79. This is a very good score that can be obtained just from a patient history, physical examination, and some simple blood tests.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Cardiovascular risk and machine learning</h1>
                </header>
            
            <article>
                
<p>As you know, scientific progress is never complacent. When a result is obtained, it is only a matter of time before people begin wondering how to improve upon it. The same is the case with cardiovascular risk assessment. Key questions that were asked include the following:</p>
<ul>
<li>What are some other risk factors that are as (or even more) important than the five risk factors in the Framingham Risk Score?</li>
<li>Can the newer machine learning algorithms outperform statistical models, such as regression, to yield higher discriminability and performance?</li>
</ul>
<p>One study, by the University of Nottingham in England, addressed those questions (Weng et al., 2017). It was a prospective study that monitored the electronic medical records of 378,256 patients from the year 2005 to 2015. For each patient, they used data on the 8 risk factors included in the Framingham Risk Score, as well as 22 additional variables that were thought to be correlated with cardiovascular risk from previous literature and consultation with physicians. The 22 additional variables encompassed information such as socioeconomic status; history of other illnesses including kidney disease, arthritis, and atrial fibrillation; newer lab tests such as C-reactive protein and gamma-glutamyl transferase; and ethnicity. They trained four types of machine learning algorithms on the patient data <span>– </span>logistic regression, random forest, neural networks, and gradient-boosting machines. All four of the algorithms improved performance over the baseline risk prediction algorithm; in fact, the neural network algorithm predicted 355 more correct cases of cardiovascular events than the established algorithm. As they looked at the variables of top importance, while many resembled the Framingham criteria, many were new. Ethnicity appeared in the top three variables in all of the algorithms. Socioeconomic status (Townsend Deprivation Index) appeared in the top ten for all four algorithms. Chronic kidney disease was also found to be linked to cardiovascular risk. For cardiovascular risk, it is clear that machine learning has enriched our knowledge of predicting cardiac events.</p>
<p class="mce-root"/>
<p class="mce-root"/>
<p class="mce-root"/>
<p class="mce-root"/>
<p class="mce-root"/>
<p class="mce-root"/>
<p class="mceNonEditable"/>
<p class="mceNonEditable"/>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Congestive heart failure</h1>
                </header>
            
            <article>
                
<p>Of all the cardiac events mentioned in the <em>Overall cardiovascular risk</em> section, CHF deserves a special section of its own. That is for three main reasons:</p>
<ul>
<li>CHF is the most common cause of hospital admission in developed countries</li>
<li><span>Its cost of management is very high, accounting for up to 2% of total healthcare expenditures</span></li>
<li><span>Its cost of diagnosis is also very high, requiring expensive echocardiograms to be performed, read, and interpreted by specialized personnel and physicians (Tripoliti et al., 2016)</span></li>
</ul>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Diagnosing CHF</h1>
                </header>
            
            <article>
                
<p>While CHF can be deemed probable in patients with particular symptoms, risk factors, electrocardiogram findings, and laboratory results, a definitive diagnosis can only be made through echocardiography or a cardiac MRI. Echocardiography requires skilled personnel to administer the test, and then a specialist physician (usually a cardiologist or radiologist) must read the study and visually assess how well the heart is pumping. This is usually done by estimating the <strong>ejection fraction</strong> (<strong>EF</strong>), which is the fraction of blood the left ventricle ejects during its contraction. An EF of 65% is considered normal, 40% indicates heart failure, and 10-15% is seen in advanced stages of CHF. The following diagram was taken from an echocardiogram, which shows the four chambers of the heart. You can imagine that it may be unreliable to quantify heart function using the fuzzy images produced by sound waves:</p>
<p class="mce-root"/>
<div class="mce-root CDPAlignCenter CDPAlign"><img src="assets/295c63bb-f4ac-471a-8b9a-ae6c7a83bf7e.jpg" style="width:43.33em;height:29.58em;"/></div>
<p>A cardiac MRI, while more expensive, is more accurate in measuring EF and is considered the gold standard for CHF diagnosis; however, it requires a cardiologist to spend up to 20 minutes reading an individual scan. In the following diagram, we see:</p>
<ul>
<li><em>A</em>) An illustration of the heart with the imaging plane used for cardiac MRI also shown.</li>
<li><em>B</em>) A 3-D angiogram of the heart (an angiogram is a study in which dye is injected into the bloodstream while images are taken to better visualize the blood vessels).</li>
<li>C), D), and E) images of normal, damaged, and ischemic left ventricles, respectively, obtained from cardiac MRIs:</li>
</ul>
<div class="mce-root CDPAlignCenter CDPAlign"><img src="assets/ecb4b9c9-ea1c-47ba-9400-d5e9f6ef21b6.jpg" style="width:28.42em;height:32.58em;"/></div>
<p>Given the nontrivial nature of CHF diagnosis, again we ask the same questions we asked previously: Can new risk factors be discovered and better performance be achieved with respect to CHF diagnosis by using machine learning algorithms?</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">CHF detection with machine learning</h1>
                </header>
            
            <article>
                
<p>One approach to improve CHF detection with machine learning is to sidestep the use of expensive and time-consuming imaging studies. A recent study from Keimyung University in South Korea used rough sets, decision trees, and logistic regression algorithms, and compared their performance to a physician's diagnosis of heart disease, which was used as the gold standard (Son et al., 2012).</p>
<p class="mce-root"/>
<p>Rough sets are similar to best subset logistic regression (for example, subsets of variables are tested for their informativeness, and the most informative subsets are chosen for the final decision rules). The algorithms were trained on demographic characteristics and lab findings only. The models achieved over 97% sensitivity and 97% specificity in differentiating CHF from non-CHF-related shortness of breath. That's astonishingly close to the human performance, with much less data, time, and resources used.</p>
<p>A second approach we should mention is the use of automated algorithms to read the echocardiography and cardiac MRI scans used to diagnose CHF. This problem was the subject of the 2015 Data Science Bowl, sponsored by the data science competition website Kaggle and Booz Allen Hamilton, the consulting company. For more on this competition, you can visit the Kaggle competition website: <a href="https://www.kaggle.com/c/second-annual-data-science-bowl">https://www.kaggle.com/c/second-annual-data-science-bowl</a>. It goes to show the interest that machine learning in healthcare has garnered.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Other applications of machine learning in CHF</h1>
                </header>
            
            <article>
                
<p>While the detection and diagnosis of disease in humans is always a problem, there are other applications of ML in CHF management. These applications are well-documented in a review paper by the University of Ioannina in Greece (Tripoliti et al., 2017). In addition to CHF detection, discussed problems in that paper relevant to CHF management include severity estimation, CHF subtype classification, exacerbation and hospital readmission prediction, and mortality.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Cancer</h1>
                </header>
            
            <article>
                
<p>In <a href="71c31b0a-fa9e-4b31-8b58-f563a815e338.xhtml" target="_blank">Chapter 2</a>, <em>Healthcare Foundations</em>, we cited several reasons why fighting cancer via ML is an important endeavor, its significant global morbidity, mortality, and emotional consequences notwithstanding. In this section, let's take a closer look at some important concepts and background about cancer, potential machine learning applications for fighting cancer, important features for cancer risk and survivability modeling, and some of the work that has already been done in the area of breast cancer as an example.</p>
<p class="mce-root"/>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">What is cancer?</h1>
                </header>
            
            <article>
                
<p>Cancer can be described as the growth and proliferation of abnormal cells. These cells differ from normal cells in their aggressive reproductive capabilities and their ability to starve normal cells from important resources such as blood and nutrients. Cancer is usually either benign, meaning that it is self-contained to a local area of the body, or malignant, meaning that it has the ability to spread to other bodily tissues. Malignant cancers almost always result in death if untreated, and many even when treated. The progression toward death depends on a number of factors, including the type of cancer, clinical stage of the cancer when detected, pathologic grade of the tumor, and clinical risk factors. Benign cancers aren't as problematic as malignant cancers, although they may cause symptoms and can still result in death (for example, a benign acoustic neuroma that causes high pressure in the brain). Treatment involves some combination of chemotherapy, radiotherapy, biological agents, and/or surgical resection of the tumor and possibly the surrounding tissue and organs.</p>
<p>As you know, cancer is usually classified by the bodily area in which it first appears. The four most deadly types of cancer in the US are lung cancer, breast cancer, prostate cancer, and colon cancer.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">ML applications for cancer</h1>
                </header>
            
            <article>
                
<p>Two comprehensive review papers thoroughly document and summarize the ML research that has been performed for cancer in the last three decades. The first review paper is by the University of Alberta in Canada and provides a thorough review of the studies undertaken prior to it writing in 2006 (<em>Cruz and Wishart</em>, 2006). The second paper is a more recent one and comes from the University of Ioannina in Greece (Kourou et al., 2015). Both papers have broken down the types of subproblems in the area of cancer ML quite well and match well with some of the subproblems that were discussed in <a href="71c31b0a-fa9e-4b31-8b58-f563a815e338.xhtml" target="_blank">Chapter 2</a>, <em>Healthcare Foundations</em>. These problems include:</p>
<ul>
<li><strong>Early detection/screening of cancer</strong>: Can machine learning models be trained to identify individuals with a high risk of developing cancer before symptoms appear?</li>
<li><strong>Diagnosis of cancer</strong>: How can machine learning aid oncologists/radiologists in making definitive diagnoses of cancer and classifying the cancer stage and grade?</li>
<li><strong>Cancer recurrence</strong>: In an individual who has been treated successfully with initial cancer, how likely is that cancer to recur?</li>
<li><strong>Life expectancy and survivability</strong>: In which patients will cancer likely cause mortality? Which patients are likely to be alive in 5 years? In 10 years?</li>
<li><strong>Tumor drug sensitivity</strong>: Which tumors are likely to respond to specific treatments for cancer (for example, chemotherapy, radiotherapy, biological agents, or surgery).</li>
</ul>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Important features of cancer</h1>
                </header>
            
            <article>
                
<p>A number of variables are particularly important for machine learning with cancer use cases. Let's take a look at those now.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Routine clinical data</h1>
                </header>
            
            <article>
                
<p>Clinical data that is routinely available in electronic medical records of all patients is particularly valuable, since it is inexpensive and can be easily included in retroactive modeling studies. Such clinical data is summarized in the following table. It should be noted that there are many exceptions to these rules; for example, while elderly age is an important risk factor for most cancers, bone cancers and some leukemias tend to occur most commonly in children (National Cancer Institute, 2015). The National Cancer Institute is an excellent resource for a more detailed breakdown of clinical risk factors for cancer (<a href="http://www.cancer.gov">www.cancer.gov</a>):</p>
<table border="1" style="border-collapse: collapse;width: 100%">
<tbody>
<tr>
<td><strong>Risk factor</strong></td>
<td><strong>Increases cancer risk</strong></td>
<td><strong>Decreases cancer risk</strong></td>
</tr>
<tr>
<td>Elderly age</td>
<td>×</td>
<td/>
</tr>
<tr>
<td>Positive family history</td>
<td>×</td>
<td/>
</tr>
<tr>
<td>High-fat diet</td>
<td>×</td>
<td/>
</tr>
<tr>
<td>High-fiber diet</td>
<td/>
<td>×</td>
</tr>
<tr>
<td>Diets high in fruits and vegetables</td>
<td/>
<td>×</td>
</tr>
<tr>
<td>Obesity</td>
<td>×</td>
<td/>
</tr>
<tr>
<td>Tobacco use</td>
<td>×</td>
<td/>
</tr>
<tr>
<td>Alcohol use</td>
<td>×</td>
<td/>
</tr>
<tr>
<td>Sun exposure</td>
<td>×</td>
<td/>
</tr>
</tbody>
</table>
<p class="mce-root"/>
<p class="mce-root"/>
<p class="mce-root"/>
<p class="mce-root"/>
<p class="mce-root"/>
<p class="mce-root"/>
<p class="mce-root"/>
<p class="mce-root"/>
<p class="mceNonEditable"/>
<p class="mceNonEditable"/>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Cancer-specific clinical data</h1>
                </header>
            
            <article>
                
<p>After the primary site of the tumor has been identified, almost every tumor can be further classified into subtypes, both clinically and pathologically. The clinical stage of the tumor classifies the extent of the neoplasm. The TNM staging system is the most common; under this system, staging is determined from three factors:</p>
<ul>
<li>The size of the tumor (<em>T</em>)</li>
<li>The involvement of nearby lymph nodes (<em>N</em>)</li>
<li>The metastasis of the tumor to other bodily sites (<em>M</em>)</li>
</ul>
<p>Usually, survival rates are given depending on the clinical stage, which in turn is determined by the TNM staging criteria, which differs for each tumor.</p>
<p>The pathologic grade of the tumor concerns the cellular characteristics of its cells. Things that pathologists look for when setting a tumor grade include the similarity of tumor cell appearance to normal cell appearance (differentiation) and the existence of normal cell organelles (National Cancer Institute, 2015).</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Imaging data</h1>
                </header>
            
            <article>
                
<p>Radiographic findings from x-rays, CT scans, and MRIs can also be used in models that are related to cancer severity and prognosis. Later in this section, we will look at a breast cancer study that trained a neural network on mammogram features, such as the presence and shape of breast tumor microcalcifications and surrounding skin characteristics (Ayer et al., 2010).</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Genomic data</h1>
                </header>
            
            <article>
                
<p>Although gene results are not always easy to obtain in prospective studies, nor are they available in retrospective studies, they are important predictors when available. Specific features include the presence of single nucleotide polymorphisms (SNPs; point mutations) in the patient's DNA and the presence of certain genes (such as BRCA1 in hereditary breast cancer) (Morin et al. Harrison's, 2005).</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Proteomic data</h1>
                </header>
            
            <article>
                
<p>The presence of specific proteins associated with the tumor also influences risk. Examples of significant proteins include tumor-associated biomarkers (for example, CA 19-9 in pancreatic cancer) and hormones (for example, HER-2/neu in breast cancer) (Longo et al., 2005).</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">An example – breast cancer prediction</h1>
                </header>
            
            <article>
                
<p>Let's take a look at how machine learning has enhanced the screening and diagnosis of breast cancer, one of the most common cancers worldwide.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Traditional screening of breast cancer</h1>
                </header>
            
            <article>
                
<p>Screening of breast cancer is a complex problem. Risk scores generally perform poorly; a systematic review of the literature for the performance of the Gail model for predicting breast cancer risk found AUCs that were typically between 0.55 and 0.65 (a random classifier would have an AUC of 0.5) (Wang et al., 2018).</p>
<p>The next least invasive test for breast cancer screening is a clinical breast exam or self-breast exam. The sensitivity and specificity for breast exams vary widely according to age, breast density, and research setting; one study found that sensitivity can be as low as 57%, although the same study found the specificity to be 88% (Baines et al., 1989). Because a good screening test has a high sensitivity, there is a consensus that physical breast examination alone is not adequate for breast cancer screening.</p>
<p>Imaging is the next least invasive screening test for breast cancer. Imaging modalities used for breast cancer screening include mammography, MRI, and ultrasound. In 2016, the <strong>US Preventive Services Task Force</strong> (<strong>USPSTF</strong>) recommended biennial mammograms (see the following diagram showing a mammogram of the breast with a whitish area diagnosed as colloid carcinoma; National Cancer Institute, 1990) for women aged 50 and older, due to the high sensitivity (77% to 95%) and high specificity (94% to 97%) of mammograms in this age group combined with their low potential for causing patient harm (US Preventive Services Task Force, 2016).</p>
<p>Biopsies are the most invasive options for breast cancer detection, and in fact, are used for definitive diagnosis when screening tests are positive.</p>
<p class="mce-root"/>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Breast cancer screening and machine learning</h1>
                </header>
            
            <article>
                
<p>The machine learning literature in breast cancer research is vast (Cruz and Wishart, 2006; Kourou et al., 2015). Here we summarize one study that highlights the potential for machine learning to aid in breast cancer diagnosis, when used in conjunction with mammography and EMRs. The study is from the University of Wisconsin, Madison and consisted of 48,744 mammograms (Ayer et al., 2010).</p>
<p>For each mammogram, information about 36 categorical variables was collected, including clinical data (age, past medical history, family history) and mammographic findings, such as tumor mass characteristics, surrounding skin and nipple characteristics, lymph node examination, and calcification characteristics. An artificial neural network consisting of 1,000 hidden layers was trained and the generated labels were compared to the true label of benign versus malignant. Eight radiologists also reviewed varying numbers of mammograms and classified the scan as benign versus malignant. The total AUC of the neural network was 0.965, while that of the radiologists was 0.939. This study, combined with other studies we will read about in the final chapter, demonstrate how ML can be used as an effective tool in the fight against cancer:</p>
<div class="mce-root CDPAlignCenter CDPAlign"><img src="assets/b556d3bc-85ac-4a31-a6ed-060da3b23170.jpg" style="width:19.50em;height:24.50em;"/></div>
<p class="mce-root"/>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Readmission prediction</h1>
                </header>
            
            <article>
                
<p>Predicting the likelihood of all-cause patient readmissions is outside the scope of a typical clinician's knowledge base, since it is not tied to a specific organ system or disease. However, it is becoming a problem of increasing importance in the healthcare world, since preventable hospital readmissions are a major cause of elevated healthcare expenditures in the United States and other countries. We discussed the incentive and rationale for predicting hospital readmissions and the US government's <strong>Hospital Readmission Reduction Program</strong> (<strong>HRRP</strong>) in <a href="023c1d7e-f3f0-42e6-a2be-64bd5ba4ab80.xhtml" target="_blank">Chapter 6</a>, <em>Measuring Healthcare Quality</em>. Let's now review how machine learning algorithms can be used to augment simpler readmission risk scores.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">LACE and HOSPITAL scores</h1>
                </header>
            
            <article>
                
<p>The most well-known readmission risk score is the LACE score, which was developed in 2010 by Canadian researchers (van Walraven et al., 2010). "LACE" stands for the four predictors used to calculate the score, and the full score calculation ranges from 0-19 and is shown in the following table. The Charlson comorbidity index is a score that assigns scores to patients based on the presence of certain illnesses in their past medical history, including myocardial infarction, cancer, CHF, and HIV infection:</p>
<table border="1" style="border-collapse: collapse;width: 100%">
<tbody>
<tr>
<td><strong>Component</strong></td>
<td><strong>Attribute</strong></td>
<td><strong>Value</strong></td>
<td><strong>Points</strong></td>
</tr>
<tr>
<td>L</td>
<td>Length of stay (days)</td>
<td>&lt;1</td>
<td>0</td>
</tr>
<tr>
<td/>
<td/>
<td>1</td>
<td>1</td>
</tr>
<tr>
<td/>
<td/>
<td>2</td>
<td>2</td>
</tr>
<tr>
<td/>
<td/>
<td>3</td>
<td>3</td>
</tr>
<tr>
<td/>
<td/>
<td>4-6</td>
<td>4</td>
</tr>
<tr>
<td/>
<td/>
<td>7-13</td>
<td>5</td>
</tr>
<tr>
<td/>
<td/>
<td>&gt;13</td>
<td>7</td>
</tr>
<tr>
<td>A</td>
<td>Acuity (emergence of admission)</td>
<td>Yes</td>
<td>3</td>
</tr>
<tr>
<td>C</td>
<td>Comorbidity (Charlson comorbidity index)</td>
<td>0</td>
<td>0</td>
</tr>
<tr>
<td/>
<td/>
<td>1</td>
<td>1</td>
</tr>
<tr>
<td/>
<td/>
<td>2</td>
<td>2</td>
</tr>
<tr>
<td/>
<td/>
<td>3</td>
<td>3</td>
</tr>
<tr>
<td/>
<td/>
<td>&gt;3</td>
<td>5</td>
</tr>
<tr>
<td>E</td>
<td>ED visits during last 6 months</td>
<td>0</td>
<td>0</td>
</tr>
<tr>
<td/>
<td/>
<td>1</td>
<td>1</td>
</tr>
<tr>
<td/>
<td/>
<td>2</td>
<td>2</td>
</tr>
<tr>
<td/>
<td/>
<td>3</td>
<td>3</td>
</tr>
<tr>
<td/>
<td/>
<td>&lt;3</td>
<td>4</td>
</tr>
</tbody>
</table>
<p> </p>
<p>To derive this index, the study authors entered over a dozen variables thought to be related to readmission risk for 2,393 patients into a multivariable logistic regression model, and were left with these four variables as the significant predictors in the model. They then developed the scoring system and externally validated it using 1,000,000 records from a Canadian patient database. Their own reported <em>C</em>-statistic for predicting early death or urgent readmission within 30 days was 0.684.</p>
<p>Another example of a hospital readmission risk score is the more recently developed HOSPITAL score (Donze et al., 2013; Donze et al., 2016). Again "HOSPITAL" stands for the seven predictors used in the score as listed in the following table:</p>
<table border="1" style="border-collapse: collapse;width: 100%">
<tbody>
<tr>
<td><strong>Component</strong></td>
<td><strong>Attribute</strong></td>
<td><strong>Value</strong></td>
<td><strong>Points</strong></td>
</tr>
<tr>
<td>H</td>
<td>Hemoglobin &lt; 12 g/dL at discharge</td>
<td>Yes</td>
<td>1</td>
</tr>
<tr>
<td>O</td>
<td>Oncology service discharge</td>
<td>Yes</td>
<td>2</td>
</tr>
<tr>
<td>S</td>
<td>Sodium &lt; 135 mmol/L at discharge</td>
<td>Yes</td>
<td>1</td>
</tr>
<tr>
<td>P</td>
<td>Procedure during hospital stay</td>
<td>Yes</td>
<td>1</td>
</tr>
<tr>
<td>IT</td>
<td>Index admission type: urgent</td>
<td>Yes</td>
<td>1</td>
</tr>
<tr>
<td>A</td>
<td>Admission count during the previous year</td>
<td>0-1</td>
<td>0</td>
</tr>
<tr>
<td/>
<td/>
<td>2-5</td>
<td>2</td>
</tr>
<tr>
<td/>
<td/>
<td>&gt;5</td>
<td>5</td>
</tr>
<tr>
<td>L</td>
<td>Length of stay &gt; 5 days</td>
<td>Yes</td>
<td>2</td>
</tr>
</tbody>
</table>
<p> </p>
<p>The HOSPITAL score ranges from 0-13 points. The score was derived using the seven factors independently related to hospital readmission, also using a multivariable logistic regression model (Donze et al., 2013). The score was externally validated using 117,065 discharges from four countries and the authors reported a C-statistic of 0.72 (Donze et al., 2016).</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Readmission modeling</h1>
                </header>
            
            <article>
                
<p>Let's look at two recent studies that have applied machine learning to the readmission risk identification problem.</p>
<p class="mce-root"/>
<p class="mce-root"/>
<p class="mce-root"/>
<p class="mce-root"/>
<p class="mce-root"/>
<p class="mceNonEditable"/>
<p>The first study comes by Duke University (Futoma et al., 2014). In this study, 3.3 million hospital admissions from New Zealand were studied. For each admission, demographic information, background information, <strong>diagnosis-related group</strong> (<strong>DRG</strong>) codes, and <strong>International Classification of Diseases</strong> (<strong>ICD</strong>) diagnosis and procedure codes were used. The matrix was then fed into six different machine learning algorithms:</p>
<ul>
<li>Logistic regression</li>
<li>Logistic regression with the multistep variable selection</li>
<li>Penalized logistic regression</li>
<li>Random forest</li>
<li>Support vector machine</li>
<li>Deep learning</li>
</ul>
<p>Of the first five methods, the random forest had the best performance, achieving an AUC of 0.684. The deep learning models were used to predict readmissions on five patient cohorts: pneumonia, <strong>chronic obstructive pulmonary disease</strong> (<strong>COPD</strong>), CHF, MI, and total hip/knee arthroplasty. The highest performance was achieved for pneumonia, with an AUC of 0.734. It should be noted that no direct comparison to LACE or HOSPITAL risk scores was performed.</p>
<p>The second study comes from the Advocate Health Care hospital system (Tong et al., 2016). The study consisted of 162,466 index (for example, initial) hospital admissions. For each index admission, 19 data elements were collected including the four LACE score components and 15 other EMR variables, such as past medical history, previous clinical encounters, employment status, and lab results. They trained three different machine learning models on this data:</p>
<ul>
<li>Logistic regression with the stepwise forward-backward variable selection</li>
<li>Logistic regression with lasso regularization</li>
<li>Boosting</li>
</ul>
<p><span>They found that when they used 80,000 index admissions for the training/validation sets, the LACE model had an AUC of ~0.65, while the three machine learning models all had AUCs of ~0.73. The results suggest the significance of additional variables outside of the four variables used for the LACE score, and they further reinforce the use of machine learning for healthcare.</span></p>
<p class="mce-root"/>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Other conditions and events</h1>
                </header>
            
            <article>
                
<p>There are many other conditions for which machine learning algorithms have been used to improve risk assessment and prediction over traditional risk scores. COPD, pneumonia, sepsis, stroke, and dementia are just a few examples.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Summary</h1>
                </header>
            
            <article>
                
<p>In this chapter, we have reviewed different types of healthcare models and the features they use to achieve efficacy. We have omitted some emerging trends in healthcare from our discussion, however; these include the use of newer technologies such as social media, the Internet of Things, and deep learning algorithms to push the healthcare prediction envelope even further. We'll examine these trends in the next chapter.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">References and further reading</h1>
                </header>
            
            <article>
                
<p>Ayer T, Alagoz O, Chhatwal J, Shavlik JW, Kahn Jr. CE, Burnside ES (2010). Breast Cancer Risk Estimation with Artificial Neural Networks Revisited: Discrimination and Calibration. <em>Cancer</em> 116 (14): 3310-3321.</p>
<p>Baines CJ (1989). Breast self-examination. <em>Cancer</em> 64(12 Suppl): 2661-2663.</p>
<p>Cruz JA, Wishart DS (2006). Applications of Machine Learning in Cancer Prediction and Prognosis. <em>Cancer Informatics</em> 2: 59-77.</p>
<p>D'Agostino RB, Vasan RS, Pencina MJ, Wolf PA, Cobain M, Massaro JM, Kannel WB (2008). <em>General Cardiovascular Risk Profile for Use in Primary Care: The Framingham Heart Study. Circulation</em> 117 (6): 743-753.</p>
<p>Donze J, Aujesky D, Williams D, Schnipper JL (2013). Potentially avoidable 30-day hospital readmissions in medical patients: derivation and validation of a prediction model. <em>JAMA Intern Med</em> 173(8): 632-638.</p>
<p>Donze JD, Williams MV, Robinson EJ et al. (2016). International Validity of the "HOSPITAL" Score to Predict 30-day Potentially Avoidable Readmissions in Medical Patients. <em>JAMA Intern Me</em>d 176(4): 496-502.</p>
<p class="mce-root"/>
<p class="mce-root"/>
<p class="mce-root"/>
<p class="mce-root"/>
<p class="mce-root"/>
<p class="mceNonEditable"/>
<p>Framingham Heart Study (2018a). <em>History of the Framingham Heart Study</em>. <a href="https://www.framinghamheartstudy.org/fhs-about/history/">https://www.framinghamheartstudy.org/fhs-about/history/</a>. Accessed June 16, 2018.</p>
<p>Framingham Heart Study (2018b). <em>Research Milestones</em>. <a href="https://www.framinghamheartstudy.org/fhs-about/research-milestones/">https://www.framinghamheartstudy.org/fhs-about/research-milestones/</a>. Accessed June 16, 2018.</p>
<p>Futoma J, Morris J, Lucas J (2015). A comparison of models for predicting early hospital readmissions. <em>Journal of Biomedical Informatics</em> 56: 229-238.</p>
<p>Kourou K, Exarchos TP, Exarchos KP, Karamouzis MV, Fotiadis DI (2015). Machine learning applications in cancer prognosis and prediction. <em>Computational and Structural Biotechnology Journal</em> 13: 8-17.</p>
<p>Lenes K (2005). <em>File: Echocardiogram 4chambers.jpg</em>. <a href="https://commons.wikimedia.org/wiki/File:Echocardiogram_4chambers.jpg">https://commons.wikimedia.org/wiki/File:Echocardiogram_4chambers.jpg</a>. Accessed June 23, 2018.</p>
<p>Longo DL (2005). "<em>Approach to the Patient with Cancer</em>." In Kasper DL, Braunwald E, Fauci AS, Hauser SL, Longo DL, Jameson JL. eds. <em>Harrison's Principles of Internal Medicine</em>, 16e. New York, NY: McGraw-Hill.</p>
<p>Morin PJ, Trent JM, Collins FS, Vogelstein B (2005). "Cancer Genetics." In Kasper DL, Braunwald E, Fauci AS, Hauser SL, Longo DL, Jameson JL. eds. <em>Harrison's Principles of Internal Medicine</em>, 16e. New York, NY: McGraw-Hill.</p>
<p>National Cancer Institute (1990). Mammogram Showing Cancer. Unknown Photographer, American College of Radiology. <a href="https://commons.wikimedia.org/wiki/File:Mammogram_showing_cancer.jpg">https://commons.wikimedia.org/wiki/File:Mammogram_showing_cancer.jpg</a>. Accessed June 23, 2018.</p>
<p>National Cancer Institute (2015a). <em>Breast Cancer Screening (PDQ®)-Health Professional Version</em>. <a href="https://www.cancer.gov/types/breast/hp/breast-screening-pdq#section/all">https://www.cancer.gov/types/breast/hp/breast-screening-pdq#section/all</a>. Accessed June 23, 2018.</p>
<p>National Cancer Institute (2015b). <em>Risk Factors for Cancer</em>. <a href="https://www.cancer.gov/about-cancer/causes-prevention/risk">https://www.cancer.gov/about-cancer/causes-prevention/risk</a>. Accessed June 23, 2018.</p>
<p>National Heart Lung and Blood Institute (2013). File:Cardiac_Mri.jpg. <a href="https://commons.wikimedia.org/wiki/File:Cardiac_mri.jpg">https://commons.wikimedia.org/wiki/File:Cardiac_mri.jpg</a>. Accessed June 23, 2018.</p>
<p>Son C, Kim Y, Kim H, Park H, Kim M (2012). Decision-making model for early diagnosis of congestive heart failure using rough set and decision tree approaches. <em>Journal of Biomedical Informatics</em> 45: 999-1008.</p>
<p class="mce-root"/>
<p>Tong L, Erdmann C, Daldalian M, Li J, Esposito T (2016). Comparison of predictive modeling approaches for 30-day all-cause non-elective readmission risk. <em>BMC Medical Research Methodology</em> 2016(16): 26.</p>
<p>Tripoliti EE, Papadopoulos TG, Karanasiou GS, Naka KK, Fotiadis DI (2017). Heart Failure: Diagnosis, Severity Estimation and Prediction of Adverse Events Through Machine Learning Techniques. <em>Computational and Structural Biotechnology Journal</em> 15: 26-47.</p>
<p>US Preventive Services Task Force (2016). <em>Final Recommendation Statement: Breast Cancer: Screening</em>. <a href="https://www.uspreventiveservicestaskforce.org/Page/Document/RecommendationStatementFinal/breast-cancer-screening1">https://www.uspreventiveservicestaskforce.org/Page/Document/RecommendationStatementFinal/breast-cancer-screening1</a>. Accessed June 23, 2018.</p>
<p>van Walraven C, Dhalla IA, Bell C, Etchells E, Stiell IG, Zarnke K, Austin PC, Forster AJ (2010). Derivation and validation of an index to predict early death or unplanned readmission after discharge from hospital to the community. <em>Canadian Medical Association Journal</em> 182(6): 551-557.</p>
<p>Wang X, Huang Y, Li L, Dai H, Song F, Chen K (2018). Assessment of performance of the Gail model for predicting breast cancer risk: a systematic review and meta-analysis with trial sequential analysis. <em>Breast Cancer Research</em> 20: 18.</p>
<p>Weng SF, Reps J, Kai J, Garibaldi JM, Qureshi N (2017). <em>Can machine-learning improve cardiovascular risk prediction using routine clinical data?</em> <em>PLOS One</em> 12(4): e0174944. <a href="https://doi.org/10.1371/journal.pone.0174944">https://doi.org/10.1371/journal.pone.0174944</a></p>


            </article>

            
        </section>
    </body></html>