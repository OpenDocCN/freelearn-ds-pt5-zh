<html><head></head><body><div><div><div><div><div><h1 class="title"><a id="ch11" class="pcalibre pcalibre3 pcalibre2 pcalibre1 calibre9"/>Chapter 11. Introduction to Deep Learning</h1></div></div></div><p class="calibre11">Innovators have always longed to make machines that can think. At the point when programmable PCs were first considered, individuals pondered whether they might get to be wise, over a hundred years before one was constructed (Lovelace in 1842).</p><p class="calibre11">Today, <strong class="calibre19">artificial intelligence </strong>(<strong class="calibre19">AI</strong>) is a flourishing field with numerous reasonable applications and dynamic exploration points. We look to intelligent programming to automate routine work, process image and audio and extract meaning out of it, automate diagnoses of several diseases, and much more.</p><p class="calibre11">In the beginning, when artificial intelligence (AI) was picking up, the field handled and tackled issues that are mentally difficult for individuals, yet moderately straightforward for computers. These issues can be depicted by a rundown of formal, scientific principles. The genuine test for artificial intelligence turned out to be unraveling the undertakings that are simple for individuals to perform yet hard for individuals to depict formally. These issues we explain naturally, for example the ability of humans to understand speech (and sarcasm) and our ability to identify images, especially faces.</p><p class="calibre11">This arrangement is to permit computers to learn by gaining experience and to comprehend the world as far as a chain or a tree of facts, with every fact defined as far as its connection to more straightforward facts. By understanding these facts, this methodology maintains a strategic distance from the requirement for human administrators to formally indicate the greater part of the information that the computer needs.</p><p class="calibre11">The progressive system of facts permits the computer to learn convoluted ideas by building them out of more straightforward ones. In the event that we draw a diagram indicating how these ideas are based on top of each other, the chart is profound, with numerous layers. Thus, we call this way to deal with AI deep learning.</p><p class="calibre11">A number of the early accomplishments of AI occurred in moderately sterile and formal situations and it was not necessary for computers to have much learning of the world. Let's take an example:</p><div><ul class="itemizedlist"><li class="listitem">IBM's Deep Blue chess-playing framework in 1997 defeated Mr. Gary Kasparov, the world champion at the time.</li></ul></div><p class="calibre11">We should also consider these factors:</p><div><ul class="itemizedlist"><li class="listitem">Chess is obviously an extremely basic world.</li><li class="listitem">It contains just 64 blocks and 32 elements that can only move in predefined ways.</li><li class="listitem">Although conceiving a fruitful chess system is a huge achievement, the test is not due to the difficulty of describing the arrangement of chess elements and passable moves to the computer.</li><li class="listitem">Chess can be totally portrayed by an extremely short rundown of totally formal principles, effortlessly given earlier by the software engineer.</li></ul></div><p class="calibre11">Computers perform better than human beings in some of the tasks and worse in others:</p><div><ul class="itemizedlist"><li class="listitem">Abstract tasks that are among the most difficult mental endeavors for a person are among the simplest for a computer. Computers are much better suited for such tasks.<div><ul class="itemizedlist1"><li class="listitem">An example of this is performing complex mathematical tasks.</li></ul></div><p class="calibre44">
</p></li><li class="listitem">Subjective and natural tasks are performed much better by the average human being than a computer.<div><ul class="itemizedlist1"><li class="listitem">A man's ordinary life requires a tremendous measure of information about the world.</li><li class="listitem">A lot of this learning is subjective and natural, and accordingly difficult to express formally.</li><li class="listitem">Computers need to catch this same information so as to act in a wise way. One of the key difficulties in artificial intelligence is the means by which you get this casual learning onto a computer.</li></ul></div><p class="calibre44">
</p></li></ul></div><p class="calibre11">A few artificial intelligence ventures have looked to hard-code information about the world in formal dialects. A computer can reason about articulations in these formal dialects, consequently utilizing legitimate deduction rules. This is known as the information base way to deal with artificial intelligence. None of these activities have prompted a noteworthy success.</p><p class="calibre11">The difficulties confronted by frameworks depending on hard-coded information propose that AI frameworks require the capacity to obtain their own particular learning, by extracting patterns from crude information. This is known as machine learning, which we studied in previous chapters.</p><p class="calibre11">The execution of these straightforward machine-learning calculations depends vigorously on the representation of the information they are given.</p><p class="calibre11">For instance, when logistic regression is utilized to suggest the future weather, the AI framework does not look at the patient straightforwardly:</p><div><ul class="itemizedlist"><li class="listitem">The specialist tells the framework a few bits of important data, for example, the varying temperatures, wind direction and speed, humidity, and so on.</li><li class="listitem">Every bit of the data incorporated into the representation of the weather is known as a feature. Logistic regression figures out how each of these features of the weather relates to different weather in different seasons or in other locations.</li><li class="listitem">In any case, it can't influence the way that the features are defined in any capacity.</li></ul></div><p class="calibre11">One answer for this issue is to utilize the machine, figuring out how to find the mapping from the representation to yield as well as the representation itself. This methodology is known as representation learning. Learned representations frequently bring about much-preferred execution over what can be acquired with hand-planned representations. They additionally permit AI frameworks to quickly adjust to new tasks, with negligible human intercession.</p><p class="calibre11">A representation learning calculation can find a decent arrangement of features for a straightforward undertaking in minutes, or for a complex assignment in hours to months. Physically outlining highlights for a complex work require a lot of human time and effort, much more than for computers.</p><p class="calibre11">In this chapter we will go through multiple topics, starting with the basic introduction:</p><div><ul class="itemizedlist"><li class="listitem">Basic foundations</li><li class="listitem">Differences between machine learning and deep learning</li><li class="listitem">What is deep learning?</li><li class="listitem">Deep feed-forward networks</li><li class="listitem">Single and multi-layer neural networks</li><li class="listitem">Convolution networks</li><li class="listitem">Practical methodology and applications</li></ul></div><div><div><div><div><h1 class="title1"><a id="ch11lvl1sec82" class="pcalibre pcalibre3 pcalibre2 pcalibre1 calibre9"/>Revisiting linear algebra</h1></div></div></div><p class="calibre11">Linear algebra is a widely used branch of mathematics. Linear algebra is a part of discrete mathematics and not of continuous mathematics. A good understanding is needed to understand the machine learning and deep learning models. We will only revise the mathematical objects.</p><div><div><div><div><h2 class="title3"><a id="ch11lvl2sec135" class="pcalibre pcalibre3 pcalibre2 pcalibre1 calibre9"/>A gist of scalars</h2></div></div></div><p class="calibre11">A scalar is just a single number (as opposed to a large portion of alternate objects examined in linear algebra, which are generally arrays of various numbers).</p></div><div><div><div><div><h2 class="title3"><a id="ch11lvl2sec136" class="pcalibre pcalibre3 pcalibre2 pcalibre1 calibre9"/>A brief outline of vectors</h2></div></div></div><p class="calibre11">A vector is an organized collection or an array of numbers. We can recognize every individual number by its index in that list. For example:</p><div><blockquote class="blockquote"><p class="calibre22">
<em class="calibre23">x = [x1, x2, x3, x4 ..... xn]</em>
</p></blockquote></div><div><ul class="itemizedlist"><li class="listitem">Vectors can also be thought of as identifying points in space.</li><li class="listitem">Each element represents the value of coordinate along a different axis.</li><li class="listitem">We can also index the positions of these values in the vector. Therefore, it makes it easier to access the specific value of the array.</li></ul></div></div><div><div><div><div><h2 class="title3"><a id="ch11lvl2sec137" class="pcalibre pcalibre3 pcalibre2 pcalibre1 calibre9"/>The importance of matrices</h2></div></div></div><div><ul class="itemizedlist"><li class="listitem">A matrix is a two-dimensional array of numbers.</li><li class="listitem">Every component is identified by two indexes rather than only one.</li><li class="listitem">For example, a point in 2D space may be identified as (3,4). It means that the point is 3 points on the <em class="calibre23">x</em> axis and 4 points on the <em class="calibre23">y</em> axis.</li><li class="listitem">We can also have arrays of such numbers as[(3,4), (2,4), (1,0)]. Such an array is called a matrix.</li></ul></div></div><div><div><div><div><h2 class="title3"><a id="ch11lvl2sec138" class="pcalibre pcalibre3 pcalibre2 pcalibre1 calibre9"/>What are tensors?</h2></div></div></div><p class="calibre11">If more than two-dimensions are needed (matrix) then we use tensors.</p><p class="calibre11">This is an array of numbers without a defined number of axes.</p><p class="calibre11">Such objects have a structure as follows: <em class="calibre23">T (x, y, z)</em>
</p><p class="calibre11">
<em class="calibre23">[(1,3,5), (11,12,23), (34,32,1)]</em>
</p></div></div></div></div>



  
<div><div><div><div><div><h1 class="title1"><a id="ch11lvl1sec83" class="pcalibre pcalibre3 pcalibre2 pcalibre1 calibre9"/>Probability and information theory</h1></div></div></div><p class="calibre11">Probability theory is a scientific system for speaking to questionable explanations. It gives a method for evaluating instability and adages for inferring new indeterminate statements.</p><p class="calibre11">In applications of AI, we utilize probability theory as follows:</p><div><ul class="itemizedlist"><li class="listitem">The laws of probability define how AI frameworks ought to reason, so algorithms are designed to figure or approximate different expressions inferred on utilizing probability theory</li><li class="listitem">Probability and statistics can be utilized to hypothetically investigate the behavior of proposed AI frameworks</li></ul></div><p class="calibre11">While probability theory permits us to put forth indeterminate expressions and reason within the sight of uncertainty, data permits us to measure the degree of uncertainty in a probability distribution.</p><div><div><div><div><h2 class="title3"><a id="ch11lvl2sec139" class="pcalibre pcalibre3 pcalibre2 pcalibre1 calibre9"/>Why probability?</h2></div></div></div><p class="calibre11">Machine learning makes substantial utilization of probability theory unlike other branches of computer science that are mainly dependent on the deterministic nature of the computer system:</p><div><ul class="itemizedlist"><li class="listitem">This is on the grounds that machine learning must dependably manage uncertain quantities.</li><li class="listitem">Some of the time it may also be necessary to manage stochastic (non-deterministic) amounts. Uncertainty and stochasticity can emerge from numerous sources.</li></ul></div><p class="calibre11">All exercises require some capacity to reason within the sight of uncertainty. Actually, with past numerical explanations that are valid by definition,, it is difficult to think about any suggestion that is completely valid or any occasion that is totally ensured to happen.</p><p class="calibre11">Uncertainty has are three possible sources:</p><div><ul class="itemizedlist"><li class="listitem">Existing stochasticity in the framework that is being modeled.<div><ul class="itemizedlist1"><li class="listitem">For instance, while playing a card game we make the assumption that the cards are truly shuffled in a random fashion.</li></ul></div><p class="calibre44">
</p></li><li class="listitem">Fragmented observability. When a greater part of the variables that drive the conduct of the framework cannot be observed then even deterministic frameworks can seem stochastic.<div><ul class="itemizedlist1"><li class="listitem">For instance, in a question with multiple-choice options as answers, one choice leads to the correct answer while others will result in nothing. The result given the challenger's decision is deterministic, yet from the candidate's perspective, the result is indeterminate.</li></ul></div><p class="calibre44">
</p></li><li class="listitem">Fragmented modeling. When we utilize a model that must dispose of a portion of the data we have observed, the disposed-of data results in instability in the model's expectations.<div><ul class="itemizedlist1"><li class="listitem"> For instance, assume we manufacture a robot that can precisely watch the area of each article around it. In the event that the robot discretizes space while anticipating the future area of these objects, then the discretization makes the robot quickly become dubious about the exact position of the articles: every item could be any place inside the discrete cell that it was seen to possess.</li></ul></div><p class="calibre44">
</p></li></ul></div><p class="calibre11">A probability can be seen as the augmentation of rationale to manage uncertainty. Rationale gives an arrangement of formal rules for figuring out what suggestions are inferred to be true or false given the suspicion that some other arrangement of recommendations is true or false.</p><p class="calibre11">Probability hypothesis gives an arrangement of formal principles for deciding the probability of a suggestion being genuine given the probability of the different recommendations.</p></div></div></div>



  
<div><div><div><div><div><h1 class="title1"><a id="ch11lvl1sec84" class="pcalibre pcalibre3 pcalibre2 pcalibre1 calibre9"/>Differences between machine learning and deep learning</h1></div></div></div><p class="calibre11">Machine learning and deep learning intend to accomplish the same objective, but, they are distinctive and amount to various thoughts. Machine learning is the most major of the two and scientists and mathematicians have been doing research on it for a few decades now. Deep learning is a comparatively new idea. Deep learning is based on learning via neural networks (multiple layers) to achieve the goal. Understanding the difference between the two is important to know where we should apply deep learning and which problems can be solved using machine learning.</p><p class="calibre11">It was understood that a more intense approach to construct pattern recognition algorithms is achieved by utilizing the information that can be effortlessly mined relying only upon the area and the deciding objective.</p><p class="calibre11">For instance, in image recognition we accumulate various pictures and expand the algorithm on that. Utilizing the information as a part of these pictures, our model can be trained to recognize creatures, human appearances, or different examples.</p><p class="calibre11">Machine learning is connected to different areas and now it is not limited to image or character recognition. It is currently utilized intensely as a part of robotics, financial markets, self-driving cars, and genome analysis. We learned about machine learning in previous chapters and now we can go further to understand how different it is from deep learning.</p><div><div><div><div><h2 class="title3"><a id="ch11lvl2sec140" class="pcalibre pcalibre3 pcalibre2 pcalibre1 calibre9"/>What is deep learning?</h2></div></div></div><p class="calibre11">Deep learning started becoming popular in 2006. It is also known as hierarchical learning. Its applications are wide and it has increased the scope of artificial intelligence and machine learning. There is a huge interest in deep learning from the community.</p><p class="calibre11">Deep learning refers to a class of machine learning techniques which:</p><div><ul class="itemizedlist"><li class="listitem">Perform unsupervised or supervised feature extraction.</li><li class="listitem">Perform pattern analysis or classification by exploiting multiple layers of non-linear information processing.</li></ul></div><p class="calibre11">It consists of a hierarchy of features or factors. In this hierarchy, lower-level features help in defining higher-level features. Artificial neural networks are typically used in deep learning.</p><div><ul class="itemizedlist"><li class="listitem">Conventional machine learning models learn patterns or clusters. Deep neural networks learn computations with a very small number of steps.</li><li class="listitem">Generally speaking, the deeper the neural network, the more powerful it gets.</li><li class="listitem">Neural networks are updated according to the new data made available.</li><li class="listitem">Artificial neural networks are fault tolerant, which means that if some part of the network is destroyed, then that may affect the performance of the network, but the key functioning of the network may still be retained.</li><li class="listitem">Deep learning algorithms learn multiple levels of representation and do the computations in parallel, which may be of increasing complexity.</li></ul></div><p class="calibre11">If we fast forward to today, there is a widespread enthusiasm for something that many refer to as deep learning. The most prominent sorts of deep learning models, as they are utilized as a part of extensive scale image recognition tasks, are known as Convolutional Neural Nets, or essentially ConvNets.</p><p class="calibre11">Deep learning emphasizes the sort of model that we need to utilize (such as a deep convolutional multi-layer neural system) and that we can utilize information to fill in the missing parameters.</p><p class="calibre11">With deep learning comes incredible obligation. Since we are beginning with a model of the world which has a high dimensionality, we truly require a great deal of information which we also call big data, and a considerable measure of computational force (General Purpose GPUs/ High performance computing). Convolutions are utilized widely as a part of deep learning (particularly computer vision applications).</p><p class="calibre11">
</p><div><img src="img/B05321_11_01-1.jpg" alt="What is deep learning?" class="calibre220"/></div><p class="calibre11">
</p><p class="calibre11">In the previous image we saw three layers:</p><div><ul class="itemizedlist"><li class="listitem"><strong class="calibre19">Output layer</strong>: Here this predicts a supervised target</li><li class="listitem"><strong class="calibre19">Hidden layer</strong>: Abstract representations of the intermediary functions</li><li class="listitem"><strong class="calibre19">Input layer</strong>: Raw inputs</li></ul></div><p class="calibre11">Artificially simulated neurons stand for the building blocks of the multi-layer artificial neural systems. The essential idea is to simulate a human brain and how it solves a complex problem. The main idea to manufacture neural systems was based upon these theories and models.</p><p class="calibre11">Numerous more significant leaps were brought about in the last few decades with regards to deep-learning algorithms. These can be utilized to make feature indicators from unlabeled information and also to pre-train deep neural networks, which are the neural systems that are made out of numerous layers.</p><p class="calibre11">Neural networks are an interesting issue in scholastic exploration, as well as in huge innovation organizations, for example for companies such as Facebook, Microsoft, and Google, who are investing heavily in deep-learning research.</p><p class="calibre11">Complex neural networks fueled by deep-learning calculations are considered as best in class with regards to critical problem solving. For example:</p><div><ul class="itemizedlist"><li class="listitem"><strong class="calibre19">Google's image search</strong>: We can search images on the Internet using the Google image search tool. This can be done by uploading an image or giving the URL of the image to search for on the Internet.</li><li class="listitem"><strong class="calibre19">Google Translate</strong>: This tool can read text in images and understand speech to translate or tell meaning in several languages.</li></ul></div><p class="calibre11">One other very famous application is used in the self-driving cars, created by Google or Tesla. They are powered by deep learning to find out the best path, drive through the traffic in real time, and perform necessary tasks as they would if they were being driven by a human driver.</p></div><div><div><div><div><h2 class="title3"><a id="ch11lvl2sec141" class="pcalibre pcalibre3 pcalibre2 pcalibre1 calibre9"/>Deep feedforward networks</h2></div></div></div><p class="calibre11">Deep feedforward networks are the most famous deep learning models. These are also called the following:</p><div><ul class="itemizedlist"><li class="listitem">Feedforward neural networks.</li><li class="listitem"><strong class="calibre19">Multi-layer perceptrons</strong> (<strong class="calibre19">MLPs</strong>)</li></ul></div><p class="calibre11">
</p><div><img src="img/B05321_11_02.jpg" alt="Deep feedforward networks" class="calibre221"/></div><p class="calibre11">
</p><p class="calibre11">The aim of the feed-forward neural network is to learn by their parameters and define a function that maps to the output <em class="calibre23">y:</em>
</p><div><blockquote class="blockquote"><p class="calibre22">
<em class="calibre23">y = f(x, theta)</em>
</p></blockquote></div><p class="calibre11">As also depicted in the image, the feedforward neural networks are called such because of their data flows in one direction. It starts from the <em class="calibre23">x</em> and passes through the function for the intermediate calculations to generate <em class="calibre23">y</em>.</p><p class="calibre11">When such systems also include connections to the previous layer (feedback), then these are known as recurrent neural networks.</p><p class="calibre11">Feedforward systems are of great significance to machine learning experts. They frame the premise of numerous imperative business applications. For instance, the convolutional systems utilized for natural language processing from speech are a specific sort of feedforward system.</p><p class="calibre11">Feedforward systems are a reasonable stepping stone on the way to recurrent networks. These systems have numerous natural language applications. Feedforward neural networks are called networks since they are represented by forming together numerous different functions. The model is connected with a directed acyclic graph portraying how the functions are created together.</p><p class="calibre11">For example, we have three functions - <em class="calibre23">f(1)</em>, <em class="calibre23">f(2)</em>, and <em class="calibre23">f(3)</em>.</p><p class="calibre11">They are chained or associated together as follows:</p><div><blockquote class="blockquote"><p class="calibre22">
<em class="calibre23">f(x) = f(3)(f(2)(f(1)(x)))</em>
</p></blockquote></div><p class="calibre11">These chain structures are the most normally utilized structures of neural systems. For this situation:</p><div><ul class="itemizedlist"><li class="listitem"><em class="calibre23">f(1)</em> is known as the first layer of the network.</li><li class="listitem"><em class="calibre23">f(2)</em> is known as the second layer, and so on.</li><li class="listitem">The general length of the chain gives the depth of the model. It is from this wording the name "deep learning" emerges.</li><li class="listitem">The final layer of a feedforward network is known as the output or yield layer.</li></ul></div><p class="calibre11">Amid neural network training, we follow these steps:</p><div><ol class="orderedlist"><li class="listitem1">Drive <em class="calibre23">f(x)</em> to coordinate <em class="calibre23">f∗(x)</em>. The training information has data with noise and inexact data off <em class="calibre23">∗(x)</em> assessed at different training sets.</li><li class="listitem1">Every example of <em class="calibre23">x</em> is associated by a label <em class="calibre23">y ≈ f∗(x)</em>.</li><li class="listitem1">The training cases determine straightforwardly what the yield layer must do at every point <em class="calibre23">x</em>. That is, it must create a value that is near <em class="calibre23">y</em>.</li></ol></div><div><div><div><div><h3 class="title5"><a id="ch11lvl3sec93" class="pcalibre pcalibre3 pcalibre2 pcalibre1 calibre9"/>Understanding the hidden layers in a neural network</h3></div></div></div><p class="calibre11">The conduct of alternate layers is not straightforwardly specified by the training information. The learning algorithm must choose how to utilize those layers to create the desired yield, yet the training information does not say what every individual layer ought to do.</p><p class="calibre11">Rather, it is the learning algorithm which must choose how to utilize these layers to best execute an estimation off ∗. Since the training information does not demonstrate the desired yield for each of these layers, these layers are called hidden layers.</p></div><div><div><div><div><h3 class="title5"><a id="ch11lvl3sec94" class="pcalibre pcalibre3 pcalibre2 pcalibre1 calibre9"/>The motivation of neural networks</h3></div></div></div><div><ul class="itemizedlist"><li class="listitem">These systems are called neural on the grounds that they are approximately motivated by neuroscience.</li><li class="listitem">Each concealed or hidden layer of the system is generally vector-valued.</li><li class="listitem">The dimension of <em class="calibre23">y</em> of these hidden layers decides the width of the model.</li><li class="listitem">Every component of the vector might be translated as assuming a part comparable to a neuron.</li><li class="listitem">As opposed to thinking about the layer as exhibiting a single vector-to-vector function, it should be thought that the layer comprises of numerous units that work in parallel, each exhibiting a vector-to-scalar function.</li><li class="listitem">Each unit looks like a neuron in respect that it gets a contribution from numerous different units and registers its own activation value.</li><li class="listitem">Using numerous layers of vector-valued representation is drawn from neuroscience.</li><li class="listitem">The decision of the function <em class="calibre23">f(i)(x)</em> used to figure out these representations is somewhat guided by neuroscientific observations about the functions that organic neurons process.</li></ul></div><p class="calibre11">We studied regularization in previous chapters. Let's study why this is important and required for deep learning models.</p></div></div><div><div><div><div><h2 class="title3"><a id="ch11lvl2sec142" class="pcalibre pcalibre3 pcalibre2 pcalibre1 calibre9"/>Understanding regularization</h2></div></div></div><p class="calibre11">The main issue in machine learning is the means by which to make an algorithm that will perform well on the training information, as well as on new inputs. Numerous techniques utilized as a part of machine learning are expressly intended to diminish test errors, potentially to the detriment of increased training errors. These techniques are referred to aggregately as regularization.</p><p class="calibre11">There are many types of regularization accessible to the deep-learning specialist. More effective regularization systems have been one of the research efforts in the field.</p><p class="calibre11">There are numerous regularization systems.</p><div><ul class="itemizedlist"><li class="listitem">Additional constraints on a machine learning model<div><ul class="itemizedlist1"><li class="listitem">For example, including constraints on the parameter values.</li></ul></div><p class="calibre44">
</p></li><li class="listitem">Additional terms in the target functions that can be taken as comparing to a delicate requirement on the parameter values</li><li class="listitem">If done strategically and carefully, these additional requirements and constraints can result in enhanced performance on the testing data</li><li class="listitem">These constraints and restrictions can also be used to encode specific sorts of prior learning</li><li class="listitem">These constraints and restrictions can also lead to generalization of the model</li><li class="listitem">Ensemble methods also use regularization to generate better results</li></ul></div><p class="calibre11">With regards to deep learning, most regularization procedures depend on regularizing estimators. To regulate the estimator:</p><div><ul class="itemizedlist"><li class="listitem">We need to exchange increased bias for reduced variance</li><li class="listitem">An effective regularizer is one that makes a profitable exchange, which means it decreases the variance drastically whilst not excessively expanding the bias</li></ul></div><p class="calibre11">In overfitting and generalization we concentrate on these situations for the model that we are training:</p><div><ul class="itemizedlist"><li class="listitem">Avoid the true information on the producing process to take into account the overfitting and inducing bias</li><li class="listitem">Include the true information on the producing process</li><li class="listitem">Include information on the producing process and additionally numerous other information on producing processes to take into account the overfitting where variance instead of bias rules the estimation error</li></ul></div><p class="calibre11">The objective of regularization is to take a model to the second process that is mentioned.</p><p class="calibre11">An excessively complex model family does not, as a matter of course, incorporate the target function or the genuine information producing process. In any case, most utilizations of deep-learning algorithms are where the genuine information producing procedure is in all likelihood outside the model family. Deep learning algorithms are normally connected, to a great degree, to complicated use cases such as image recognition, speech recognition, self-driving cars, and so on.</p><p class="calibre11">This means that controlling the complexity of the nature of the model is not just a matter of finding a model of the appropriate size with the right set of parameters.</p></div><div><div><div><div><h2 class="title3"><a id="ch11lvl2sec143" class="pcalibre pcalibre3 pcalibre2 pcalibre1 calibre9"/>Optimizing deep learning models</h2></div></div></div><p class="calibre11">Optimization methods are vital in designing algorithms to extract desired knowledge from huge volumes of data. Deep learning is a rapidly evolving field where new optimization techniques are generated.</p><p class="calibre11">Deep learning algorithms include enhancement in numerous connections. For instance, performing deduction in models, for example, PCA, includes taking care of an improvement issue.</p><p class="calibre11">We regularly utilize diagnostic optimization to compose verifications or configuration calculations. Of the majority of the numerous optimization issues required in deep learning, the most difficult is preparing the neural network.</p><p class="calibre11">It is very common to contribute days, or even months, of time to many machines with a specific end goal to solve even a single case of the neural system-training problem. Since this issue is so critical and thus expensive, a specific arrangement of optimization strategies has been produced for enhancing it.</p><div><div><div><div><h3 class="title5"><a id="ch11lvl3sec95" class="pcalibre pcalibre3 pcalibre2 pcalibre1 calibre9"/>The case of optimization</h3></div></div></div><p class="calibre11">To find the parameters θ of a neural network that significantly lessen a cost function J(θ), commonly incorporates an execution measure assessed on the whole training set and additionally extra regularization terms.</p><p class="calibre11">An optimization used as a training algorithm for a machine learning task is different from immaculate optimization. More complex algorithms adjust their learning rates amid training or influence data contained in the second derivatives of the cost function. Finally, a few optimization methodologies are created by joining basic optimization algorithms into higher-level strategies.</p><p class="calibre11">Optimization algorithms utilized for the training of deep learning models are different from conventional optimization algorithms in a few ways:</p><div><ul class="itemizedlist"><li class="listitem">Machine learning typically acts in a roundabout way. In most machine-learning situations, we think about some execution measure <em class="calibre23">P</em>, that is defined as for the test set and may likewise be obstinate. We accordingly upgrade <em class="calibre23">P</em> just in a roundabout way. We decrease a different cost function <em class="calibre23">J(θ) </em>with the expectation that doing so will enhance <em class="calibre23">P</em>.</li></ul></div><p class="calibre11">This is as opposed to pure optimization, where minimizing <em class="calibre23">J</em> is an objective all by itself. Optimization algorithms for preparing deep learning models likewise commonly incorporate some specialization on the specific structure of machine learning target functions.</p></div></div></div></div>



  
<div><div><div><div><div><h1 class="title1"><a id="ch11lvl1sec85" class="pcalibre pcalibre3 pcalibre2 pcalibre1 calibre9"/>Implementation in Julia</h1></div></div></div><p class="calibre11">There are many good and tested libraries for deep learning in popular programming languages:</p><div><ul class="itemizedlist"><li class="listitem">Theano (Python)  can utilize both CPU and GPU (from the MILA Lab at the University of Montreal)</li><li class="listitem">Torch (Lua) is a Matlab-like environment (from Ronan Collobert, Clement Farabet, and Koray Kavukcuoglu)</li><li class="listitem">Tensorflow (Python) makes use of data flow graphs</li><li class="listitem">MXNet (Python, R, Julia, C++)</li><li class="listitem">Caffe is the most popular and widely used</li><li class="listitem">Keras (Python) based on Theano</li><li class="listitem">Mocha (Julia) by Chiyuan Zhang</li></ul></div><p class="calibre11">We will mainly go through Mocha for Julia, which is an amazing package written by Chiyuan Zhang, a PhD student at MIT.</p><p class="calibre11">To start, add the package as follows:</p><pre class="programlisting">
<strong class="calibre19">Pkg.update() 
Pkg.add("Mocha") 
</strong>
</pre><div><div><div><div><h2 class="title3"><a id="ch11lvl2sec144" class="pcalibre pcalibre3 pcalibre2 pcalibre1 calibre9"/>Network architecture</h2></div></div></div><p class="calibre11">Network architecture in Mocha refers to a set of layers:</p><pre class="programlisting">data_layer = HDF5DataLayer(name="data", source="data-list.txt", batch_size=64, tops=[:data]) 
ip_layer   = InnerProductLayer(name="ip", output_dim=500, tops=[:ip], bottoms=[:data]) 
</pre><div><ul class="itemizedlist"><li class="listitem">The input of the <code class="literal">ip_layer</code> has the same name as the output of the <code class="literal">data_layer</code></li><li class="listitem">The same name connects them</li></ul></div><p class="calibre11">A topological sort is carried out by Mocha on a collection of layers.</p></div><div><div><div><div><h2 class="title3"><a id="ch11lvl2sec145" class="pcalibre pcalibre3 pcalibre2 pcalibre1 calibre9"/>Types of layers</h2></div></div></div><div><ul class="itemizedlist"><li class="listitem">Data layers<div><ul class="itemizedlist1"><li class="listitem">These layers read information from the source and feed them to the top layers</li></ul></div><p class="calibre44">
</p></li><li class="listitem">Computation layers<div><ul class="itemizedlist1"><li class="listitem">These take the input stream from the base layers, do the calculations, and feed the results generated to the top layers</li></ul></div><p class="calibre44">
</p></li><li class="listitem">Loss layers<div><ul class="itemizedlist1"><li class="listitem">These layers take processed results (and ground truth names/labels) from the base layers and figure a scalar loss value</li><li class="listitem">Loss values from all the layers and regularizers in a net are included to characterize the final loss function of the net</li><li class="listitem">The net parameters in the back propagation are trained with the help of the loss function</li></ul></div><p class="calibre44">
</p></li><li class="listitem">Statistics layers<div><ul class="itemizedlist1"><li class="listitem">These take information from the base layers and generate valuable insights like classification accuracy</li><li class="listitem">Insights are gathered all through the various iterations</li><li class="listitem"><code class="literal">reset_statistics</code> can be utilized to unequivocally reset the statistics aggregation</li></ul></div><p class="calibre44">
</p></li><li class="listitem">Utility Layers</li></ul></div></div><div><div><div><div><h2 class="title3"><a id="ch11lvl2sec146" class="pcalibre pcalibre3 pcalibre2 pcalibre1 calibre9"/>Neurons (activation functions)</h2></div></div></div><p class="calibre11">Let's understand real neural nets (brains). Neuroscience is the study of the functioning of the brain and has given us good evidence about the way in which it works. Neurons are the real information storage of the brain. It is also very important to understand their connection strengths, namely how strongly one neuron can influence those neurons connected to it.</p><p class="calibre11">Learning or the repetition of a task and exposure to new stimulating procedures or environment often leads to activity in the brain which is actually the neurons acting according to the new data being received.</p><p class="calibre11">The neurons, and therefore the brain, behave very differently to different stimuli and environments. They may react or get excited more in some scenarios as compared to others.</p><p class="calibre11">Some understanding of this is important in getting to know about artificial neural networks:</p><div><ul class="itemizedlist"><li class="listitem">Neurons can be connected to any layer</li><li class="listitem">The neuron of every layer will influence the yield in the forward pass and the slope in the backward pass consequently, unless it is an identity neuron</li><li class="listitem">By default, layers have an identity neuron</li></ul></div><p class="calibre11">Let's go through the various types of neurons that we can utilize to make the network:</p><div><ul class="itemizedlist"><li class="listitem"><code class="literal">class Neurons.Identity</code><div><ul class="itemizedlist1"><li class="listitem">This is an activation function whose input is not changed.</li></ul></div><p class="calibre44">
</p></li><li class="listitem"><code class="literal">class Neurons.ReLU</code><div><ul class="itemizedlist1"><li class="listitem">Rectified Linear Unit. Amid the forward pass, this restrains all restraints underneath some limit <em class="calibre23">ϵ</em>, normally 0.</li><li class="listitem">It processes point-wise <em class="calibre23">y=max(ϵ,x)</em>.</li></ul></div><p class="calibre44">
</p></li><li class="listitem"><code class="literal">class Neurons.LreLU</code><div><ul class="itemizedlist1"><li class="listitem">Leaky Rectified Linear Unit. A Leaky ReLU can settle the "dying ReLU" issue.</li><li class="listitem">ReLU's can "die" if a sufficiently substantial gradient changes the weights such that the neuron never activates on new information.</li></ul></div><p class="calibre44">
</p></li><li class="listitem"><code class="literal">class Neurons.Sigmoid</code><div><ul class="itemizedlist1"><li class="listitem">Sigmoid is a smoothed step function</li><li class="listitem">It produces roughly 0 for negative information with vast absolute values and estimated 1 for huge positive inputs</li><li class="listitem">The point-wise equation is <em class="calibre23">y=1/(1+e−x)y=1/(1+e−x)</em></li></ul></div><p class="calibre44">
</p></li><li class="listitem"><code class="literal">class Neurons.Tanh</code><div><ul class="itemizedlist1"><li class="listitem">Tanh is a variation of Sigmoid</li><li class="listitem">It takes values in <em class="calibre23">±1±1</em> rather than the unit interim</li><li class="listitem">The point-wise equation is <em class="calibre23">y=(1−e−2x)/(1+e−2x)</em></li></ul></div><p class="calibre44">
</p></li></ul></div><p class="calibre11">
</p><div><img src="img/image_11_003.jpg" alt="Neurons (activation functions)" class="calibre222"/></div><p class="calibre11">
</p></div><div><div><div><div><h2 class="title3"><a id="ch11lvl2sec147" class="pcalibre pcalibre3 pcalibre2 pcalibre1 calibre9"/>Understanding regularizers for ANN</h2></div></div></div><p class="calibre11">We studied regularizers in our previous sections. Regularizers include additional penalties or restrictions for network parameters to confine the complexity of the model. In a popular deep-learning framework, caffe, it is known as decay.</p><p class="calibre11">Weight decay and regularization are comparable in back-propagation. The theoretical contrast in the forward pass is that when regarded as weight decay, they are not considered as being a piece of the objective function.</p><p class="calibre11">By default, Mocha similarly eliminates the forward calculation for regularizers with a specific end goal to decrease the quantity of calculations. We utilize the term regularization rather than weight decay since it is less demanding to comprehend.</p><div><ul class="itemizedlist"><li class="listitem">class <code class="literal">NoRegu</code>: No regularization</li><li class="listitem">class <code class="literal">L2Regu</code>: L2 regularizer</li><li class="listitem">class <code class="literal">L1Regu</code>:  L1 regularizer</li></ul></div></div><div><div><div><div><h2 class="title3"><a id="ch11lvl2sec148" class="pcalibre pcalibre3 pcalibre2 pcalibre1 calibre9"/>Norm constraints</h2></div></div></div><p class="calibre11">Norm restrictions are a more immediate method for limiting the complexity of the model by unequivocally contracting the parameters in each of the n cycles if the standard or norm of the parameters surpasses a given threshold.</p><div><ul class="itemizedlist"><li class="listitem">class <code class="literal">NoCons</code>: No constraints</li><li class="listitem">class <code class="literal">L2Cons</code>: Restrict the Euclidean norm of parameters. Threshold and contracting are applied to every parameter. In particular, the threshold is applied to each filter for the filters parameter of a convolution layer.</li></ul></div></div><div><div><div><div><h2 class="title3"><a id="ch11lvl2sec149" class="pcalibre pcalibre3 pcalibre2 pcalibre1 calibre9"/>Using solvers in deep neural networks</h2></div></div></div><p class="calibre11">Mocha contains broadly useful stochastic (sub-) gradient-based solvers. These can be utilized to prepare deep neural networks.</p><p class="calibre11">A solver is developed by indicating a lexicon of solver parameters that give vital configuration:</p><div><ul class="itemizedlist"><li class="listitem">General settings like stop conditions</li><li class="listitem">Parameters particular to a specific calculation</li></ul></div><p class="calibre11">Additionally, it is generally recommended to take some short breaks between training iterations to print progress or for saving a snapshot. These are called coffee breaks in Mocha.</p><p class="calibre11">
<strong class="calibre19">Solver algorithms</strong>
</p><div><ul class="itemizedlist"><li class="listitem">class <code class="literal">SGD</code>: Stochastic Gradient Descent with momentum.<div><ul class="itemizedlist1"><li class="listitem"><code class="literal">lr_policy</code>: Learning rate policy.</li><li class="listitem"><code class="literal">mom_policy</code>: Momentum policy.</li></ul></div><p class="calibre44">
</p></li><li class="listitem">class <code class="literal">Nesterov</code>: Stochastic Nesterov accelerated gradient method.<div><ul class="itemizedlist1"><li class="listitem"><code class="literal">lr_policy</code>: Learning rate policy.</li><li class="listitem"><code class="literal">mom_policy</code>: Momentum policy.</li></ul></div><p class="calibre44">
</p></li><li class="listitem">class <code class="literal">Adam</code>: A Method for Stochastic Optimization<div><ul class="itemizedlist1"><li class="listitem"><code class="literal">lr_policy</code>: Learning rate policy.</li><li class="listitem"><code class="literal">beta1</code>: Exponential decay factor for first order moment estimates. <em class="calibre23">0&lt;=beta1&lt;1</em>, default <em class="calibre23">0.9</em></li><li class="listitem"><code class="literal">beta2</code>: Exponential decay factor for second order moment estimates, <em class="calibre23">0&lt;=beta1&lt;1</em>, default <em class="calibre23">0.999</em>.</li><li class="listitem"><code class="literal">epsilon</code>: Affects the scaling of the parameter updates for numerical conditioning, default <em class="calibre23">1e-8</em>.</li></ul></div><p class="calibre44">
</p></li></ul></div></div><div><div><div><div><h2 class="title3"><a id="ch11lvl2sec150" class="pcalibre pcalibre3 pcalibre2 pcalibre1 calibre9"/>Coffee breaks</h2></div></div></div><p class="calibre11">Training can become a very computationally intensive iteration of several loops. It is generally recommended to take some short breaks between training iterations to print progress or for saving a snapshot. These are called coffee breaks in Mocha. They are performed as follows:</p><pre class="programlisting"># report training progress every 1000 iterations 
add_coffee_break(solver, TrainingSummary(), every_n_iter=1000) 
 
# save snapshots every 5000 iterations 
add_coffee_break(solver, Snapshot(exp_dir), every_n_iter=5000) 
</pre><p class="calibre11">This prints the training summary every 1,000 iterations and saves a snapshot every 5,000 iterations.</p></div><div><div><div><div><h2 class="title3"><a id="ch11lvl2sec151" class="pcalibre pcalibre3 pcalibre2 pcalibre1 calibre9"/>Image classification with pre-trained Imagenet CNN</h2></div></div></div><p class="calibre11">MNIST is a handwritten digit recognition dataset. It contains the following:</p><div><ul class="itemizedlist"><li class="listitem">60,000 training examples</li><li class="listitem">10,000 test examples</li><li class="listitem">28 x 28 single channel grayscale images</li></ul></div><p class="calibre11">We can use <code class="literal">get-mnist.sh</code> script to download the dataset</p><p class="calibre11">It calls <code class="literal">mnist.convert.jl</code> to convert the binary dataset into a HDF5 file that Mocha can read.</p><p class="calibre11">
<code class="literal">data/train.hdf5</code> and <code class="literal">data/test.hdf5</code> will be generated when the conversion finishes.</p><p class="calibre11">We are using Mocha's native extension here to get faster convolution:</p><pre class="programlisting">ENV["MOCHA_USE_NATIVE_EXT"] = "true" 
 
using Mocha 
 
backend = CPUBackend() 
init(backend) 
</pre><p class="calibre11">This configures Mocha to use the native background and not the GPU (CUDA).</p><p class="calibre11">Now, we will proceed with defining the network structure. We will start by defining a data layer that will read the HDF5 file. This will be the input for the network.</p><p class="calibre11">The <code class="literal">source</code> contains a list of real data files:</p><pre class="programlisting">data_layer  = HDF5DataLayer(name="train-data", source="data/train.txt", 
batch_size=64, shuffle=true) 
</pre><p class="calibre11">Mini-batches are formed to process the data. As the batch size increases, the variance decreases but it affects the computational performance.</p><p class="calibre11">Shuffling reduces the effect of ordering during the training.</p><p class="calibre11">Now we will proceed with defining the convolution layer:</p><pre class="programlisting">conv_layer = ConvolutionLayer(name="conv1", n_filter=20, kernel=(5,5), 
bottoms=[:data], tops=[:conv1]) 
</pre><div><ul class="itemizedlist"><li class="listitem"><code class="literal">name</code>: The name of the layer to identify it.</li><li class="listitem"><code class="literal">n_filter</code>: The number of convolution filters.</li><li class="listitem"><code class="literal">kernel</code>: The size of the filter.</li><li class="listitem"><code class="literal">bottoms</code>: An array to define where to get the input. (The HDF5 data layer that we defined.)</li><li class="listitem"><code class="literal">tops</code>: The output of the convolution layer.</li></ul></div><p class="calibre11">Define more convolution layers as follows:</p><pre class="programlisting">pool_layer = PoolingLayer(name="pool1", kernel=(2,2), stride=(2,2), 
    bottoms=[:conv1], tops=[:pool1]) 
conv2_layer = ConvolutionLayer(name="conv2", n_filter=50, kernel=(5,5), 
    bottoms=[:pool1], tops=[:conv2]) 
pool2_layer = PoolingLayer(name="pool2", kernel=(2,2), stride=(2,2), 
    bottoms=[:conv2], tops=[:pool2]) 
</pre><p class="calibre11">These are two fully connected layers after convolution and pooling layers.</p><p class="calibre11">The computation to create the layer is an inner product between the input and the layer weights. These are also called an <code class="literal">InnerProductLayer</code>.</p><p class="calibre11">The layer weights are also learned, so we also give names to the two layers:</p><pre class="programlisting">fc1_layer  = InnerProductLayer(name="ip1", output_dim=500, 
    neuron=Neurons.ReLU(), bottoms=[:pool2], tops=[:ip1]) 
fc2_layer  = InnerProductLayer(name="ip2", output_dim=10, 
    bottoms=[:ip1], tops=[:ip2]) 
</pre><p class="calibre11">The last inner product layer has the dimension of 10, which represents the number of classes (digits 0~9).</p><p class="calibre11">This is the basic structure of LeNet. To train this network, we will define a loss function by adding a loss layer:</p><pre class="programlisting">loss_layer = SoftmaxLossLayer(name="loss", bottoms=[:ip2,:label]) 
</pre><p class="calibre11">We can now construct our network:</p><pre class="programlisting">common_layers = [conv_layer, pool_layer, conv2_layer, pool2_layer, 
    fc1_layer, fc2_layer] 
 
net = Net("MNIST-train", backend, [data_layer, common_layers..., loss_layer]) 
</pre><p class="calibre11">Training the neural network with Stochastic Gradient Descent is performed as follows:</p><pre class="programlisting">exp_dir = "snapshots" 
method = SGD() 
 
params = make_solver_parameters(method, max_iter=10000, regu_coef=0.0005, 
    mom_policy=MomPolicy.Fixed(0.9), 
    lr_policy=LRPolicy.Inv(0.01, 0.0001, 0.75), 
    load_from=exp_dir) 
 
solver = Solver(method, params) 
</pre><p class="calibre11">The parameters used are:</p><div><ul class="itemizedlist"><li class="listitem"><code class="literal">max_iter</code>: These are the maximum number of iterations the solver will execute to train the network</li><li class="listitem"><code class="literal">regu_coef</code>: The regularization coefficient</li><li class="listitem"><code class="literal">mom_policy</code>: The momentum policy</li><li class="listitem"><code class="literal">lr_policy</code>: The learning rate policy</li><li class="listitem"><code class="literal">load_from</code>: Here we can load the saved model from a file or a directory</li></ul></div><p class="calibre11">Add some coffee breaks as follows:</p><pre class="programlisting">setup_coffee_lounge(solver, save_into="$exp_dir/statistics.hdf5", every_n_iter=1000) 
 
add_coffee_break(solver, TrainingSummary(), every_n_iter=100) 
 
add_coffee_break(solver, Snapshot(exp_dir), every_n_iter=5000) 
</pre><p class="calibre11">Performance is checked periodically on a separate validation set so we can see the progress. The validation dataset that we have will be used as the test dataset.</p><p class="calibre11">To perform an evaluation, a new network is defined with the same architecture but a different data layer, which will get the input from the validation set:</p><pre class="programlisting">data_layer_test = HDF5DataLayer(name="test-data", source="data/test.txt", batch_size=100) 
 
acc_layer = AccuracyLayer(name="test-accuracy", bottoms=[:ip2, :label]) 
 
test_net = Net("MNIST-test", backend, [data_layer_test, common_layers..., acc_layer]) 
</pre><p class="calibre11">Add a coffee break to get the report of the validation performance, as follows:</p><pre class="programlisting">add_coffee_break(solver, ValidationPerformance(test_net), every_n_iter=1000) 
</pre><p class="calibre11">Finally, start the training, as follows:</p><pre class="programlisting">solve(solver, net) 
 
destroy(net) 
destroy(test_net) 
shutdown(backend)  
</pre><p class="calibre11">These are the two networks we created:</p><p class="calibre11">
</p><div><img src="img/image_11_004.jpg" alt="Image classification with pre-trained Imagenet CNN" class="calibre223"/></div><p class="calibre11">
</p><p class="calibre11">Now we run the model generated on the test data that we have. We get the following output:</p><pre class="programlisting">
<strong class="calibre19">Correct label index: 5</strong>
<strong class="calibre19">Label probability vector:</strong>
<strong class="calibre19">Float32[5.870685e-6</strong>
<strong class="calibre19">0.00057068263</strong>
<strong class="calibre19">1.5419962e-5</strong>
<strong class="calibre19">8.387835e-7</strong>
<strong class="calibre19">0.99935246</strong>
<strong class="calibre19">5.5915066e-6</strong>
<strong class="calibre19">4.284061e-5</strong>
<strong class="calibre19">1.2896479e-6</strong>
<strong class="calibre19">4.2869314e-7</strong>
<strong class="calibre19">4.600691e-6]</strong>
</pre></div></div></div>



  
<div><div><div><div><div><h1 class="title1"><a id="ch11lvl1sec86" class="pcalibre pcalibre3 pcalibre2 pcalibre1 calibre9"/>Summary</h1></div></div></div><p class="calibre11">In this chapter, we learned about deep learning and how different it is from machine learning. Deep learning refers to a class of machine learning techniques that perform unsupervised or supervised feature extraction and pattern analysis or classification by exploiting multiple layers of non-linear information processing.</p><p class="calibre11">We studied deep feedforward networks, regularization, and optimizing deep learning models. We also learned how to create a neural network to classify hand-written digits using Mocha in Julia.</p></div></div>



  
<div><div><div><div><div><h1 class="title1"><a id="ch11lvl1sec87" class="pcalibre pcalibre3 pcalibre2 pcalibre1 calibre9"/>References</h1></div></div></div><div><ul class="itemizedlist"><li class="listitem"><a class="calibre4 pcalibre3 pcalibre pcalibre1 pcalibre2" href="http://docs.julialang.org/en/release-0.4/manual/">http://docs.julialang.org/en/release-0.4/manual/</a></li><li class="listitem"><a class="calibre4 pcalibre3 pcalibre pcalibre1 pcalibre2" href="https://github.com/pluskid/Mocha.jl">https://github.com/pluskid/Mocha.jl</a></li><li class="listitem"><a class="calibre4 pcalibre3 pcalibre pcalibre1 pcalibre2" href="http://psych.utoronto.ca/users/reingold/courses/ai/nn.html">http://psych.utoronto.ca/users/reingold/courses/ai/nn.html</a></li><li class="listitem"><a class="calibre4 pcalibre3 pcalibre pcalibre1 pcalibre2" href="https://www.microsoft.com/en-us/research/wp-content/uploads/2016/02/DeepLearning-NowPublishing-Vol7-SIG-039.pdf">https://www.microsoft.com/en-us/research/wp-content/uploads/2016/02/DeepLearning-NowPublishing-Vol7-SIG-039.pdf</a></li><li class="listitem"><a class="calibre4 pcalibre3 pcalibre pcalibre1 pcalibre2" href="http://www.deeplearningbook.org/contents/intro.html">http://www.deeplearningbook.org/contents/intro.html</a></li><li class="listitem"><a class="calibre4 pcalibre3 pcalibre pcalibre1 pcalibre2" href="http://deeplearning.net/tutorial/deeplearning.pdf">http://deeplearning.net/tutorial/deeplearning.pdf</a></li></ul></div></div></div>



  </body></html>