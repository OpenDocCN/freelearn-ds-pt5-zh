- en: '*Preface*'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: About
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: This section briefly introduces the authors, the what this book covers, the
    technical skills you'll need to get started, and the hardware and software requirements
    required to complete the activities and exercises.
  prefs: []
  type: TYPE_NORMAL
- en: About the Book
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Processing big data in real time is challenging due to scalability, information
    inconsistency, and fault tolerance. Big Data Analysis with Python teaches you
    how to use tools that can control this data avalanche for you. With this book,
    you'll learn practical techniques to aggregate data into useful dimensions for
    posterior analysis, extract statistical measurements, and transform datasets into
    features for other systems.
  prefs: []
  type: TYPE_NORMAL
- en: The book begins with an introduction to data manipulation in Python using pandas.
    You'll then get familiar with statistical analysis and plotting techniques. With
    multiple hands-on activities in store, you'll be able to analyze data that is
    distributed on several computers by using Dask. As you progress, you'll study
    how to aggregate data for plots when the entire data cannot be accommodated in
    memory. You'll also explore Hadoop (HDFS and YARN), which will help you tackle
    larger datasets. The book also covers Spark and explains how it interacts with
    other tools.
  prefs: []
  type: TYPE_NORMAL
- en: By the end of this book, you'll be able to bootstrap your own Python environment,
    process large files, and manipulate data to generate statistics, metrics, and
    graphs.
  prefs: []
  type: TYPE_NORMAL
- en: About the Authors
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '**Ivan Marin** is a systems architect and data scientist working at Daitan
    Group, a Campinas-based software company. He designs big data systems for large
    volumes of data and implements machine learning pipelines end to end using Python
    and Spark. He is also an active organizer of data science, machine learning, and
    Python in SÃ£o Paulo, and has given Python for data science courses at university
    level.'
  prefs: []
  type: TYPE_NORMAL
- en: '**Ankit Shukla** is a data scientist working with World Wide Technology, a
    leading US-based technology solution provider, where he develops and deploys machine
    learning and artificial intelligence solutions to solve business problems and
    create actual dollar value for clients. He is also part of the company''s R&D
    initiative, which is responsible for producing intellectual property, building
    capabilities in new areas, and publishing cutting-edge research in corporate white
    papers. Besides tinkering with AI/ML models, he likes to read and is a big-time
    foodie.'
  prefs: []
  type: TYPE_NORMAL
- en: '**Sarang VK** is a lead data scientist at StraitsBridge Advisors, where his
    responsibilities include requirement gathering, solutioning, development, and
    productization of scalable machine learning, artificial intelligence, and analytical
    solutions using open source technologies. Alongside this, he supports pre-sales
    and competency.'
  prefs: []
  type: TYPE_NORMAL
- en: Learning Objectives
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Use Python to read and transform data into different formats
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Generate basic statistics and metrics using data on disk
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Work with computing tasks distributed over a cluster
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Convert data from various sources into storage or querying formats
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Prepare data for statistical analysis, visualization, and machine learning
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Present data in the form of effective visuals
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Approach
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Big Data Analysis with Python takes a hands-on approach to understanding how
    to use Python and Spark to process data and make something useful out of it. It
    contains multiple activities that use real-life business scenarios for you to
    practice and apply your new skills in a highly relevant context.
  prefs: []
  type: TYPE_NORMAL
- en: Audience
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Big Data Analysis with Python is designed for Python developers, data analysts,
    and data scientists who want to get hands-on with methods to control data and
    transform it into impactful insights. Basic knowledge of statistical measurements
    and relational databases will help you to understand various concepts explained
    in this book.
  prefs: []
  type: TYPE_NORMAL
- en: Minimum Hardware Requirements
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'For the optimal student experience, we recommend the following hardware configuration:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Processor: Intel or AMD 4-core or better'
  prefs: []
  type: TYPE_NORMAL
- en: 'Memory: 8 GB RAM'
  prefs: []
  type: TYPE_NORMAL
- en: 'Storage: 20 GB available space'
  prefs: []
  type: TYPE_NORMAL
- en: Software Requirements
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: You'll need the following software installed in advance.
  prefs: []
  type: TYPE_NORMAL
- en: 'Any of the following operating systems:'
  prefs: []
  type: TYPE_NORMAL
- en: Windows 7 SP1 32/64-bit
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Windows 8.1 32/64-bit or Windows 10 32/64-bit
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Ubuntu 14.04 or later
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: macOS Sierra or later
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Browser: Google Chrome or Mozilla Firefox'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Jupyter lab
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'You''ll also need the following software installed in advance:'
  prefs: []
  type: TYPE_NORMAL
- en: Python 3.5+
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Anaconda 4.3+
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'These Python libraries are included with the Anaconda installation:'
  prefs: []
  type: TYPE_NORMAL
- en: matplotlib 2.1.0+
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: iPython 6.1.0+
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: requests 2.18.4+
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: NumPy 1.13.1+
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: pandas 0.20.3+
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: scikit-learn 0.19.0+
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: seaborn 0.8.0+
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: bokeh 0.12.10+
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'These Python libraries require manual installation:'
  prefs: []
  type: TYPE_NORMAL
- en: mlxtend
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: version_information
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: ipython-sql
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: pdir2
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: graphviz
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Conventions
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'Code words in text, database table names, folder names, filenames, file extensions,
    pathnames, dummy URLs, user input, and Twitter handles are shown as follows: "To
    transform the data into the right data types, we can use conversion functions,
    such as `to_datetime`, `to_numeric`, and `astype`."'
  prefs: []
  type: TYPE_NORMAL
- en: 'A block of code is set as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: 'New terms and important words are shown in bold. Words that you see on the
    screen, for example, in menus or dialog boxes, appear in the text like this: "**Pandas**
    ([https://pandas.pydata.org](https://pandas.pydata.org)) is a data manipulation
    and analysis library that''s widely used in the data science community."'
  prefs: []
  type: TYPE_NORMAL
- en: Installation and Setup
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'Installing Anaconda:'
  prefs: []
  type: TYPE_NORMAL
- en: Visit [https://www.anaconda.com/download/](https://www.anaconda.com/download/)
    in your browser.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Click on Windows, Mac, or Linux, depending on the OS you are working on.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Next, click on the Download option. Make sure you download the latest version.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Open the installer after download.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Follow the steps in the installer and that's it! Your Anaconda distribution
    is ready.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'PySpark is available on PyPi. To install PySpark run the following command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: 'Updating Jupyter and installing dependencies:'
  prefs: []
  type: TYPE_NORMAL
- en: Search for Anaconda Prompt and open it.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Type the following commands to update Conda and Jupyter:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'To open Jupyter Notebook from Anaconda Prompt, use the following command:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: Installing the Code Bundle
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Copy the code bundle for the class to the `C:/Code` folder.
  prefs: []
  type: TYPE_NORMAL
- en: Additional Resources
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'The code bundle for this book is also hosted on GitHub at: [https://github.com/TrainingByPackt/Big-Data-Analysis-with-Python](https://github.com/TrainingByPackt/Big-Data-Analysis-with-Python).'
  prefs: []
  type: TYPE_NORMAL
- en: We also have other code bundles from our rich catalog of books and videos available
    at [https://github.com/PacktPublishing/](https://github.com/PacktPublishing/).
    Check them out!
  prefs: []
  type: TYPE_NORMAL
