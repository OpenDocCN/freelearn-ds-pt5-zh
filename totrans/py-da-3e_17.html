<html><head></head><body>
        <section>

                            <header class="header-title chapter-title">
                    Analyzing Image Data
                </header>
            
            <article>
                
<p>We are in the age of information, where every movement will generate data in a variety of formats, such as text, images, geospatial data, and videos. Smartphones have reached rural areas of the world and people are capturing activities, especially in images and videos, and sharing them on social media platforms. This is how lots of big chunks of data are generated and most of the data is in image and video formats. Industry and research institutes want to analyze image and video datasets to generate value and make automated solutions to reduce costs. Image processing and computer vision are fields that explore and develop image- and video-based solutions. There are lots of opportunities for research, innovation, and start-ups in the area of computer vision. In this chapter, we focus on the basics of image processing to build your fundamental knowledge in the computer vision area.</p>
<p>Image processing is a subset of computer vision. Computer vision is an advanced and more powerful field within machine learning and artificial intelligence. Computer vision offers enormous applications, such as detecting objects, classifying images and objects, image captioning, and image segmentation. <span>An image can be defined as two-dimensional signals in signal processing, a set of points in 2D or 3D in geometry, and a two-dimensional or three-dimensional NumPy array in Python. </span>Image processing refers to processing image data and performing operations such as drawing, writing, resizing, flipping, blurring, changing the brightness, and detecting faces. In this chapter, we will focus on all these image processing operations in detail.</p>
<p>We will cover the following topics in this chapter:</p>
<ul>
<li>Installing OpenCV</li>
<li>Understanding image data</li>
<li>Color models</li>
<li>Drawing on images</li>
<li>Writing on images</li>
<li>Resizing images</li>
<li>Flipping images</li>
</ul>
<ul>
<li>Changing the brightness</li>
<li>Blurring an image</li>
<li>Face detection</li>
</ul>
<h1 id="uuid-56b84cae-21d4-4b95-8ba4-91f6b1e8a86c">Technical requirements</h1>
<p>This chapter has the following technical requirements:</p>
<ul>
<li>You can find the code, face classifier file, and the datasets at the following Github link:<a href="https://github.com/PacktPublishing/Python-Data-Analysis-Third-Edition/tree/master/Chapter13"> https://github.com/PacktPublishing/Python-Data-Analysis-Third-Edition/tree/master/Chapter13</a><a href="https://github.com/PacktPublishing/Python-Data-Analysis-Third-Edition/tree/master/Python-Data-Analysis-Third-Edition/Ch13"><span>.</span></a></li>
<li>All the code blocks are available in the<span> </span><kbd>ch13.ipynb</kbd> file.  </li>
<li>This chapter uses <kbd>.jpg</kbd>/<kbd>.jpeg</kbd> files (<kbd>google.jpg</kbd>, <kbd>image.jpg</kbd>, <kbd>messi.png</kbd>, <kbd>nature.jpeg</kbd>, <kbd>barcelona.jpeg</kbd>, and <kbd>tajmahal.jpg</kbd>) for practice purposes.</li>
<li>This chapter uses one face classifier XML file (<kbd>haarcascade_frontalface_default.xml</kbd>).</li>
<li>In this chapter, we will use the OpenCV, NumPy, and matplotlib<span> Python libraries.</span></li>
</ul>
<h1 id="uuid-f228bab1-100b-41f2-acdf-4378dd92a2d5">Installing OpenCV</h1>
<p>OpenCV is an open source library for computer vision operations such as image and video analysis. OpenCV is primarily developed by Intel in C++ and offers interfaces with Python, Java, and Matlab. OpenCV has the following features:</p>
<ul>
<li>It is an open source image processing Python library.</li>
<li>OpenCV is the core Python library for image processing and computer vision.</li>
<li>OpenCV is easy to learn and deploy with web and mobile applications.</li>
<li>OpenCV in Python is an API and wrapper around its C++ core implementation.</li>
<li>It is fast due to background C++ code.</li>
</ul>
<p>We  can install OpenCV using the following command:</p>
<pre><strong>pip install opencv-python</strong></pre>
<p>Using the preceding pip command, we can easily install OpenCV. OpenCV is the most popular library for image processing and computer vision tasks. It offers various use cases related to image analysis operations such as improving image quality, filtering and transforming images, drawing on images, changing colors, detecting faces and objects, identifying human actions, tracking objects, analyzing motion, and finding similar images.  After installing the OpenCV library, it's time to understand the basics of image processing.</p>
<h1 id="uuid-3e45240e-6108-450e-91f7-4327529c33dc">Understanding image data</h1>
<p>Image data is a two-dimensional array or function <kbd>f(x,y)</kbd> with spatial coordinates. The amplitude of the <kbd>coordinate(x,y)</kbd> is known as intensity. In Python, an image is a 2D or 3D NumPy array with pixel values. Pixels are the smallest, core tiny picture elements, which decide the image quality. A large number of pixels results in a higher resolution. Also, there are various image formats available, such as <kbd>.</kbd><kbd>jpeg</kbd>, <kbd>.png</kbd>, <kbd>.gif</kbd>, and <kbd>.tiff</kbd>. These file formats are helpful in organizing and maintaining digital image files. Before analyzing image data, we need to understand the types of images. Image data can be of three types:</p>
<ul>
<li>Binary</li>
<li>Grayscale</li>
<li>Color</li>
</ul>
<h2 id="uuid-89a87932-9299-4972-980f-0e8c6658673b">Binary images</h2>
<p>Binary image pixels have only two colors, generally black and white. Binary image pixels take only binary values 0 or 1.</p>
<div class="CDPAlignCenter CDPAlign"><img src="assets/be833763-eeaf-4f2d-83e5-96cd7826d04e.png" style=""/></div>
<p class="mce-root"/>
<p>The preceding image is an example of a binary image. It has only two colors, black and white. It does not use shades of black and white.</p>
<h2 id="uuid-c4c40ceb-c312-4763-a327-6e78b8aa2239">Grayscale images</h2>
<p>A grayscale image looks like a black and white image. It is represented by 8 bits per pixel, that is, 256 intensity values or tones ranging from 0 to 255. These 256 shades move from pure black to pure white; 0 represents pure black while 255 represents the color white.</p>
<div class="CDPAlignCenter CDPAlign"><img src="assets/707a69e9-3a34-42f3-83a8-5b962598e35e.png" style=""/></div>
<p><span>The</span> preceding image is a grayscale image. It is a black and white image where shades move from <span>pure black to pure white. </span></p>
<h2 id="uuid-c363f6b3-7bdf-4b38-95df-5f3d551d2ad2">Color images</h2>
<p>Color images are a mixture of the primary colors red, blue, and green. These primary colors have the capability to form new colors by blending in certain proportions. Each color uses eight bits (intensity values between 0-255), that is, 24 bits per pixel. Let's take an example of a color image:</p>
<div class="mce-root CDPAlignCenter CDPAlign"><img src="assets/be37f829-ac45-43a3-aec0-8d91aedeae31.png" style=""/></div>
<p>In the preceding image file, we can see most of the color shades with different intensities. <span>After understanding the type of images, it's time to understand color models such as </span><span>RGB, CMYK, HSV, HSL, and grayscale. Let's jump to color models.</span></p>
<h1 id="uuid-06cfab82-86cd-4b32-b1d3-d5138c37d6fa">Color models</h1>
<p>Color models are a structure for processing and measuring the combination of primary colors. They help us to explain how colors will display on the computer screen or on paper. Color models can be of two types: additive or subtractive. Additive models are used for computer screens, for example, the RGB (red, green, and blue) model, and subtractive models are used for printing images, for example, the CMYK (cyan, magenta, yellow, and black) model:</p>
<div class="CDPAlignCenter CDPAlign"><img src="assets/abbdc731-fa1c-4e51-ad1b-301597242bd9.png" style=""/></div>
<p><span>There </span>are lots of models other than RGB and CMYK, such as HSV, HSL, and Gray Scale. HSV is an acronym for hue, saturation, and value. It is a three-dimensional color model, which is an improved version of the RGB model. In the HSV model, the top of the center axis is white, the bottom is black, and the remaining colors lie in between. Here, the hue is the angle, saturation is the distance from the center axis, and value is the distance from the bottom of the axis.</p>
<p>HSL is an acronym for hue, saturation, and lightness. The main difference between HSV and HSL is the amount of lightness and the value of colors from the center axis.</p>
<div class="CDPAlignCenter CDPAlign"><img src="assets/04a62af2-b68e-4586-ab6d-cf2789b9a00e.png" style=""/></div>
<p>Let's learn how to read and display the image file:</p>
<pre><span># Import cv2 latest version of OpenCV library <br/>import cv2<br/><br/># Import numeric python (NumPy) library
import numpy as np<br/></span><br/># Import matplotlib for showing the image <br/>import matplotlib.pyplot as plt <br/><br/># magic function to render the figure in a notebook <br/>%matplotlib inline <br/><br/># Read image using imread() function<br/>image = cv2.imread('google.jpg') <br/><br/># Let's check image data type<br/>print('Image Type:',type(image)) <br/><br/># Let's check dimension of image <br/>print('Image Dimension:',image.shape) <br/><br/># Let's show the image <br/>plt.imshow(image)<br/>plt.show()</pre>
<p><span>This results in the following output:</span></p>
<div class="CDPAlignCenter CDPAlign"><img src="assets/29a3e562-3c87-4a8c-9067-7307faf75f69.png" style=""/></div>
<p>In the preceding example, we imported <kbd>cv2</kbd>, NumPy, and <kbd>matplotlib.pyplot</kbd>. <kbd>cv2</kbd> is for image processing, NumPy is for arrays, and <kbd>matplotlib.pyplot</kbd> is for displaying an image. We read the image using the <kbd>imread()</kbd> function and returned an array of images. We can check its type using the <kbd>type()</kbd> function and its shape using the <kbd>shape</kbd> attribute of the NumPy array. We can display the image using the <kbd>show()</kbd> function of the <kbd>matpltlib.pyplot</kbd> module. The preceding image is not showing the correct colors of the Google logo image. This is because <kbd>imread()</kbd> reads images in the BGR color model. Lets convert BGR to the RGB color model using the <kbd>cvtColor()</kbd> function and passing tthe flag <kbd>cv2.COLOR_BGR2RGB</kbd>:</p>
<pre># Convert image color space BGR to RGB
rgb_image=cv2.cvtColor(image,cv2.COLOR_BGR2RGB)
<br/># Display the image
plt.imshow(rgb_image)
plt.show()</pre>
<p><span>This results in the following output:</span></p>
<div class="CDPAlignCenter CDPAlign"><img src="assets/52f718fb-86b0-4a87-a371-41e86a25057f.png" style=""/></div>
<p>Here, you can see the correct image in RGB format.</p>
<p>Let's write the image file on a local disk using the <kbd>imwrite()</kbd> function:</p>
<pre># Write image using imwrite()<br/>cv2.imwrite('image.jpg',image)<br/><br/><strong>Output:</strong> True</pre>
<p>In the preceding code block, we have written the image file on a local disk with the image name <kbd>image.jpg</kbd>. After understanding color models, it's time to learn how to draw elements on an image.</p>
<h1 id="uuid-e13f5402-4f94-46bc-88be-3b8783ea1868">Drawing on images</h1>
<p>Let's learn how to draw different figure shapes, such as a line, square, or triangle, on an image using OpenCV. When we draw any shape on an image, we need to take care of the coordinates, color, and thickness of the shape. Let's first create a blank image with a white or black background:</p>
<pre># Import cv2 latest version of OpenCV library
import cv2
<br/># Import numeric python (NumPy) library
import numpy as np
<br/># Import matplotlib for showing the image
import matplotlib.pyplot as plt
<br/># Magic function to render the figure in a notebook
%matplotlib inline
<br/># Let's create a black image
image_shape=(600,600,3)
black_image = np.zeros(shape=image_shape,dtype=np.int16)
<br/># Show the image
plt.imshow(black_image)</pre>
<p><span>This results in the following output:</span></p>
<div class="CDPAlignCenter CDPAlign"><img src="assets/ecdc3915-4e69-4fc3-ac05-c7c2abc70fd7.png" style=""/></div>
<p>In the preceding example, we created a blank image with a black background using the <kbd>zeros()</kbd> function of the NumPy module. The <kbd>zeros()</kbd> function creates an array of the given size and fills the matrix with zeros.</p>
<p>Let's create a blank image with a white background:</p>
<pre># Create a white image<br/>image_shape=(600,600,3)<br/>white_image = np.zeros(shape=image_shape,dtype=np.int16)<br/><br/># Set every pixel of the image to 255<br/>white_image.fill(255)<br/><br/># Show the image<br/>plt.imshow(white_image)</pre>
<p>This results in the following output:</p>
<div class="CDPAlignCenter CDPAlign"><img src="assets/fa9e9d82-e338-4be8-83d7-f8f96c6f1de2.png" style=""/></div>
<p>In the preceding example, we created a blank image with a white background using the <kbd>zeros()</kbd> function of the NumPy module and filled <span><span>the image </span></span>with 255 for each pixel. The <kbd>zeros()</kbd> function creates an array of the given size and fills the matrix with zeros. The <kbd>fill()</kbd> function assigns a given value to all the elements of the matrix. Let's draw a line using OpenCV on a black image:</p>
<pre># Draw a line on black image<br/>line = cv2.line(black_image,(599,0),(0,599),(0,255,0),4)<br/><br/># Show image<br/>plt.imshow(line)</pre>
<p>This results in the following output:</p>
<div class="CDPAlignCenter CDPAlign"><img src="assets/ad50b113-98f2-4ec4-83a6-95967e4c3ebf.png" style=""/></div>
<p>In the preceding example, we drew the green line on the black image using the <kbd>line()</kbd> function. The <kbd>line()</kbd> function takes the following arguments: image file, <kbd>start_point</kbd>, <kbd>end_point</kbd>, color, and thickness. In our example, the start and endpoints are <span>(599,0) and (0,599), the color tuple is</span> <span>(0,255,0), and the thickness is 4. Similarly, we can create a line on a white image. Let's see the following example:</span></p>
<pre># Let's draw a blue line on white image<br/><br/>line = cv2.line(white_image,(599,0),(0,599),(0,0,255),4)<br/># Show the image<br/>plt.imshow(line)</pre>
<p>This results in the following output:</p>
<div class="CDPAlignCenter CDPAlign"><img src="assets/b0f328e6-f9f3-47fc-9448-a3cea18c12e6.png" style=""/></div>
<p> </p>
<p>Let's see an example of drawing a circle on a white image:</p>
<pre># Let's create a white image<br/>img_shape=(600,600,3)<br/>white_image = np.zeros(shape=image_shape,dtype=np.int16)<br/><br/># Set every pixel of the image to 255<br/>white_image.fill(255)<br/><br/># Draw a red circle on white image<br/>circle=cv2.circle(white_image,(300, 300), 100, (255,0,0),6)<br/><br/># Show the image<br/>plt.imshow(circle)</pre>
<p>This results in the following output:</p>
<div class="CDPAlignCenter CDPAlign"><img src="assets/dc8f192c-851a-470b-956f-260e9843a5af.png" style=""/></div>
<p>In the preceding example, we created a white image and drew a circle using the <kbd>circle()</kbd> function. The <kbd>circle()</kbd> function takes the following arguments: image, <kbd>center_coordinates</kbd>, radius, color, and thickness. In our example, the center is <span>(300, 300), the radius is 100, a color tuple is (255,0,0), and the thickness is 6.</span></p>
<p>Let's see an example of drawing a rectangle on a black image:</p>
<pre># Let's create a black image<br/>img_shape=(600,600,3)<br/>black_image = np.zeros(shape=image_shape,dtype=np.int16)<br/><br/># Draw a green rectangle on black image<br/>rectangle= cv2.rectangle(black_image,(200,200),(400,500),(0,255,0),5)<br/><br/># Show the image<br/>plt.imshow(rectangle)<br/><br/></pre>
<p class="mce-root">This results in the following output:</p>
<div class="CDPAlignCenter CDPAlign"><img src="assets/2ec1550b-9e86-4e38-83f4-dc9c15e8a4f5.png" style=""/></div>
<p>In the preceding example, we created a black image and drew a rectangle using the <kbd>rectangle()</kbd> function. The <kbd>rectangle()</kbd> function takes the following arguments: image, <kbd>start_point</kbd>, <kbd>end_point</kbd>, color, and thickness. Here, thickness also takes an argument <kbd>-1</kbd>, the <kbd>-1</kbd> px value will fill the rectangle shape with the specified color. Let's see an example of a filled rectangle:</p>
<pre># Let's create a black image<br/>img_shape=(600,600,3)<br/>black_image = np.zeros(shape=image_shape,dtype=np.int16)<br/><br/># Draw a green filled rectangle on black image<br/>rectangle= cv2.rectangle(black_image,(200,200),(400,500),(0,255,0),-1)<br/><br/># Show the image<br/>plt.imshow(rectangle)<br/><br/></pre>
<p class="mce-root"><span>This results in the following output:</span></p>
<div class="CDPAlignCenter CDPAlign"><img src="assets/fad53d80-1e53-4070-9fde-3a996e76ca8e.png" style=""/></div>
<p>In the preceding example, we filled the rectangle by passing thickness values as -1 px. In a nutshell, we can say that the line takes mainly the start and endpoints as the input, the rectangle takes the top-left and the bottom-right coordinates, and the circle takes center coordinates and radius values.</p>
<h1 id="uuid-740c1dde-4265-4272-85f6-c68de69c7186">Writing on images</h1>
<p>In the previous section, we created various shapes on images. Now, we will learn how to write text on images. Writing text on an image is similar to drawing shapes. Let's see an example of writing on an image:</p>
<pre># Let's create a black image<br/>img_shape=(600,800,3)<br/>black_image = np.zeros(shape=image_shape,dtype=np.int16)<br/><br/># Write on black image<br/>text = cv2.putText(black_image,'Thanksgiving',(10,500),<br/>cv2.FONT_HERSHEY_SIMPLEX, 3,(255,0,0),2,cv2.LINE_AA)<br/><br/># Display the image<br/>plt.imshow(text)</pre>
<p>This results in the following output:</p>
<div class="CDPAlignCenter CDPAlign"><img src="assets/a1e7e723-853d-4407-8eda-080ed11f136b.png" style=""/></div>
<p>In the preceding example, we created a blank image with the color black. We have written text on an image using the <kbd>putText()</kbd> function. The <kbd>putText()</kbd> function will take the following arguments: image, text, coordinates of the bottom-left corner, font, <kbd>fontScale</kbd>, color, thickness, and <kbd>linetype</kbd>.</p>
<h1 id="uuid-1586986b-de1b-4dd1-aacd-eeffa6b7ee59">Resizing images</h1>
<p>Resizing an image means changing the dimension or scaling of a given image. Scaling or resizing is done either from the width, height, or both. One of the applications of resizing images is training deep learning models where reduced image sizes can speed up the training. Training a deep learning model is out of the scope of this book. If you are interested, then you can refer to any deep learning book from Packt Publishing. Let's see an example of resizing an image:</p>
<pre># Import cv2 module<br/>import cv2<br/><br/># Import matplotlib for showing the image<br/>import matplotlib.pyplot as plt<br/><br/># magic function to render the figure in a notebook<br/>%matplotlib inline<br/><br/># read image<br/>image = cv2.imread('tajmahal.jpg')<br/><br/># Convert image color space BGR to RGB<br/>rgb_image=cv2.cvtColor(image,cv2.COLOR_BGR2RGB)<br/><br/># Display the image<br/>plt.imshow(rgb_image)</pre>
<p>This results in the following output:</p>
<div class="CDPAlignCenter CDPAlign"><img src="assets/68efbd7f-e4d1-4474-96a7-68e4580c7376.png" style=""/></div>
<p>In the preceding code, we read the image and converted it from BGR into the RGB space. Let's resize it now using the <kbd>resize()</kbd> function:</p>
<pre># Resize the image<br/>image_resized = cv2.resize(rgb_image, (200, 200))<br/>interpolation = cv2.INTER_NEAREST<br/><br/># Display the image<br/>plt.imshow(image_resized)</pre>
<p class="mce-root">This results in the following output:</p>
<div class="CDPAlignCenter CDPAlign"><img src="assets/b2deb151-83b5-4020-9698-96f27f21013b.png" style=""/></div>
<p><span>In the preceding example, we read the image, converted BGR to RGB color using the <kbd>cvtColor()</kbd> function, and resized the image using the <kbd>resize()</kbd> function. The <kbd>resize()</kbd> function takes the following arguments: image, size, and interpolation. Interpolation is used to scale moire-free images. Interpolation takes one of the following flags: <kbd>INTER_NEAREST</kbd> (for nearest-neighbor interpolation), <kbd>INTER_LINEAR</kbd> (bilinear interpolation), and <kbd>INTER_AREA</kbd> (resampling using pixel area relation).</span></p>
<h1 id="uuid-55e6424e-87a6-4096-b349-d04ba5b2837e">Flipping images</h1>
<p>Flipping an image is equivalent to a mirror effect. Let's learn how to flip an image across the <em>x</em> axis (vertical flipping), <em>y</em> axis (horizontal flipping), or both axes. OpenCV offers the <kbd>flip()</kbd> function to flip an image. The <kbd>flip()</kbd> function will take two arguments: image and flipcode. The image is a NumPy array of pixel values and the flipcode used defines the type of flip, such as horizontal, vertical, or both. The following flipcode values are for different types of flips:</p>
<ul>
<li>Flipcode &gt; 0 is for a horizontal flip.</li>
<li>Flipcode = 0 is for a vertical flip.</li>
<li>Flipcode &lt; 0 is for both a horizontal and vertical flip.</li>
</ul>
<p>Let's see an example of flipping an image:</p>
<pre># Import OpenCV module<br/>import cv2<br/><br/># Import NumPy<br/>import numpy as np<br/><br/># Import matplotlib for showing the image<br/>import matplotlib.pyplot as plt<br/><br/># magic function to render the figure in a notebook<br/>%matplotlib inline<br/><br/># Read image<br/>image = cv2.imread('messi.png')<br/><br/># Convert image color space BGR to RGB<br/>rgb_image=cv2.cvtColor(image,cv2.COLOR_BGR2RGB)<br/><br/># Display the image<br/>plt.imshow(rgb_image)</pre>
<p class="mce-root">This results in the following output:</p>
<div class="CDPAlignCenter CDPAlign"><img src="assets/5663bc78-a38a-4ab9-9120-0fa76efb8fb9.png" style=""/></div>
<p>This is the original image, of Lionel Messi. Let's flip it horizontally using the <kbd>flip()</kbd> function by passing 1 as the flipcode in the <kbd>flip()</kbd> function:</p>
<pre># Flipping image (Horizontal flipping)<br/>image_flip = cv2.flip(rgb_image, 1)<br/><br/># Display the image<br/>plt.imshow(image_flip)</pre>
<p>This results in the following output:</p>
<div class="CDPAlignCenter CDPAlign"><img src="assets/bad1b298-a750-4f95-97af-8e70a9f17024.png" style=""/></div>
<p>This is the horizontally flipped image. Let's flip the original image vertically:</p>
<pre># Flipping image (Vertical flipping)<br/>image_flip = cv2.flip(rgb_image,0)<br/><br/># Display the image<br/>plt.imshow(image_flip)</pre>
<p>This results in the following output:</p>
<div class="CDPAlignCenter CDPAlign"><img src="assets/42ddf381-81cc-462d-a6dd-e74e98db6c5e.png" style=""/></div>
<p>You can see the vertically flipped image. Let's flip the original image on both axes:</p>
<pre># Flipping image (Horizontal and vertical flipping)<br/>image_flip = cv2.flip(rgb_image, -1)<br/><br/># Display the image<br/>plt.imshow(image_flip)</pre>
<p>This results in the following output:</p>
<div class="CDPAlignCenter CDPAlign"><img src="assets/7d664c59-8a20-4ede-9030-3ae72e769a4c.png" style=""/></div>
<p>You can see the vertically and horizontally flipped image. After flipping the image, let's learn how to change the brightness of the image in the next section.</p>
<h1 id="uuid-9e7da731-5b92-45cd-bcec-ba7984135041">Changing the brightness</h1>
<p>Brightness is a comparative term that is determined by visual perception. Sometimes it is difficult to perceive the brightness. The value of pixel intensity can help us to find a brighter image. For example, if two pixels have the intensity values 110 and 230, then the latter one is brighter.</p>
<p>In OpenCV, adjusting image brightness is a very basic operation. Brightness can be controlled by changing the intensity of each pixel in an image:</p>
<pre># Import cv2 latest version of OpenCV library<br/>import cv2<br/><br/># Import matplotlib for showing the image<br/>import matplotlib.pyplot as plt<br/><br/># Magic function to render the figure in a notebook<br/>%matplotlib inline<br/><br/># Read image<br/>image = cv2.imread('nature.jpeg')<br/><br/># Convert image color space BGR to RGB<br/>rgb_image=cv2.cvtColor(image,cv2.COLOR_BGR2RGB)<br/><br/># Display the image<br/>plt.imshow(rgb_image)</pre>
<p class="mce-root">This results in the following output:</p>
<div class="CDPAlignCenter CDPAlign"><img src="assets/7d7bd975-084f-48d1-9e10-615dec4e44c9.png" style=""/></div>
<p>In the preceding code example, we have read the image and converted the BGR color model-based image into an RGB color model-based image. Let's change the brightness of the image in the following code block:</p>
<pre># set weightage for alpha and betaboth the matrix<br/>alpha_=1<br/>beta_=50<br/><br/># Add weight to the original image to change the brightness<br/>image_change=cv2.addWeighted(rgb_image, alpha_,<br/>np.zeros(image.shape,image.dtype),0, beta_)<br/><br/># Display the image<br/>plt.imshow(image_change)</pre>
<p>This results in the following output:</p>
<div class="CDPAlignCenter CDPAlign"><img src="assets/565994a3-d029-43a2-985a-c145bf7694dc.png" style=""/></div>
<p>In the preceding example, we added the two matrices with the given weightage; alpha and beta using the <kbd>addWeighted()</kbd> function. <kbd>addWeighted()</kbd> takes the following arguments: <kbd>first_image</kbd>, <kbd>alpha, second_image</kbd>, <kbd>gamma</kbd>, and <kbd>beta</kbd>. In our example, the argument <kbd>first_image</kbd> input image and the argument <kbd>second_image</kbd> is the null matrix. The values of <kbd>alpha</kbd> and <kbd>beta</kbd> are the weights for both matrices and <kbd>gamma</kbd> is 0.</p>
<h1 id="uuid-29abd392-b59b-4e1b-98f4-85dba6ed057f">Blurring an image</h1>
<p>Blurring is one of the crucial steps of image preprocessing. In preprocessing, the removal of noise impacts the performance of algorithms. Blurring is the process of reducing noise in image data to achieve better accuracy. Blurring also helps us to take charge of handling pixel intensity.</p>
<p>Let's see an example of blurring an image:</p>
<pre># Import OpenCV module<br/>import cv2<br/><br/># Import matplotlib for showing the image<br/>import matplotlib.pyplot as plt<br/><br/># Magic function to render the figure in a notebook<br/>%matplotlib inline<br/><br/># Read image<br/>image = cv2.imread('tajmahal.jpg')<br/><br/># Convert image color space BGR to RGB<br/>rgb_image=cv2.cvtColor(image,cv2.COLOR_BGR2RGB)<br/><br/># Display the image<br/>plt.imshow(rgb_image)</pre>
<p>This results in the following output:</p>
<div class="CDPAlignCenter CDPAlign"><img src="assets/5c7fadcd-940c-41ec-af6f-20f83059e767.png" style=""/></div>
<p>In the preceding code sample, we read the image and converted it from a BGR to RGB based image. Let's blur it using the <kbd>blur()</kbd> function. Blur takes two arguments: image and kernel size. The <kbd>blur()</kbd> function uses the average blurring method:</p>
<pre># Blur the image using blur() function<br/>image_blur = cv2.blur(rgb_image,(15,15))<br/><br/># Display the image<br/>plt.imshow(image_blur)</pre>
<p class="mce-root">This results in the following output:</p>
<div class="CDPAlignCenter CDPAlign"><img src="assets/163204d0-ae8f-450c-8d1f-74eca759d268.png" style=""/></div>
<p>In the preceding example, we read the image, converted BGR to RGB color using the <kbd>cvtColor()</kbd> function, and displayed the image. Here, we blurred the image using the <kbd>blur()</kbd> function. The <kbd>blur()</kbd> function applies average blurring, which uses a normalized box filter. The <kbd>blur()</kbd> function takes the following arguments: image and kernel size.</p>
<p>We have seen a blurred image using average blurring. Let's explore blurring using Gaussian blurring. In this blurring, the Gaussian kernel is used instead of a box filter. <kbd>GaussianBlur()</kbd> will take the image and kernel size. The kernel size will be a tuple of the width and height. Both width and height must be a positive and odd number: </p>
<pre># Import cv2 module<br/>import cv2<br/><br/># Import matplotlib for showing the image<br/>import matplotlib.pyplot as plt<br/><br/># magic function to render the figure in a notebook<br/>%matplotlib inline<br/><br/># read image<br/>image = cv2.imread('tajmahal.jpg')<br/><br/># Convert image color space BGR to RGB<br/>rgb_image=cv2.cvtColor(image,cv2.COLOR_BGR2RGB)<br/><br/># Blurring the image using Gaussian Blur<br/>image_blur = cv2.GaussianBlur(rgb_image, (7,7), 0)<br/><br/># Display the image<br/>plt.imshow(image_blur)</pre>
<p>This results in the following output:</p>
<div class="CDPAlignCenter CDPAlign"><img src="assets/f4346a12-f6e3-42b9-9abf-bf8b9c9c26e0.png" style=""/></div>
<p>Let's explore the median blurring of the given image. Median blur takes pixels in the kernel area and replaces the central element with the median value. <kbd>medianBlur()</kbd> will take image and kernel size as an argument. It is recommended that the kernel size should be an odd number and greater than 1, for example, 3, 5, 7, 9, 11, and so on:</p>
<pre># Import cv2 module<br/>import cv2<br/><br/># Import matplotlib for showing the image<br/>import matplotlib.pyplot as plt<br/><br/># Convert image color space BGR to RGB<br/>%matplotlib inline<br/><br/># read image<br/>image = cv2.imread('tajmahal.jpg')<br/><br/># Convert image color space BGR to RGB<br/>rgb_image=cv2.cvtColor(image,cv2.COLOR_BGR2RGB)<br/><br/># Blurring the image using Median blurring<br/>image_blur = cv2.medianBlur(rgb_image,11)<br/><br/># Display the image<br/>plt.imshow(image_blur)</pre>
<p>This results in the following output:</p>
<div class="CDPAlignCenter CDPAlign"><img src="assets/f5ac0ef4-2ceb-4d7a-8924-d03d8bce731c.png" style=""/></div>
<p>In the preceding code block, we blurred the image using <span>median blurring. Here, we used the <kbd>medianBlur()</kbd> method for median blurring and we can observe the blurred image in the output. </span>In this section, we discussed average blurring, Gaussian blurring, and median blurring techniques. In the next section, we will learn how to detect human faces in images.</p>
<h1 id="uuid-6a2fab23-7841-4604-9780-6ca7565e5f17">Face detection</h1>
<p>Nowadays, everyone is using Facebook and you all must have seen facial recognition in an image on Facebook. Facial recognition identifies who a face belongs to and face detection only finds faces in an image, that is, face detection does not determine to whom the detected face belongs. Face detection in a given input image is quite a popular functionality in lots of applications; for example, counting the number of people in an image. In face detection, the algorithm tries to find human faces in a digital image.</p>
<p>Face detection is a kind of classification problem. We can classify images into two classes, face or not face. We need lots of images to train such a model for classification. Thankfully, OpenCV offers pre-trained models such as the Haar Feature-Based Cascade Classifier and the <strong>Local Binary Pattern</strong> (<strong>LBP</strong>) classifier, trained on thousands of images. In our example, we will use Haar feature extraction to detect a face. Let's see how to capture a face in an image using OpenCV:</p>
<ol>
<li>Read the image and convert it into grayscale:</li>
</ol>
<pre style="padding-left: 60px"># Import cv2 latest version of OpenCV library<br/>import cv2<br/><br/># Import numeric python (NumPy) library<br/>import numpy as np<br/><br/># Import matplotlib for showing the image<br/>import matplotlib.pyplot as plt<br/><br/># magic function to render the figure in a notebook<br/>%matplotlib inline<br/><br/># Read image<br/>image= cv2.imread('messi.png')<br/><br/># Convert image color space BGR to grayscale<br/>image_gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)<br/><br/># Displaying the grayscale image<br/>plt.imshow(image_gray, cmap='gray')</pre>
<p style="padding-left: 60px" class="mce-root">This results in the following output:</p>
<div class="CDPAlignCenter CDPAlign"><img src="assets/f3468c8d-b2ff-4b9a-81fe-6249cfa3f3f5.png" style=""/></div>
<p style="padding-left: 60px">In the preceding code example, we read the Lionel Messi image and converted it into a grayscale image using the <kbd>cvtColor()</kbd> function.</p>
<p style="padding-left: 60px">Let's find the faces in the generated gray image:</p>
<ol start="2">
<li>Load the Haar cascade face classifier file:</li>
</ol>
<pre style="padding-left: 60px"># Load the haar cascade face classifier file<br/>haar_cascade = cv2.CascadeClassifier('haarcascade_frontalface_default.xml')</pre>
<ol start="3">
<li>Get coordinates for all the faces in the image:</li>
</ol>
<pre style="padding-left: 60px"># Get the faces coordinates for all the faces in the image<br/>faces_cordinates = haar_cascade.detectMultiScale(image_gray, scaleFactor = 1.3, minNeighbors = 7);</pre>
<ol start="4">
<li>Draw a rectangle on detected faces:</li>
</ol>
<pre style="padding-left: 60px"># Draw rectangle on detected faces<br/>for (p,q,r,s) in faces_cordinates:<br/>    cv2.rectangle(image, (p, q), (p+r, q+s), (255,255,0), 2)</pre>
<ol start="5">
<li>Convert image color space BGR to RGB and display the image:</li>
</ol>
<pre style="padding-left: 60px"># Convert image color space BGR to RGB<br/>image_rgb=cv2.cvtColor(image, cv2.COLOR_BGR2RGB)<br/><br/># Display face detected image<br/>plt.imshow(image_rgb)</pre>
<p style="padding-left: 60px">This results in the following output:</p>
<div class="CDPAlignCenter CDPAlign"><img src="assets/7c803d9f-c090-4999-951b-28b500decdab.png" style=""/></div>
<p>In the preceding example, we converted the BGR image to a grayscale image. OpenCV has pre-trained classifiers for face, eye, and smile detection. We can use a pre-trained face cascade classifier XML file (<kbd>haarcascade_frontalface_default.xml</kbd>). You can get the classifier file (<kbd>haarcascade_frontalface_default.xml</kbd><span>) from the official Git repo: <a href="https://github.com/opencv/opencv/tree/master/data/haarcascades">https://github.com/opencv/opencv/tree/master/data/haarcascades</a> or you can get it from our GitHub repo: <a href="https://github.com/PacktPublishing/Python-Data-Analysis-Third-Edition/tree/master/Chapter13">https://github.com/PacktPublishing/Python-Data-Analysis-Third-Edition/tree/master/Chapter13</a>. </span></p>
<p><span>After this, we can pass the image to the cascade classifier and get the face coordinates in the image. We have drawn rectangles on these face coordinates using the <kbd>rectangle()</kbd> function. Before displaying the output, we need to convert the RGB image to BGR to display it properly. Let's try this example on an image with multiple faces:</span></p>
<pre># Read the image<br/>image= cv2.imread('barcelona.jpeg')<br/><br/># Convert image BGR to grayscale<br/>image_gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)<br/><br/># Load the haar cascade face classifier file<br/>haar_cascade = cv2.CascadeClassifier('haarcascade_frontalface_default.xml')<br/><br/># Get the faces coordinates for all the faces in the image<br/>faces_cordinates = haar_cascade.detectMultiScale(image_gray, scaleFactor = 1.3, minNeighbors = 5);<br/><br/># Draw rectangle on detected faces<br/>for (x1,y1,x2,y2) in faces_cordinates:<br/>cv2.rectangle(image, (x1, y1), (x1+x2, y1+y2), (255,255,0), 2)<br/><br/># Convert image color space BGR to RGB<br/>image_rgb=cv2.cvtColor(image, cv2.COLOR_BGR2RGB)<br/><br/># Display face detected the image<br/>plt.imshow(image_rgb)</pre>
<p>This results in the following output:</p>
<div class="CDPAlignCenter CDPAlign"><img src="assets/a5fb031e-9d60-4b9a-8848-5d93a2cfca36.png" style=""/></div>
<p>In the preceding example, we can see the program has detected all the faces in the image.</p>
<h1 id="uuid-abc8aba4-77df-45ce-9ec4-aa1fd9c449ea">Summary</h1>
<p><span>In this chapter, we discussed image processing using OpenCV. The main focus of the chapter was on basic image processing operations and face detection. The chapter started with an introduction to types of images and image color models. In later sections, the focus was on image operations such as drawing, resizing, flipping, and blurring an image. In the last section, we discussed face detection in a given input image</span></p>
<p><span>The next chapter, <a href="b106abe7-1a2a-44d1-bf17-778e1588e0f1.xhtml">Chapter 14</a>, <em>Parallel Computing Using Dask</em>, will focus on parallel computation on basic data science Python libraries such as Pandas, NumPy, and scikit-learn using Dask. The chapter will start with Dask data types such as dataframes, arrays, and bags. In later sections, we'll shift focus from dataFrames and arrays to delayed, preprocessing, and machine learning algorithms in parallel using Dask.</span></p>


            </article>

            
        </section>
    </body></html>