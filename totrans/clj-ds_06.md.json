["```py\nscript/download-data.sh\n\n```", "```py\n(:import [org.apache.lucene.benchmark.utils ExtractReuters])\n\n(defn sgml->txt [in-path out-path]\n  (let [in-file  (clojure.java.io/file in-path)\n        out-file (clojure.java.io/file out-path)]\n    (.extract (ExtractReuters. in-file out-file))))\n```", "```py\nlein extract-reuters\n\n```", "```py\n19-OCT-1987 16:14:37.57\n\nWALL STREET SUFFERS WORST EVER SELLOFF\n\nWall Street tumbled to its worst point loss ever and the worst percentage decline since the First World War as a frenzy of stock selling stunned even the most bearish market participants. \"Everyone is in awe and the word 'crash' is on everyone's mind,\" one trader said.     The Dow Jones industrial average fell 508 points to 1738, a level it has not been at since the Autumn of 1986\\.     Volume soared to 603 mln shares, almost doubling the previous record of 338 mln traded just last Friday. Reuter &#3;\n```", "```py\n20-OCT-1987 17:09:34.49\nREAGAN SAYS HE SEES NO RECESSION\n```", "```py\n(:require [clojure.set :as set])\n\n(defn jaccard-similarity [a b]\n  (let [a (set a)\n        b (set b)]\n    (/ (count (set/intersection a b))\n       (count (set/union a b)))))\n\n(defn ex-6-1 []\n  (let [a [1 2 3]\n        b [2 3 4]]\n    (jaccard a b)))\n\n;; => 1/2\n```", "```py\n(defn tokenize [s]\n  (str/split s #\"\\W+\"))\n```", "```py\n(tokenize \"doesn't handle apostrophes\")\n;; [\"doesn\" \"t\" \"handle\" \"apostrophes\"]\n```", "```py\n(tokenize \"good-looking user-generated content\")\n;; [\"good\" \"looking\" \"user\" \"generated\" \"content\"]\n```", "```py\n(tokenize \"New York-based\")\n;; [\"New\" \"York\" \"based\"]\n```", "```py\n(defn tokenize-reuters [content]\n  (-> (str/replace content  #\"^.*\\n\\n\" \"\")\n      (str/lower-case)\n      (tokenize)))\n\n(defn reuters-terms [file]\n  (-> (io/resource file)\n      (slurp)\n      (tokenize-reuters)))\n```", "```py\n(defn ex-6-2 []\n  (let [a (set (reuters-terms \"reut2-020.sgm-761.txt\"))\n        b (set (reuters-terms \"reut2-007.sgm-750.txt\"))\n        s (jaccard a b)]\n    (println \"A:\" a)\n    (println \"B:\" b)\n    (println \"Similarity:\" s)))\n\nA: #{recession says reagan sees no he}\nB: #{bill transit says highway reagan and will veto he}\nSimilarity: 1/4\n```", "```py\n19-OCT-1987 16:41:40.58\nNYSE CHAIRMAN JOHN PHELAN SAYS NYSE WILL OPEN TOMORROW ON TIME\n```", "```py\n(defn euclidean-distance [a b]\n  (->> (map (comp i/sq -) a b)\n       (apply +)\n       (i/sqrt)))\n```", "```py\n(def dictionary\n  (atom {:count 0\n         :words {}}))\n\n(defn add-term-to-dict [dict word]\n  (if (contains? (:terms dict) word)\n    dict\n    (-> dict\n        (update-in [:terms] assoc word (get dict :count))\n        (update-in [:count] inc))))\n\n(defn add-term-to-dict! [dict term]\n  (doto dict\n    (swap! add-term-to-dict term)))\n```", "```py\n(add-term-to-dict! dictionary \"love\")\n\n;; #<Atom@261d1f0a: {:count 1, :terms {\"love\" 0}}>\n```", "```py\n(add-term-to-dict! dictionary \"music\")\n\n;; #<Atom@261d1f0a: {:count 2, :terms {\"music\" 1, \"love\" 0}}>\n```", "```py\n(add-term-to-dict! dictionary \"love\")\n\n;; #<Atom@261d1f0a: {:count 2, :terms {\"music\" 1, \"love\" 0}}>\n```", "```py\n(defn build-dictionary! [dict terms]\n  (reduce add-term-to-dict! dict terms))\n```", "```py\n(defn term-id [dict term]\n  (get-in @dict [:terms term]))\n\n(defn term-frequencies [dict terms]\n  (->> (map #(term-id dict %) terms)\n       (remove nil?)\n       (frequencies)))\n\n(defn map->vector [dictionary id-counts]\n  (let [zeros (vec (replicate (:count @dictionary) 0))]\n    (-> (reduce #(apply assoc! %1 %2) (transient zeros) id-counts)\n        (persistent!))))\n\n(defn tf-vector [dict document]\n  (map->vector dict (term-frequencies dict document)))\n```", "```py\n(defn ex-6-3 []\n  (let [doc  (reuters-terms \"reut2-020.sgm-742.txt\")\n        dict (build-dictionary! dictionary doc)]\n    (println \"Document:\" doc)\n    (println \"Dictionary:\" dict)\n    (println \"Vector:\" (tf-vector dict doc))))\n```", "```py\n;; Document: [nyse s phelan says nyse will continue program\n;;            trading curb until volume slows]\n;; Dictionary: #<Atom@bb156ec: {:count 12, :terms {s 1, curb 8,\n;;             phelan 2, says 3, trading 7, nyse 0, until 9,\n;;             continue 5, volume 10, will 4, slows 11,\n;;             program 6}}>\n;; Vector: [2 1 1 1 1 1 1 1 1 1 1 1]\n```", "```py\n(defn print-distance [doc-a doc-b measure]\n  (let [a-terms (reuters-terms doc-a)\n        b-terms (reuters-terms doc-b)\n        dict (-> dictionary\n                 (build-dictionary! a-terms)\n                 (build-dictionary! b-terms))\n        a (tf-vector dict a-terms)\n        b (tf-vector dict b-terms)]\n    (println \"A:\" a)\n    (println \"B:\" b)\n    (println \"Distance:\" (measure a b))))\n\n(defn ex-6-4 []\n  (print-distance \"reut2-020.sgm-742.txt\"\n                  \"reut2-020.sgm-932.txt\"\n                  euclidean-distance))\n\n;; A: [2 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0]\n;; B: [2 0 1 1 1 0 0 0 0 0 0 0 1 1 1 1 1 1]\n;; Distance: 3.7416573867739413\n```", "```py\n(defn cosine-similarity [a b]\n  (let [dot-product (->> (map * a b)\n                         (apply +))\n        magnitude (fn [d]\n                    (->> (map i/sq d)\n                         (apply +)\n                         (i/sqrt)))]\n    (/ dot-product (* (magnitude a) (magnitude b)))))\n```", "```py\n(defn ex-6-5 []\n  (print-distance \"reut2-020.sgm-742.txt\"\n                  \"reut2-020.sgm-932.txt\"\n                  cosine-similarity))\n\n;; A: [2 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0]\n;; B: [2 0 1 1 1 0 0 0 0 0 0 0 1 1 1 1 1 1]\n;; Distance: 0.5012804118276031\n```", "```py\n(defn ex-6-6 []\n  (let [a (tokenize \"music is the food of love\")\n        b (tokenize \"war is the locomotive of history\")]\n    (add-documents-to-dictionary! dictionary [a b])\n    (cosine-similarity (tf-vector dictionary a)\n                       (tf-vector dictionary b))))\n\n;; 0.5\n```", "```py\n(defn ex-6-7 []\n  (let [a (tokenize \"music is the food of love\")\n        b (tokenize \"it's lovely that you're musical\")]\n    (add-documents-to-dictionary! dictionary [a b])\n    (cosine-similarity (tf-vector dictionary a)\n                       (tf-vector dictionary b))))\n\n;; 0.0\n```", "```py\n(defn ex-6-8 []\n  (let [a (stemmer/stems \"music is the food of love\")\n        b (stemmer/stems \"it's lovely that you're musical\")]\n    (add-documents-to-dictionary! dictionary [a b])\n    (cosine-similarity (tf-vector dictionary a)\n                       (tf-vector dictionary b))))\n\n;; 0.8164965809277259\n```", "```py\n(defn centroid [xs]\n  (let [m (i/trans (i/matrix xs))]\n    (if (> (i/ncol m) 1)\n      (i/matrix (map s/mean m))\n     m)))\n\n(defn ex-6-9 []\n  (let [m (i/matrix [[1 2 3]\n                     [2 2 5]])]\n    (centroid m)))\n\n;; A 3x1 matrix\n;;  -------------\n;; 1.50e+00\n;; 2.00e+00\n;; 4.00e+00\n```", "```py\n(defn clusters [cluster-ids data]\n  (->> (map vector cluster-ids data)\n       (conj-into {})\n       (vals)\n       (map i/matrix))) \n\n(defn ex-6-10 []\n  (let [m (i/matrix [[1 2 3]\n                     [4 5 6]\n                     [7 8 9]])]\n    (clusters [0 1 0] m)))\n\n;; A 1x3 matrix\n;; -------------\n;; 4.00e+00  5.00e+00  6.00e+00 \n;;  A 2x3 matrix\n;; -------------\n;; 7.00e+00  8.00e+00  9.00e+00 \n;; 1.00e+00  2.00e+00  3.00e+00\n```", "```py\n(defn k-means [data k]\n  (loop [centroids (s/sample data :size k)\n         previous-cluster-ids nil]\n    (let [cluster-id (fn [x]\n                       (let [distance  #(s/euclidean-distance x %)\n                             distances (map distance centroids)]\n                         (->> (apply min distances)\n                              (index-of distances))))\n          cluster-ids (map cluster-id data)]\n      (if (not= cluster-ids previous-cluster-ids)\n        (recur (map centroid (clusters cluster-ids data))\n               cluster-ids)\n        clusters))))\n```", "```py\n(defn ex-6-11 []\n  (let [documents (fs/glob \"data/reuters-text/*.txt\")\n        doc-count 100\n        k 5\n        tokenized (->> (map slurp documents)\n                       (remove too-short?)\n                       (take doc-count)\n                       (map stem-reuters))]\n    (add-documents-to-dictionary! dictionary tokenized)\n    (-> (map #(tf-vector dictionary %) tokenized)\n        (k-means k))))\n```", "```py\n(defn cluster-summary [dict clusters top-term-count]\n  (for [cluster clusters]\n    (let [sum-terms (if (= (i/nrow cluster) 1)\n                      cluster\n                      (->> (i/trans cluster)\n                           (map i/sum)\n                           (i/trans)))\n          popular-term-ids (->> (map-indexed vector sum-terms)\n                                (sort-by second >)\n                                (take top-term-count)\n                                (map first))\n          top-terms (map #(id->term dict %) popular-term-ids)]\n      (println \"N:\" (i/nrow cluster))\n      (println \"Terms:\" top-terms))))\n\n(defn ex-6-12 []\n  (cluster-summary dictionary (ex-6-11) 5))\n```", "```py\n;; N: 2\n;; Terms: (rocket launch delta satellit first off weather space)\n;;  N: 4\n;; Terms: (said will for system 000 bank debt from bond farm)\n;; N: 12\n;; Terms: (said reuter for iranian it iraq had new on major)\n;; N: 62\n;; Terms: (said pct dlr for year mln from reuter with will)\n;; N: 20\n;; Terms: (said for year it with but dlr mln bank week)\n```", "```py\n(defn ex-6-13 []\n  (let [documents (fs/glob \"data/reuters-text/*.txt\")\n        doc-count 1000\n        top-terms 25\n        term-frequencies (->> (map slurp documents)\n                              (remove too-short?)\n                              (take doc-count)\n                              (mapcat tokenize-reuters)\n                              (frequencies)\n                              (vals)\n                              (sort >)\n                              (take top-terms))]\n    (-> (c/xy-plot (range (inc top-terms)) term-frequencies\n                   :x-label \"Terms\"\n                   :y-label \"Term Frequency\")\n        (i/view))))\n```", "```py\n(defn inc-df! [dictionary term-id]\n  (doto dictionary\n    (swap! update-in [:df term-id] (fnil inc 0))))\n\n(defn build-df-dictionary! [dictionary document]\n  (let [terms    (distinct document)\n        dict     (build-dictionary! dictionary document)\n        term-ids (map #(term-id dictionary %) document)]\n    (doseq [term-id term-ids]\n      (inc-df! dictionary term-id))\n    dict))\n```", "```py\n(defn document-frequencies [dict terms]\n  (->> (map (partial term-id dict) terms)\n       (select-keys (:df @dict))))\n\n(defn tfidf-vector [dict doc-count terms]\n  (let [tf (term-frequencies dict terms)\n        df (document-frequencies dict (distinct terms))\n        idf   (fn [df] (i/log (/ doc-count df)))\n        tfidf (fn [tf df] (* tf (idf df)))]\n    (map->vector dict (merge-with tfidf tf df))))\n```", "```py\n(defn ex-6-14 []\n  (let [documents (fs/glob \"data/reuters-text/*.txt\")\n        doc-count 100\n        k 5\n        tokenized (->> (map slurp documents)\n                       (remove too-short?)\n                       (take doc-count)\n                       (map stem-reuters))]\n    (reduce build-df-dictionary! dictionary tokenized)\n    (-> (map #(tfidf-vector dictionary doc-count %) tokenized)\n        (k-means k)\n        (cluster-summary dictionary 10))))\n```", "```py\nN: 5\nTerms: (unquot unadjust year-on-year novemb grew sundai labour m-3 ahead 120)\nN: 15\nTerms: (rumor venezuela azpurua pai fca keat ongpin boren gdp moder)\nN: 16\nTerms: (regan drug lng soviet bureau deleg gao dean fdic algerian)\nN: 46\nTerms: (form complet huski nrc rocket north underwrit card oat circuit)\nN: 18\nTerms: (freez cocoa dec brown bean sept seixa telex argentin brown-forman)\n```", "```py\n(defn n-grams [n words]\n  (->> (partition n 1 words)\n       (map (partial str/join \" \")))) \n\n(defn ex-6-15 []\n  (let [terms (reuters-terms \"reut2-020.sgm-761.txt\")]\n    (n-grams 2 terms)))\n\n;; (\"reagan says\" \"says he\" \"he sees\" \"sees no\" \"no recession\")\n```", "```py\n(defn multi-grams [n words]\n  (->> (range 1 (inc n))\n       (mapcat #(n-grams % words))))\n\n(defn ex-6-16 []\n  (let [terms (reuters-terms \"reut2-020.sgm-761.txt\")]\n    (multi-grams 4 terms)))\n\n;; (\"reagan\" \"says\" \"he\" \"sees\" \"no\" \"recession\" \"reagan says\" \n;; \"says he\" \"he sees\" \"sees no\" \"no recession\" \"reagan says he\" \n;; \"says he sees\" \"he sees no\" \"sees no recession\" \"reagan says he \n;; sees\" \"says he sees no\" \"he sees no recession\")\n```", "```py\n(:import [org.apache.mahout.text\n           SequenceFilesFromDirectory])\n\n(defn text->sequencefile [in-path out-path]\n  (SequenceFilesFromDirectory/main\n   (into-array String (vector \"-i\" in-path\n                              \"-o\" out-path\n                              \"-xm\" \"sequential\"\n                              \"-ow\"))))\n\n(defn ex-6-17 []\n  (text->sequencefile \"data/reuters-text\"\n                      \"data/reuters-sequencefile\"))\n```", "```py\nlein create-sequencefile\n\n```", "```py\n(defn uuid []\n  (str (java.util.UUID/randomUUID)))\n```", "```py\n(defn document-count-m\n  {::mr/source-as :vals}\n  [documents]\n  (->> documents\n       (r/mapcat (comp distinct stemmer/stems))\n       (r/map #(vector % 1))))\n```", "```py\n(defn unique-index-r\n  {::mr/source-as :keyvalgroups,\n   ::mr/sink-as dux/named-keyvals}\n  [coll]\n  (let [global-offset (conf/get-long mr/*context*\n                                     \"mapred.task.partition\" -1)]\n    (tr/mapcat-state\n     (fn [local-offset [word doc-counts]]\n       [(inc local-offset)\n        (if (identical? ::finished word)\n          [[:counts [global-offset local-offset]]]\n          [[:data [word [[global-offset local-offset]\n                         (apply + doc-counts)]]]])])\n     0 (r/mapcat identity [coll [[::finished nil]]]))))\n```", "```py\n(defn df-j [dseq]\n  (-> (pg/input dseq)\n      (pg/map #'document-count-m)\n      (pg/partition (mra/shuffle [:string :long]))\n      (pg/reduce #'unique-index-r)\n      (pg/output :data (mra/dsink [:string index-value])\n                 :counts (mra/dsink [:long :long]))))\n```", "```py\n(def long-pair (avro/tuple-schema [:long :long]))\n```", "```py\n(defn global-id [offsets [global-offset local-offset]]\n  (+ local-offset (get offsets global-offset)))\n\n(defn calculate-offsets [dseq]\n  (->> (into [] dseq)\n       (sort-by first)\n       (reductions (fn [[_ t] [i n]]\n                     [(inc i) (+ t n)])\n                   [0 0])\n       (into {})))\n```", "```py\n(defn unique-word-ids [conf df-data df-counts]\n  (let [offsets-dval (-> (calculate-offsets df-counts)\n                         (dval/edn-dval))]\n    (-> (pg/input df-data)\n        (pg/map #'word-id-m offsets-dval)\n        (pg/output (mra/dsink [word-id]))\n        (pg/fexecute conf `word-id)\n        (->> (r/map parse-idf)\n             (into {}))\n        (dval/edn-dval))))\n```", "```py\n(defn word-id-m\n  {::mr/sink-as :keys}\n  [offsets-dval coll]\n  (let [offsets @offsets-dval]\n    (r/map\n     (fn [[word word-offset]]\n       [word (global-id offsets word-offset)])\n     coll)))\n```", "```py\n(defn create-sparse-tfidf-vector [dictionary [id doc]]\n  (let [vector (RandomAccessSparseVector. (count dictionary))]\n    (doseq [[term tf] (-> doc stemmer/stems frequencies)]\n      (let [term-info (get dictionary term)\n            id  (:id term-info)\n            idf (:idf term-info)]\n        (.setQuick vector id (* tf idf))))\n    [id vector]))\n\n(defn create-tfidf-vectors-m [dictionary coll]\n  (let [dictionary @dictionary]\n    (r/map #(create-sparse-tfidf-vector dictionary %) coll)))\n```", "```py\n(defn tfidf [conf dseq dictionary-path vector-path]\n  (let [doc-count (->> dseq (into []) count)\n        [df-data df-counts] (pg/execute (df-j dseq) conf df)\n        dictionary-dval (make-dictionary conf df-data\n                                         df-counts doc-count)]\n    (write-dictionary dictionary-path dictionary-dval)\n    (-> (pg/input dseq)\n        (pg/map #'create-tfidf-vectors-m dictionary-dval)\n        (pg/output (seqf/dsink [Text VectorWritable] vector-path))\n        (pg/fexecute conf `vectorize))))\n```", "```py\n(defn ex-6-18 []\n  (let [input-path  \"data/reuters-sequencefile\" \n        output-path \"data/reuters-vectors\"]\n    (vectorizer/tfidf-job (conf/ig) input-path output-path)))\n```", "```py\nlein create-vectors\n\n```", "```py\n(defn run-kmeans [in-path clusters-path out-path k]\n  (let [distance-measure  \"org.apache.mahout.common.distance.CosineDistanceMeasure\"\n        max-iterations    100\n        convergence-delta 0.001]\n    (KMeansDriver/main\n     (->> (vector \"-i\"  in-path\n                  \"-c\"  clusters-path\n                  \"-o\"  out-path\n                  \"-dm\" distance-measure\n                  \"-x\"  max-iterations\n                  \"-k\"  k\n                  \"-cd\" convergence-delta\n                  \"-ow\"\n                  \"-cl\")\n          (map str)\n          (into-array String)))))\n```", "```py\n(defn ex-6-19 []\n  (run-kmeans \"data/reuters-vectors/vectors\"\n              \"data/kmeans-clusters/clusters\"\n              \"data/kmeans-clusters\"\n              10))\n```", "```py\n(defn run-cluster-dump [in-path dict-path points-dir out-path]\n  (let [distance-measure\n        \"org.apache.mahout.common.distance.CosineDistanceMeasure\"]\n    (ClusterDumper/main\n     (->> (vector \"-i\" in-path\n                  \"-o\" out-path\n                  \"-d\" dict-path\n                  \"--pointsDir\" points-dir\n                  \"-dm\" distance-measure\n                  \"-dt\" \"sequencefile\"\n                  \"-b\" \"100\"\n                  \"-n\" \"20\"\n                  \"-sp\" \"0\"\n                  \"--evaluate\")\n          (map str)\n          (into-array String)))))\n```", "```py\n(defn path-for [path]\n  (-> (fs/glob path)\n      (first)\n      (.getAbsolutePath)))\n\n(defn ex-6-20 []\n  (run-cluster-dump\n   (path-for \"data/kmeans-clusters/clusters-*-final\")\n   \"data/reuters-vectors/dictionary/part-r-00000\"\n   \"data/kmeans-clusters/clusteredPoints\"\n   \"data/kmeans-clusterdump\"))\n```", "```py\n:VL-11417{n=312 c=[0.01:0.039, 0.02:0.030, 0.07:0.047, 0.1:0.037, 0.10:0.078, 0.11:0.152, 0.12:0.069,\n  Top Terms:\n    tonnes              =>   2.357810452962533\n    department          =>   1.873890568048526\n    wheat               =>  1.7797807546762319\n    87                  =>  1.6685682321206117\n    u.s                 =>   1.634764205186795\n    mln                 =>  1.5050923755535712\n    agriculture         =>  1.4595903158187866\n    ccc                 =>  1.4314624499051998\n    usda                =>  1.4069041441648433\n    dlrs                =>  1.2770121846443567\n```", "```py\nVL-12535{n=514 c=[0:0.292, 0.25:0.015, 0.5:0.012, 00:0.137, 00.46:0.018, 00.50:0.036, 00.91:0.018, 0\n  Top Terms:\n    president           =>   3.330068911559851\n    reagan              =>   2.485271333256584\n    chief               =>  2.1148699971952327\n    senate              =>   1.876725117983985\n    officer             =>  1.8531712558019022\n    executive           =>  1.7373591731030653\n    bill                =>  1.6326750159727461\n    chairman            =>  1.6280977206471365\n    said                =>  1.6279512813119108\n    house               =>  1.5771017798189988\n```", "```py\nInter-Cluster Density: 0.6135607681542804\nIntra-Cluster Density: 0.6957348405534836\n```", "```py\n(defn load-cluster-points [dir]\n  (->> (points-path dir)\n       (seqf/dseq)\n       (r/reduce\n        (fn [accum [k v]]\n          (update-in accum [k] conj v)) {})))\n```", "```py\n(defn load-cluster-centroids [dir]\n  (let [to-tuple (fn [^Cluster kluster]\n                   (let [id (.getId kluster)]\n                     [id  {:id id\n                           :centroid (.getCenter kluster)}]))]\n    (->> (centroids-path dir)\n         (seqf/dseq)\n         (r/map (comp to-tuple last))\n         (into {}))))\n```", "```py\n(defn assoc-points [cluster points]\n  (assoc cluster :points points))\n\n(defn load-clusters [dir]\n  (->> (load-cluster-points dir)\n       (merge-with assoc-points\n                   (load-cluster-centroids dir))\n       (vals)))\n```", "```py\n(def measure\n  (CosineDistanceMeasure.))\n\n(defn distance [^DistanceMeasure measure a b]\n  (.distance measure a b))\n\n(defn centroid-distances [cluster]\n  (let [centroid (:centroid cluster)]\n    (->> (:points cluster)\n         (map #(distance measure centroid %)))))\n\n(defn squared-errors [cluster]\n  (->> (centroid-distances cluster)\n       (map i/sq)))\n\n(defn root-mean-square-error [clusters]\n  (->> (mapcat squared-errors clusters)\n       (s/mean)\n       (i/sqrt)))\n```", "```py\n(defn ex-6-21 []\n  (doseq [k (range 2 21)\n          :let [dir (str \"data/kmeans-clusters-\" k)]]\n    (println dir)\n    (run-kmeans \"data/reuters-vectors/vectors\"\n                (str dir \"/clusters\")\n                dir k)))\n```", "```py\n(defn ex-6-22 []\n  (let [ks (range 2 21)\n        ys (for [k ks\n                 :let [dir (str \"data/kmeans-clusters-\" k)\n                       clusters (load-clusters dir)]]\n             (root-mean-square-error clusters))]\n    (-> (c/scatter-plot ks ys\n                        :x-label \"k\"\n                        :y-label \"RMSE\")\n        (i/view))))\n```", "```py\n(defn cluster-size [cluster]\n  (-> cluster\n      centroid-distances\n      s/median))\n\n(defn dunn-index [clusters]\n  (let [min-separation (->> (combinations clusters 2)\n                            (map #(apply separation %))\n                            (apply min))\n        max-cluster-size (->> (map cluster-size clusters)\n                              (apply max))]\n    (/ min-separation max-cluster-size)))\n```", "```py\n(defn ex-6-23 []\n  (let [ks (range 2 21)\n        ys (for [k ks\n                 :let [dir (str \"data/kmeans-clusters-\" k)\n                       clusters (load-clusters dir)]]\n             (dunn-index clusters))]\n    (-> (c/scatter-plot ks ys\n                        :x-label \"k\"\n                        :y-label \"Dunn Index\")\n        (i/view))))\n```", "```py\n(defn scatter [cluster]\n  (-> (centroid-distances cluster)\n      (s/mean)))\n\n(defn assoc-scatter [cluster]\n  (assoc cluster :scatter (scatter cluster)))\n\n(defn separation [a b]\n  (distance measure (:centroid a) (:centroid b)))\n\n(defn davies-bouldin-ratio [a b]\n  (/ (+ (:scatter a)\n        (:scatter b))\n     (separation a b)))\n\n(defn max-davies-bouldin-ratio [[cluster & clusters]]\n  (->> (map #(davies-bouldin-ratio cluster %) clusters)\n       (apply max)))\n\n(defn rotations [xs]\n  (take (count xs)\n        (partition (count xs) 1 (cycle xs))))\n\n(defn davies-bouldin-index [clusters]\n  (let [ds (->> (map assoc-scatter clusters)\n                (rotations)\n                (map max-davies-bouldin-ratio))]\n    (s/mean ds)))\n```", "```py\n(defn ex-6-24 []\n  (let [ks (range 2 21)\n        ys (for [k ks\n                 :let [dir (str \"data/kmeans-clusters-\" k)\n                       clusters (load-clusters dir)]]\n             (davies-bouldin-index clusters))]\n    (-> (c/scatter-plot ks ys\n                        :x-label \"k\"\n                        :y-label \"Davies-Bouldin Index\")\n        (i/view))))\n```", "```py\n(defn ex-6-25 []\n  (let [data (dataset-with-outlier)\n        centroid  (i/matrix [[0 0]])\n        distances (map #(s/euclidean-distance centroid %) data)]\n    (-> (c/bar-chart (range 202) distances\n                     :x-label \"Points\"\n                     :y-label \"Euclidean Distance\") \n        (i/view))))\n```", "```py\n(defn ex-6-26 []\n  (let [data (dataset-with-outlier)\n        distances    (map first (s/mahalanobis-distance data))]\n    (-> (c/bar-chart (range 202) distances\n                     :x-label \"Points\"\n                     :y-label \"Mahalanobis Distance\")\n        (i/view))))\n```", "```py\n(defn ex-6-27 []\n  (let [distances (for [d (range 2 100)\n                        :let [data (->> (dataset-of-dimension d)\n                                        (s/mahalanobis-distance)\n                                        (map first))]]\n                    [(apply min data) (apply max data)])]\n    (-> (c/xy-plot (range 2 101) (map first distances)\n                   :x-label \"Number of Dimensions\"\n                   :y-label \"Distance Between Points\"\n                   :series-label \"Minimum Distance\"\n                   :legend true)\n        (c/add-lines (range 2 101) (map second distances)\n                     :series-label \"Maximum Distance\")\n        (i/view))))\n```"]