- en: A/B Testing for Better Marketing Strategy
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: When building different marketing strategies, whether your idea is going to
    work or not. Typically, there is a lot of guesswork involved when coming up with
    new marketing ideas, and often there is a lack of tools, resources, or even motivation
    to test whether any of your marketing ideas will work. However, this way of putting
    your marketing strategy ideas into work is risky and can be very costly. What
    if you spent lots of money on your new marketing campaign and it did not help
    you reach your marketing goal at all? What if you spent hundreds of hours refining
    your marketing message and it never attracted your prospects to engage with your
    marketing message?
  prefs: []
  type: TYPE_NORMAL
- en: In this chapter, we are going to discuss a way of testing your marketing ideas
    before you fully commit to them. More specifically, we are going to learn about
    what A/B testing is, why running A/B tests is important, and how it can help you
    reach your marketing goal in a more efficient and less expensive way.
  prefs: []
  type: TYPE_NORMAL
- en: 'In this chapter, we will cover the following topics:'
  prefs: []
  type: TYPE_NORMAL
- en: A/B testing for marketing
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Statistical hypothesis testing
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Evaluating A/B testing results with Python
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Evaluating A/B testing results with R
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: A/B testing for marketing
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: '**A/B testing** plays a critical role in decision-making processes across various
    industries. A/B testing is essentially a method of comparing and testing the effectiveness
    and benefits of two different business strategies. It can be considered as an
    experiment where two or more variants are tested for a set period of time and
    then the experiment results are evaluated to find the strategy that works best.
    Running A/B testing before fully committing to a single option helps businesses
    take the guesswork out of their decision-making processes and saves valuable resources,
    such as time and capital, that could have been wasted if the chosen strategy did
    not work.'
  prefs: []
  type: TYPE_NORMAL
- en: In a typical A/B testing setting, you would create and test two or more versions
    of marketing strategies for their effectiveness in achieving your marketing goal.
    Consider a case where your goal is to improve marketing email open rates. If your
    hypothesis is that email subject line B will result in higher open rates than
    email subject line A, then you would run an A/B test with these two subject lines.
    You will randomly select half of the users and send out marketing emails with
    subject line A. The other half of randomly selected users will receive emails
    with subject line B. You will run this test for a predetermined period of time
    (which could be one week, two weeks, or one month, for instance) or until a predetermined
    number of users receive the two versions of emails (which is a minimum of 1,000
    users to receive each version of the subject line). Once your tests are complete,
    then you analyze and evaluate the experiment results. When analyzing the results,
    you will need to check whether there is a statistically significant difference
    between the results of the two versions. We will cover more about statistical
    hypothesis testing and statistical significance in the following section. If your
    experiment results show a clear winner between the two versions of subject line,
    you can use the winning subject line in your future marketing emails.
  prefs: []
  type: TYPE_NORMAL
- en: Aside from the aforementioned email subject line scenario, A/B testing can be
    applied in many different areas of marketing. For instance, you can run A/B testing
    on your advertisements on social media. You can have two or more variants of your
    ads and run A/B tests to see which variation works better for click-through rates
    or conversion rates. As another example, you can use A/B testing to test whether
    product recommendations on your web page result in higher purchase rates. If you
    have built a different version of your product recommendation algorithm, then
    you can use and expose the initial version of your product recommendation algorithm
    to some randomly selected users and the second version to some other randomly
    selected users. You can gather the A/B test results and evaluate which version
    of your product recommendation algorithm helps you bring in more revenue.
  prefs: []
  type: TYPE_NORMAL
- en: As you can see from these example use cases, A/B testing plays an important
    role in decision-making. As you test different scenarios before you fully commit
    to one, it helps you save your energy, time, and capital that you could have wasted
    if you had fully committed to it but failed. A/B tests also help you take your
    guesswork away and quantify the performance gains (or losses) of your future marketing
    strategy. Whenever you have a new marketing idea that you would like to iterate
    on, you should consider running A/B tests first.
  prefs: []
  type: TYPE_NORMAL
- en: Statistical hypothesis testing
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: When you run A/B tests, it is important to test your hypothesis and seek for
    statistically significant differences among the test groups. Student's t-test,
    or simply the **t-test**, is frequently used to test whether the difference between
    two tests is statistically significant. The t-test compares the two averages and
    examines whether they are significantly different from each other.
  prefs: []
  type: TYPE_NORMAL
- en: 'There are two important statistics in a t-test—the **t-value** and **p-value**.
    The t-value measures the degree of difference relative to the variation in the
    data. The larger the t-value is, the more difference there is between the two
    groups. On the other hand, the p-value measures the probability that the results
    would occur by chance. The smaller the p-value is, the more statistically significant
    difference there will be between the two groups. The equation to compute the t-value
    is as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/7e564400-c20a-46a9-bf2e-08b039624cf2.png)'
  prefs: []
  type: TYPE_IMG
- en: In this equation, *M*[1] and *M[2]* are the averages of group *1* and *2*. *S[1]*
    and *S[2]* are the standard deviations of group *1* and *2**,* and *N[1]* and
    *N[2]* are number of samples in group *1* and *2* respectively.
  prefs: []
  type: TYPE_NORMAL
- en: There is a concept of the null hypothesis and the alternate hypothesis, which
    you should be familiar with. Generally speaking, the null hypothesis is that the
    two groups show no statistically significant difference. On the other hand, the
    alternate hypothesis states that the two groups show a statistically significant
    difference. When the t-value is larger than a threshold and the p-value is smaller
    than a threshold, we say that we can reject the null hypothesis and that the two
    groups show a statistically significant difference. Typically, 0.01 or 0.05 are
    used as the p-value thresholds for testing statistical significance. If the p-value
    is less than 0.05, then it suggests that there is less than 5% probability that
    the difference between the two groups occurs by chance. In other words, the difference
    is highly unlikely to be by chance.
  prefs: []
  type: TYPE_NORMAL
- en: Evaluating A/B testing results with Python
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this section, we are going to discuss how to evaluate A/B testing results
    to decide which marketing strategy works the best. By the end of this section,
    we will have covered how to run statistical hypothesis testing and compute the
    statistical significance. We will be mainly using the `pandas`, `matplotlib`,
    and `scipy` packages to analyze and visualize the data, and evaluate the A/B testing
    results.
  prefs: []
  type: TYPE_NORMAL
- en: For those readers who would like to use R instead of Python for this exercise,
    you can skip to the next section.
  prefs: []
  type: TYPE_NORMAL
- en: 'For this exercise, we will be using one of the publicly available datasets
    from the IBM Watson Analytics community, which can be found at this link: [https://www.ibm.com/communities/analytics/watson-analytics-blog/marketing-campaign-eff-usec_-fastf/](https://www.ibm.com/communities/analytics/watson-analytics-blog/marketing-campaign-eff-usec_-fastf/).
    You can follow this link and download the data, which is available in XLSX format,
    named `WA_Fn-UseC_-Marketing-Campaign-Eff-UseC_-FastF.xlsx`. Once you have downloaded
    this data, you can load it into your Jupyter Notebook by running the following
    command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: 'The `df` DataFrame looks as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/cba7050d-9fa8-4ffc-b7c9-6e01e6c7d49f.png)'
  prefs: []
  type: TYPE_IMG
- en: 'There are a total of seven variables in the dataset. You can find the descriptions
    of these variables on the IBM Watson Analytics Community page, but we will reiterate
    in the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '`MarketID`: unique identifier for market'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`MarketSize`: size of market area by sales'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`LocationID`: unique identifier for store location'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`AgeOfStore`: age of store in years'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`Promotion`: one of three promotions that was tested'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`week`: one of four weeks when the promotions were run'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`SalesInThousands`: sales amount for specific `LocationID`, `Promotion`, and
    `week`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Data analysis
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Let's take a deeper look at the data. In this section, we are going to focus
    on understanding the distributions of sales, market sizes, store locations, and
    store ages used to test different promotions. The goal of this analysis is to
    make sure the controls and attributes of each of the promotion groups are symmetrically
    distributed, so that the promotion performances among different groups are comparable
    to each other.
  prefs: []
  type: TYPE_NORMAL
- en: 'The total sales distributions across different promotions can be visualized
    using the following code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: As you can see from this code, we are grouping the data by the `Promotion` column and
    aggregating the total sales amount by summing over the `SalesInThousands` column.
    Using a pie chart, we can easily visualize how much of the pie each group takes.
  prefs: []
  type: TYPE_NORMAL
- en: 'The resulting pie chart looks as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/154b46df-a5f7-4828-b304-3a2bcb3c7be5.png)'
  prefs: []
  type: TYPE_IMG
- en: 'As is easily visible from this pie chart, promotion group **3** has the largest
    aggregate sales among the three groups. However, each promotion group takes roughly
    about one third of the total sales during the promotion weeks. Similarly, we can
    also visualize the compositions of different market sizes in each promotion group.
    Take a look at the following code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: 'The bar plot looks as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/43368d36-9f76-4c0b-a58a-4c9c50372d88.png)'
  prefs: []
  type: TYPE_IMG
- en: 'If you think a stacked bar chart will be easier to view, you can use the following
    code to display this data in a stacked bar plot:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: 'You may notice that the only difference between this code and the previous
    code is the `stacked=True` flag. The result looks as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/925c9804-6231-4cdb-81e8-164466db21de.png)'
  prefs: []
  type: TYPE_IMG
- en: As you can see from this bar chart, the medium market size occupies the most
    among all three promotion groups, while the small market size occupies the least.
    We can verify that the compositions of different market sizes are similar among
    the three promotion groups from this plot.
  prefs: []
  type: TYPE_NORMAL
- en: 'Another attribute, `AgeOfStore`, and its overall distribution across all different
    promotions groups, can be visualized by using the following code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: 'And the result looks as in the following bar plot:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/c17e98dd-0db7-4db6-b748-782b367030cd.png)'
  prefs: []
  type: TYPE_IMG
- en: 'As you can see from this plot, a large number of stores are **1** year old
    and the majority of stores are **10** years old or less. However, what we are
    more interested in is whether the stores in the three different promotion groups
    have similar store age profiles. Take a look at the following code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: 'Using this code, you will get the following output:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/203b97a7-78a0-42d0-8713-8fb94d496e30.png)'
  prefs: []
  type: TYPE_IMG
- en: 'The store age distributions across the three different promotion groups seem
    to align with each other, but it is quite difficult to digest the information
    presented from this plot. It will be easier to look at the summary statistics
    of store ages across the three promotion groups. Take a look at the following
    code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: 'The output of this code looks as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/bc132c1f-8897-4faf-b738-89a283ac1438.png)'
  prefs: []
  type: TYPE_IMG
- en: As you may notice from this output, it is much easier to understand the overall
    store age distributions from these summary statistics. We can see that all three
    test groups seem to have similar store age profiles. The average ages of stores
    for the three groups are 8–9 years old and the majority of the stores are 10–12
    years old or younger.
  prefs: []
  type: TYPE_NORMAL
- en: By analyzing how each promotion or test group is comprised, we could verify
    that the store profiles are similar to each other. This suggests that the sample
    groups are well controlled and the A/B testing results will be meaningful and
    trustworthy.
  prefs: []
  type: TYPE_NORMAL
- en: Statistical hypothesis testing
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The ultimate goal of A/B testing of different marketing strategies is to find
    out which strategy is the most efficient and works the best among the others.
    As briefly discussed in an earlier section, a strategy having a higher response
    number does not necessarily mean that it outperforms the rest. We will discuss
    how we can use the t-test to evaluate the relative performances of different marketing
    strategies and see which strategy wins over the others with significance.
  prefs: []
  type: TYPE_NORMAL
- en: 'In Python, there are two approaches to computing the t-value and p-value in
    a t-test. We will demonstrate both approaches in this section, and it is up to
    you to decide which one works more conveniently for you. The two approaches to
    compute the t-value and p-value for a t-test are as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Computing t-value and p-value from the equations**: The first approach is
    to manually calculate the t-value using the equation we have learned in the previous
    section. As you may recall, there are three things we need to compute to get the
    t-value—the mean, the standard deviation, and the number of samples. Take a look
    at the following code:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: 'As you can see from this code, you can easily compute the mean, the standard
    deviation, and the number of samples in each test group by using the `mean`, `std`,
    and `count` functions respectively. With these, we can compute the t-value using
    the previously discussed equation. Take a look at the following code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs: []
  type: TYPE_PRE
- en: 'Using this code, we can compute the t-value for comparing the performances
    of promotion 1 and promotion 2\. The t-value we get from running the code is `6.4275`.
    From this t-value, we can get the p-value with the following code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs: []
  type: TYPE_PRE
- en: As you can see from this code, we first compute the degrees of freedom, which
    is the sum of the number of samples in both groups minus two. With the t-value
    calculated previously, we can compute the p-value, using the `t.cdf` function
    from `scipy` package's `stats` module. The p-value we get from running this code
    is `4.143e-10`. This is an extremely small number that is close to `0`. As discussed
    earlier, a p-value closer to 0 suggests that there is a strong evidence against
    the null hypothesis and that the difference between the two test groups is significant.
  prefs: []
  type: TYPE_NORMAL
- en: The average sales (in thousands) for promotion group 1 is about `58.1`, and
    for promotion group 2 it's about `47.33`. From our t-test, we have shown that
    the marketing performances for these two groups are significantly different and
    that promotion group 1 outperforms promotion group 2\. However, if we run a t-test
    between the promotion group 1 and promotion group 3, we see different results.
  prefs: []
  type: TYPE_NORMAL
- en: On the surface, the average sales from promotion group 1 (`58.1`) looks higher
    than those from promotion group 2 (`55.36`). However, when we run a t-test between
    these two groups, we get a t-value of `1.556` and a p-value of `0.121`. The computed
    p-value is much higher than `0.05`, which is a generally accepted cut-off line.
    This suggests that the marketing performance from promotion group 1 is not statistically
    different from the marketing performance from promotion group 2\. Thus, even though
    promotion group 1's average sales number is higher than the promotion group 2's
    from the A/B test, the difference is not statistically significant and we cannot
    conclude that promotion group 1 performs much better than promotion group 2\.
    From these evaluation results, we can conclude that promotion groups 1 and 3 outperform
    promotion group 2, but the difference between promotion groups 1 and 3 is not
    statistically significant.
  prefs: []
  type: TYPE_NORMAL
- en: '**Computing the t-value and p-value using scipy**: Another approach to computing
    the t-value and p-value is by using the `stats` module from the `scipy` package.
    Take a look at the following code:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[PRE10]'
  prefs: []
  type: TYPE_PRE
- en: As you can see from this code, the `stats` module from the `scipy` package has
    a function named `ttest_ind`. This function computes t-value and p-value, given
    the data. Using this function, we can easily compute t-values and p-values to
    compare the marketing performances of different promotion or test groups. The
    results are the same in both approaches. Whether we use the previous approach
    of manually computing the t-values and p-values from the equation or the approach
    of using the `ttest_ind` function in the `scipy` package, the t-values we get
    to compare promotion group 1 against 2 and promotion group 1 against 3 are `6.4275`
    and `1.556`; whereas, the p-values we get are `4.29e-10` and `0.121` respectively.
    And, of course, the interpretations of these t-test results are the same as before.
  prefs: []
  type: TYPE_NORMAL
- en: We have shown two approaches to computing t-values and p-values. It may look
    easier to use the `scipy` package's out-of-the-box solution to compute those values,
    but it is always helpful to have the equation in the back in your mind.
  prefs: []
  type: TYPE_NORMAL
- en: The full code for this Python exercise can be found at the following link: [https://github.com/yoonhwang/hands-on-data-science-for-marketing/blob/master/ch.12/python/ABTesting.ipynb](https://github.com/yoonhwang/hands-on-data-science-for-marketing/blob/master/ch.12/python/ABTesting.ipynb).
  prefs: []
  type: TYPE_NORMAL
- en: Evaluating A/B testing results with R
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this section, we are going to discuss how to evaluate A/B testing results
    to decide which marketing strategy works the best. By the end of this section,
    we will have covered how to run statistical hypothesis testing and compute the
    statistical significance. We will be mainly using `dplyr` and `ggplot2` to analyze
    and visualize the data and evaluate the A/B testing results.
  prefs: []
  type: TYPE_NORMAL
- en: For those readers who would like to use Python instead of R for this exercise,
    you can refer to the previous section.
  prefs: []
  type: TYPE_NORMAL
- en: 'For this exercise, we will be using one of the publicly available datasets
    from the IBM Watson Analytics community, which can be found at this link: [https://www.ibm.com/communities/analytics/watson-analytics-blog/marketing-campaign-eff-usec_-fastf/](https://www.ibm.com/communities/analytics/watson-analytics-blog/marketing-campaign-eff-usec_-fastf/).
    You can follow this link and download the data, which is available in XLSX format,
    named `WA_Fn-UseC_-Marketing-Campaign-Eff-UseC_-FastF.xlsx`. Once you have downloaded
    this data, you can load it into your RStudio by running the following command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE11]'
  prefs: []
  type: TYPE_PRE
- en: 'The `df` DataFrame looks as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/789290db-bc30-45b4-b6cb-024f2145de85.png)'
  prefs: []
  type: TYPE_IMG
- en: 'There are a total of seven variables in the dataset. You can find the descriptions
    of these variables on the IBM Watson Analytics Community page, but we will reiterate
    in the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '`MarketID`: unique identifier for market'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`MarketSize`: size of market area by sales'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`LocationID`: unique identifier for store location'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`AgeOfStore`: age of store in years'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`Promotion`: one of three promotions that was tested'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`week`: one of four weeks when the promotions were run'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`SalesInThousands`: sales amount for a specific `LocationID`, `Promotion`,
    and `week`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Data analysis
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Let's take a deeper look at the data. In this section, we are going to focus
    on understanding the distributions of sales, market sizes, store locations, and
    store ages used to test different promotions. The goal of this analysis is to
    make sure that the controls and attributes of each promotion groups are symmetrically
    distributed, so that the promotion performances among different groups are comparable
    to each other.
  prefs: []
  type: TYPE_NORMAL
- en: 'The total sales distributions across different promotions can be visualized
    using the following code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE12]'
  prefs: []
  type: TYPE_PRE
- en: As you can see from this code, we are grouping the data by the `Promotion` column and
    aggregating the total sales amount by summing over the `SalesInThousands` column.
    Using a pie chart, we can easily visualize how much of the pie each group takes.
  prefs: []
  type: TYPE_NORMAL
- en: 'The resulting pie chart looks as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/55644525-9f11-4aa8-a57b-b747c89df7c8.png)'
  prefs: []
  type: TYPE_IMG
- en: 'As is easily visible from this pie chart, promotion group 3 has the largest
    aggregate sales among the three groups. However, each promotion group takes roughly
    one third of the total sales during the promotion weeks. Similarly, we can also
    visualize the compositions of different market sizes in each promotion group.
    Take a look at the following code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE13]'
  prefs: []
  type: TYPE_PRE
- en: 'The bar plot looks as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/86c3d24a-7177-4acf-9dfe-ebaa156e40d1.png)'
  prefs: []
  type: TYPE_IMG
- en: 'If you think a stacked bar chart will be easier to view, you can use the following
    code to display this data in a stacked bar plot:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE14]'
  prefs: []
  type: TYPE_PRE
- en: 'You may notice that the only difference between this code and the previous
    code is the `position="stack"` flag in the `geom_bar` function. The result looks
    as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/bfa1e513-4576-42dd-990b-79b111d71d4b.png)'
  prefs: []
  type: TYPE_IMG
- en: As you can see from this bar chart, the medium market size occupies the most
    among all three promotion groups, while small market size occupies the least.
    We can verify that the compositions of different market sizes are similar among
    the three promotion groups from this plot.
  prefs: []
  type: TYPE_NORMAL
- en: 'Another attribute, `AgeOfStore`, and its overall distributions across all different
    promotions groups, can be visualized by using the following code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE15]'
  prefs: []
  type: TYPE_PRE
- en: 'And the result looks like the following bar plot:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/2545b6a9-074f-4164-b4b7-38798c1b60d9.png)'
  prefs: []
  type: TYPE_IMG
- en: 'As you can see from this plot, a large number of stores are **1** year old
    and the majority of stores are **10** years old or less. However, what we are
    more interested in is whether the stores in the three different promotion groups
    have similar store age profiles. Take a look at the following code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE16]'
  prefs: []
  type: TYPE_PRE
- en: 'Using this code, you will get the following output:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/73f3b9ec-bf12-432c-99c1-e051ab9bb93d.png)'
  prefs: []
  type: TYPE_IMG
- en: 'The store age distributions across the three different promotion groups seem
    to align with each other, but it is quite difficult to digest the information
    presented from this plot. It will be easier to look at the summary statistics
    of store ages across the three promotion groups. Take a look at the following
    code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE17]'
  prefs: []
  type: TYPE_PRE
- en: 'The output of this code looks as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/200bc692-cd85-41ff-87a6-a7b086bf35bb.png)'
  prefs: []
  type: TYPE_IMG
- en: As you may notice from this output, it is much easier to understand the overall
    store age distributions from these summary statistics. We can see that all three
    test groups seem to have similar store age profiles. The average ages of stores
    for the three groups are 8-9 years old and the majority of the stores are 10-12
    years old or younger.
  prefs: []
  type: TYPE_NORMAL
- en: By analyzing how each promotion or test group is comprised, we could verify
    that the store profiles are similar to each other. This suggests that the sample
    groups are well controlled and the A/B testing results will be meaningful and
    trustworthy.
  prefs: []
  type: TYPE_NORMAL
- en: Statistical hypothesis testing
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The ultimate goal of A/B testing of different marketing strategies is to find
    out which strategy is the most efficient and works the best among the others.
    As briefly discussed in an earlier section, a strategy with a higher response
    number does not necessarily mean that it outperforms the rest. We will discuss
    how we can use the t-test to evaluate the relative performances of different marketing
    strategies and see which strategy wins over the others with significance.
  prefs: []
  type: TYPE_NORMAL
- en: 'In R, there are two approaches to compute the t-value and p-value for a t-test.
    We will demonstrate both approaches in this section, and it is up to you to decide
    which one works more conveniently for you. The two approaches to compute the t-value
    and p-value for a t-test are as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Computing the t-value and p-value from the equations**: The first approach
    is to manually calculate the t-value using the equation we have learned in the
    previous section. As you may recall, there are three things we need to compute
    to get the t-value: the mean, the standard deviation, and the number of samples.
    Take a look at the following code:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[PRE18]'
  prefs: []
  type: TYPE_PRE
- en: 'As you can see from this code, you can easily compute the mean, the standard
    deviation, and the number of samples in each test group by using the `mean`, `sd`,
    and `length` functions respectively. With these, we can compute the t-value using
    the previously discussed equation. Take a look at the following code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE19]'
  prefs: []
  type: TYPE_PRE
- en: 'Using this code, we can compute the t-value for comparing the performances
    of promotion 1 and promotion 2\. The t-value we get from running the code is `6.4275`.
    From this t-value, we can get the p-value with the following code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE20]'
  prefs: []
  type: TYPE_PRE
- en: As you can see from this code, we first compute the degrees of freedom, which
    is the sum of the number of samples in both groups minus two. With the t-value
    calculated previously, we can compute the p-value using the `pt` function, which
    returns a probability value from the t-distribution, given the t-value and degree
    of freedom. The p-value we get from running this code is `4.143e-10`. This is
    an extremely small number that is close to 0\. As discussed earlier, a p-value
    close to 0 suggests that there is strong evidence against the null hypothesis
    and that the difference between the two test groups is significant.
  prefs: []
  type: TYPE_NORMAL
- en: The average sales (in thousands) for promotion group 1 is about `58.1`, and
    for promotion group 2 it's about `47.33`. From our t-test, we have shown that
    the marketing performances for these two groups are significantly different and
    that promotion group 1 outperforms promotion group 2\. However, if we run a t-test
    between promotion group 1 and promotion group 3, we see different results.
  prefs: []
  type: TYPE_NORMAL
- en: On the surface, the average sales from promotion group 1 (`58.1`) looks higher
    than those from promotion group 2 (`55.36`). However, when we run a t-test between
    these two groups, we get a t-value of `1.556` and a p-value of `0.121`. The computed
    p-value is much higher than `0.05`, which is a generally accepted cut-off line.
    This suggests that the marketing performance for promotion group 1 is not statistically
    different from the marketing performance of promotion group 2\. Thus, even though
    promotion group 1's average sales number is higher than promotion group 2's from
    the A/B test, the difference is not statistically significant, and we cannot conclude
    that promotion group 1 performs much better than promotion group 2\. From these
    evaluation results, we can conclude that promotions groups 1 and 3 outperform
    promotion group 2, but the difference between promotion groups 1 and 3 is not
    statistically significant.
  prefs: []
  type: TYPE_NORMAL
- en: '**Computing the t-value and p-value using t.test**: Another approach to compute
    the t-value and p-value is by using the `t.test` function in R. Take a look at
    the following code:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[PRE21]'
  prefs: []
  type: TYPE_PRE
- en: As you can see from this code, R has a `t.test` function, which computes the
    t-value and p-value, given data. Using this function, we can easily compute t-values
    and p-values to compare the marketing performances of different promotions or
    test groups. The results are the same in both approaches. Whether we use the previous
    approach of manually computing the t-values and p-values from the equation or
    the approach of using the `ttest_ind` function in the `scipy` package, the t-values
    we get to compare promotion group 1 against promotion group 2 and promotion group
    1 against promotion group 3 are `6.4275` and `1.556`; whereas, the p-values we
    get are `4.29e-10` and `0.121` respectively. And, of course, the interpretations
    of these t-test results are the same as before.
  prefs: []
  type: TYPE_NORMAL
- en: We have shown two approaches to computing t-values and p-values. It may look
    easier to use the `t.test` function in R, but it is always helpful to have the
    equation in the back of your mind.
  prefs: []
  type: TYPE_NORMAL
- en: The full code for this R exercise can be found at the following link: [https://github.com/yoonhwang/hands-on-data-science-for-marketing/blob/master/ch.12/R/ABTesting.R](https://github.com/yoonhwang/hands-on-data-science-for-marketing/blob/master/ch.12/R/ABTesting.R).
  prefs: []
  type: TYPE_NORMAL
- en: Summary
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this chapter, we have learned about one of the most frequently used testing
    methods in marketing for making decisions on future marketing strategies. We have
    discussed what A/B testing is, why it is important to run A/B tests before you
    fully commit to one marketing strategy, and how it can help you reach your marketing
    goal in a more efficient and less expensive way. By working through a sample use
    case, where your goal was to choose the best email subject line, we learned what a
    typical process for running A/B tests looks like. A/B testing does not need to
    happen only once. A/B tests are best used when you consistently test your new
    ideas against currently running strategies or against other ideas through experiments.
    Simply put, whenever there is a new idea, it should be A/B tested. Using the t-test
    and the Python and R tools that we have learned about in this chapter, you should
    be able to easily evaluate A/B test results and identify which strategy is the
    winning strategy.
  prefs: []
  type: TYPE_NORMAL
- en: This chapter was the last technical chapter with case studies and programming
    exercises. In the next chapter, we are going to summarize and review all the topics
    that we have covered throughout this book. Then, we will discuss some common data
    science and machine learning applications in marketing and some other Python and
    R libraries that you can benefit from in your future projects that have not been
    covered in this book.
  prefs: []
  type: TYPE_NORMAL
