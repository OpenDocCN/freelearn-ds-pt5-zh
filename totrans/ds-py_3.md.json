["```py\n    import pandas as pd\n    df = pd.read_csv('glass.csv')\n    ```", "```py\n    print(df.info()):\n    ```", "```py\n    from sklearn.utils import shuffle\n    df_shuffled = shuffle(df, random_state=42)\n    ```", "```py\n    from sklearn.preprocessing import StandardScaler\n    scaler = StandardScaler() \n    scaled_features = scaler.fit_transform(df_shuffled)\n    ```", "```py\n    from scipy.cluster.hierarchy import linkage \n    model = linkage(scaled_features, method='complete')\n    ```", "```py\n    import matplotlib.pyplot as plt \n    from scipy.cluster.hierarchy import dendrogram\n    plt.figure(figsize=(10,5))\n    plt.title('Dendrogram for Glass Data')\n    dendrogram(model, leaf_rotation=90, leaf_font_size=6)\n    plt.show()\n    ```", "```py\n    from scipy.cluster.hierarchy import fcluster\n    labels = fcluster(model, t=9, criterion='distance')\n    ```", "```py\n    df_shuffled['Predicted_Cluster'] = labels\n    print(df_shuffled.head(5))\n    ```", "```py\n    from sklearn.cluster import KMeans\n    model = KMeans(n_clusters=2)\n    ```", "```py\n    model.fit(scaled_features)\n    ```", "```py\n    labels = model.labels_\n    ```", "```py\n    import pandas as pd\n    pd.value_counts(labels)\n    ```", "```py\n    df_shuffled['Predicted_Cluster'] = labels\n    print(df_shuffled.head(5))\n    ```", "```py\n    from sklearn.cluster import KMeans\n    import numpy as np\n    ```", "```py\n    inertia_list = []\n    ```", "```py\n    for i in range(100):\n    ```", "```py\n    model = KMeans(n_clusters=x)\n    ```", "```py\n    model.fit(scaled_features)\n    ```", "```py\n    inertia = model.inertia_\n    ```", "```py\n    inertia_list.append(inertia)\n    ```", "```py\n    mean_inertia_list = []\n    ```", "```py\n    for x in range(1, 11):\n    ```", "```py\n    mean_inertia = np.mean(inertia_list)\n    ```", "```py\n    mean_inertia_list.append(mean_inertia)\n    ```", "```py\n    print(mean_inertia_list)  \n    ```", "```py\n    import matplotlib.pyplot as plt\n    ```", "```py\n    x = list(range(1, len(mean_inertia_list)+1))\n    ```", "```py\n    y = mean_inertia_list\n    ```", "```py\n    plt.plot(x, y)\n    ```", "```py\n     plt.title('Mean Inertia by n_clusters') \n    ```", "```py\n    plt.ylabel ('Mean Inertia')\n    ```", "```py\n    plt.xticks(x)\n    ```", "```py\n    plt.plot(x, y)\n    plt.title('Mean Inertia by n_clusters')\n    plt.xlabel('n_clusters')\n    plt.xticks(x)\n    plt.ylabel('Mean Inertia')\n    plt.show()\n    ```", "```py\n    from sklearn.decomposition import PCA\n    model = PCA()\n    ```", "```py\n    model.fit(scaled_features)\n    ```", "```py\n    explained_var_ratio = model.explained_variance_ratio_\n    print(explained_var_ratio)\n    ```", "```py\n    import numpy as np\n    cum_sum_explained_var = np.cumsum(model.explained_variance_ratio_)\n    print(cum_sum_explained_var)\n    ```", "```py\n    threshold = .95\n    ```", "```py\n    for i in range(len(cum_sum_explained_var)):\n    ```", "```py\n    if cum_sum_explained_var[i] >= threshold:\n    ```", "```py\n    best_n_components = i+1\n    break\n    ```", "```py\n    else:\n    pass\n    ```", "```py\n    print('The best n_components is {}'.format(best_n_components))\n    ```", "```py\n    import matplotlib.pyplot as plt\n    ```", "```py\n    x = list(range(1,len(mean_inertia_list_PCA)+1))\n    ```", "```py\n    y = mean_inertia_list_PCA\n    ```", "```py\n    y2 = mean_inertia_list\n    ```", "```py\n    plt.plot(x, y, label='PCA')\n    ```", "```py\n    plt.plot(x, y2, label='No PCA)\n    ```", "```py\n    plt.title('Mean Inertia by n_clusters for Original Features and PCA Transformed Features')\n    ```", "```py\n    plt.xlabel('n_clusters')\n    ```", "```py\n    plt.ylabel('Mean Inertia')\n    ```", "```py\n    plt.legend()\n    plt.show()\n    ```", "```py\n    import pandas as pd\n    df = pd.read_csv(‘glass_w_outcome.csv’)\n    ```", "```py\n    from sklearn.utils import shuffle\n    df_shuffled = shuffle(df, random_state=42)\n    ```", "```py\n    DV = ‘Type’\n    ```", "```py\n    from sklearn.model_selection import train_test_split\n    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)\n    ```", "```py\n    from sklearn.preprocessing import StandardScaler\n    scaler = StandardScaler() \n    X_train_scaled = scaler.fit_transform(X_train) \n    X_test_scaled = scaler.fit_transform(X_test)\n    ```", "```py\n    from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n    -model = LinearDiscriminantAnalysis()\n    ```", "```py\n    model.fit(X_train_scaled, y_train)\n    ```", "```py\n    model.explained_variance_ratio_\n    ```", "```py\n    X_train_LDA = model.transform(X_train_scaled)\n    ```", "```py\n    X_test_LDA = model.transform(X_test_scaled)\n    ```", "```py\n    from sklearn.ensemble import RandomForestClassifier\n    model = RandomForestClassifier()\n    ```", "```py\n    model.fit(X_train_LDA, y_train)\n    ```", "```py\n    predictions = model.predict(X_test_LDA)\n    ```", "```py\n    from sklearn.metrics import confusion_matrix \n    import pandas as pd\n    import numpy as np\n    cm = pd.DataFrame(confusion_matrix(y_test, predictions))\n    cm[‘Total’] = np.sum(cm, axis=1)\n    cm = cm.append(np.sum(cm, axis=0), ignore_index=True)\n    cm.columns = [‘Predicted 1’, ‘Predicted 2’, ‘Predicted 3’, ‘Total’]\n    cm = cm.set_index([[‘Actual 1’, ‘Actual 2’, ‘Actual 3’, ‘Total’]])\n    print(cm)\n    ```"]