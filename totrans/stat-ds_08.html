<html><head></head><body><div><h1 class="header-title">Database Development and Assessment</h1>
                
            
            
                
<p class="calibre4">In this chapter, we will cover the practice of data (database) assessment. We will provide an understanding of what statistical assessment is, and why it is important to the data scientist, as well as providing instructive examples using R to perform various statistical assessment methods.</p>
<p class="calibre4">As we have been endeavoring to do throughout this book, we will draw similarities between certain data developer and data scientist concepts, looking at the differences between data or database development and data (database) assessment, as well as offer a comparison between the practice of data assessment and data (quality) assurance.</p>
<p class="calibre4">We've organized information in this chapter into the following areas:</p>
<ul class="calibre18">
<li class="calibre19">Comparison of assessment and statistical assessments</li>
<li class="calibre19">Development versus assessment</li>
<li class="calibre19">Is data assessment an assurance of data quality?</li>
<li class="calibre19">Applying the idea of statistical assessment to your data using R</li>
</ul>
<p class="calibre4">Let's get started!</p>


            

            
        
    </div>



  
<div><h1 class="header-title">Assessment and statistical assessment</h1>
                
            
            
                
<p class="calibre4">Merriam-Webster defines assessment as:</p>
<p>The action or an instance of making a judgment about something.</p>
<p class="calibre4">The following image shows flow for assessing statistical data:</p>
<div><strong class="calibre3"><img class="image-border41" src="img/c78bdd2b-3cc2-4748-9fab-e4edddcd725b.png"/></strong></div>
<p class="calibre4">We need to keep a few pointers in mind for statistical assessment. They are listed as follows.</p>


            

            
        
    </div>



  
<div><h1 class="header-title">Objectives</h1>
                
            
            
                
<p class="calibre4">With that in mind, to be able to make a reasonable assessment--that is, make a judgment--on something (anything really), one must first have to set objective(s). Assessment objectives help the data scientist determine how to assess data, a database, or a statistical data model. Without clear objectives, you'll waste valuable time, and potentially, put confidence in a model that doesn't meet a business requirement or may even lead to incorrect assumptions (predictions).</p>


            

            
        
    </div>



  
<div><h1 class="header-title">Baselines</h1>
                
            
            
                
<p class="calibre4">Next, (based on your set objectives) standards, minimum acceptable performance, or a baseline to establish an opinion on what is being assessed need to be established. In other words, how well does what you are assessing compare to what you agree is acceptable?</p>
<p class="calibre4">Although we won't spend any significant time here on the process of database assessment (rather focus on statistical data or statistical data model assessment), we will mention the use of specific measures of performance (performance measures or metrics).</p>
<p class="calibre4">Data scientists will frequently use very specific (performance) metrics when evaluating the predictive accuracy of a statistical model. These metrics depend on the class or type of the problem being assessed and require one to use slightly different ways of assessing (the model's) performance. This approach also survives as a rule to assess standard, non-statistical data and databases. For example, there are specific performance metrics used to assess an <strong class="calibre7">online transaction processing</strong> (<strong class="calibre7">OLTP</strong>) data model and those will be quite different from those used to assess an <strong class="calibre7">enterprise data warehouse</strong> (<strong class="calibre7">EDW</strong>) model.</p>
<p class="calibre4">Looking a little deeper, when evaluating, performance testing, or assessing a (non-statistical) database, one would focus on the identification of various benchmarks (that is, benchmarking), capacity determination and planning, executing soaking or soak tests, peak-rest intervals (to name a few examples) as part of the effort.</p>


            

            
        
    </div>



  
<div><h1 class="header-title">Planning for assessment</h1>
                
            
            
                
<p class="calibre4">Just as the type of non-statistical database (OLTP, EDW, and so on) would determine what tests would be used to perform an assessment, so would the type of statistical model (for example, regression, classification, binary classification, and so on) dictate the appropriate assessment techniques or methods (more on this later in this chapter) a data scientist would use to assess a statistical model.</p>
<p class="calibre4">Once you have set the objectives for an assessment and established a baseline, an execution plan is developed. The plan typically outlines the entire process to be performed. The plan will list the tests to be performed along with the test objectives, baselines to be compared to, and even expected outcomes.</p>


            

            
        
    </div>



  
<div><h1 class="header-title">Evaluation</h1>
                
            
            
                
<p class="calibre4">In statistics, the term <strong class="calibre7">performance</strong> is usually interchangeably with the idea of a model's accuracy. When speaking about a non-statistical database or model, performance is perhaps all about speed—how long it takes for a query to return values, how long it takes to commit a transaction, and so on—and accuracy, and usually revolves around the idea of quality assurance, not an ability to predict values!</p>
<p class="calibre4">When assessing statistical models, a data scientist will look at a model's error rate, the number of misclassifications (that were made by a model), the ratio of the number of correctly predicted compared to the total number of predicted instances (by the model), and more. Again, all of this is dependent on the statistical model type and the objectives.</p>
<p class="calibre4">Finally, once completed, the results of both a database and statistical data model assessment typically will be visualized in various ways for easier evaluation, using commonly accepted methods (again, how one exposes or visualizes process results will depend on the objectives of the one preparing the visualizations or the objectives of the model). It should be understood that it is not uncommon for various portions of an assessment process (or even the entire assessment process) to be repeated once the results of the assessment have been evaluated. This may be to further clarify something identified in the presented results or for revalidation of certain results. In some situations, new project objectives, baselines, and even a new plan may be developed and executed.</p>
<p class="calibre4">To summarize, the process of performing a database or (statistical) data model assessment is, in a broad sense, similar to that both require the following:</p>
<ul class="calibre18">
<li class="calibre19">Set objectives (of the database or data model)</li>
<li class="calibre19">Establish baselines (to compare performances too)</li>
<li class="calibre19">Determine (the) plan (to carry out the assessment)</li>
<li class="calibre19">Evaluate the results</li>
</ul>


            

            
        
    </div>



  
<div><h1 class="header-title">Development versus assessment</h1>
                
            
            
                
<p class="calibre4">Although an assessment process does produce output, which ultimately is perhaps just a decision (that is, does the data, database, or statistical data model under observation meet the acceptable limits of performance, based on the objectives?), development implies building.</p>
<p class="calibre4">Development can also mean improving by expanding, enlarging, or refining. This means that (or at least it implies that) whatever one is developing may never be completely done. In fact, development and assessment do go hand in hand.</p>
<p class="calibre4">An industry-proven practice recommendation to develop anything is as follows:</p>
<ul class="calibre18">
<li class="calibre19">Build (or develop)</li>
<li class="calibre19">Test</li>
<li class="calibre19">Assess</li>
<li class="calibre19">Repeat</li>
</ul>
<p class="calibre4">When developing a relational data model, one might utilize a <kbd class="calibre22">create</kbd> SQL statement, something like the following code:</p>
<pre class="calibre29">mysql&gt; CREATE TABLE test (a INT NOT NULL AUTO_INCREMENT,<br class="calibre2"/>-&gt; PRIMARY KEY (a), KEY(b))<br class="calibre2"/>-&gt; ENGINE=MyISAM SELECT b,c FROM test2;</pre>
<p class="calibre4">Dissecting the preceding code, we can see that the outcome is that a table object <kbd class="calibre22">test</kbd> is generated. Perhaps, keeping the same in mind, assessing a (relational) database or data model might use some form of the following code example:</p>
<pre class="calibre29">USE AdventureWorks;<br class="calibre2"/>GO<br class="calibre2"/>SET STATISTICS IO ON<br class="calibre2"/>SET STATISTICS TIME ON<br class="calibre2"/>SELECT p.Name, pr.ProductReviewID<br class="calibre2"/>FROM Production.Product p<br class="calibre2"/>JOIN Production.ProductReview pr<br class="calibre2"/>ON p.ProductID = pr.ProductID<br class="calibre2"/>SET STATISTICS IO OFF<br class="calibre2"/>SET STATISTICS TIME OFF</pre>
<p class="calibre4">Statements like the preceding ones execute performance tools that return relevant statistics that can be visualized and analyzed.</p>
<p class="calibre4">A comparable (although simplistic) statistical development (or create) example might look like the following R code (taken from <a href="46966f7a-6d7f-4e47-b230-e71ef7d5ad01.xhtml" target="_blank" class="pcalibre pcalibre3 pcalibre1 calibre8 pcalibre2">Chapter 7</a>, <em class="calibre21">Regularization for Database Improvement</em>):</p>
<pre class="calibre29"># --- using the R lm function to create an ordinary least squares (OLS) # -- fit of 3-variable model using x3 as an independent x3 variable<br class="calibre2"/>ols &lt;- lm(y~ x1 + x2 + x3)<br class="calibre2"/>summary(ols)</pre>
<p class="calibre4">Also from <a href="46966f7a-6d7f-4e47-b230-e71ef7d5ad01.xhtml" target="_blank" class="pcalibre pcalibre3 pcalibre1 calibre8 pcalibre2">Chapter 7</a>, <em class="calibre21">Regularization for Database Improvement</em>, we used the R function summary to start performing some assessment of the performance of the generated linear regression model:</p>
<div><img class="image-border36" src="img/3bef23e9-cbf9-4318-a0c3-c662ca52409d.png"/></div>
<p class="calibre4">As mentioned earlier, depending on the <strong class="calibre7">class</strong> of a statistical problem, the data scientist will use different approaches or methods to assess (a model's) performance (including the R function summary).</p>


            

            
        
    </div>



  
<div><h1 class="header-title">Planning</h1>
                
            
            
                
<p class="calibre4">In the previous section of this chapter, we compared and drew similarities between assessment and statistical assessment and also noted that as part of any assessment project (or at least one that you want to be successful), you need to create a plan.</p>
<p class="calibre4">Moving on to this section where we are relating development and assessment, we again see that the first step in the process of developing is perhaps to create a plan.</p>
<p>The author believes that the act of creating a plan is a basic requirement for any endeavor in life, even getting up in the morning!</p>
<p class="calibre4">The plan that one creates when having database development in mind can be used as both a guidebook when implementing (in this case, a database or statistical data model) as well as a functional specification (for the database) after implementing it.</p>
<p class="calibre4">What about the task of assessing a database (or in statistics, a data model)? Well, the same applies. The first step is to develop a detailed assessment plan, again that can be used to guide the entire assessment process, then become a functional specification reference after the assessment is completed.</p>
<p class="calibre4">Planning always pays for itself. A good development or assessment plan can become a detailed project plan, an acceptance testing plan, documentation for deployment, and, as already mentioned, a functional specification reference.</p>
<p class="calibre4">Database design is part of the process of data or database development. Designing a database can be a complex task. Part of the design process is for a data modeler (or very experienced data developer) to study the data, its source(s), the requirements, and so on, then produce a detailed data model. This data model will contain all of the needed logical as well as physical design choices as well as the physical storage parameters needed to generate a design in a <strong class="calibre7">data definition language</strong> (<strong class="calibre7">DDL</strong>), which can then be used to actually create the database.</p>
<p class="calibre4">A comprehensive database development plan would include the database design phase (modeling through creation) as well as call-outs to multiple testing and evaluation steps along the way.</p>
<p class="calibre4">Statistical modeling (actually considered to be a form of mathematical modeling) involves embodying or pulling together a set of assumptions concerning or about the generation of some sample data and similar data from a (hopefully) much bigger population (of data).</p>
<p class="calibre4">A plan for the generation of a statistical model would (similar to a plan to generate a database model) include the examination of (sample) data, its source(s), all requirements, and so on. Again, as with the previously mentioned plan, the statistical modeling plan would include mentioning of each assessment and evaluation that the data scientist plans to use on the statistical model.</p>
<p class="calibre4">Typically, a statistical model assessment plan would also include references to the visualizations that the data scientist plans to make the point or summarize the results following each assessment test.</p>
<p class="calibre4">Statistical modeling has been described as studying a system or process to predict its future behavior, as said by Madhuri Kulkarni:</p>
<p>With the availability of observed data of a system, models can help infer various alternatives for the system.</p>
<p class="calibre4">Of all the generic tools that can be used for statistical modeling (and to understand and manipulate data), R seems to be the most powerful and the most popular.</p>
<p class="calibre4">From a non-statistical modeling perspective, data modeling defines and analyzes the requirements to support the business process (within the space of certain information systems in the organization). Here, tools such as Erwin Data Modeler and MySQL Workbench seem to constitute the tools most often successfully used.</p>
<p class="calibre4">Finally, although development and assessment are separate efforts, they are intimately related and, statistical or non-statistical, one does not exist without the existence of the other.</p>


            

            
        
    </div>



  
<div><h1 class="header-title">Data assessment and data quality assurance</h1>
                
            
            
                
<p class="calibre4">To be methodical with our discussions here, let's look at how data assessment compares or stacks up to data quality (assurance).</p>
<p class="calibre4">Data quality assurance, or often referred to as <strong class="calibre7">tidying the data</strong> by data scientists, is the process of addressing (perhaps perceived) issues or concerns that had been identified within data. These issues affect the use, quality, and outcome (performance) of a database or data model—data quality, of course, being relative to the proposed purpose of use (of the data, database, or data model).</p>


            

            
        
    </div>



  
<div><h1 class="header-title">Categorizing quality</h1>
                
            
            
                
<p class="calibre4">Typically, issues with data quality may be categorized into one of the following areas:</p>
<ul class="calibre18">
<li class="calibre19">Accuracy</li>
<li class="calibre19">Completeness</li>
<li class="calibre19">Update Status</li>
<li class="calibre19">Relevance</li>
<li class="calibre19">Consistency (across sources)</li>
<li class="calibre19">Reliability</li>
<li class="calibre19">Appropriateness</li>
<li class="calibre19">Accessibility</li>
</ul>
<p class="calibre4">You'll find plenty of data quality categorizing overlap between statistical and non-statistical data. Sometimes, a data quality issue may appear to apply strictly to a particular genre—stat versus non-stat—but after further investigation or at least more experience with the data or in the field, you may find the quality is quality.</p>
<p class="calibre4">The quality of data can affect outcomes and data's quality can be affected by the way it is entered, stored, and managed and the process of addressing data quality (referred to most often as quality assurance, <strong class="calibre7">data quality assurance</strong> (<strong class="calibre7">DQA</strong>)) requires a routine and regular review and evaluation of the data and, performing on-going processes termed profiling and scrubbing. (This is vital even if the data is stored in multiple disparate systems making these processes difficult.)</p>
<p class="calibre4">Although the concept of data quality assurance and tidying data are similar in many ways, DQA is typically much more focused on repeatable processes, while tidying is most often as needed and at the discretion of the data scientist, based on the objectives of the statistical model (although the experienced data scientist would most likely make an effort to create reusable routines or scripts that can be used by them later to manipulate or tidy data on this particular project or others).</p>


            

            
        
    </div>



  
<div><h1 class="header-title">Relevance</h1>
                
            
            
                
<p class="calibre4">A lot of noteworthy emphases can be found on statistical relevance. The relevance of statistical information reflects the degree to which it meets the real needs of a particular project. It is concerned with whether the available information sheds light on the concerns that are important to the project. Assessing relevance is subjective and depends on the varying needs of users.</p>
<p class="calibre4">One of the key methods to establish and measure the relevance of data is through a process known as <strong class="calibre7">adding context</strong> or <strong class="calibre7">profiling</strong>.</p>
<p class="calibre4">Let's see, what is this profiling?</p>
<p class="calibre4">Generally speaking, similarly looking data can actually mean very different things. For example, the average <strong class="calibre7">revolutions per minute</strong> (<strong class="calibre7">RPM</strong>) carries a different connotation if the data represents sports cars compared to economy cars or even trucks.</p>
<p class="calibre4">With data, context clues should be developed, through the process we've mentioned referred to as profiling, so that the data consumer can better understand (the data) when used. Additionally, having context and perspective on the data you are working with is a vital step in determining what kind of assessments should be performed or, in the case to a non-statistical model, perhaps the kind of performance evaluations might best suit.</p>
<p class="calibre4">Another motive to add context to data might be to gain a new perspective on the data. An example of this might be recognizing and examining a comparison present in the data. For example, home or housing values could be compared by zip code or other criteria.</p>
<p class="calibre4">Adding context to data (statistical or otherwise) as part of the development and assessment process (recall that we mentioned the two go hand in hand) can certainly make it (the data) more relevant, but context still can't serve as a substitute for value.</p>
<p class="calibre4">Before you consider any variables within your data, such as average rpm, torque, top speed, wheelbase, weight (or whatever), first and foremost, assessment testing needs to benefit those who are going to consume it or, in other words, whatever the data scientist is interested in predicting. For example, if we were to extend this vehicle data example, the expected MPG or miles per gallon, so establishing appropriate context requirements will be critical.</p>
<p class="calibre4">For data profiling (or adding context to the data you will be using in a project), the rule is as follows:</p>
<p class="calibre4"><strong class="calibre7">Before Context, Think −&gt;</strong> <strong class="calibre7">Value</strong></p>
<p class="calibre4">Similar to how we categorized the types of data quality issues, there are several contextual categories, which can be used to argument or increase the value and understanding of data for visualization:</p>
<ul class="calibre18">
<li class="calibre19">Definitions and explanations</li>
<li class="calibre19">Comparisons</li>
<li class="calibre19">Contrasts</li>
<li class="calibre19">Tendencies</li>
<li class="calibre19">Dispersion</li>
</ul>
<p class="calibre4">Assessment value and data quality, or even data or data model value, although may have areas of overlap, have different objectives.</p>


            

            
        
    </div>



  
<div><h1 class="header-title">Cross-validation</h1>
                
            
            
                
<p class="calibre4">We cannot have a chapter in a book focusing on statistics (and assessing statistical models) without a least a section on cross-validation. You may hear some data scientists refer to cross-validation as rotation estimation or simply a general technique to assess models.</p>
<p class="calibre4">Cross-validation is one of the most common methods a data scientist may use to assess how accurately a statistical model will perform. The key concept of cross-validation is testing a model's ability to generalize or, specifically, how well the model applies what it infers from training on data samples (to an entire population or dataset).</p>
<p>There are two goals in cross-validation—estimating the performance of a model from available data using one algorithm, and comparing the performance of two or more different algorithms and finding out the best algorithm for the available data<strong class="calibre3">.</strong></p>
<p class="calibre4">At a high level, the process of cross-validation is to identify a known dataset called the <strong class="calibre7">validation dataset</strong>, train on that dataset, then the second dataset of unknown data (or first seen data) against which the algorithm or data model will be tested (this is known as your <strong class="calibre7">testing dataset</strong>). The objective here is to try to ensure that complications like overfitting (allowing non-inclusive information to influence results) are controlled, as well as to provide some understanding on how the model will generalize a real problem or on a real data file.</p>


            

            
        
    </div>



  
<div><h1 class="header-title">Preparing data</h1>
                
            
            
                
<p class="calibre4">To perform cross-validation, the data scientist must prepare the data. This work will consist of gaining an understanding of the data through profiling (which we mentioned in an earlier section of this chapter) so that the data can be separated into samples of comparable subsets. One subset of the data is then determined to be the training set and the analysis is performed on it. Next, once the analysis (or training) is completed, the result (or performance) is validated using the other subset (called the <strong class="calibre7">validation set</strong> or <strong class="calibre7">testing set</strong>).</p>
<p class="calibre4">To reduce variability, multiple iterations (also called <strong class="calibre7">folds</strong> or <strong class="calibre7">rounds</strong>) of cross-validation are performed using different partitions, and the validation results are averaged over the rounds.</p>
<p class="calibre4">Typically, a data scientist will use a model's stability to determine the actual number of rounds of cross-validation that should be performed:</p>
<div><img class="image-border42" src="img/593151c3-a6b3-484c-8c15-7fc4568abd40.png"/></div>
<p class="calibre4">As you can see in the preceding screenshot, the <strong class="calibre7">Cross Validation</strong> method can perhaps be better understood by thinking about the data scientist organizing a population of data into two subsets: <strong class="calibre7">Known Data</strong> and <strong class="calibre7">Unknown Data</strong> (you'll see an example of how this can be done in the next section of this chapter). The data scientist then performs an analysis of the data and manually calculates results. Once the expected or correct results are established, they can be compared to the statistical model-produced results (using that separate unknown subset of data).</p>
<p>The preceding is one round. Multiple rounds would be performed and the compared results would then be averaged and reviewed, eventually providing a fair estimate of a model's prediction performance.</p>
<p class="calibre4">Let's think of a real-world use case.</p>
<p class="calibre4">In <a href="46966f7a-6d7f-4e47-b230-e71ef7d5ad01.xhtml" target="_blank" class="pcalibre pcalibre3 pcalibre1 calibre8 pcalibre2">Chapter 6</a>, <em class="calibre21">Regularization for Database Improvement</em>, we again reviewed some sample data consisting of consulting project results. In that example, we explored the relationship between the total hours billed to the project, the total project management hours spent on the project, and the project's supposed profitability.</p>
<p class="calibre4">Looking back at that data to illustrate a point here, we can consider the various project characteristics (rather than variables):</p>
<ul class="calibre18">
<li class="calibre19">Was the project within the organization's core technology strength?</li>
<li class="calibre19">Was there a full-time project manager assigned to the project?</li>
<li class="calibre19">Was there a full-time client resource assigned to the project?</li>
<li class="calibre19">Was the project work sub-contracted?</li>
<li class="calibre19">Was the project a time and materials type of project?</li>
<li class="calibre19">Was the project a not to exceed type of project?</li>
<li class="calibre19">Was there a formal <strong class="calibre3">quality assurance</strong> (<strong class="calibre3">QA</strong>) part of the project?</li>
<li class="calibre19">Was the work performed primarily on-site?</li>
<li class="calibre19">Was the work performed primarily remote (from the customer site)?</li>
</ul>
<p class="calibre4">Again, our predictive model wants to predict what characteristics a profitable consulting project had.</p>
<p class="calibre4">The following is a representation of the results of using a five-round cross-validation process to predict our model's expected accuracy:</p>
<div><img class="image-border43" src="img/2ae6f612-eabc-419b-81a9-2ecd551ca059.png"/></div>
<p class="calibre4">Given the preceding figure, I'd say our predictive model is expected to be very accurate!</p>
<p class="calibre4">In summary, cross-validation combines (averages) measures of fit (prediction error) to derive a more accurate estimate of model prediction performance. This method is typically used in cases where there is not enough data available to test without losing significant modeling or testing quality.</p>
<p class="calibre4">Let's now move on to the final section of this chapter and look at some assessment examples using the R programming language.</p>


            

            
        
    </div>



  
<div><h1 class="header-title">R and statistical assessment</h1>
                
            
            
                
<p class="calibre4">So, let's get started with some statistical assessment work!</p>
<p class="calibre4">As we discussed in the previous section, instead of using all the data (the entire population of observations) to train a statistical model (and then test using some of that data), cross-validation divides the data into training and testing datasets.</p>
<p class="calibre4">The first step that a data scientist needs to take when he or she is interested in using cross-validation to assess the performance of a statistical model is to organize (or split) the data into two separate subsets.</p>
<p class="calibre4">There are actually several approaches of cross-validation:</p>
<ul class="calibre18">
<li class="calibre19"><strong class="calibre3">Leave-one-out cross-validation</strong> (<strong class="calibre3">LOOCV</strong>)</li>
<li class="calibre19">Holdout</li>
<li class="calibre19">k-fold and repeated k-fold</li>
<li class="calibre19">Re-substitution (most agree that this method is the simplest method)</li>
</ul>
<p class="calibre4">This cross-validation approaches all focus on how to split the data for the training, testing, and validation. Each has its own merit (pros and cons).</p>
<p class="calibre4">There are (as always) many approaches to programming a problem. The following is one such simple method. This example randomly splits the total file using a 70 to 30 split:</p>
<pre class="calibre29"># --- setting seed so we get same data split each time<br class="calibre2"/># --- we'll use 100 for seed<br class="calibre2"/>set.seed(100)<br class="calibre2"/># --- determine the total number of rows in the data<br class="calibre2"/># --- using nrow function<br class="calibre2"/>nall = nrow(MyData)<br class="calibre2"/># --- number of rows for train subset is 70%<br class="calibre2"/># --- of the total rowsntrain = floor(0.7 * nall)<br class="calibre2"/># --- number of rows for test subset is 30%<br class="calibre2"/># --- of the total rows<br class="calibre2"/>ntest = floor(0.3* nall)<br class="calibre2"/>index = seq(1:nall)<br class="calibre2"/># --- create the train data subsettrainIndex = sample(index, ntrain)<br class="calibre2"/>testIndex = index[-train]<br class="calibre2"/>train = mydata[trainIndex,]<br class="calibre2"/>test = mydata[test,]</pre>
<p class="calibre4">Once we have created the files we want, we can proceed with training and validate our statistical model.</p>
<p>As we have mentioned from time to time throughout this book, a proven practice is to save the preceding code so that it can be used again and again with new datasets.</p>


            

            
        
    </div>



  
<div><h1 class="header-title">Questions to ask</h1>
                
            
            
                
<p class="calibre4">In the previous sections of this chapter, we discussed the various approaches or methods for cross-validation, the number of rounds of cross-validation (in fact, we showed the results of a five-round cross validation effort), as well as how to organize and split the data for the purpose of performing cross-validation on a statistical model.</p>
<p class="calibre4">Before proceeding with the cross-validation process, a number of points need to be considered. (A plan is created!) This brings up the following questions:</p>
<ol class="calibre25">
<li class="calibre27">Which method or approach for cross-validation should I use? The answer is the method that is the best. Then again a new question arises—what does best mean? Each approach has its own strengths and weaknesses. The best cross-validation approach is one that best suits your data and objectives. More often than not, which approach you should use may not be revealed until other approaches are attempted.</li>
<li class="calibre27">What is the appropriate number of rounds or folds one should be performing? Usually, the more the better! However, this will be determined by factors such as which cross-validation approach you choose to use and the amount of available data and time.</li>
<li class="calibre27">What is the method to create each of the round's data? Again, this will be determined by factors such as the cross-validation approach you choose to use, the amount of available data and time, and the data scientist's abilities!</li>
</ol>


            

            
        
    </div>



  
<div><h1 class="header-title">Learning curves</h1>
                
            
            
                
<p class="calibre4">Another method of assessing a statistical model's performance is by evaluating the model's growth of learning or the model's ability to improve learning (obtain a better score) with additional experience (for example, more rounds of cross-validation).</p>
<p class="calibre4">The phrase, <strong class="calibre7">with additional experience</strong>, is vitally important in statistics as we not only look for a statistical model to perform well on a given population of data, but we hope that the model's performance will improve as it is trained and tested on more and more data.</p>
<p class="calibre4">The information indicating a model's performance, result, or score with a data file population is usually combined with other scores to show a line or curve—this is known as the statistical model's learning curve.</p>
<p class="calibre4">This means that the learning curve is a graphical representation of the growth of learning (the scores shown in a vertical axis) with practice (the individual data files or rounds shown in the horizontal axis).</p>
<p class="calibre4">This can also be conceptualized as follows:</p>
<ul class="calibre18">
<li class="calibre19">The same task repeated in a series</li>
<li class="calibre19">A body of knowledge learned over time</li>
</ul>


            

            
        
    </div>



  
<div><h1 class="header-title">Example of a learning curve</h1>
                
            
            
                
<p class="calibre4">For illustration, suppose we wanted to visualize the rate of growth of learning of a statistical model over multiple rounds of performance results, comparing test versus training data for a selected characteristic.</p>
<p class="calibre4">This was shown in an earlier section of this chapter:</p>
<div><img class="image-border43" src="img/98aed56b-2606-4146-bcab-7d10d472c76e.png"/></div>
<p class="calibre4">The following is a visualization showing the learning curve that indicates the rate of learning of a predictive model using the preceding resultant scores of cross-validation rounds for the selected characteristic:</p>
<div><img class="image-border44" src="img/907f4198-ee8b-41ba-84f3-5285859883d3.png"/></div>
<p>Core Technology</p>
<p class="calibre4">The following is the sample R code that generated the preceding visualization:</p>
<pre class="calibre29"># --- load scores from 5 rounds of testing<br class="calibre2"/>v &lt;-c(90,80, 89,72, 90)<br class="calibre2"/># -- plot the model scores round by round<br class="calibre2"/>plot(v, type = "o", col = "red", xlab = "Round", ylab = "Score", main = "Core Technology")</pre>
<p class="calibre4">Again, learning curves relating a statistical model's performance to experience are commonly found to be used when performing model assessments, especially when performing many rounds of tests (or in an analysis effort to determine the correct cross-validation method to use on a statistical model).</p>
<p class="calibre4">To this point, simply performing the rounds of testing and then reviewing the results is not quite enough. A seasoned data scientist will make sure to properly document each iteration of the testing, along with its corresponding results and conclusions.</p>
<p class="calibre4">Looking again at the preceding example, we can add to use of the R function <kbd class="calibre22">png</kbd>, which can be used to automatically create and save an image file of any visualization you create during the assessment processing that you do. If you predefine a file structure to save your assessment results and this or a similar approach, it will save much time later.</p>
<p>The R function <kbd class="calibre22">png</kbd> can easily be converted to many other bitmap formats, and both can be displayed in modern web browsers!</p>
<p class="calibre4">The following is our example R code statements that show the setup of the data, the creation of an image file, and the generation of the plot visualization:</p>
<pre class="calibre29"># --- load scores from 5 rounds of testing<br class="calibre2"/>v &lt;-c(90,80, 89,72, 90)<br class="calibre2"/># -- create an image file for the visualization for later use<br class="calibre2"/>png(file = "c:/provenpratice/learning curve.png", type = c("windows", "cairo", "cairo-png"))<br class="calibre2"/># -- plot the model scores round by round<br class="calibre2"/>plot(v, type = "o", col = "red", xlab = "Round", ylab = "Score", main = "Learning Curve")<br class="calibre2"/># -- close output<br class="calibre2"/>dev.off()</pre>
<p class="calibre4">You should note that, if you're expecting an interactive result, you won't receive it! The preceding code uses <kbd class="calibre22">png</kbd> and this simply writes the output (of the <kbd class="calibre22">plot</kbd> function) to that file.</p>
<p>Good practice advice: use the <kbd class="calibre22">dev.off()</kbd> to make sure that the file is closed.</p>
<p class="calibre4">This creates the following graphic as a file:</p>
<div><img class="image-border45" src="img/f093697c-ffb6-427c-b5ad-d907cda34f2d.png"/></div>


            

            
        
    </div>



  
<div><h1 class="header-title">Summary</h1>
                
            
            
                
<p class="calibre4">In this chapter, we defined assessment and then examined the similarities and differences between assessment and statistical assessment. Next, we covered development versus assessment and then explained how data assessment and data quality assurance have some overlap, and go hand in hand, but also have different objectives. Finally, we applied the idea of statistical assessment using the programming tool R.</p>
<p class="calibre4">In the next chapter, we will define the neural network model and draw from a developer's knowledge of data models to help understand the purpose and use of neural networks in data science.</p>
<p class="calibre4"> </p>
<p class="calibre4"/>


            

            
        
    </div>



  </body></html>