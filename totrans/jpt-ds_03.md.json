["```py\n#define all the imports we are using import matplotlib.pyplot as plt import numpy as np import pandas as pd import random from sklearn import datasets, linear_model from sklearn.cross_validation import train_test_split # load the data set df = pd.read_table('http://archive.ics.uci.edu/ml/machine-learning-databases/housing/housing.data', sep='\\s+') # add column names df.columns = ['CRIM', 'ZN', 'INDUS', 'CHAS', 'NOX', \\\n 'RM', 'AGE', 'DIS', 'RAD', 'TAX', 'PRATIO',\\ 'B', 'LSTAT', 'MDEV'] #produce basic statistics to make sure things are lined up df.head()\n```", "```py\ndf.describe()  \n```", "```py\n#we are going to be splitting up the data set 'randomly', #however we need to reproduce results so set the seed random.seed(3277) #split the data into training and testing (25% for testing) training, testing = train_test_split(df, test_size = 0.25) #need this step to create an instance of the lreg model regr = linear_model.LinearRegression() # Train the model using the training set (MDEV=target) training_data = training.drop('MDEV', axis=1) training_test = training.iloc[:,-1] #training.loc[:,['MDEV']] #look at coefficients in the model to validate regr.fit(training_data,training_test) print('Coefficients: \\n', regr.coef_) 'Coefficients: \\n', array([\n -1.18763385e-01,   4.19752612e-02,  -1.18584543e-02, 5.53125252e-01,  -1.19774970e+01,   3.80050180e+00, -8.55663104e-03,  -1.46613256e+00,   3.86772585e-01, -1.53024705e-02,  -9.55933426e-01,   1.31347272e-02, -5.28183554e-01])) \n```", "```py\n#split up our test set testing_data = testing.loc[:,['CRIM', 'ZN', 'INDUS', 'CHAS',\\ 'NOX', 'RM', 'AGE', 'DIS', 'RAD', 'TAX', 'PRATIO', 'B',\\ 'LSTAT']] testing_test = testing[['MDEV']].as_matrix() #make our prediction prediction_of_test = regr.predict(testing_data) # compute MSE # would usually use the built-in mse function, # but the test_test and prediction have diff # cols sum = 0 rows = len(testing_test) for i in range(rows):\n test = testing_test[i] prediction = prediction_of_test[i] diff = (test - prediction) ** 2 sum = sum + diff mse = sum / rows print(\"MSE \", mse) ('MSE ', array([ 23.1571225]))\n```", "```py\n**#this preceding line is needed to display inline on Jupyter** **#plot the tests and predictions** **plt.scatter(testing_test, prediction_of_test, color='black')\n****#draw a line through the middle showing the fit** **x0 = min(testing_test)** **x1 = max(testing_test)** **y0 = min(prediction_of_test)** **y1 = max(prediction_of_test)** **plt.plot([x0,x1],[y0,y1], color=\"red\")\n****#add labels** **plt.xlabel(\"Actual Price\")** **plt.ylabel(\"Predicted Price\")** **plt.title(\"Actual Price vs Predicted Price\")\n****plt.show()**\n```", "```py\n#load in the data set from uci.edu (slightly different from other housing model)\nhousing <- read.table(\"http://archive.ics.uci.edu/ml/machine-learning-databases/housing/housing.data\")\n\n#assign column names\ncolnames(housing) <- c(\"CRIM\", \"ZN\", \"INDUS\", \"CHAS\", \"NOX\",\n \"RM\", \"AGE\", \"DIS\", \"RAD\", \"TAX\", \"PRATIO\",\n \"B\", \"LSTAT\", \"MDEV\")\n#make sure we have the right data being loaded\nsummary(housing)\n CRIM                ZN             INDUS            CHAS \n Min.   : 0.00632   Min.   :  0.00   Min.   : 0.46   Min.   :0.00000 \n 1st Qu.: 0.08204   1st Qu.:  0.00   1st Qu.: 5.19   1st Qu.:0.00000 \n Median : 0.25651   Median :  0.00   Median : 9.69   Median :0.00000 \n Mean   : 3.61352   Mean   : 11.36   Mean   :11.14   Mean   :0.06917 \n 3rd Qu.: 3.67708   3rd Qu.: 12.50   3rd Qu.:18.10   3rd Qu.:0.00000 \n Max.   :88.97620   Max.   :100.00   Max.   :27.74   Max.   :1.00000 \n NOX               RM             AGE              DIS \n Min.   :0.3850   Min.   :3.561   Min.   :  2.90   Min.   : 1.130 \n 1st Qu.:0.4490   1st Qu.:5.886   1st Qu.: 45.02   1st Qu.: 2.100 \n Median :0.5380   Median :6.208   Median : 77.50   Median : 3.207 \n Mean   :0.5547   Mean   :6.285   Mean   : 68.57   Mean   : 3.795 \n 3rd Qu.:0.6240   3rd Qu.:6.623   3rd Qu.: 94.08   3rd Qu.: 5.188 \n Max.   :0.8710   Max.   :8.780   Max.   :100.00   Max.   :12.127 \n...  \n```", "```py\nhousing <- housing[order(housing$MDEV),]\n\n#check if there are any relationships between the data items\nplot(housing)  \n```", "```py\n#force the random seed so we can reproduce results\nset.seed(133)\n\n#caret package has function to partition data set\nlibrary(caret)\ntrainingIndices <- createDataPartition(housing$MDEV, p=0.75, list=FALSE)\n#break out the training vs testing data sets\nhousingTraining <- housing[trainingIndices,]\nhousingTesting <- housing[-trainingIndices,]\n#note their sizes\nnrow(housingTraining)\nnrow(housingTesting)\n#note there may be warning messages to update packages\n381\n125\n\n#build a linear model\nlinearModel <- lm(MDEV ~ CRIM + ZN + INDUS + CHAS + NOX + RM + AGE +\n DIS + RAD + TAX + PRATIO + B + LSTAT, data=housingTraining)\nsummary(linearModel)\nCall:\nlm(formula = MDEV ~ CRIM + ZN + INDUS + CHAS + NOX + RM + AGE + \n DIS + RAD + TAX + PRATIO + B + LSTAT, data = housingTraining)\n\nResiduals:\n Min       1Q   Median       3Q      Max \n-15.8448  -2.7961  -0.5602   2.0667  25.2312 \n\nCoefficients:\n Estimate Std. Error t value Pr(>|t|) \n(Intercept)  36.636334   5.929753   6.178 1.72e-09 ***\nCRIM         -0.134361   0.039634  -3.390 0.000775 ***\nZN            0.041861   0.016379   2.556 0.010997 * \nINDUS         0.029561   0.068790   0.430 0.667640 \nCHAS          3.046626   1.008721   3.020 0.002702 ** \nNOX         -17.620245   4.610893  -3.821 0.000156 ***\nRM            3.777475   0.484884   7.790 6.92e-14 ***\nAGE           0.003492   0.016413   0.213 0.831648 \nDIS          -1.390157   0.235793  -5.896 8.47e-09 ***\nRAD           0.309546   0.078496   3.943 9.62e-05 ***\nTAX          -0.012216   0.004323  -2.826 0.004969 ** \nPRATIO       -0.998417   0.155341  -6.427 4.04e-10 ***\nB             0.009745   0.003300   2.953 0.003350 ** \nLSTAT        -0.518531   0.060614  -8.555 3.26e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 4.867 on 367 degrees of freedom\nMultiple R-squared:  0.7327,  Adjusted R-squared:  0.7233 \nF-statistic:  77.4 on 13 and 367 DF,  p-value: < 2.2e-16  \n```", "```py\n# now that we have a model, make a prediction\npredicted <- predict(linearModel,newdata=housingTesting)\nsummary(predicted)\n\n#visually compare prediction to actual\nplot(predicted, housingTesting$MDEV)  \n```", "```py\n**output_notebook()** **# load the counts from other histogram example** **from_counts = np.load(\"from_counts.npy\")** **# convert array to a dataframe for Histogram** **df = pd.DataFrame({'Votes':from_counts})** **# make sure dataframe is working correctly** **print(df.head())\n** **Votes** **0     23** **1     29** **2     23** **3    302** **4     24** **# display the Bokeh histogram** **hist = Histogram(from_counts, \\** **title=\"How Many Votes Made By Users\", \\** **bins=12)** **show(hist)** \n```", "```py\nimport plotly\nimport plotly.graph_objs as go\nimport plotly.plotly as py\nimport pandas as pd\nimport numpy as np\n\n#once you set credentials they are stored in local space and referenced automatically\n#you need to subscribe to the site to get the credentials\n#the api key would need to be replaced with your key\n#plotly.tools.set_credentials_file(username='DemoAccount', api_key='lr17zw81')\n\n#we are generating a graphic that anyone can see it\nplotly.tools.set_config_file(world_readable=True, sharing='public')\n\n# load voting summary from other project\nfrom_counts = np.load(\"from_counts.npy\")\nprint(from_counts.shape)\n(6110,)\n\n#plotly expects a list in a data block\nfrom_count_list = []\nfor from_count in from_counts:\n from_count_list.append(from_count)\n\ndata = [go.Histogram(x=from_count_list)]\n\n# plot on plot.ly site\npy.iplot(data, filename='basic histogram')  \n```", "```py\n**import matplotlib.pyplot as plt** **from mpl_toolkits.basemap import Basemap** **from matplotlib.patches import Polygon** **import pandas as pd** **import numpy as np** **import matplotlib** **# create the map** **map = Basemap(llcrnrlon=-119,llcrnrlat=22,urcrnrlon=-64,urcrnrlat=49,\n** **projection='lcc',lat_1=33,lat_2=45,lon_0=-95)** **# load the shapefile, use the name 'states'** **# download from https://github.com/matplotlib/basemap/tree/master/examples/st99_d00.dbf,shx,shp** **map.readshapefile('st99_d00', name='states', drawbounds=True)** **# collect the state names from the shapefile attributes so we can** **# look up the shape obect for a state by it's name** **state_names = []** **for shape_dict in map.states_info:\n** **state_names.append(shape_dict['NAME'])** **ax = plt.gca() # get current axes instance** **# load density data drawn from** **# https://en.wikipedia.org/wiki/List_of_U.S._states_by_population_density** **df = pd.read_csv('states.csv')** **print(df.head())** **State        rank density/mi2  density/km2  pop_rank   2015_pop** **New Jersey      1       1,218          470        11  8,958,013** **Rhode Island    2       1,021          394        43  1,056,298** **Massachusetts   3         871          336        15  6,794,422** **Connecticut     4         741          286        29  3,590,886** **Maryland        5         618          238        19  6,006,401  \n****land_rank area_mi2   area_km2** **0         46    7,354  19,046.80** **1         50    1,034   2,678.00** **2         45    7,800  20,201.90** **3         48    4,842  12,540.70** **4         42    9,707  25,141.00** **# determine the range of density values** **max_density = -1.0** **min_density = -1.0** **for index, row in df.iterrows():\n** **d = row['density/mi2']** **density = float(d.replace(',' , ''))** **if (max_density==-1.0) or (max_density<density):** **max_density = density** **if (min_density==-1.0) or (min_density>density):** **min_density = density** **print('max',max_density)** **print('min',min_density)** **range_density = max_density - min_density** **print(range_density)** **('max', 1218.0)** **('min', 1.0)** **1217.0** **# we pick a color for the state density out of color map** **cmap = matplotlib.cm.get_cmap('Spectral')** **# for each state get the color for it's density** **for index, row in df.iterrows():\n** **state_name = row['State']** **d = row['density/mi2']** **density = float(d.replace(',' , ''))** **color = cmap((density - min_density)/range_density)** **seg = map.states[state_names.index(state_name)]** **poly = Polygon(seg, facecolor=color, edgecolor=color)** **ax.add_patch(poly)** **plt.show()**\n```", "```py\n**# import all packages being used** **import matplotlib.pyplot as plt** **import pandas as pd** **import numpy as np** **import matplotlib\n****# load voting data drawn from https://snap.stanford.edu/data/wiki-Vote.html** **df = pd.read_table('wiki-Vote.txt', sep=r\"\\s+\", index_col=0)\n****# produce standard summary info to validate** **print(df.head())** **print(df.describe())**\n```", "```py\n ToNodeId FromNodeId 30              1412 30              3352 30              5254 30              5543 30              7478\n ToNodeId count  103689.000000 mean     3580.347018 std      2204.045658 min         3.000000 25%      1746.000000 50%      3260.000000 75%      5301.000000 max      8297.000000\n```", "```py\nfrom_counter = {} to_counter = {} for index, row in df.iterrows():\n ton = row['ToNodeId'] fromn = index    #add the from entry\n if from_counter.has_key(fromn): # bump entry from_counter[fromn] = from_counter.get(fromn) + 1 else: # create entry from_counter[fromn] = 1    #add the to entry\n if to_counter.has_key(ton): # bump entry to_counter[ton] = to_counter.get(ton) + 1 else: # create entry to_counter[ton] = 1print(from_counter) print(to_counter) {3: 23, 4: 29, 5: 23, 6: 302, 7: 24, 8: 182, 9: 81, 10: 86, 11: 743,…\n```", "```py\n#extract the count values from_counts = from_counter.values() to_counts = to_counter.values()\nprint(\"Most votes by a user\",max(from_counts)) print(\"Most voted for\",max(to_counts)) ('Most votes by a user', 893) ('Most voted for', 457)\n#make histogram of number of references made by a user plt.hist(from_counts) plt.title(\"How Many Votes Made By Users\") plt.xlabel(\"Value\") plt.ylabel(\"Frequency\") plt.show()\n```", "```py\n#make histogram of number of references made for a user plt.hist(to_counts) plt.title(\"How Many Votes Made for User\") plt.xlabel(\"Value\") plt.ylabel(\"Frequency\") plt.show()\n```", "```py\n**# import tools we are using** **import pandas as pd** **import numpy as np** **from mpl_toolkits.mplot3d import Axes3D** **import matplotlib.pyplot as plt** **# read in the car 'table' – not a csv, so we need** **# to add in the column names** **column_names = ['mpg', 'cylinders', 'displacement', 'horsepower', 'weight', 'acceleration', 'year', 'origin', 'name']** **df = pd.read_table('http://archive.ics.uci.edu/ml/machine-learning-databases/auto-mpg/auto-mpg.data', \\\n** **sep=r\"\\s+\", index_col=0, header=None, names = column_names)** **print(df.head())\n** **cylinders  displacement horsepower  weight  acceleration  year  origin  \\** **mpg** **18.0          8         307.0  130.0  3504.0          12.0    70       1** **15.0          8         350.0  165.0  3693.0          11.5    70       1** **18.0          8         318.0  150.0  3436.0          11.0    70       1** **16.0          8         304\\.   150.0  3433.0          12.0    70       1** **17.0          8         302\\.   140.0  3449.0          10.5    70       1  \n****mpg                        name** **18.0  chevrolet chevelle malibu** **15.0          buick skylark 320** **18.0         plymouth satellite** **16.0              amc rebel sst** **17.0                ford torino** \n```", "```py\n#start out plotting (uses a subplot as that can be 3d)\nfig = plt.figure()\nax = fig.add_subplot(111, projection='3d') # pull out the 3 columns that we want\nxs = []\nys = []\nzs = []\nfor index, row in df.iterrows():\n xs.append(row['weight'])\n ys.append(index) #read_table uses first column as index\n zs.append(row['cylinders']) # based on our data, set the extents of the axes\nplt.xlim(min(xs), max(xs))\nplt.ylim(min(ys), max(ys))\nax.set_zlim(min(zs), max(zs)) # standard scatter diagram (except it is 3d)\nax.scatter(xs, ys, zs) ax.set_xlabel('Weight')\nax.set_ylabel('MPG')\nax.set_zlabel('Cylinders') plt.show()\n```"]