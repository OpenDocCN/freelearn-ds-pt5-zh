<html><head></head><body>
        <section id="A73GU1-21aec46d8593429cacea59dbdcd64e1c">

                            <header>
                    </header><h1 class="header-title" id="calibre_pb_0">Learning Machine Learning - Spark MLlib and Spark ML</h1>
                
            
            <article>
                
<div class="book-info-bottom-author-body">"Each of us, actually every animal, is a data scientist. We collect data from our sensors, and then we process the data to get abstract rules to perceive our environment and control our actions in that environment to minimize pain and/or maximize pleasure. We have memory to store those rules in our brains, and then we recall and use them when needed. Learning is lifelong; we forget rules when they no longer apply or revise them when the environment changes."</div>
<p class="cdpalignright">- Ethem Alpaydin, Machine Learning: The New AI</p>
<p class="mce-root">The purpose of this chapter is to provide a conceptual introduction to statistical machine learning (ML) techniques for those who might not normally be exposed to such approaches during their typical required statistical training. This chapter also aims to take a newcomer from having minimal knowledge of machine learning all the way to being a knowledgeable practitioner in a few steps. We will focus on Spark's machine learning APIs, called Spark MLlib and ML, in theoretical and practical ways. Furthermore, we will provide some examples covering feature extraction and transformation, dimensionality reduction, regression, and classification analysis. In a nutshell, we will cover the following topics in this chapter:</p>
<ul class="calibre9">
<li class="mce-root1">Introduction to machine learning</li>
<li class="mce-root1">Spark machine learning APIs</li>
<li class="mce-root1">Feature extractor and transformation</li>
<li class="mce-root1">Dimensionality reduction using PCA for regression</li>
<li class="mce-root1">Binary and multiclass classification</li>
</ul>


            </article>

            
        </section>
    

        <section id="A821G1-21aec46d8593429cacea59dbdcd64e1c">

                            <header>
                    </header><h1 class="header-title" id="calibre_pb_0">Introduction to machine learning</h1>
                
            
            <article>
                
<p class="mce-root">In this section, we will try to define machine learning from computer science, statistics, and data analytical perspectives. <strong class="calibre1">Machine learning (ML)</strong> is the branch of computer science that provides the computers the ability to learn without being explicitly programmed (Arthur Samuel in 1959). This field of study being evolved from the study of pattern recognition and computational learning theory in artificial intelligence.</p>
<p class="mce-root">More specifically, ML explores the study and construction of algorithms that can learn from heuristics and make predictions on data. This kind of algorithms overcome the strictly static program instructions by making data-driven predictions or decisions, through building a model from sample inputs. Now let's more explicit and versatile definition from Prof. Tom M. Mitchell, who explained what machine learning really means from the computer science perspective:</p>
<div class="book-info-bottom-author-body">A computer program is said to learn from experience E with respect to some class of tasks T and performance measure P, if its performance at tasks in T, as measured by P, improves with experience E.</div>
<p class="mce-root">Based on that definition, we can conclude that a computer program or machine can:</p>
<ul class="calibre9">
<li class="mce-root1">Learn from data and histories</li>
<li class="mce-root1">Be improved with experience</li>
<li class="mce-root1">Interactively enhance a model that can be used to predict the outcomes of questions</li>
</ul>
<p class="mce-root">Typical machine learning tasks are concept learning, predictive modeling, clustering, and finding useful patterns. The ultimate goal is to improve learning in such a way that it becomes automatic so that no human interactions are needed anymore, or to reduce the level of human interaction as much as possible. Although machine learning is sometimes conflated with <strong class="calibre1">Knowledge Discovery and Data Mining</strong> (<strong class="calibre1">KDDM</strong>), but KDDM, focuses more on exploratory data analysis and is known as unsupervised learning. Typical machine learning applications can be classified into scientific knowledge discovery and more commercial applications, ranging from Robotics or <strong class="calibre1">Human-Computer Interaction</strong> (<strong class="calibre1">HCI</strong>) to anti-spam filtering and recommender systems.</p>


            </article>

            
        </section>
    

        <section id="A90I21-21aec46d8593429cacea59dbdcd64e1c">

                            <header>
                    </header><h1 class="header-title" id="calibre_pb_0">Typical machine learning workflow</h1>
                
            
            <article>
                
<p class="mce-root">A typical machine learning application involves several steps ranging from the input, processing, to output, which forms a scientific workflow, as shown in <em class="calibre8">Figure 1</em>. The following steps are involved in a typical machine learning application:</p>
<ol class="calibre14">
<li value="1" class="mce-root1">Load the sample data.</li>
<li value="2" class="mce-root1">Parse the data into the input format for the algorithm.</li>
<li value="3" class="mce-root1">Preprocess the data and handle the missing values.</li>
</ol>
<ol start="4" class="calibre14">
<li value="4" class="mce-root1">Split the data into two sets: one for building the model (training dataset) and one for testing the model (validation dataset).</li>
<li value="5" class="mce-root1">Run the algorithm to build or train your ML model.</li>
<li value="6" class="mce-root1">Make predictions with the training data and observe the results.</li>
<li value="7" class="mce-root1">Test and evaluate the model with the test data or, alternatively, validate the model using a cross-validator technique using the third dataset, called the validation dataset.</li>
<li value="8" class="mce-root1">Tune the model for better performance and accuracy.</li>
<li value="9" class="mce-root1">Scale up the model so that it will be able to handle massive datasets in future.</li>
<li value="10" class="mce-root1">Deploy the ML model in commercialization.</li>
</ol>
<div class="cdpaligncenter"><img class="image-border131" src="../images/00266.jpeg"/></div>
<div class="cdpaligncenter1"><strong class="calibre1">Figure 1:</strong> Machine learning workflow</div>
<p class="mce-root">Often, the machine learning algorithms have some ways to handle skewness in the datasets. That skewness is sometimes immense though. In step 4, the experimental dataset is randomly split, often into a training set and a test set, which is called sampling. The training dataset is used to train the model, whereas the test dataset is used to evaluate the performance of the best model at the very end. The better practice is to use the training dataset as much as you can to increase generalization performance. On the other hand, it is recommended to use the test dataset only once, to avoid the overfitting problem while computing the prediction error and the related metrics.</p>


            </article>

            
        </section>
    

        <section id="A9V2K1-21aec46d8593429cacea59dbdcd64e1c">

                            <header>
                    </header><h1 class="header-title" id="calibre_pb_0">Machine learning tasks</h1>
                
            
            <article>
                
<p class="mce-root">depending on the nature of the learning feedback available to a learning system, ML tasks or process are typically classified into three broad categories: supervised learning, unsupervised learning, and reinforcements learning shown in figure 2. Furthermore, there are other machine learning tasks as well, for example, dimensionality reduction, recommendation system, frequent pattern mining, and so on.</p>
<div class="cdpaligncenter"><img class="image-border132" src="../images/00272.jpeg"/></div>
<div class="cdpaligncenter1"><strong class="calibre1">Figure 2:</strong> Machine learning tasks</div>


            </article>

            
        </section>
    

        <section id="AATJ61-21aec46d8593429cacea59dbdcd64e1c">

                            <header>
                    </header><h1 class="header-title" id="calibre_pb_0">Supervised learning</h1>
                
            
            <article>
                
<p class="mce-root">A supervised learning application makes predictions based on a set of examples, and the goal is to learn general rules that map inputs to outputs aligning with the real world. For example, a dataset for spam filtering usually contains spam messages as well as non-spam messages. Therefore, we are able to know whether messages in the training set are spam or ham. Nevertheless, we might have the opportunity to use this information to train our model in order to classify new unseen messages. The following figure shows the schematic diagram of supervised learning. After the algorithm has found the required patterns, those patterns can be used to make predictions for unlabeled test data. This is the most popular and useful type of machine learning task, that is not an exception for Spark as well, where most of the algorithms are supervised learning techniques:</p>
<div class="cdpaligncenter"><img class="image-border133" src="../images/00278.jpeg"/></div>
<div class="cdpaligncenter1"><strong class="calibre1">Figure 3</strong>: Supervised learning in action</div>
<p class="mce-root">Examples include classification and regression for solving supervised learning problems. We will provide several examples of supervised learning, such as logistic regression, random forest, decision trees, Naive Bayes, One-vs-the-Rest, and so on in this book. However, to make the discussion concrete, only logistic regression and the random forest will be discussed, and other algorithms will be discussed in <a href="part0383.html#BD87E1-21aec46d8593429cacea59dbdcd64e1c" class="calibre10">Chapter 12</a>, <em class="calibre8">Advanced Machine Learning Best Practices</em>, with some practical examples. On the other hand, linear regression will be discussed for the regression analysis.</p>


            </article>

            
        </section>
    

        <section id="ABS3O1-21aec46d8593429cacea59dbdcd64e1c">

                            <header>
                    </header><h1 class="header-title" id="calibre_pb_0">Unsupervised learning</h1>
                
            
            <article>
                
<p class="mce-root">In unsupervised learning, data points have no labels related with them. Therefore, we need to put labels on it algorithmically, as shown in the following figure. In other words, the correct classes of the training dataset in unsupervised learning are unknown. Consequently, classes have to be inferred from the unstructured datasets, which imply that the goal of an unsupervised learning algorithm is to preprocess the data in some structured ways by describing its structure.</p>
<p class="mce-root">To overcome this obstacle in unsupervised learning, clustering techniques are commonly used to group the unlabeled samples based on certain similarity measures. Therefore, this task also involves mining hidden patterns toward feature learning. Clustering is the process of intelligently categorizing the items in your dataset. The overall idea is that two items in the same cluster are “closer” to each other than items that belong to separate clusters. That is the general definition, leaving the interpretation of “closeness” open.</p>
<div class="cdpaligncenter1"><img class="image-border134" src="../images/00282.jpeg"/></div>
<div class="cdpaligncenter1"><strong class="calibre1">Figure 4</strong>: Unsupervised learning</div>
<p class="mce-root">Examples include clustering, frequent pattern mining, and dimensionality reduction for solving unsupervised learning problems (it can be applied to supervised learning problems too). We will provide several examples of unsupervised learning, such as k-means, bisecting k-means, Gaussian mixture model, <strong class="calibre1">Latent dirichlet allocation</strong> (<strong class="calibre1">LDA</strong>), and so on, in this book. We will also show how to use a dimensionality reduction algorithm such as <strong class="calibre1">Principal Component Analysis</strong> (<strong class="calibre1">PCA</strong>) or <strong class="calibre1">Singular Value Decomposition</strong> (<strong class="calibre1">SVD</strong>) in supervised learning through regression analysis.</p>
<div class="packt_tip"><strong class="calibre27">Dimensionality reduction</strong> (<strong class="calibre27">DR</strong>): Dimensionality reduction is a technique used to reduce the number of random variables under certain considerations. This technique is used for both supervised and unsupervised learning. Typical advantages of using DR techniques are as follows:<br class="calibre23"/>
<ul class="calibre41">
<li class="calibre42">It reduces the time and storage space required in machine learning tasks</li>
<li class="calibre42">It helps remove multicollinearity and improves the performance of the machine learning model</li>
<li class="calibre42">Data visualization becomes easier when reduced to very low dimensions such as 2D or 3D</li>
</ul>
</div>


            </article>

            
        </section>
    

        <section id="ACQKA1-21aec46d8593429cacea59dbdcd64e1c">

                            <header>
                    </header><h1 class="header-title" id="calibre_pb_0">Reinforcement learning</h1>
                
            
            <article>
                
<p class="mce-root">As a human being, you and we also learn from past experiences. We haven't got so charming by accident. Years of positive compliments as well as negative criticism have all helped shape us who we are today. You learn what makes people happy by interacting with friends, family, or even strangers, and you figure out how to ride a bike by trying out different muscle movements until it just clicks. When you perform actions, you're sometimes rewarded immediately. For example, finding a shopping mall nearby might yield instant gratification. Other times, the reward doesn't appear right away, such as traveling a long distance to find an exceptional place to eat. These are all about Reinforcement Learning (RL)<strong class="calibre1">.</strong></p>
<p class="mce-root">Thus RL is a technique, where the model itself learns from a series of actions or behaviors. The complexity of the dataset, or sample complexity, is very important in the reinforcement learning needed for the algorithms to learn a target function successfully. Moreover, in response to each data point for achieving the ultimate goal, maximization of the reward function should be ensured while interacting with an external environment, as demonstrated in the following figure:</p>
<div class="cdpaligncenter"><img class="image-border135" src="../images/00288.jpeg"/></div>
<div class="cdpaligncenter1"><strong class="calibre1">Figure 5</strong>: Reinforcement learning</div>
<p class="mce-root">Reinforcement learning techniques are being used in many areas. Here's a very short list includes the following:</p>
<ul class="calibre9">
<li class="mce-root1">Advertising helps in learning rank, using one-shot learning for emerging items, and new users will bring more money</li>
<li class="mce-root1">Teaching robots new tasks, while retaining prior knowledge</li>
<li class="mce-root1">Deriving complex hierarchical schemes, from chess gambits to trading strategies</li>
<li class="mce-root1">Routing problems, for example, management of a shipping fleet, which trucks/truckers to assign to which cargo</li>
<li class="mce-root1">In robotics, the algorithm must choose the robot's next action based on a set of sensor readings</li>
<li class="mce-root1">It is also a natural fit for <strong class="calibre1">Internet of Things</strong> (<strong class="calibre1">IoT</strong>) applications, where a computer program interacts with a dynamic environment in which it must perform a certain goal without an explicit mentor</li>
<li class="mce-root1">
<p class="calibre32">One of the simplest RL problems is called n-armed bandits. The thing is there are n-many slot machines but each has different fixed pay-out probability. The goal is to maximize the profit by always choosing the machine with the best payout</p>
</li>
<li class="mce-root1">An emerging area for applying is the stock market trading. Where a trader acts like a reinforcement agent since buying and selling (i.e. action) particular stock changes the state of the trader by generating profit or loss i.e. reward.</li>
</ul>


            </article>

            
        </section>
    

        <section id="ADP4S1-21aec46d8593429cacea59dbdcd64e1c">

                            <header>
                    </header><h1 class="header-title" id="calibre_pb_0">Recommender system</h1>
                
            
            <article>
                
<p class="mce-root">A recommender system is a subclass of an information filtering system that looks to predict the rating or preference that users usually provide for an item. The concept of recommender systems has become very common in recent years subsequently being applied in different applications.</p>
<div class="cdpaligncenter"><img class="image-border136" src="../images/00294.jpeg"/></div>
<div class="cdpaligncenter1"><strong class="calibre1">Figure 6</strong>: Different recommender system</div>
<p class="mce-root">The most popular ones are probably products (for example, movies, music, books, research articles, news, search queries, social tags, and so on). Recommender systems can be classified into the following four categories typically:</p>
<ul class="calibre9">
<li class="mce-root1">Collaborative filtering, also referred to as social filtering that filters information by using the recommendations of other people. The thing is people who agreed in their evaluation of certain items in the past are likely to agree again in the future. Therefore, a person who wants to see a movie for example, might ask for recommendations from his/her friends. Now once he received the recommendations from some of his/her friends who have similar interests, are trusted more than recommendations from others. This information is used in the decision on which movie to see.</li>
<li class="mce-root1">Content-based filtering (also known as cognitive filtering), which recommends items based on a comparison between the content of the items and a user profile. The content of each item is represented as a set of descriptors or terms, typically the words that occur in a document. The user profile is represented with the same terms and built up by analyzing the content of items that have been seen by the user. However, while implementing these types of recommendation systems, some issues that need to be considered are as follows:
<ul class="calibre38">
<li class="mce-root1">First, terms can be assigned automatically or manually. For automatic assignment, a method has to be chosen so that these items can be extracted from the item list. Second, terms have to be represented in a way so that both the user profile and the items can be compared in a meaningful way. The learning algorithm itself has to be chosen wisely so that it's going to be able to learn a user profile based on already observer (that is, seen) items and makes appropriate recommendations based on this user profile. Content-based filtering systems are mostly used with text documents, where term parsers are used to select single words from the documents. The vector space model and latent semantic indexing are two methods that use these terms to represent documents as vectors in a multidimensional space. Furthermore, it is also used in relevance feedback, genetic algorithms, neural networks, and the Bayesian classifier for learning a user profile.</li>
</ul>
</li>
<li class="mce-root1">A hybrid recommender system is a recent research and hybrid approach (that is, combining collaborative filtering and content-based filtering). Netflix is a good example of such a recommendation system that uses the <strong class="calibre1">Restricted Boltzmann Machines</strong> (<strong class="calibre1">RBM</strong>) and a form of the matrix factorization algorithm for large movie database like IMDb (see more at <a href="https://pdfs.semanticscholar.org/789a/d4218d1e2e920b4d192023f840fe8246d746.pdf" class="calibre10">https://pdfs.semanticscholar.org/789a/d4218d1e2e920b4d192023f840fe8246d746.pdf</a>). This recommendation which simply recommends movies, dramas, or streaming by comparing the watching and searching habits of similar users, is called rating prediction.</li>
<li class="mce-root1">Knowledge-based systems, where knowledge about users and products is used to reason what fulfills a user's requirements, using perception tree, decision support systems, and case-based reasoning.</li>
</ul>
<p class="mce-root">In this chapter, we will discuss the collaborative filtering based recommender system for the movie recommendations.</p>


            </article>

            
        </section>
    

        <section id="AENLE1-21aec46d8593429cacea59dbdcd64e1c">

                            <header>
                    </header><h1 class="header-title" id="calibre_pb_0">Semisupervised learning</h1>
                
            
            <article>
                
<p class="mce-root">Between supervised and unsupervised learning, there is a small place for semi-supervised learning. In this case, the ML model usually receives an incomplete training signal. More statistically, the ML model receives a training set with some of the target outputs missing. Semi-supervised learning is more or less assumption based and often uses three kinds of assumption algorithms as the learning algorithm for the unlabeled datasets. The following assumptions are used: smoothness, cluster, and manifold. In other words, semi-supervised learning can furthermore be denoted as weakly supervised or a bootstrapping technique for using the hidden wealth of unlabeled examples to enhance the learning from a small amount of labeled data.</p>
<p class="mce-root">As already mentioned that the acquisition of labeled data for a learning problem often requires a skilled human agent. Therefore, the cost associated with the labeling process thus may render a fully labeled training set infeasible, whereas acquisition of unlabeled data is relatively inexpensive.</p>
<p class="mce-root">For example: to transcribe an audio segment, in determining the 3D structure of a protein or determining whether there is oil at a particular location, expectation minimization and human cognition, and transitive. The In such situations, semi-supervised learning can be of great practical value.</p>


            </article>

            
        </section>
    

        <section id="AFM601-21aec46d8593429cacea59dbdcd64e1c">

                            <header>
                    </header><h1 class="header-title" id="calibre_pb_0">Spark machine learning APIs</h1>
                
            
            <article>
                
<p class="mce-root">In this section, we will describe two key concepts introduced by the Spark machine learning libraries (Spark MLlib and Spark ML) and the most widely used implemented algorithms that align with the supervised and unsupervised learning techniques we discussed in the previous sections.</p>


            </article>

            
        </section>
    

        <section id="AGKMI1-21aec46d8593429cacea59dbdcd64e1c">

                            <header>
                    </header><h1 class="header-title" id="calibre_pb_0">Spark machine learning libraries</h1>
                
            
            <article>
                
<p class="mce-root">As already stated, in the pre-Spark era, big data modelers typically used to build their ML models using statistical languages such as R, STATA, and SAS. However, this kind of workflow (that is, the execution flow of these ML algorithms) lacks efficiency, scalability, and throughput, as well as accuracy, with, of course, extended execution times.</p>
<p class="mce-root">Then, data engineers used to reimplement the same model in Java, for example, to deploy on Hadoop. Using Spark, the same ML model can be rebuilt, adopted, and deployed, making the whole workflow much more efficient, robust, and faster, allowing you to provide hands-on insight to increase the performance. Moreover, implementing these algorithms in Hadoop means that these algorithms can run in parallel that cannot be run on R, STATA and SAS and so on. The Spark machine learning library is divided into two packages: Spark MLlib (<kbd class="calibre11">spark.mllib</kbd>) and Spark ML (<kbd class="calibre11">spark.ml</kbd>).</p>


            </article>

            
        </section>
    

        <section id="AHJ741-21aec46d8593429cacea59dbdcd64e1c">

                            <header>
                    </header><h1 class="header-title" id="calibre_pb_0">Spark MLlib</h1>
                
            
            <article>
                
<p class="mce-root">MLlib is Spark's scalable machine learning library and is an extension of the Spark Core API which provides a library of easy-to-use machine learning algorithms. Spark algorithms are implemented in Scala and then expose the API for Java, Scala, Python, and R. Spark provides support of local vectors and matrix data types stored on a single machine, as well as distributed matrices backed by one or multiple RDDs. The beauties of Spark MLlib are numerous. For example, algorithms are highly scalable and leverage Spark's ability to work with a massive amounts of data.</p>
<ul class="calibre9">
<li class="mce-root1">They are fast foward designed for parallel computing with an in-memory based operation that is 100 times faster compared to MapReduce data processing (they also support disk-based operation, which is 10 times faster compared to what MapReduce has as normal data processing).</li>
<li class="mce-root1">They are diverse, since they cover common machine learning algorithms for regression analysis, classification, clustering, recommender systems, text analytics, and frequent pattern mining, and obviously cover all the steps required to build a scalable machine learning application.</li>
</ul>


            </article>

            
        </section>
    

        <section id="AIHNM1-21aec46d8593429cacea59dbdcd64e1c">

                            <header>
                    </header><h1 class="header-title" id="calibre_pb_0">Spark ML</h1>
                
            
            <article>
                
<p class="mce-root">Spark ML adds a new set of machine learning APIs to let users quickly assemble and configure practical machine learning pipelines on top of datasets. Spark ML aims to offer a uniform set of high-level APIs built on top of DataFrames rather than RDDs that help users create and tune practical machine learning pipelines. Spark ML API standardizes machine learning algorithms to make the learning tasks easier to combine multiple algorithms into a single pipeline or data workflow for data scientists. The Spark ML uses the concepts of DataFrame and Datasets, which are much newer concepts introduced (as experimental) in Spark 1.6 and then used in Spark 2.0+.</p>
<div class="packt_tip">In Scala and Java, DataFrame and Dataset have been unified, that is, DataFrame is just a type alias for a dataset of row. In Python and R, given the lack of type safety, DataFrame is the main programming interface.</div>
<p class="mce-root">The datasets hold diverse data types such as columns storing text, feature vectors, and true labels for the data. In addition to this, Spark ML also uses the transformer to transform one DataFrame into another or vice-versa, where the concept of the estimator is used to fit on a DataFrame to produce a new transformer. The pipeline API, on the other hand, can restrain multiple transformers and estimators together to specify an ML data workflow. The concept of the parameter was introduced to specify all the transformers and estimators to share a common API under an umbrella during the development of an ML application.</p>


            </article>

            
        </section>
    

        <section id="AJG881-21aec46d8593429cacea59dbdcd64e1c">

                            <header>
                    </header><h1 class="header-title" id="calibre_pb_0">Spark MLlib or Spark ML?</h1>
                
            
            <article>
                
<p class="mce-root"><span>Spark ML</span> <span>provides a higher-level API built on top of</span> <span>DataFrames</span> <span>for constructing ML pipelines. B</span>asically, Spark ML provides you with a toolset to create pipelines of different machine learning related transformations on your data. It makes it easy to, for example, chain feature extraction, dimensionality reduction, and the training of a classifier into one model, which as a whole can be later used for classification. MLlib, however, is older and has been in development longer, it has more features because of this. Therefore, using Spark ML is recommended <span>because, the API is more versatile and flexible with DataFrames.</span></p>


            </article>

            
        </section>
    

        <section id="AKEOQ1-21aec46d8593429cacea59dbdcd64e1c">

                            <header>
                    </header><h1 class="header-title" id="calibre_pb_0">Feature extraction and transformation</h1>
                
            
            <article>
                
<p class="mce-root">Suppose you are going to build a machine learning model that will predict whether a credit card transaction is fraudulent or not. Now, based on the available background knowledge and data analysis, you might decide which data fields (aka features) are important for training your model. For example, amount, customer name, buying company name, and the address of the credit card owners are worth to providing for the overall learning process. These are important to consider since, if you just provide a randomly generated transaction ID, that will not carry any information so would not be useful at all. Thus, once you have decided which features to include in your training set, you then need to transform those features to train the model for better learning. The feature transformations help you add additional background information to the training data. The information enables the machine learning model to benefit from this experience eventually. To make the preceding discussion more concrete, suppose you have the following address of one of the customers represented in the string:</p>
<p class="mce-root"><kbd class="calibre11">"123 Main Street, Seattle, WA 98101"</kbd></p>
<p class="mce-root">If you see the preceding address, the address lacks proper semantics. In other words, the string has limited expressive power. This address will be useful only for learning address patterns associated with that exact address in a database, for example. However, breaking it up into fundamental parts can provide additional features such as the following:</p>
<ul class="calibre9">
<li class="mce-root1">"Address" (123 Main Street)</li>
<li class="mce-root1">"City" (Seattle)</li>
<li class="mce-root1">"State" (WA)</li>
<li class="mce-root1">"Zip" (98101)</li>
</ul>
<p class="mce-root">If you see the preceding patterns, your ML algorithm can now group more different transactions together and discover broader patterns. This is normal, since some customer's zip codes contribute to more fraudulent activity than others. Spark provides several algorithms implemented for the feature extractions and to make transformation easier. For example, the current version provides the following algorithms for feature extractions:</p>
<ul class="calibre9">
<li class="mce-root1">TF-IDF</li>
<li class="mce-root1">Word2vec</li>
<li class="mce-root1">CountVectorizer</li>
</ul>
<p class="mce-root"><span>On the other hand,</span> a feature transformer is an abstraction that includes feature transformers and learned models. Technically, a transformer implements a method named <kbd class="calibre11">transform()</kbd>, which converts one DataFrame into another, generally by appending one or more columns. Spark supports the following transformers to RDD or DataFrame:</p>
<ul class="calibre9">
<li class="mce-root1">Tokenizer</li>
<li class="mce-root1">StopWordsRemover</li>
<li class="mce-root1">n-gram</li>
<li class="mce-root1">Binarizer</li>
<li class="mce-root1">PCA</li>
<li class="mce-root1">PolynomialExpansion</li>
<li class="mce-root1">Discrete cosine transform (DCT)</li>
<li class="mce-root1">StringIndexer</li>
<li class="mce-root1">IndexToString</li>
<li class="mce-root1">OneHotEncoder</li>
<li class="mce-root1">VectorIndexer</li>
<li class="mce-root1">Interaction</li>
<li class="mce-root1">Normalizer</li>
<li class="mce-root1">StandardScaler</li>
<li class="mce-root1">MinMaxScaler</li>
<li class="mce-root1">MaxAbsScaler</li>
<li class="mce-root1">Bucketizer</li>
<li class="mce-root1">ElementwiseProduct</li>
<li class="mce-root1">SQLTransformer</li>
<li class="mce-root1">VectorAssembler</li>
<li class="mce-root1">QuantileDiscretizer</li>
</ul>
<p class="mce-root">Due to page limitations, we cannot describe all of them. But we will discuss some widely used algorithms such as <kbd class="calibre11">CountVectorizer</kbd>, <kbd class="calibre11">Tokenizer</kbd>, <kbd class="calibre11">StringIndexer</kbd>, <kbd class="calibre11">StopWordsRemover</kbd>, <kbd class="calibre11">OneHotEncoder</kbd>, and so on. PCA, which is commonly used in dimensionality reduction, will be discussed in the next section.</p>


            </article>

            
        </section>
    

        <section id="ALD9C1-21aec46d8593429cacea59dbdcd64e1c">

                            <header>
                    </header><h1 class="header-title" id="calibre_pb_0">CountVectorizer</h1>
                
            
            <article>
                
<p class="mce-root"><kbd class="calibre11">CountVectorizer</kbd> and <kbd class="calibre11">CountVectorizerModel</kbd> aim to help convert a collection of text documents to vectors of token counts. When the prior dictionary is not available, <kbd class="calibre11">CountVectorizer</kbd> can be used as an estimator to extract the vocabulary and generates a <kbd class="calibre11">CountVectorizerModel</kbd>. The model produces sparse representations for the documents over the vocabulary, which can then be passed to other algorithms such LDA.</p>
<p class="mce-root">Suppose we have the text corpus as follows:</p>
<div class="cdpaligncenter"><img class="image-border137" src="../images/00296.gif"/></div>
<div class="cdpaligncenter1"><strong class="calibre1">Figure 7</strong>: Text corpus containing name only</div>
<p class="mce-root">Now, if we want to convert the preceding collection of texts to vectors of token counts, Spark provides the <kbd class="calibre11">CountVectorizer ()</kbd> API for doing so. First, let's create a simple DataFrame for the earlier table, as follows:</p>
<pre class="calibre19">
val df = spark.createDataFrame(<br class="title-page-name"/>Seq((0, Array("Jason", "David")),<br class="title-page-name"/>(1, Array("David", "Martin")),<br class="title-page-name"/>(2, Array("Martin", "Jason")),<br class="title-page-name"/>(3, Array("Jason", "Daiel")),<br class="title-page-name"/>(4, Array("Daiel", "Martin")),<br class="title-page-name"/>(5, Array("Moahmed", "Jason")),<br class="title-page-name"/>(6, Array("David", "David")),<br class="title-page-name"/>(7, Array("Jason", "Martin")))).toDF("id", "name")<br class="title-page-name"/>df.show(false)
</pre>
<p class="mce-root">In many cases, you can set the input column with <kbd class="calibre11">setInputCol</kbd>. Let's look at an example of it and let's fit a <kbd class="calibre11">CountVectorizerModel</kbd> object from the corpus, as follows:</p>
<pre class="calibre19">
val cvModel: CountVectorizerModel = new CountVectorizer()<br class="title-page-name"/>                           .setInputCol("name")<br class="title-page-name"/>                           .setOutputCol("features")<br class="title-page-name"/>                           .setVocabSize(3)<br class="title-page-name"/>                           .setMinDF(2)<br class="title-page-name"/>                           .fit(df)
</pre>
<p class="mce-root">Now let's downstream the vectorizer using the extractor, as follows:</p>
<pre class="calibre19">
val feature = cvModel.transform(df)<br class="title-page-name"/>spark.stop()
</pre>
<p class="mce-root">Now let's check to make sure it works properly:</p>
<pre class="calibre19">
feature.show(false)
</pre>
<p class="mce-root">The preceding line of code produces the following output:</p>
<div class="cdpaligncenter"><img class="image-border138" src="../images/00306.gif"/></div>
<div class="cdpaligncenter1"><strong class="calibre1">Figure 8</strong>: Name text corpus has been featurized</div>
<p class="mce-root">Now let's move to the feature transformers. One of the most important transformers is the tokenizer, which is frequently used in the machine learning task for handling categorical data. We will see how to work with this transformer in the next section.</p>


            </article>

            
        </section>
    

        <section id="AMBPU1-21aec46d8593429cacea59dbdcd64e1c">

                            <header>
                    </header><h1 class="header-title" id="calibre_pb_0">Tokenizer</h1>
                
            
            <article>
                
<p class="mce-root">Tokenization is the process of enchanting important components from raw text, such as words, and sentences, and breaking the raw texts into individual terms (also called words). If you want to have more advanced tokenization on regular expression matching, <kbd class="calibre11">RegexTokenizer</kbd> is a good option for doing so. By default, the parameter <em class="calibre8">pattern</em> (regex, default: <kbd class="calibre11">s+</kbd>) is used as delimiters to split the input text. Otherwise, you can also set parameter <em class="calibre8">gaps</em> to false, indicating the regex <em class="calibre8">pattern</em> denotes <em class="calibre8">tokens</em> rather than splitting gaps. This way, you can find all matching occurrences as the tokenization result.</p>
<p class="mce-root">Suppose you have the following sentences:</p>
<ul class="calibre9">
<li class="mce-root1">Tokenization,is the process of enchanting words,from the raw text.</li>
<li class="mce-root1">If you want,to have more advance tokenization, <kbd class="calibre11">RegexTokenizer</kbd>,is a good option.</li>
<li class="mce-root1">Here,will provide a sample example on how to tokenize sentences.</li>
<li class="mce-root1">This way, you can find all matching occurrences.</li>
</ul>
<p class="mce-root">Now, you want to tokenize each meaningful word from the preceding four sentences. Let's create a DataFrame from the earlier sentences, as follows:</p>
<pre class="calibre19">
val sentence = spark.createDataFrame(Seq(<br class="title-page-name"/> (0, "Tokenization,is the process of enchanting words,from the raw text"),<br class="title-page-name"/> (1, " If you want,to have more advance tokenization,RegexTokenizer,<br class="title-page-name"/>       is a good option"),<br class="title-page-name"/> (2, " Here,will provide a sample example on how to tockenize sentences"),<br class="title-page-name"/> (3, "This way,you can find all matching occurrences"))).toDF("id",<br class="title-page-name"/>                                                        "sentence")
</pre>
<p class="mce-root">Now let's create a tokenizer by instantiating the <kbd class="calibre11">Tokenizer ()</kbd> API, as follows:</p>
<pre class="calibre19">
val tokenizer = new Tokenizer().setInputCol("sentence").setOutputCol("words") 
</pre>
<p class="mce-root">Now, count the number of tokens in each sentence using a UDF, as follows: <kbd class="calibre11">import org.apache.spark.sql.functions._</kbd></p>
<pre class="calibre19">
val countTokens = udf { (words: Seq[String]) =&gt; words.length } 
</pre>
<p class="mce-root">Now tokenize words form each sentence, as follows:</p>
<pre class="calibre19">
val tokenized = tokenizer.transform(sentence) 
</pre>
<p class="mce-root">Finally, show each token against each raw sentence, as follows:</p>
<pre class="calibre19">
tokenized.select("sentence", "words")<br class="title-page-name"/>.withColumn("tokens", countTokens(col("words")))<br class="title-page-name"/>.show(false) 
</pre>
<p class="mce-root">The preceding line of code prints a snap from the tokenized DataFrame containing the raw sentence, bag of words, and number of tokens:</p>
<div class="cdpaligncenter"><img class="image-border31" src="../images/00315.gif"/></div>
<div class="cdpaligncenter1"><strong class="calibre1">Figure 9</strong>: Tokenized words from the raw texts</div>
<p class="mce-root">However, if you use <kbd class="calibre11">RegexTokenizer</kbd> API, you will get better results. This goes as follows:<br class="title-page-name"/>
Create a regex tokenizer by instantiating the <kbd class="calibre11">RegexTokenizer ()</kbd> API:</p>
<pre class="calibre19">
val regexTokenizer = new RegexTokenizer()<br class="title-page-name"/>                     .setInputCol("sentence")<br class="title-page-name"/>                     .setOutputCol("words")<br class="title-page-name"/>                     .setPattern("\\W+")<br class="title-page-name"/>                     .setGaps(true)
</pre>
<p class="mce-root">Now tokenize words from each sentence, as follows:</p>
<pre class="calibre19">
val regexTokenized = regexTokenizer.transform(sentence) <br class="title-page-name"/>regexTokenized.select("sentence", "words") <br class="title-page-name"/>              .withColumn("tokens", countTokens(col("words")))<br class="title-page-name"/>              .show(false)
</pre>
<p class="mce-root">The preceding line of code prints a snap from the tokenized DataFrame using RegexTokenizer containing the raw sentence, bag of words, and number of tokens:</p>
<div class="cdpaligncenter"><img class="image-border31" src="../images/00318.gif"/></div>
<div class="cdpaligncenter1"><strong class="calibre1">Figure 10</strong>: Better tokenization using RegexTokenizer</div>


            </article>

            
        </section>
    

        <section id="ANAAG1-21aec46d8593429cacea59dbdcd64e1c">

                            <header>
                    </header><h1 class="header-title" id="calibre_pb_0">StopWordsRemover</h1>
                
            
            <article>
                
<p class="mce-root">Stop words are words that should be excluded from the input, typically because the words appear frequently and don't carry as much meaning. Spark's <kbd class="calibre11">StopWordsRemover</kbd> takes as input a sequence of strings, which is tokenized by <kbd class="calibre11">Tokenizer</kbd> or <kbd class="calibre11">RegexTokenizer</kbd>. Then, it removes all the stop words from the input sequences. The list of stop words is specified by the <kbd class="calibre11">stopWords</kbd> parameter. The current implementation for the <kbd class="calibre11">StopWordsRemover</kbd> API provides the options for the Danish, Dutch, Finnish, French, German, Hungarian, Italian, Norwegian, Portuguese, Russian, Spanish, Swedish, Turkish, and English languages. To provide an example, we can simply extend the preceding <kbd class="calibre11">Tokenizer</kbd> example in the previous section, since they are already tokenized. For this example, however, we will use the <kbd class="calibre11">RegexTokenizer</kbd> API.</p>
<p class="mce-root">At first, create a stop word remover instance from the <kbd class="calibre11">StopWordsRemover ()</kbd> API, as follows:</p>
<pre class="calibre19">
val remover = new StopWordsRemover()<br class="title-page-name"/>             .setInputCol("words")<br class="title-page-name"/>             .setOutputCol("filtered")
</pre>
<p class="mce-root">Now, let's remove all the stop words and print the results as follows:</p>
<pre class="calibre19">
val newDF = remover.transform(regexTokenized)<br class="title-page-name"/> newDF.select("id", "filtered").show(false)
</pre>
<p class="mce-root">The preceding line of code prints a snap from the filtered DataFrame excluding the stop words:</p>
<div class="cdpaligncenter1"><img class="image-border139" src="../images/00324.gif"/></div>
<div class="cdpaligncenter1"><strong class="calibre1">Figure 11</strong>: Filtered (that is, without stop words) tokens</div>


            </article>

            
        </section>
    

        <section id="AO8R21-21aec46d8593429cacea59dbdcd64e1c">

                            <header>
                    </header><h1 class="header-title" id="calibre_pb_0">StringIndexer</h1>
                
            
            <article>
                
<p class="mce-root">StringIndexer encodes a string column of labels to a column of label indices. The indices are in <kbd class="calibre11">[0, numLabels)</kbd>, ordered by label frequencies, so the most frequent label gets index 0. If the input column is numeric, we cast it to string and index the string values. When downstream pipeline components such as estimator or transformer make use of this string-indexed label, you must set the input column of the component to this string-indexed column name. In many cases, you can set the input column with <kbd class="calibre11">setInputCol</kbd>. Suppose you have some categorical data in the following format:</p>
<div class="cdpaligncenter"><img class="image-border140" src="../images/00158.gif"/></div>
<div class="cdpaligncenter1"><strong class="calibre1">Figure 12</strong>: DataFrame for applying String Indexer</div>
<p class="mce-root">Now, we want to index the name column so that the most frequent name (that is, Jason in our case) gets index 0. To make this, Spark provides <kbd class="calibre11">StringIndexer</kbd> API for doing so. For our example, this can be done, as follows:</p>
<p class="mce-root">At first, let's create a simple DataFrame for the preceding table:</p>
<pre class="calibre19">
val df = spark.createDataFrame(<br class="title-page-name"/> Seq((0, "Jason", "Germany"),<br class="title-page-name"/> (1, "David", "France"),<br class="title-page-name"/> (2, "Martin", "Spain"),<br class="title-page-name"/> (3, "Jason", "USA"),<br class="title-page-name"/> (4, "Daiel", "UK"),<br class="title-page-name"/> (5, "Moahmed", "Bangladesh"),<br class="title-page-name"/> (6, "David", "Ireland"),<br class="title-page-name"/> (7, "Jason", "Netherlands"))).toDF("id", "name", "address")
</pre>
<p class="mce-root">Now let's index the name column, as follows:</p>
<pre class="calibre19">
val indexer = new StringIndexer()<br class="title-page-name"/> .setInputCol("name")<br class="title-page-name"/> .setOutputCol("label")<br class="title-page-name"/> .fit(df)
</pre>
<p class="mce-root">Now let's downstream the indexer using the transformer, as follows:</p>
<pre class="calibre19">
val indexed = indexer.transform(df)
</pre>
<p class="mce-root">Now let's check to make sure if it works properly:</p>
<pre class="calibre19">
indexed.show(false)
</pre>
<div class="cdpaligncenter"><img class="image-border141" src="../images/00381.gif"/></div>
<div class="cdpaligncenter1"><strong class="calibre1">Figure 13</strong>: Label creation using StringIndexer</div>
<p class="mce-root">Another important transformer is the OneHotEncoder, which is frequently used in machine learning tasks for handling categorical data. We will see how to work with this transformer in the next section.</p>


            </article>

            
        </section>
    

        <section id="AP7BK1-21aec46d8593429cacea59dbdcd64e1c">

                            <header>
                    </header><h1 class="header-title" id="calibre_pb_0">OneHotEncoder</h1>
                
            
            <article>
                
<p class="mce-root">A one-hot encoding maps a column of label indices to a column of binary vectors, with at most a single value. This encoding allows algorithms that expect continuous features, such as Logistic Regression, to use categorical features. Suppose you have some categorical data in the following format (the same that we used for describing the <kbd class="calibre11">StringIndexer</kbd> in the previous section):</p>
<div class="cdpaligncenter"><img class="image-border142" src="../images/00253.gif"/></div>
<div class="cdpaligncenter1"><strong class="calibre1">Figure 14:</strong> DataFrame for applying OneHotEncoder</div>
<p class="mce-root">Now, we want to index the name column so that the most frequent name in the dataset (that is, <strong class="calibre1">Jason</strong> in our case) gets index <strong class="calibre1">0</strong>. However, what's the use of just indexing them? In other words, you can further vectorize them and then you can feed the DataFrame to any ML models easily. Since we have already seen how to create a DataFrame in the previous section, here, we will just show how to encode them toward Vectors:</p>
<pre class="calibre19">
val indexer = new StringIndexer()<br class="title-page-name"/>                  .setInputCol("name")<br class="title-page-name"/>                  .setOutputCol("categoryIndex")<br class="title-page-name"/>                  .fit(df)<br class="title-page-name"/>val indexed = indexer.transform(df)<br class="title-page-name"/>val encoder = new OneHotEncoder()<br class="title-page-name"/>                  .setInputCol("categoryIndex")<br class="title-page-name"/>                  .setOutputCol("categoryVec")
</pre>
<p class="mce-root"><br class="title-page-name"/>
Now let's transform it into a vector using <kbd class="calibre11">Transformer</kbd> and then see the contents, as follows:</p>
<pre class="calibre19">
val encoded = encoder.transform(indexed)<br class="title-page-name"/>encoded.show()
</pre>
<p class="mce-root">The resulting DataFrame containing a snap is as follows:</p>
<div class="cdpaligncenter"><img class="image-border143" src="../images/00228.gif"/></div>
<div class="cdpaligncenter1"><strong class="calibre1">Figure 15</strong>: Creating category index and vector using OneHotEncoder</div>
<p class="mce-root">Now you can see that a new column containing feature vectors has been added in the resulting DataFrame.</p>


            </article>

            
        </section>
    

        <section id="AQ5S61-21aec46d8593429cacea59dbdcd64e1c">

                            <header>
                    </header><h1 class="header-title" id="calibre_pb_0">Spark ML pipelines</h1>
                
            
            <article>
                
<p class="mce-root">MLlib's goal is to make practical machine learning (ML) scalable and easy. Spark introduced the pipeline API for the easy creation and tuning of practical ML pipelines. As discussed previously, extracting meaningful knowledge through feature engineering in an ML pipeline creation involves a sequence of data collection, preprocessing, feature extraction, feature selection, model fitting, validation, and model evaluation stages. For example, classifying the text documents might involve text segmentation and cleaning, extracting features, and training a classification model with cross-validation toward tuning. Most ML libraries are not designed for distributed computation or they do not provide native support for pipeline creation and tuning.</p>


            </article>

            
        </section>
    

        <section id="AR4CO1-21aec46d8593429cacea59dbdcd64e1c">

                            <header>
                    </header><h1 class="header-title" id="calibre_pb_0">Dataset abstraction</h1>
                
            
            <article>
                
<p class="mce-root">When running SQL queries from another programming language (<span>for example,</span> Java), the result is returned as a DataFrame. A DataFrame is a distributed collection of data organized into named columns. A dataset, on the other hand, is an interface that tries to provide the benefits of RDDs out of the Spark SQL. A dataset can be constructed from some JVM objects such as primitive types (for example, <kbd class="calibre11">String</kbd>, <kbd class="calibre11">Integer</kbd>, and <kbd class="calibre11">Long</kbd>), Scala case classes, and Java Beans. An ML pipeline involves a number of the sequences of dataset transformations and models. Each transformation takes an input dataset and outputs the transformed dataset, which becomes the input to the next stage. Consequently, the data import and export are the start and end points of an ML pipeline. To make these easier, Spark MLlib and Spark ML provide import and export utilities of a dataset, DataFrame, RDD, and model for several application-specific types, including:</p>
<ul class="calibre9">
<li class="mce-root1">LabeledPoint for classification and regression</li>
<li class="mce-root1">LabeledDocument for cross-validation and Latent Dirichlet Allocation (LDA)</li>
<li class="mce-root1">Rating and ranking for collaborative filtering</li>
</ul>
<p class="mce-root">However, real datasets usually contain numerous types, such as user ID, item IDs, labels, timestamps, and raw records. Unfortunately, the current utilities of Spark implementation cannot easily handle datasets consisting of these types, especially time-series datasets. The feature transformation usually forms the majority of a practical ML pipeline. A feature transformation can be viewed as appending or dropping a new column created from existing columns.</p>
<p class="mce-root">In the following figure, you will see that the text tokenizer breaks a document into a bag of words. After that, the TF-IDF algorithm converts a bag of words into a feature vector. During the transformations, the labels need to be preserved for the model-fitting stage:</p>
<div class="cdpaligncenter"><img class="image-border144" src="../images/00137.jpeg"/></div>
<div class="cdpaligncenter1"><strong class="calibre1">Figure 16</strong>: Text processing for machine learning model (DS indicates data sources)</div>
<p class="mce-root">Here, the ID, text, and words are conceded during the transformations steps. They are useful in making predictions and model inspection. However, they are actually unnecessary for model fitting to state. These also don't provide much information if the prediction dataset contains only the predicted labels. Consequently, if you want to inspect the prediction metrics, such as the accuracy, precision, recall, weighted true positives, and weighted false positives, it is quite useful to look at the predicted labels along with the raw input text and tokenized words. The same recommendation also applies to other machine learning applications using Spark ML and Spark MLlib.</p>
<p class="mce-root">Therefore, an easy conversion between RDDs, dataset, and DataFrames has been made possible for in-memory, disk, or external data sources such as Hive and Avro. Although creating new columns from existing columns is easy with user-defined functions, the manifestation of dataset is a lazy operation. In contrast, the dataset supports only some standard data types. However, to increase the usability and to make a better fit for the machine learning model, Spark has also added the support for the <kbd class="calibre11">Vector</kbd> type as a user-defined type that supports both dense and sparse feature vectors under <kbd class="calibre11">mllib.linalg.DenseVector</kbd> and <kbd class="calibre11">mllib.linalg.Vector</kbd>.</p>
<p class="mce-root">Complete DataFrame, dataset, and RDD examples in Java, Scala, and Python can be found in the <kbd class="calibre11">examples/src/main/</kbd> folder under the Spark distribution. Interested readers can refer to Spark SQL's user guide at <a href="http://spark.apache.org/docs/latest/sql-programming-guide.html" class="calibre10">http://spark.apache.org/docs/latest/sql-programming-guide.html</a> to learn more about DataFrame, dataset, and the operations they support.</p>


            </article>

            
        </section>
    

        <section id="AS2TA1-21aec46d8593429cacea59dbdcd64e1c">

                            <header>
                    </header><h1 class="header-title" id="calibre_pb_0">Creating a simple pipeline</h1>
                
            
            <article>
                
<p class="mce-root">Spark provides pipeline APIs under Spark ML. A pipeline comprises a sequence of stages consisting of transformers and estimators. There are two basic types of pipeline stages, called transformer and estimator:</p>
<ul class="calibre9">
<li class="mce-root1">A transformer takes a dataset as an input and produces an augmented dataset as the output so that the output can be fed to the next step. For example, <strong class="calibre1">Tokenizer</strong> and <strong class="calibre1">HashingTF</strong> are two transformers. Tokenizer transforms a dataset with text into a dataset with tokenized words. A HashingTF, on the other hand, produces the term frequencies. The concept of tokenization and HashingTF is commonly used in text mining and text analytics.</li>
<li class="mce-root1">On the contrary, an estimator must be the first on the input dataset to produce a model. In this case, the model itself will be used as the transformer for transforming the input dataset into the augmented output dataset. For example, a <strong class="calibre1">Logistic Regression</strong> or linear regression can be used as an estimator after fitting the training dataset with corresponding labels and features.</li>
</ul>
<p class="mce-root">After that, it produces a logistic or linear regression model, which implies that developing a pipeline is easy and simple. Well, all you need to do is to declare required stages, then configure the related stage's parameters; finally, chain them in a pipeline object, as shown in the following figure:</p>
<div class="cdpaligncenter"><img class="image-border145" src="../images/00374.jpeg"/></div>
<div class="cdpaligncenter1"><strong class="calibre1">Figure 17</strong>: Spark ML pipeline model using logistic regression estimator (DS indicates data store, and the steps inside the dashed line only happen during pipeline fitting)</div>
<p class="mce-root">If you look at <em class="calibre8">Figure 17</em>, the fitted model consists of a Tokenizer, a HashingTF feature extractor, and a fitted logistic regression model. The fitted pipeline model acts as a transformer that can be used for prediction, model validation, model inspection, and, finally, model deployment. However, to increase the performance in terms of prediction accuracy, the model itself needs to be tuned.</p>
<p class="mce-root">Now we know about the available algorithms in Spark MLlib and ML, now it's time to get prepared before starting to use them in a formal way for solving supervised and unsupervised learning problems. In the next section, we will start on feature extraction and transformation.</p>


            </article>

            
        </section>
    

        <section id="AT1DS1-21aec46d8593429cacea59dbdcd64e1c">

                            <header>
                    </header><h1 class="header-title" id="calibre_pb_0">Unsupervised machine learning</h1>
                
            
            <article>
                
<p class="mce-root">In this section, to make the discussion concrete, only the dimensionality reduction using PCA and the LDA for topic modeling will be discussed for text clustering. Other algorithms for unsupervised learning will be discussed in <a href="part0413.html#C9ROA1-21aec46d8593429cacea59dbdcd64e1c" class="calibre10">Chapter 13</a>, <em class="calibre8">My Name is Bayes, Naive Bayes</em> with some practical examples.</p>


            </article>

            
        </section>
    

        <section id="ATVUE1-21aec46d8593429cacea59dbdcd64e1c">

                            <header>
                    </header><h1 class="header-title" id="calibre_pb_0">Dimensionality reduction</h1>
                
            
            <article>
                
<p class="mce-root">Dimensionality reduction is the process of reducing the number of variables under consideration. It can be used to extract latent features from raw and noisy features or to compress data while maintaining the structure. Spark MLlib provides support for dimensionality reduction on the <kbd class="calibre11">RowMatrix</kbd> class. The most commonly used algorithms for reducing the dimensionality of data are PCA and SVD. However, in this section, we will discuss PCA only to make the discussion more concrete.</p>


            </article>

            
        </section>
    

        <section id="AUUF01-21aec46d8593429cacea59dbdcd64e1c">

                            <header>
                    </header><h1 class="header-title" id="calibre_pb_0">PCA</h1>
                
            
            <article>
                
<p class="mce-root">PCA is a statistical procedure that uses an orthogonal transformation to convert a set of observations of possibly correlated variables into a set of values of linearly uncorrelated variables called principal components. A PCA algorithm can be used to project vectors to a low-dimensional space using PCA. Then, based on the reduced feature vectors, an ML model can be trained. The following example shows how to project 6D feature vectors into four-dimensional principal components. Suppose, you have a feature vector as follows:</p>
<pre class="calibre19">
val data = Array(<br class="title-page-name"/> Vectors.dense(3.5, 2.0, 5.0, 6.3, 5.60, 2.4),<br class="title-page-name"/> Vectors.dense(4.40, 0.10, 3.0, 9.0, 7.0, 8.75),<br class="title-page-name"/> Vectors.dense(3.20, 2.40, 0.0, 6.0, 7.4, 3.34) )
</pre>
<p class="mce-root">Now let's create a DataFrame from it, as follows:</p>
<pre class="calibre19">
val df = spark.createDataFrame(data.map(Tuple1.apply)).toDF("features")<br class="title-page-name"/>df.show(false)
</pre>
<p class="mce-root">The preceding code produces a feature DataFrame having 6D feature vector for the PCA:</p>
<div class="cdpaligncenter"><img class="image-border146" src="../images/00291.gif"/></div>
<div class="cdpaligncenter1"><strong class="calibre1">Figure 18</strong>: Creating a feature DataFrame (6-dimensional feature vectors) for PCA</div>
<p class="mce-root">Now let's instantiate the PCA model by setting necessary parameters as follows:</p>
<pre class="calibre19">
val pca = new PCA()<br class="title-page-name"/> .setInputCol("features")<br class="title-page-name"/> .setOutputCol("pcaFeatures")<br class="title-page-name"/> .setK(4) <br class="title-page-name"/> .fit(df)
</pre>
<p class="mce-root">Now, to make a difference, we set the output column as <kbd class="calibre11">pcaFeatures</kbd> using the <kbd class="calibre11">setOutputCol()</kbd> method. Then, we set the dimension of the PCA. Finally, we fit the DataFrame to make the transformation. Note that the PCA model includes an <kbd class="calibre11">explainedVariance</kbd> member. A model can be loaded from such older data but will have an empty vector for <kbd class="calibre11">explainedVariance</kbd>. Now let's show the resulting features:</p>
<pre class="calibre19">
val result = pca.transform(df).select("pcaFeatures") <br class="title-page-name"/>result.show(false)
</pre>
<p class="mce-root">The preceding code produces a feature DataFrame having 4D feature vectors as principal components using the PCA:</p>
<div class="cdpaligncenter"><br class="title-page-name"/>
<img class="image-border147" src="../images/00384.gif"/></div>
<div class="cdpaligncenter1"><strong class="calibre1">Figure 19</strong>: Four-dimensional principal components (PCA features)</div>


            </article>

            
        </section>
    

        <section id="AVSVI1-21aec46d8593429cacea59dbdcd64e1c">

                            <header>
                    </header><h1 class="header-title" id="calibre_pb_0">Using PCA</h1>
                
            
            <article>
                
<p class="mce-root">PCA, which is used widely in dimensionality reduction, is a statistical method that helps to find the rotation matrix. For example, if we want to check if the first coordinate has the largest variance possible. Also it helps to check if there is any succeeding coordinate that will turn the largest variance possible.</p>
<p class="mce-root">Eventually, the PCA model calculates such parameters and returns them as a rotation matrix. The columns of the rotation matrix are called principal components. Spark MLlib supports PCA for tall and skinny matrices stored in a row-oriented format and any vectors.</p>


            </article>

            
        </section>
    

        <section id="B0RG41-21aec46d8593429cacea59dbdcd64e1c">

                            <header>
                    </header><h1 class="header-title" id="calibre_pb_0">Regression Analysis - a practical use of PCA</h1>
                
            
            <article>
                
<p class="mce-root">In this section, we will first explore the <strong class="calibre1">MSD</strong> (<strong class="calibre1">Million Song Dataset</strong>) that will be used for the regression analysis. Then we will show how to use PCA to reduce the dimensions of the dataset. Finally, we will evaluate the linear regression model for the regression quality.</p>


            </article>

            
        </section>
    

        <section id="B1Q0M1-21aec46d8593429cacea59dbdcd64e1c">

                            <header>
                    </header><h1 class="header-title" id="calibre_pb_0">Dataset collection and exploration</h1>
                
            
            <article>
                
<p class="mce-root">In this section, we will describe the very famous MNIST dataset. This dataset will be used throughout this chapter. The MNIST database of handwritten digits (downloaded from <a href="https://www.csie.ntu.edu.tw/~cjlin/libsvmtools/datasets/multiclass.html" class="calibre10">https://www.csie.ntu.edu.tw/~cjlin/libsvmtools/datasets/multiclass.html</a>) has a training set of 60,000 examples and a test set of 10,000 examples. It is a subset of a larger set available from NIST. The digits have been size-normalized and centered in a fixed-size image. Consequently, this is a very good example dataset for those who are trying to learn techniques and pattern recognition methods on real-world data while spending minimal efforts on preprocessing and formatting. The original black and white (bi-level) images from NIST were size-normalized to fit in a 20 x 20 pixel box while preserving their aspect ratio.</p>
<p class="mce-root">The MNIST database was constructed from NIST's special database 3 and special database 1, which contain binary images of handwritten digits. A sample of the dataset is given in the following:</p>
<div class="cdpaligncenter"><img class="image-border148" src="../images/00121.gif"/></div>
<div class="cdpaligncenter1"><strong class="calibre1">Figure 20</strong>: A snap of the MNIST dataset</div>
<p class="mce-root">You can see that there are 780 features altogether. Consequently, sometimes, many machine learning algorithms will fail due to the high-dimensional nature of your dataset. Therefore, to address this issue, in the next section, we will show you how to reduce the dimensions without sacrificing the qualities machine learning tasks, such as classification. However, before diving into the problem, let's get some background knowledge on regression analysis first.</p>


            </article>

            
        </section>
    

        <section>

                            <header id="B2OH82-21aec46d8593429cacea59dbdcd64e1c">
                    </header><h1 class="header-title" id="calibre_pb_0">What is regression analysis?</h1>
                
            
            <article>
                
<p class="mce-root">Linear regression belongs to the family of regression algorithms. The goal of regression is to find relationships and dependencies between variables. It is modeling the relationship between a continuous scalar dependent variable <em class="calibre8">y</em> (also, label or target in machine learning terminology) and one or more (a D-dimensional vector) explanatory variables (also, independent variables, input variables, features, observed data, observations, attributes, dimensions, data point, and so on) denoted <em class="calibre8">x</em> using a linear function. In regression analysis, the goal is to predict a continuous target variable, as shown in the following figure:</p>
<div class="cdpaligncenter1"><img class="image-border149" src="../images/00171.jpeg"/></div>
<div class="cdpaligncenter1">Figure 21: A regression algorithm is meant to produce continuous output. The input is allowed to be either<br class="title-page-name"/>
discrete or continuous (source: Nishant Shukla, Machine Learning with TensorFlow, Manning Publications co. 2017)</div>
<p class="mce-root">Now, you might have some confusion in your mind about what the basic difference between a classification and a regression problem is. The following information box will make it clearer:</p>
<div class="packt_infobox"><strong class="calibre27">Regression versus classification:</strong> On the other hand, another area, called classification, is about predicting a label from a finite set but with discrete values. This distinction is important to know because discrete-valued output is handled better by classification, which will be discussed in upcoming sections.</div>
<p class="mce-root">The model for a multiple regression that involves a linear combination of input variables takes the following form:</p>
<p class="mce-root">y = ss<sub class="calibre43">0</sub> + ss<sub class="calibre43">1</sub>x<sub class="calibre43">1</sub> + ss<sub class="calibre43">2</sub>x<sub class="calibre43">2</sub> + ss<sub class="calibre43">3</sub>x<sub class="calibre43">3</sub> +..... + e</p>
<p class="mce-root">Figure 22 shows an example of simple linear regression with one independent variable (<em class="calibre8">x</em> axis). The model (red line) is calculated using training data (blue points), where each point has a known label (<em class="calibre8">y</em> axis) to fit the points as accurately as possible by minimizing the value of a chosen loss function. We can then use the model to predict unknown labels (we only know <em class="calibre8">x</em> value and want to predict <em class="calibre8">y</em> value).</p>
<div class="cdpaligncenter"><img class="image-border150" src="../images/00383.jpeg"/></div>
<div class="cdpaligncenter1">Figure 22: Regression graph that separates data points (the dots [.] refer to data points in the graph and the red line refers to the regression)</div>
<div class="packt_infobox">Spark provides an RDD-based implementation of the linear regression algorithm. You can train a linear regression model with no regularization using stochastic gradient descent. This solves the least squares regression formulation <em class="calibre25">f (weights) = 1/n ||A weights-y||^2</em> (which is the mean squared error). Here, the data matrix has <em class="calibre25">n</em> rows, and the input RDD holds the set of rows of <em class="calibre25">A</em>, each with its corresponding right-hand side label <em class="calibre25">y</em>. For more information, refer to <a href="https://github.com/apache/spark/blob/master/mllib/src/main/scala/org/apache/spark/mllib/regression/LinearRegression.scala" class="calibre21">https://github.com/apache/spark/blob/master/mllib/src/main/scala/org/apache/spark/mllib/regression/LinearRegression.scala</a>.</div>
<p class="mce-root"><strong class="calibre1">Step 1. Load the dataset and create RDD</strong></p>
<p class="mce-root">For loading the MNIST dataset in LIBSVM format, here we used the built-in API called MLUtils from Spark MLlib:</p>
<pre class="calibre19">
val data = MLUtils.loadLibSVMFile(spark.sparkContext, "data/mnist.bz2") 
</pre>
<p class="mce-root"><strong class="calibre1">Step 2. Compute the number of features to make the dimensionality reduction easier:</strong></p>
<pre class="calibre19">
val featureSize = data.first().features.size<br class="title-page-name"/>println("Feature Size: " + featureSize)
</pre>
<p class="mce-root">This will result in the following output:</p>
<pre class="calibre19">
<strong class="calibre1">Feature Size: 780</strong>
</pre>
<p class="mce-root">So the dataset has 780 columns -i.e. features so this can be considered as high-dimensional one (features). Therefore, sometimes it is worth reducing the dimensions of the dataset.<br class="title-page-name"/>
<br class="title-page-name"/>
<strong class="calibre1">Step 3. Now prepare the training and test set as follows:</strong></p>
<p class="mce-root">The thing is that we will train the <kbd class="calibre11">LinearRegressionwithSGD</kbd> model twice. First, we will use the normal dataset with the original dimensions of the features, secondly, using half of the features. With the original one, the training and test set preparation go as follows:</p>
<pre class="calibre19">
val splits = data.randomSplit(Array(0.75, 0.25), seed = 12345L)<br class="title-page-name"/>val (training, test) = (splits(0), splits(1))
</pre>
<p class="mce-root">Now, for the reduced features, the training goes as follows:</p>
<pre class="calibre19">
val pca = new PCA(featureSize/2).fit(data.map(_.features))<br class="title-page-name"/>val training_pca = training.map(p =&gt; p.copy(features = pca.transform(p.features)))<br class="title-page-name"/>val test_pca = test.map(p =&gt; p.copy(features = pca.transform(p.features))) 
</pre>
<p class="mce-root"><strong class="calibre1">Step 4. Training the linear regression model</strong><br class="title-page-name"/>
Now iterate 20 times and train the <kbd class="calibre11">LinearRegressionWithSGD</kbd> for the normal features and reduced features, respectively, as follows:</p>
<pre class="calibre19">
val numIterations = 20<br class="title-page-name"/>val stepSize = 0.0001<br class="title-page-name"/>val model = LinearRegressionWithSGD.train(training, numIterations)<br class="title-page-name"/>val model_pca = LinearRegressionWithSGD.train(training_pca, numIterations)
</pre>
<p class="mce-root">Beware! Sometimes, <kbd class="calibre11">LinearRegressionWithSGD()</kbd> returns <kbd class="calibre11">NaN</kbd>. In my opinion, there are two reasons for this happening:</p>
<ul class="calibre9">
<li class="mce-root1">If the <kbd class="calibre11">stepSize</kbd> is big. In that case, you should use something smaller, such as 0.0001, 0.001, 0.01, 0.03, 0.1, 0.3, 1.0, and so on.</li>
<li class="mce-root1">Your train data has <kbd class="calibre11">NaN</kbd>. If so, the result will likely be <kbd class="calibre11">NaN</kbd>. So, it is recommended to remove the null values prior to training the model.</li>
</ul>
<p class="mce-root"><strong class="calibre1">Step 5. Evaluating both models</strong></p>
<p class="mce-root">Before we evaluate the classification model, first, let's prepare for computing the MSE for the normal to see the effects of dimensionality reduction on the original predictions. Obviously, if you want a formal way to quantify the accuracy of the model and potentially increase the precision and avoid overfitting. Nevertheless, you can do from residual analysis. Also it would be worth to analyse the selection of the training and test set to be used for the model building and then the evaluation. Finally, selection techniques help you to describe the various attributes of a model:</p>
<pre class="calibre19">
val valuesAndPreds = test.map { point =&gt;<br class="title-page-name"/>                      val score = model.predict(point.features)<br class="title-page-name"/>                      (score, point.label)<br class="title-page-name"/>                     }
</pre>
<p class="mce-root">Now compute the prediction sets for the PCA one as follows:</p>
<pre class="calibre19">
val valuesAndPreds_pca = test_pca.map { point =&gt;<br class="title-page-name"/>                         val score = model_pca.predict(point.features)<br class="title-page-name"/>                         (score, point.label)<br class="title-page-name"/>                       }
</pre>
<p class="mce-root">Now compute the MSE and print them for each case as follows:</p>
<pre class="calibre19">
val MSE = valuesAndPreds.map { case (v, p) =&gt; math.pow(v - p 2) }.mean()<br class="title-page-name"/>val MSE_pca = valuesAndPreds_pca.map { case (v, p) =&gt; math.pow(v - p, 2) }.mean()<br class="title-page-name"/>println("Mean Squared Error = " + MSE)<br class="title-page-name"/>println("PCA Mean Squared Error = " + MSE_pca)
</pre>
<p class="mce-root">You will get the following output:</p>
<pre class="calibre19">
<strong class="calibre1">Mean Squared Error = 2.9164359135973043E78</strong><br class="title-page-name"/><strong class="calibre1">PCA Mean Squared Error = 2.9156682256149184E78</strong>
</pre>
<p class="mce-root">Note that the MSE is actually calculated using the following formula:</p>
<div class="cdpaligncenter"><img class="image-border151" src="../images/00238.gif"/></div>
<p class="mce-root"><strong class="calibre1">Step 6.</strong> <strong class="calibre1">Observing the model coefficient for both models</strong></p>
<p class="mce-root">Compute the model coefficient as follows:</p>
<pre class="calibre19">
println("Model coefficients:"+ model.toString())<br class="title-page-name"/>println("Model with PCA coefficients:"+ model_pca.toString())
</pre>
<p class="mce-root">Now you should observer the following output on your terminal/console:</p>
<pre class="calibre19">
<strong class="calibre1">Model coefficients: intercept = 0.0, numFeatures = 780</strong><br class="title-page-name"/><strong class="calibre1">Model with PCA coefficients: intercept = 0.0, numFeatures = 390</strong>
</pre>


            </article>

            
        </section>
    

        <section id="B3N1Q1-21aec46d8593429cacea59dbdcd64e1c">

                            <header>
                    </header><h1 class="header-title" id="calibre_pb_0">Binary and multiclass classification</h1>
                
            
            <article>
                
<p class="mce-root">Binary classifiers are used to separate the elements of a given dataset into one of two possible groups (for example, fraud or not fraud) and are a special case of multiclass classification. Most binary classification metrics can be generalized to multiclass classification metrics. A multiclass classification describes a classification problem, where there are <em class="calibre8">M&gt;2</em> possible labels for each data point (the case where <em class="calibre8">M=2</em> is the binary classification problem).</p>
<p class="mce-root">For multiclass metrics, the notion of positives and negatives is slightly different. Predictions and labels can still be positive or negative, but they must be considered in the context of a particular class. Each label and prediction takes on the value of one of the multiple classes and so they are said to be positive for their particular class and negative for all other classes. So, a true positive occurs whenever the prediction and the label match, while a true negative occurs when neither the prediction nor the label takes on the value of a given class. By this convention, there can be multiple true negatives for a given data sample. The extension of false negatives and false positives from the former definitions of positive and negative labels is straightforward.</p>


            </article>

            
        </section>
    

        <section id="B4LIC1-21aec46d8593429cacea59dbdcd64e1c">

                            <header>
                    </header><h1 class="header-title" id="calibre_pb_0">Performance metrics</h1>
                
            
            <article>
                
<p class="mce-root">While there are many different types of classification algorithms, evaluation metrics more or less shares similar principles. In a supervised classification problem, there exists a true output and a model-generated predicted output for each data point. For this reason, the results for each data point can be assigned to one of four categories:</p>
<ul class="calibre9">
<li class="mce-root1"><strong class="calibre1">True positive</strong> (<strong class="calibre1">TP</strong>): Label is positive and prediction is also positive.</li>
<li class="mce-root1"><strong class="calibre1">True negative</strong> (<strong class="calibre1">TN</strong>): Label is negative and prediction is also negative.</li>
<li class="mce-root1"><strong class="calibre1">False positive</strong> (<strong class="calibre1">FP</strong>): Label is negative but prediction is positive.</li>
<li class="mce-root1"><strong class="calibre1">False negative</strong> (<strong class="calibre1">FN</strong>): Label is positive but prediction is negative.</li>
</ul>
<p class="mce-root">Now, to get a clearer idea about these parameters, refer to the following figure:</p>
<div class="cdpaligncenter1"><img class="image-border152" src="../images/00181.jpeg"/></div>
<div class="cdpaligncenter1"><strong class="calibre1">Figure 23</strong>: Prediction classifier (that is, confusion matrix)</div>
<p class="mce-root">The TP, FP, TN, FN are the building blocks for most classifier evaluation metrics. A fundamental point when considering classifier evaluation is that pure accuracy (that is, was the prediction correct or incorrect) is not generally a good metric. The reason for this is that a dataset may be highly unbalanced. For example, if a model is designed to predict fraud from a dataset where 95% of the data points are not fraud and 5% of the data points are fraud. Then suppose a naive classifier predicts not fraud (regardless of input) will be 95% accurate. For this reason, metrics such as precision and recall are typically used because they take into account the type of error. In most applications, there is some desired balance between precision and recall, which can be captured by combining the two into a single metric, called the <strong class="calibre1">F-measure</strong>.</p>
<p class="mce-root">Precision signifies how many of the positively classified were relevant. On the other hand, recall signifies how good a test is at detecting the positives? In binary classification, recall is called sensitivity. It is important to note that the the precision may not decrease with recall. The relationship between recall and precision can be observed in the stair step area of the plot:</p>
<ul class="calibre9">
<li class="mce-root1">Receiver operating characteristic (ROC)</li>
<li class="mce-root1">Area under ROC curve</li>
<li class="mce-root1">Area under precision-recall curve</li>
</ul>
<p class="mce-root">These curves are typically used in binary classification to study the output of a classifier. However, sometimes it is good to combine precision and recall to choose between two models. In contrast, using precision and recall with multiple-number evaluation metrics makes it harder to compare algorithms. Suppose you have two algorithms that perform as follows:</p>
<table class="calibre24">
<tbody class="calibre5">
<tr class="calibre6">
<td class="calibre7">
<p class="mce-root"><strong class="calibre1">Classifier</strong></p>
</td>
<td class="calibre7">
<p class="mce-root"><strong class="calibre1">Precision</strong></p>
</td>
<td class="calibre7">
<p class="mce-root"><strong class="calibre1">Recall</strong></p>
</td>
</tr>
<tr class="calibre6">
<td class="calibre7">
<p class="mce-root">X</p>
</td>
<td class="calibre7">
<p class="mce-root">96%</p>
</td>
<td class="calibre7">
<p class="mce-root">89%</p>
</td>
</tr>
<tr class="calibre6">
<td class="calibre7">
<p class="mce-root">Y</p>
</td>
<td class="calibre7">
<p class="mce-root">99%</p>
</td>
<td class="calibre7">
<p class="mce-root">84%</p>
</td>
</tr>
</tbody>
</table>
<p class="mce-root"> </p>
<p class="mce-root">Here, neither classifier is obviously superior, so it doesn't immediately guide you toward picking the optimal one. But using F1 score, which is a measure that combines precision and recall (that is, the harmonic mean of precision and recall), balanced the F1 score. Let's calculate it and place it in the table:</p>
<table class="calibre24">
<tbody class="calibre5">
<tr class="calibre6">
<td class="calibre7">
<p class="mce-root"><strong class="calibre1">Classifier</strong></p>
</td>
<td class="calibre7">
<p class="mce-root"><strong class="calibre1">Precision</strong></p>
</td>
<td class="calibre7">
<p class="mce-root"><strong class="calibre1">Recall</strong></p>
</td>
<td class="calibre7">
<p class="mce-root"><strong class="calibre1">F1 score</strong></p>
</td>
</tr>
<tr class="calibre6">
<td class="calibre7">
<p class="mce-root">X</p>
</td>
<td class="calibre7">
<p class="mce-root">96%</p>
</td>
<td class="calibre7">
<p class="mce-root">89%</p>
</td>
<td class="calibre7">
<p class="mce-root">92.36%</p>
</td>
</tr>
<tr class="calibre6">
<td class="calibre7">
<p class="mce-root">Y</p>
</td>
<td class="calibre7">
<p class="mce-root">99%</p>
</td>
<td class="calibre7">
<p class="mce-root">84%</p>
</td>
<td class="calibre7">
<p class="mce-root">90.885%</p>
</td>
</tr>
</tbody>
</table>
<p class="mce-root">Therefore, having F1-score helps make a decision for selecting from a large number of classifiers. It gives a clear preference ranking among all of them and therefore a clear direction for progress, that is, classifier <strong class="calibre1">X</strong>.</p>
<p class="mce-root">For the binary classification, the preceding performance metrics can be calculated as follows:</p>
<div class="cdpaligncenter"><img class="image-border153" src="../images/00057.jpeg"/></div>
<div class="cdpaligncenter1"><strong class="calibre1">Figure 24</strong>: Mathematical formula for computing performance metrics for binary classifiers (source: <a href="https://spark.apache.org/docs/2.1.0/mllib-evaluation-metrics.html" class="calibre44">https://spark.apache.org/docs/2.1.0/mllib-evaluation-metrics.html</a>)</div>
<p class="mce-root">However, in multiclass classification problems where more than two predicted labels are associated, computing the earlier metrics is more complex but can be computed using the following mathematical equations:</p>
<div class="cdpaligncenter"><img class="image-border31" src="../images/00169.jpeg"/></div>
<div class="cdpaligncenter1"><strong class="calibre1">Figure 25</strong>: Mathematical formula for computing performance metrics for multiclass classifiers</div>
<p class="mce-root">Where <span><em class="calibre8">δ</em></span><span>^(</span><span><em class="calibre8">x</em></span><span>)</span> is called modified delta function and that can be defined as follows (source: <a href="https://spark.apache.org/docs/2.1.0/mllib-evaluation-metrics.html" class="calibre10">https://spark.apache.org/docs/2.1.0/mllib-evaluation-metrics.html</a>):</p>
<div class="cdpaligncenter"><img class="image-border154" src="../images/00026.jpeg"/></div>


            </article>

            
        </section>
    

        <section id="B5K2U1-21aec46d8593429cacea59dbdcd64e1c">

                            <header>
                    </header><h1 class="header-title" id="calibre_pb_0">Binary classification using logistic regression</h1>
                
            
            <article>
                
<p class="mce-root">Logistic regression is widely used to predict a binary response. This is a linear method that can be written mathematically as follows:</p>
<div class="cdpaligncenter"><img class="alignnone" src="../images/00160.jpeg"/></div>
<p class="mce-root">In the preceding equation, <em class="calibre8">L(w; x, y)</em> is the loss function is called logistic loss.</p>
<p class="mce-root">For binary classification problems, the algorithm will output a binary logistic regression model. Given a new data point, denoted by <em class="calibre8">x</em>, the model makes predictions by applying the logistic function:</p>
<div class="cdpaligncenter"><br class="title-page-name"/>
<img class="alignnone1" src="../images/00233.jpeg"/></div>
<p class="cdpalignleft1">Where <em class="calibre8">z = w<sup class="calibre26">T</sup>x,</em> and by default, if <em class="calibre8">f(w<sup class="calibre26">T</sup>x)&gt;0.5</em>, the outcome is positive, or negative otherwise, though unlike linear SVMs, the raw output of the logistic regression model, <em class="calibre8">f(z)</em>, has a probabilistic interpretation (that is, the probability that <em class="calibre8">x</em> is positive).</p>
<p class="mce-root"><span><strong class="calibre1">Linear SVM</strong> is the newest extremely fast machine learning (data mining) algorithm for solving multiclass classification problems from ultralarge datasets that implements an original proprietary version of a cutting plane algorithm for designing a linear support vector machine (source:</span> <a href="http://www.linearsvm.com/" class="calibre10">www.linearsvm.com/</a> <span>).</span></p>


            </article>

            
        </section>
    

        <section id="B6IJG1-21aec46d8593429cacea59dbdcd64e1c">

                            <header>
                    </header><h1 class="header-title" id="calibre_pb_0">Breast cancer prediction using logistic regression of Spark ML</h1>
                
            
            <article>
                
<p class="mce-root">In this section, we will look at how to develop a cancer diagnosis pipeline with Spark ML. A real dataset will be used to predict the probability of breast cancer. To be more specific, Wisconsin Breast Cancer Dataset will be used.</p>


            </article>

            
        </section>
    

        <section id="B7H421-21aec46d8593429cacea59dbdcd64e1c">

                            <header>
                    </header><h1 class="header-title" id="calibre_pb_0">Dataset collection</h1>
                
            
            <article>
                
<p class="mce-root">Here, we have used simpler datasets that are structured and manually curated for machine learning application development, and, of course, many of them show good classification accuracy. The Wisconsin Breast Cancer Dataset from the UCI machine learning repository (<a href="https://archive.ics.uci.edu/ml/datasets/Breast+Cancer+Wisconsin+(Original)" class="calibre10">https://archive.ics.uci.edu/ml/datasets/Breast+Cancer+Wisconsin+(Original)</a>, contains data that was donated by researchers at the University of Wisconsin and includes measurements from digitized images of fine-needle aspirations of breast masses. The values represent characteristics of the cell nuclei present in the digital images described in the following subsection:</p>
<pre class="calibre19">
0. Sample code number id number<br class="title-page-name"/>1. Clump Thickness 1 - 10<br class="title-page-name"/>2. Uniformity of Cell Size 1 - 10<br class="title-page-name"/>3. Uniformity of Cell Shape 1 - 10<br class="title-page-name"/>4. Marginal Adhesion 1 - 10<br class="title-page-name"/>5. Single Epithelial Cell Size 1 - 10<br class="title-page-name"/>6. Bare Nuclei 1 - 10<br class="title-page-name"/>7. Bland Chromatin 1 - 10<br class="title-page-name"/>8. Normal Nucleoli 1 - 10<br class="title-page-name"/>9. Mitoses 1 - 10<br class="title-page-name"/>10. Class: (2 for benign, 4 for malignant)
</pre>
<p class="mce-root">To read more about the Wisconsin Breast Cancer Dataset, refer to the authors' publication: <em class="calibre8">Nuclear feature extraction for breast tumor diagnosis</em>, <em class="calibre8">IS&amp;T/SPIE</em> 1993 <em class="calibre8">International Symposium on Electronic Imaging: Science and Technology</em>, volume 1905, pp 861-870 by <em class="calibre8">W.N. Street</em>, <em class="calibre8">W.H. Wolberg</em>, and <em class="calibre8">O.L. Mangasarian</em>, 1993.</p>


            </article>

            
        </section>
    

        <section>

                            <header id="B8FKK2-21aec46d8593429cacea59dbdcd64e1c">
                    </header><h1 class="header-title" id="calibre_pb_0">Developing the pipeline using Spark ML</h1>
                
            
            <article>
                
<p class="mce-root">Now we will show you how to predict the possibility of breast cancer with step-by-step example:</p>
<p class="mce-root"><strong class="calibre1">Step 1: Load and parse the data</strong></p>
<pre class="calibre19">
val rdd = spark.sparkContext.textFile("data/wbcd.csv") <br class="title-page-name"/>val cancerRDD = parseRDD(rdd).map(parseCancer) 
</pre>
<p class="mce-root">The <kbd class="calibre11">parseRDD()</kbd> method goes as follows:</p>
<pre class="calibre19">
def parseRDD(rdd: RDD[String]): RDD[Array[Double]] = { <br class="title-page-name"/>  rdd.map(_.split(",")).filter(_(6) != "?").map(_.drop(1)).map(_.map(_.toDouble)) <br class="title-page-name"/>} 
</pre>
<p class="mce-root">The <kbd class="calibre11">parseCancer()</kbd> method is as follows:</p>
<pre class="calibre19">
def parseCancer(line: Array[Double]): Cancer = { <br class="title-page-name"/>  Cancer(if (line(9) == 4.0) 1 else 0, line(0), line(1), line(2), line(3), line(4), line(5), line(6), line(7), line(8)) <br class="title-page-name"/>}  
</pre>
<p class="mce-root">Note that here we have simplified the dataset. For the value 4.0, we have converted them to 1.0, and 0.0 otherwise. The <kbd class="calibre11">Cancer</kbd> class is a case class that can be defined as follows:</p>
<pre class="calibre19">
<strong class="calibre1">case </strong><strong class="calibre1">class</strong> Cancer(cancer_class: Double, thickness: Double, size: Double, shape: Double, madh: Double, epsize: Double, bnuc: Double, bchrom: Double, nNuc: Double, mit: Double)
</pre>
<p class="mce-root"><strong class="calibre1">Step 2: Convert RDD to DataFrame for the ML pipeline</strong></p>
<pre class="calibre19">
import spark.sqlContext.implicits._<br class="title-page-name"/>val cancerDF = cancerRDD.toDF().cache() <br class="title-page-name"/>cancerDF.show() 
</pre>
<p class="mce-root">The DataFrame looks like the following:</p>
<div class="cdpaligncenter"><img class="image-border155" src="../images/00334.gif"/></div>
<div class="cdpaligncenter1"><strong class="calibre1">Figure 26:</strong> A snap of the cancer dataset</div>
<p class="mce-root"><strong class="calibre1">Step 3: Feature extraction and transformation</strong></p>
<p class="mce-root">At first, let's select the feature column, as follows:</p>
<pre class="calibre19">
val featureCols = Array("thickness", "size", "shape", "madh", "epsize", "bnuc", "bchrom", "nNuc", "mit") 
</pre>
<p class="mce-root">Now let's assemble them into a feature vector, as follows:</p>
<pre class="calibre19">
val assembler = new VectorAssembler().setInputCols(featureCols).setOutputCol("features") 
</pre>
<p class="mce-root">Now transform them into a DataFrame, as follows:</p>
<pre class="calibre19">
val df2 = assembler.transform(cancerDF) 
</pre>
<p class="mce-root">Let's see the structure of the transformed DataFrame:</p>
<pre class="calibre19">
df2.show() 
</pre>
<p class="mce-root">Now you should observe a DataFrame containing the features calculated based on the columns on the left:</p>
<div class="cdpaligncenter"><img class="image-border156" src="../images/00361.gif"/></div>
<div class="cdpaligncenter1"><strong class="calibre1">Figure 27:</strong> New DataFrame containing features</div>
<p class="mce-root">Finally, let's use the <kbd class="calibre11">StringIndexer</kbd> and create the label for the training dataset, as follows:</p>
<pre class="calibre19">
val labelIndexer = new StringIndexer().setInputCol("cancer_class").setOutputCol("label")<br class="title-page-name"/>val df3 = labelIndexer.fit(df2).transform(df2)<br class="title-page-name"/>df3.show() 
</pre>
<p class="mce-root">Now you should observe a DataFrame containing the features and labels calculated based on the columns in the left:</p>
<div class="cdpaligncenter"><img class="image-border157" src="../images/00204.gif"/></div>
<div class="cdpaligncenter1"><strong class="calibre1">Figure 28:</strong> New DataFrame containing features and labels to training the ML models</div>
<p class="mce-root"><strong class="calibre1">Step 4: Create test and training set</strong></p>
<pre class="calibre19">
val splitSeed = 1234567 <br class="title-page-name"/>val Array(trainingData, testData) = df3.randomSplit(Array(0.7, 0.3), splitSeed)
</pre>
<p class="mce-root"><strong class="calibre1">Step 5: Creating an estimator using the training sets</strong></p>
<p class="mce-root">Let's create an estimator for the pipeline using the logistic regression with <kbd class="calibre11">elasticNetParam</kbd>. We also specify the max iteration and regression parameter, as follows:</p>
<pre class="calibre19">
val lr = new LogisticRegression().setMaxIter(50).setRegParam(0.01).setElasticNetParam(0.01) <br class="title-page-name"/>val model = lr.fit(trainingData)  
</pre>
<p class="mce-root"><strong class="calibre1">Step 6: Getting raw prediction, probability, and prediction for the test set</strong></p>
<p class="cdpalignleft1">Transform the model using the test set to get raw prediction, probability, and prediction for the test set:</p>
<pre class="calibre19">
val predictions = model.transform(testData) <br class="title-page-name"/>predictions.show() 
</pre>
<p class="mce-root">The resulting DataFrame is as follows:</p>
<div class="title-page-name"><img class="image-border158" src="../images/00159.gif"/></div>
<div class="cdpaligncenter1"><strong class="calibre1">Figure 29:</strong> New DataFrame with raw prediction and actual prediction against each row</div>
<p class="mce-root"><strong class="calibre1">Step 7: Generating objective history of training</strong></p>
<p class="mce-root">Let's generate the objective history of the model in each iteration, as follows:</p>
<pre class="calibre19">
val trainingSummary = model.summary <br class="title-page-name"/>val objectiveHistory = trainingSummary.objectiveHistory <br class="title-page-name"/>objectiveHistory.foreach(loss =&gt; println(loss))
</pre>
<p class="mce-root">The preceding code segment produces the following output in terms of training loss:</p>
<pre class="calibre19">
    <strong class="calibre1">0.6562291876496595</strong><br class="title-page-name"/>    <strong class="calibre1">0.6087867761081431</strong><br class="title-page-name"/>    <strong class="calibre1">0.538972588904556</strong><br class="title-page-name"/>    <strong class="calibre1">0.4928455913405332</strong><br class="title-page-name"/>    <strong class="calibre1">0.46269258074999386</strong><br class="title-page-name"/>    <strong class="calibre1">0.3527914819973198</strong><br class="title-page-name"/>    <strong class="calibre1">0.20206901337404978</strong><br class="title-page-name"/>    <strong class="calibre1">0.16459454874996993</strong><br class="title-page-name"/>    <strong class="calibre1">0.13783437051276512</strong><br class="title-page-name"/>    <strong class="calibre1">0.11478053164710095</strong><br class="title-page-name"/>    <strong class="calibre1">0.11420433621438157</strong><br class="title-page-name"/>    <strong class="calibre1">0.11138884788059378</strong><br class="title-page-name"/>    <strong class="calibre1">0.11041889032338036</strong><br class="title-page-name"/>    <strong class="calibre1">0.10849477236373875</strong><br class="title-page-name"/>    <strong class="calibre1">0.10818880537879513</strong><br class="title-page-name"/>    <strong class="calibre1">0.10682868640074723</strong><br class="title-page-name"/>    <strong class="calibre1">0.10641395229253267</strong><br class="title-page-name"/>    <strong class="calibre1">0.10555411704574749</strong><br class="title-page-name"/>    <strong class="calibre1">0.10505186414044905</strong><br class="title-page-name"/>    <strong class="calibre1">0.10470425580130915</strong><br class="title-page-name"/>    <strong class="calibre1">0.10376219754747162</strong><br class="title-page-name"/>    <strong class="calibre1">0.10331139609033112</strong><br class="title-page-name"/>    <strong class="calibre1">0.10276173290225406</strong><br class="title-page-name"/>    <strong class="calibre1">0.10245982201904923</strong><br class="title-page-name"/>    <strong class="calibre1">0.10198833366394071</strong><br class="title-page-name"/>    <strong class="calibre1">0.10168248313103552</strong><br class="title-page-name"/>    <strong class="calibre1">0.10163242551955443</strong><br class="title-page-name"/>    <strong class="calibre1">0.10162826209311404</strong><br class="title-page-name"/>    <strong class="calibre1">0.10162119367292953</strong><br class="title-page-name"/>    <strong class="calibre1">0.10161235376791203</strong><br class="title-page-name"/>    <strong class="calibre1">0.1016114803209495</strong><br class="title-page-name"/>    <strong class="calibre1">0.10161090505556039</strong><br class="title-page-name"/>    <strong class="calibre1">0.1016107261254795</strong><br class="title-page-name"/>    <strong class="calibre1">0.10161056082112738</strong><br class="title-page-name"/>    <strong class="calibre1">0.10161050381332608</strong><br class="title-page-name"/>    <strong class="calibre1">0.10161048515341387</strong><br class="title-page-name"/>    <strong class="calibre1">0.10161043900301985</strong><br class="title-page-name"/>    <strong class="calibre1">0.10161042057436288</strong><br class="title-page-name"/>    <strong class="calibre1">0.10161040971267737</strong><br class="title-page-name"/>    <strong class="calibre1">0.10161040846923354</strong><br class="title-page-name"/>    <strong class="calibre1">0.10161040625542347</strong><br class="title-page-name"/>    <strong class="calibre1">0.10161040595207525</strong><br class="title-page-name"/>    <strong class="calibre1">0.10161040575664354</strong><br class="title-page-name"/>    <strong class="calibre1">0.10161040565870835</strong><br class="title-page-name"/>    <strong class="calibre1">0.10161040519559975</strong><br class="title-page-name"/>    <strong class="calibre1">0.10161040489834573</strong><br class="title-page-name"/>    <strong class="calibre1">0.10161040445215266</strong><br class="title-page-name"/>    <strong class="calibre1">0.1016104043469577</strong><br class="title-page-name"/>    <strong class="calibre1">0.1016104042793553</strong><br class="title-page-name"/>    <strong class="calibre1">0.1016104042606048</strong><br class="title-page-name"/>    <strong class="calibre1">0.10161040423579716 </strong>
</pre>
<p class="mce-root">As you can see, the loss gradually reduces in later iterations.</p>
<p class="mce-root"><strong class="calibre1">Step 8: Evaluating the model</strong></p>
<p class="mce-root">First, we will have to make sure that the classifier that we used comes from the binary logistic regression summary:</p>
<pre class="calibre19">
<strong class="calibre1">val</strong> binarySummary = trainingSummary.asInstanceOf[BinaryLogisticRegressionSummary]
</pre>
<p class="mce-root">Now let's <span>obtain the ROC as a</span> <kbd class="calibre11">DataFrame</kbd> <span>and</span> <kbd class="calibre11">areaUnderROC</kbd><span>. A value approximate to 1.0 is better:</span></p>
<pre class="calibre19">
val roc = binarySummary.roc <br class="title-page-name"/>roc.show() <br class="title-page-name"/>println("Area Under ROC: " + binarySummary.areaUnderROC)
</pre>
<p class="mce-root">The preceding lines prints the value of <kbd class="calibre11">areaUnderROC</kbd>, as follows:</p>
<pre class="calibre19">
<strong class="calibre1">Area Under ROC: 0.9959095884623509</strong>
</pre>
<p class="mce-root">This is excellent! Now let's compute other metrics, such as true positive rate, false positive rate, false negative rate, and total count, and a number of instances correctly and wrongly predicted, as follows:</p>
<pre class="calibre19">
import org.apache.spark.sql.functions._<br class="title-page-name"/><br class="title-page-name"/>// Calculate the performance metrics<br class="title-page-name"/>val lp = predictions.select("label", "prediction") <br class="title-page-name"/>val counttotal = predictions.count() <br class="title-page-name"/>val correct = lp.filter($"label" === $"prediction").count() <br class="title-page-name"/>val wrong = lp.filter(not($"label" === $"prediction")).count() <br class="title-page-name"/>val truep = lp.filter($"prediction" === 0.0).filter($"label" === $"prediction").count() <br class="title-page-name"/>val falseN = lp.filter($"prediction" === 0.0).filter(not($"label" === $"prediction")).count() <br class="title-page-name"/>val falseP = lp.filter($"prediction" === 1.0).filter(not($"label" === $"prediction")).count() <br class="title-page-name"/>val ratioWrong = wrong.toDouble / counttotal.toDouble <br class="title-page-name"/>val ratioCorrect = correct.toDouble / counttotal.toDouble <br class="title-page-name"/> <br class="title-page-name"/>println("Total Count: " + counttotal) <br class="title-page-name"/>println("Correctly Predicted: " + correct) <br class="title-page-name"/>println("Wrongly Identified: " + wrong) <br class="title-page-name"/>println("True Positive: " + truep) <br class="title-page-name"/>println("False Negative: " + falseN) <br class="title-page-name"/>println("False Positive: " + falseP) <br class="title-page-name"/>println("ratioWrong: " + ratioWrong) <br class="title-page-name"/>println("ratioCorrect: " + ratioCorrect) 
</pre>
<p class="mce-root">Now you should observe an output from the preceding code as follows:</p>
<p class="mce-root"><strong class="calibre1">Total Count: 209<br class="title-page-name"/></strong> <strong class="calibre1">Correctly Predicted: 202<br class="title-page-name"/></strong> <strong class="calibre1">Wrongly Identified: 7<br class="title-page-name"/></strong> <strong class="calibre1">True Positive: 140<br class="title-page-name"/></strong> <strong class="calibre1">False Negative: 4<br class="title-page-name"/></strong> <strong class="calibre1">False Positive: 3<br class="title-page-name"/></strong> <strong class="calibre1">ratioWrong: 0.03349282296650718<br class="title-page-name"/></strong> <strong class="calibre1">ratioCorrect: 0.9665071770334929</strong></p>
<p class="mce-root">Finally, let's judge the accuracy of the model. However, first, we need to set the model threshold to maximize <kbd class="calibre11">fMeasure</kbd>:</p>
<pre class="calibre19">
val fMeasure = binarySummary.fMeasureByThreshold <br class="title-page-name"/>val fm = fMeasure.col("F-Measure") <br class="title-page-name"/>val maxFMeasure = fMeasure.select(max("F-Measure")).head().getDouble(0) <br class="title-page-name"/>val bestThreshold = fMeasure.where($"F-Measure" === maxFMeasure).select("threshold").head().getDouble(0) <br class="title-page-name"/>model.setThreshold(bestThreshold) 
</pre>
<p class="mce-root">Now let's compute the accuracy, as follows:</p>
<pre class="calibre19">
val evaluator = new BinaryClassificationEvaluator().setLabelCol("label") <br class="title-page-name"/>val accuracy = evaluator.evaluate(predictions) <br class="title-page-name"/>println("Accuracy: " + accuracy)     
</pre>
<p class="mce-root">The preceding code produces the following output, which is almost 99.64%:</p>
<pre class="calibre19">
<strong class="calibre1">Accuracy: 0.9963975418520874</strong>
</pre>


            </article>

            
        </section>
    

        <section id="B9E561-21aec46d8593429cacea59dbdcd64e1c">

                            <header>
                    </header><h1 class="header-title" id="calibre_pb_0">Multiclass classification using logistic regression</h1>
                
            
            <article>
                
<p class="mce-root">A binary logistic regression can be generalized into multinomial logistic regression to train and predict multiclass classification problems. For example, for <em class="calibre8">K</em> possible outcomes, one of the outcomes can be chosen as a pivot, and the other <em class="calibre8">K−1</em> outcomes can be separately regressed against the pivot outcome. In <kbd class="calibre11">spark.mllib</kbd>, the first class 0 is chosen as the <kbd class="calibre11">pivot</kbd> class.</p>
<p class="mce-root">For multiclass classification problems, the algorithm will output a multinomial logistic regression model, which contains <em class="calibre8">k−1binary</em> logistic regression models regressed against the first class. Given a new data point, <em class="calibre8">k−1models</em> will be run, and the class with the largest probability will be chosen as the predicted class. In this section, we will show you an example of a classification using the logistic regression with L-BFGS for faster convergence.</p>
<p class="mce-root"><strong class="calibre1">Step 1. Load and parse the MNIST dataset in LIVSVM format</strong></p>
<pre class="calibre19">
// Load training data in LIBSVM format.<br class="title-page-name"/> val data = MLUtils.loadLibSVMFile(spark.sparkContext, "data/mnist.bz2")
</pre>
<p class="mce-root"><strong class="calibre1">Step 2. Prepare the training and test sets</strong></p>
<p class="mce-root">Split data into training (75%) and test (25%), as follows:</p>
<pre class="calibre19">
val splits = data.randomSplit(Array(0.75, 0.25), seed = 12345L)<br class="title-page-name"/>val training = splits(0).cache()<br class="title-page-name"/>val test = splits(1)
</pre>
<p class="mce-root"><strong class="calibre1">Step 3. Run the training algorithm to build the model</strong></p>
<p class="mce-root">Run the training algorithm to build the model by setting a number of classes (10 for this dataset). For better classification accuracy, you can also specify intercept and validate the dataset using the Boolean true value, as follows:</p>
<pre class="calibre19">
val model = new LogisticRegressionWithLBFGS()<br class="title-page-name"/>           .setNumClasses(10)<br class="title-page-name"/>           .setIntercept(true)<br class="title-page-name"/>           .setValidateData(true)<br class="title-page-name"/>           .run(training)
</pre>
<p class="mce-root">Set intercept as true if the algorithm should add an intercept using <kbd class="calibre11">setIntercept()</kbd>. If you want the algorithm to validate the training set before the model building itself, you should set the value as true using the <kbd class="calibre11">setValidateData()</kbd> method.</p>
<p class="mce-root"><strong class="calibre1">Step 4. Clear the default threshold</strong></p>
<p class="mce-root">Clear the default threshold so that the training does not occur with the default setting, as follows:</p>
<pre class="calibre19">
model.clearThreshold()
</pre>
<p class="mce-root"><strong class="calibre1">Step 5. Compute raw scores on the test set</strong></p>
<p class="mce-root">Compute raw scores on the test set so that we can evaluate the model using the aforementioned performance metrics, as follows:</p>
<pre class="calibre19">
val scoreAndLabels = test.map { point =&gt;<br class="title-page-name"/>  val score = model.predict(point.features)<br class="title-page-name"/>  (score, point.label)<br class="title-page-name"/>}
</pre>
<p class="mce-root"><strong class="calibre1">Step 6. Instantiate a multiclass metrics for the evaluation</strong></p>
<pre class="calibre19">
val metrics = new MulticlassMetrics(scoreAndLabels)
</pre>
<p class="mce-root"><strong class="calibre1">Step 7. Constructing the confusion matrix</strong></p>
<pre class="calibre19">
println("Confusion matrix:")<br class="title-page-name"/>println(metrics.confusionMatrix)
</pre>
<p class="mce-root">In a confusion matrix, each column of the matrix represents the instances in a predicted class, while each row represents the instances in an actual class (or vice versa). The name stems from the fact that it makes it easy to see if the system is confusing two classes. For more, refer to matrix (<a href="https://en.wikipedia.org/wiki/Confusion_matrix.Confusion" class="calibre10">https://en.wikipedia.org/wiki/Confusion_matrix.Confusion</a>):</p>
<div class="cdpaligncenter"><img class="image-border159" src="../images/00065.gif"/></div>
<div class="cdpaligncenter1"><strong class="calibre1">Figure 30:</strong> Confusion matrix generated by the logistic regression classifier</div>
<p class="mce-root"><strong class="calibre1">Step 8. Overall statistics</strong></p>
<p class="mce-root">Now let's compute the overall statistics to judge the performance of the model:</p>
<pre class="calibre19">
val accuracy = metrics.accuracy<br class="title-page-name"/>println("Summary Statistics")<br class="title-page-name"/>println(s"Accuracy = $accuracy")<br class="title-page-name"/>// Precision by label<br class="title-page-name"/>val labels = metrics.labels<br class="title-page-name"/>labels.foreach { l =&gt;<br class="title-page-name"/>  println(s"Precision($l) = " + metrics.precision(l))<br class="title-page-name"/>}<br class="title-page-name"/>// Recall by label<br class="title-page-name"/>labels.foreach { l =&gt;<br class="title-page-name"/>  println(s"Recall($l) = " + metrics.recall(l))<br class="title-page-name"/>}<br class="title-page-name"/>// False positive rate by label<br class="title-page-name"/>labels.foreach { l =&gt;<br class="title-page-name"/>  println(s"FPR($l) = " + metrics.falsePositiveRate(l))<br class="title-page-name"/>}<br class="title-page-name"/>// F-measure by label<br class="title-page-name"/>labels.foreach { l =&gt;<br class="title-page-name"/>  println(s"F1-Score($l) = " + metrics.fMeasure(l))<br class="title-page-name"/>}
</pre>
<p class="mce-root">The preceding code segment produces the following output, containing some performance metrics, such as accuracy, precision, recall, true positive rate , false positive rate, and f1 score:</p>
<pre class="calibre19">
<strong class="calibre1">Summary Statistics<br class="title-page-name"/> ----------------------<br class="title-page-name"/> Accuracy = 0.9203609775377116<br class="title-page-name"/> Precision(0.0) = 0.9606815203145478<br class="title-page-name"/> Precision(1.0) = 0.9595732734418866<br class="title-page-name"/> .<br class="title-page-name"/> .<br class="title-page-name"/> Precision(8.0) = 0.8942172073342737<br class="title-page-name"/> Precision(9.0) = 0.9027210884353741<br class="title-page-name"/> <br class="title-page-name"/> Recall(0.0) = 0.9638395792241946<br class="title-page-name"/> Recall(1.0) = 0.9732346241457859<br class="title-page-name"/> .<br class="title-page-name"/> .<br class="title-page-name"/> Recall(8.0) = 0.8720770288858322<br class="title-page-name"/> Recall(9.0) = 0.8936026936026936<br class="title-page-name"/> <br class="title-page-name"/> FPR(0.0) = 0.004392386530014641<br class="title-page-name"/> FPR(1.0) = 0.005363128491620112<br class="title-page-name"/> .<br class="title-page-name"/> .<br class="title-page-name"/> FPR(8.0) = 0.010927369417935456<br class="title-page-name"/> FPR(9.0) = 0.010441004672897197</strong><br class="title-page-name"/> <strong class="calibre1"><br class="title-page-name"/> F1-Score(0.0) = 0.9622579586478502<br class="title-page-name"/> F1-Score(1.0) = 0.966355668645745<br class="title-page-name"/> .<br class="title-page-name"/> .<br class="title-page-name"/> F1-Score(9.0) = 0.8981387478849409</strong>
</pre>
<p class="mce-root"><span>Now let's compute the overall, that is, summary statistics:</span></p>
<pre class="calibre19">
<span>println(s"Weighted precision: ${metrics.weightedPrecision}")<br class="title-page-name"/>println(s"Weighted recall: ${metrics.weightedRecall}")<br class="title-page-name"/>println(s"Weighted F1 score: ${metrics.weightedFMeasure}")<br class="title-page-name"/>println(s"Weighted false positive rate: ${metrics.weightedFalsePositiveRate}")</span> 
</pre>
<p class="mce-root"><span>The preceding code segment prints the following output containing weighted precision, recall, f1 score, and false positive rate:</span></p>
<pre class="calibre19">
<strong class="calibre1">Weighted precision: 0.920104303076327<br class="title-page-name"/> Weighted recall: 0.9203609775377117<br class="title-page-name"/> Weighted F1 score: 0.9201934861645358<br class="title-page-name"/> Weighted false positive rate: 0.008752250453215607</strong>
</pre>
<p class="mce-root">The overall statistics say that the accuracy of the model is more than 92%. However, we can still improve it using a better algorithm such as <strong class="calibre1">random forest</strong> (<strong class="calibre1">RF</strong>). In the next section, we will look at the random forest implementation to classify the same model.</p>


            </article>

            
        </section>
    

        <section id="BACLO1-21aec46d8593429cacea59dbdcd64e1c">

                            <header>
                    </header><h1 class="header-title" id="calibre_pb_0">Improving classification accuracy using random forests</h1>
                
            
            <article>
                
<p class="mce-root">Random forests (also sometimes called random decision forests) are ensembles of decision trees. Random forests are one of the most successful machine learning models for classification and regression. They combine many decision trees in order to reduce the risk of overfitting. Like decision trees, random forests handle categorical features, extend to the multiclass classification setting, do not require feature scaling, and are able to capture nonlinearities and feature interactions. There are numerous advantageous RFs. They can overcome the overfitting problem across their training dataset by combining many decision trees.</p>
<p class="mce-root">A forest in the RF or RDF usually consists of hundreds of thousands of trees. These trees are actually trained on different parts of the same training set. More technically, an individual tree that has grown very deep tends to learn from highly unpredictable patterns. This kind of nature of the trees creates overfitting problems on the training sets. Moreover, low biases make the classifier a low performer even if your dataset quality is good in terms of features presented. On the other hand, an RF helps to average multiple decision trees together with the goal of reducing the variance to ensure consistency by computing proximities between pairs of cases.</p>
<p class="mce-root">However, this increases a small bias or some loss of the interpretability of the results. But, eventually, the performance of the final model is increased dramatically. While using the RF as a classifier, here goes the parameter setting:</p>
<ul class="calibre9">
<li class="mce-root1">If the number of trees is 1, then no bootstrapping is used at all; however, if the number of trees is <em class="calibre8">&gt; 1</em>, then bootstrapping is accomplished. The supported values are <kbd class="calibre11">auto</kbd>, <kbd class="calibre11">all</kbd>, <kbd class="calibre11">sqrt</kbd>, <kbd class="calibre11">log2</kbd>, and <kbd class="calibre11">onethird</kbd>.</li>
<li class="mce-root1">The supported numerical values are <em class="calibre8">(0.0-1.0]</em> and <em class="calibre8">[1-n]</em>. However, if <kbd class="calibre11">featureSubsetStrategy</kbd> is chosen as <kbd class="calibre11">auto</kbd>, the algorithm chooses the best feature subset strategy automatically.</li>
<li class="mce-root1">If <kbd class="calibre11">numTrees == 1</kbd>, the <kbd class="calibre11">featureSubsetStrategy</kbd> is set to be <kbd class="calibre11">all</kbd>. However, if <kbd class="calibre11">numTrees &gt; 1</kbd> (that is, forest), <kbd class="calibre11">featureSubsetStrategy</kbd> is set to be <kbd class="calibre11">sqrt</kbd> for classification.</li>
<li class="mce-root1">Moreover, if a real value <em class="calibre8">n</em> is set in the range of <em class="calibre8">(0, 1.0]</em>, <kbd class="calibre11">n*number_of_features</kbd> will be used. However, if an integer value say <em class="calibre8">n</em> is in the <kbd class="calibre11">range (1, the number of features)</kbd>, only <kbd class="calibre11">n</kbd> features are used alternatively.</li>
<li class="mce-root1">The <kbd class="calibre11">categoricalFeaturesInfo</kbd> parameter , which is a map, is used for storing arbitrary categorical features. An entry <em class="calibre8">(n -&gt; k)</em> indicates that feature <em class="calibre8">n</em> is categorical with <em class="calibre8">k</em> categories indexed from <em class="calibre8">0: {0, 1,...,k-1}.</em></li>
<li class="mce-root1">The impurity criterion is used only for the information gain calculation. The supported values are <em class="calibre8">gini</em> and <em class="calibre8">variance</em> for classification and regression, respectively.</li>
<li class="mce-root1">The <kbd class="calibre11">maxDepth</kbd> is the maximum depth of the tree (for example, depth 0 means 1 leaf node, depth 1 means 1 internal node <em class="calibre8">+ 2</em> leaf nodes, and so on).</li>
<li class="mce-root1">The <kbd class="calibre11">maxBins</kbd> signifies the maximum number of bins used for splitting the features, where the suggested value is 100 to get better results.</li>
<li class="mce-root1">Finally, the random seed is used for bootstrapping and choosing feature subsets to avoid the random nature of the results.</li>
</ul>
<p class="mce-root">As already mentioned, since RF is fast and scalable enough for the large-scale dataset, Spark is a suitable technology to implement the RF to take the massive scalability. However, if the proximities are calculated, storage requirements also grow exponentially.</p>


            </article>

            
        </section>
    

        <section id="BBB6A1-21aec46d8593429cacea59dbdcd64e1c">

                            <header>
                    </header><h1 class="header-title" id="calibre_pb_0">Classifying MNIST dataset using random forest</h1>
                
            
            <article>
                
<p class="mce-root">In this section, we will show an example of a classification using the random forest. We will break down the code step-by-step so that you can understand the solution easily.</p>
<p class="mce-root"><strong class="calibre1">Step 1. Load and parse the MNIST dataset in LIVSVM format</strong></p>
<pre class="calibre19">
// Load training data in LIBSVM format.<br class="title-page-name"/> val data = MLUtils.loadLibSVMFile(spark.sparkContext, "data/mnist.bz2")
</pre>
<p class="mce-root"><strong class="calibre1">Step 2. Prepare the training and test sets</strong></p>
<p class="mce-root">Split data into training (75%) and test (25%) and also set the seed for the reproducibility, as follows:</p>
<pre class="calibre19">
val splits = data.randomSplit(Array(0.75, 0.25), seed = 12345L)<br class="title-page-name"/>val training = splits(0).cache()<br class="title-page-name"/>val test = splits(1)
</pre>
<p class="mce-root"><strong class="calibre1">Step 3. Run the training algorithm to build the model</strong></p>
<p class="mce-root">Train a random forest model with an empty <kbd class="calibre11">categoricalFeaturesInfo. This required</kbd> since all the features are continuous in the dataset:</p>
<pre class="calibre19">
val numClasses = 10 //number of classes in the MNIST dataset<br class="title-page-name"/>val categoricalFeaturesInfo = Map[Int, Int]()<br class="title-page-name"/>val numTrees = 50 // Use more in practice.More is better<br class="title-page-name"/>val featureSubsetStrategy = "auto" // Let the algorithm choose.<br class="title-page-name"/>val impurity = "gini" // see above notes on RandomForest for explanation<br class="title-page-name"/>val maxDepth = 30 // More is better in practice<br class="title-page-name"/>val maxBins = 32 // More is better in practice <br class="title-page-name"/>val model = RandomForest.trainClassifier(training, numClasses, categoricalFeaturesInfo, numTrees, featureSubsetStrategy, impurity, maxDepth, maxBins)
</pre>
<p class="mce-root">Note that training a random forest model is very resource extensive. Consequently, it will take more memory, so beware of OOM. I would say increase the Java heap space prior to running this code.</p>
<p class="mce-root"><strong class="calibre1">Step 4. Compute raw scores on the test set</strong></p>
<p class="mce-root">Compute raw scores on the test set so that we can evaluate the model using the aforementioned performance metrics, as follows:</p>
<pre class="calibre19">
val scoreAndLabels = test.map { point =&gt;<br class="title-page-name"/>  val score = model.predict(point.features)<br class="title-page-name"/>  (score, point.label)<br class="title-page-name"/>}
</pre>
<p class="mce-root"><strong class="calibre1">Step 5. Instantiate a multiclass metrics for the evaluation</strong></p>
<pre class="calibre19">
val metrics = new MulticlassMetrics(scoreAndLabels)
</pre>
<p class="mce-root"><strong class="calibre1">Step 6. Constructing the confusion matrix</strong></p>
<pre class="calibre19">
println("Confusion matrix:")<br class="title-page-name"/>println(metrics.confusionMatrix)
</pre>
<p class="mce-root">The preceding code prints the following confusion matrix for our classification:</p>
<div class="cdpaligncenter"><img class="image-border160" src="../images/00122.gif"/></div>
<div class="cdpaligncenter1"><strong class="calibre1">Figure 31:</strong> Confusion matrix generated by the random forest classifier</div>
<p class="mce-root"><strong class="calibre1">Step 7. Overall statistics</strong></p>
<p class="mce-root">Now let's compute the overall statistics to judge the performance of the model:</p>
<pre class="calibre19">
val accuracy = metrics.accuracy<br class="title-page-name"/>println("Summary Statistics")<br class="title-page-name"/>println(s"Accuracy = $accuracy")<br class="title-page-name"/>// Precision by label<br class="title-page-name"/>val labels = metrics.labels<br class="title-page-name"/>labels.foreach { l =&gt;<br class="title-page-name"/>  println(s"Precision($l) = " + metrics.precision(l))<br class="title-page-name"/>}<br class="title-page-name"/>// Recall by label<br class="title-page-name"/>labels.foreach { l =&gt;<br class="title-page-name"/>  println(s"Recall($l) = " + metrics.recall(l))<br class="title-page-name"/>}<br class="title-page-name"/>// False positive rate by label<br class="title-page-name"/>labels.foreach { l =&gt;<br class="title-page-name"/>  println(s"FPR($l) = " + metrics.falsePositiveRate(l))<br class="title-page-name"/>}<br class="title-page-name"/>// F-measure by label<br class="title-page-name"/>labels.foreach { l =&gt;<br class="title-page-name"/>  println(s"F1-Score($l) = " + metrics.fMeasure(l))<br class="title-page-name"/>} 
</pre>
<p class="mce-root">The preceding code segment produces the following output, containing some performance metrics, such as accuracy, precision, recall, true positive rate , false positive rate, and F1 score:</p>
<pre class="calibre19">
<strong class="calibre1">Summary Statistics:<br class="title-page-name"/> ------------------------------<br class="title-page-name"/> Precision(0.0) = 0.9861932938856016<br class="title-page-name"/> Precision(1.0) = 0.9891799544419134<br class="title-page-name"/> .<br class="title-page-name"/> .<br class="title-page-name"/> Precision(8.0) = 0.9546079779917469<br class="title-page-name"/> Precision(9.0) = 0.9474747474747475<br class="title-page-name"/> <br class="title-page-name"/> Recall(0.0) = 0.9778357235984355<br class="title-page-name"/> Recall(1.0) = 0.9897435897435898<br class="title-page-name"/> .<br class="title-page-name"/> .<br class="title-page-name"/> Recall(8.0) = 0.9442176870748299<br class="title-page-name"/> Recall(9.0) = 0.9449294828744124<br class="title-page-name"/> <br class="title-page-name"/> FPR(0.0) = 0.0015387997362057595<br class="title-page-name"/> FPR(1.0) = 0.0014151646059883808<br class="title-page-name"/> .<br class="title-page-name"/> .<br class="title-page-name"/> FPR(8.0) = 0.0048136532710962<br class="title-page-name"/> FPR(9.0) = 0.0056967572304995615<br class="title-page-name"/> <br class="title-page-name"/> F1-Score(0.0) = 0.9819967266775778<br class="title-page-name"/> F1-Score(1.0) = 0.9894616918256907<br class="title-page-name"/> .<br class="title-page-name"/> .<br class="title-page-name"/> F1-Score(8.0) = 0.9493844049247605<br class="title-page-name"/> F1-Score(9.0) = 0.9462004034969739</strong>
</pre>
<p class="mce-root">Now let's compute the overall statistics, as follows:</p>
<pre class="calibre19">
println(s"Weighted precision: ${metrics.weightedPrecision}")<br class="title-page-name"/>println(s"Weighted recall: ${metrics.weightedRecall}")<br class="title-page-name"/>println(s"Weighted F1 score: ${metrics.weightedFMeasure}")<br class="title-page-name"/>println(s"Weighted false positive rate: ${metrics.weightedFalsePositiveRate}")<br class="title-page-name"/>val testErr = labelAndPreds.filter(r =&gt; r._1 != r._2).count.toDouble / test.count()<br class="title-page-name"/>println("Accuracy = " + (1-testErr) * 100 + " %")
</pre>
<p class="mce-root"><span>The preceding code segment prints the following output, containing weighted precision, recall, F1 score, and false positive rate:</span></p>
<pre class="calibre19">
<strong class="calibre1">Overall statistics</strong><br class="title-page-name"/><strong class="calibre1"> ----------------------------</strong><br class="title-page-name"/><strong class="calibre1"> Weighted precision: 0.966513107682512</strong><br class="title-page-name"/><strong class="calibre1"> Weighted recall: 0.9664712469534286</strong><br class="title-page-name"/><strong class="calibre1"> Weighted F1 score: 0.9664794711607312</strong><br class="title-page-name"/><strong class="calibre1"> Weighted false positive rate: 0.003675328222679072</strong><br class="title-page-name"/><strong class="calibre1"> Accuracy = 96.64712469534287 %</strong>
</pre>
<p class="mce-root">The overall statistics say that the accuracy of the model is more than 96%, which is better than that of logistic regression. However, we can still improve it using better model tuning.</p>


            </article>

            
        </section>
    

        <section id="BC9MS1-21aec46d8593429cacea59dbdcd64e1c">

                            <header>
                    </header><h1 class="header-title" id="calibre_pb_0">Summary</h1>
                
            
            <article>
                
<p class="mce-root">In this chapter, we had a brief introduction to the topic and got a grasp of simple, yet powerful and common ML techniques. Finally, you saw how to build your own predictive model using Spark. You learned how to build a classification model, how to use the model to make predictions, and finally, how to use common ML techniques such as dimensionality reduction and One-Hot Encoding.</p>
<p class="mce-root">In the later sections, you saw how to apply the regression technique to high-dimensional datasets. Then, you saw how to apply a binary and multiclass classification algorithm for predictive analytics. Finally, you saw how to achieve outstanding classification accuracy using a random forest algorithm. However, we have other topics in machine learning that need to be covered too, for example, recommendation systems and model tuning for even more stable performance before you finally deploy the models.</p>
<p class="mce-root">In the next chapter, we will cover some advanced topics of Spark. We will provide examples of machine learning model tuning for better performance, and we will also cover two examples for movie recommendation and text clustering, respectively.</p>


            </article>

            
        </section>
    </body></html>