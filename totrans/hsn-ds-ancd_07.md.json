["```py\nx<-seq(-10,10,0.1) \na<-4 \nb<- -2 \nc<-10 \ny<-a*x^2+b*x+c \nplot(x,y,type='l') \n```", "```py\nx<-seq(-4,4,0.1) \na<-1 \nb<-2 \nc<-3 \nmyFunction<-function(x)a*x^2+b*x+c \ny<-myFunction(x) \nname<-\"For a convex function:chord is above\" \nplot(x,y,type='l',main=name) \nx1<--2 \ny1<-myFunction(x1) \nx2<-3 \ny2<-myFunction(x2) \nsegments(x1, y1, x2, y2,col = par(\"fg\"), lty = par(\"lty\"), xpd = FALSE) \n```", "```py\nlibrary(scatterplot3d) \nx<-seq(-2,2,0.05) \ny<-seq(-2,2,0.05) \nz<-(x^2-1)^2+(x^2*y-x-1)^2 \nname<-\"3 dimensional graph\"  \nscatterplot3d(x, y, z, highlight.3d = TRUE, col.axis = \"blue\", \ncol.grid = \"lightblue\", main =name, pch = 2) \n```", "```py\nx<-seq(-10,10,0.1) \na<--2 \nb<-10 \nc<-5 \ny<-a*x^2+b*x+c \nplot(x,y,type='l') \n```", "```py\ny<-20-3.5*x^2 \na<--2 \nb<-10 \nc<-5 \nf<-function(x)-(a*x^2+b*x+c) \n```", "```py\n> optim(0.3,f) \n$par \n[1] 2.500078 \n$value \n[1] -17.5 \n$counts \nfunction gradient  \n      36       NA  \n$convergence \n[1] 0 \n\n$message \nNULL \n```", "```py\npath<-\"http://canisius.edu/~yany/RData/ff5industries.RData\" \nload(url(path)) \nhead(.ff5industries,3)  \n```", "```py\nretMatrix<-as.matrix(.ff5industries[,2:6]/100)\nn1<-ncol(retMatrix)\nw<-rep(1/n1,n1)\nA<-1.5\nbigValue=100\n#\nutilityFunction<-function(w){\n    portfolioRet<-retMatrix%*%w\n    x<-portfolioRet\n    loss<-(sum(w)-1)^2*bigValue\n    u=-(mean(x)-0.5*A*var(x))+loss\n    return(u)\n}\n```", "```py\n>optim(w,utilityFunction)\n$par\n[1] 1.0274904 -0.1901590 0.1474859 0.8867341 -0.8715205\n$value\n[1] -0.009195987\n$counts\nfunction gradient \n 502 NA \n$convergence\n[1] 1\n$message\nNULL\n```", "```py\n>optim(w,utilityFunction,lower=-0.1,upper=0.5,method=\"L-BFGS-B\")\n$par\n[1] 0.50000000 0.01584360 0.08418691 0.50000000 -0.10000000\n$value\n[1] -0.008587635\n$counts\nfunction gradient \n 21 21 \n$convergence\n[1] 0\n$message\n[1] \"CONVERGENCE: REL_REDUCTION_OF_F <= FACTR*EPSMCH\"\n```", "```py\noptim(par, fn, gr = NULL, ...,\n      method = c(\"Nelder-Mead\", \"BFGS\", \"CG\", \"L-BFGS-B\", \"SANN\",\n                 \"Brent\"),\n      lower = -Inf, upper = Inf,\n      control = list(), hessian = FALSE)\n```", "```py\nimport scipy.optimize as sp\nx=dir(sp.optimize)\nprint(x)\n```", "```py\nfrom scipy.optimize import minimize \nhelp(minimize) \n```", "```py\nimport numpy as np \nfrom scipy.optimize import minimize \ndef rosen(x): \n    return sum(100.0*(x[1:]-x[:-1]**2.0)**2.0 + (1-x[:-1])**2.0) \n# \nx0 = np.array([1.3, 0.7, 0.8, 1.9, 1.2]) \nsolution= minimize(rosen, x0, method='nelder-mead',options={'xtol': 1e-8, 'disp': True}) \nprint(solution.x) \n```", "```py\nusing JuMP \nusing ECOS \nm= Model(solver =ECOSSolver()) \n@variable(m, 0 <= x <= 2 ) \n@variable(m, 0 <= y <= 30 ) \n@setObjective(m, Max, 5x + 3*y ) \n@addConstraint(m, 1x + 5y <= 3.0 ) \nprint(m) \nstatus = solve(m) \nprintln(\"Objective value: \", getObjectiveValue(m)) \nprintln(\"x = \", getValue(x)) \nprintln(\"y = \", getValue(y)) \n```", "```py\nusing Optim \nf(x) = (1.0 - x[1])^2 + 200.0 * (x[2] - x[1]^2)^2 \noptimize(f, [0.0, 0.0]) \n```", "```py\nusing Optim \nfunction g!(s, x) \n s[1] = -2.0*(1.0-x[1])-400.0*(x[2]-x[1]^2)*x[1] \n s[2] = 200.0*(x[2]-x[1]^2) \nend \nlower = [1.25, -2.1] \nupper = [Inf, Inf] \ninitial_x = [2.0, 2.0] \nod = OnceDifferentiable(f, g!, initial_x) \nresults = optimize(od, initial_x,lower,upper,Fminbox{GradientDescent}()) \n```", "```py\npkg load optim \npkg describe -verbose optim \n```", "```py\nhelp fminsearch\n```", "```py\n>> fun = @(x)50*(x(1)^2-x(2))^2 + (x(1)-3)^2;\n>> x0 = [0,0];\n>> x = fminsearch(fun,x0)\nx \n 3.0000 9.0000\n```", "```py\nOPTIONS = optimset('Display','iter');\nfunction f = fun2(x)\n   f = 0;\n   for k = -5:5\n      f = f + exp(-(x(1)-x(2))^2 - 2*x(1)^2)*cos(x(2))*sin(2*x(2));\n   end\nendfunction \nx0 = [0.5,-0.5];\n[x,fval] = fminsearch(@fun2,x0,OPTIONS)\n```", "```py\ninstall.packages(\"fPortfolio\") \n```", "```py\nlibrary(fPortfolio)\ndata(GCCINDEX.RET)\ndim(GCCINDEX.RET)\n [1] 824  11 \n```", "```py\nlibrary(fPortfolio) \ndata(GCCINDEX.RET) \nretMatrix<-GCCINDEX.RET \nfrontier=portfolioFrontier(as.timeSeries(retMatrix)) \nfrontierPlot(frontier) \ngrid() \n```", "```py\nimport numpy as np \nfrom numpy import array \nbeta= 1 / 1.05 \nrho, mg = .7, .35 \nA = np.identity(2) \nA[0, :] = rho, mg * (1-rho) \nC = np.zeros((2, 1)) \nC[0,0] = np.sqrt(1 - rho**2) * mg / 10\\. \nSg = array((1, 0)).reshape(1, 2) \nSd = array((0, 0)).reshape(1, 2) \nSb = array((0, 2.135)).reshape(1, 2) \nSs = array((0, 0)).reshape(1, 2) \neconomy=Economy(beta=beta,Sg=Sg,Sd=Sd,Sb=Sb,Ss=Ss,discrete=False,proc=(A, C)) \nT = 50 \npath = compute_paths(T, economy) \ngen_fig_1(path) \n```", "```py\ninstall.packages(\"ctv\") \nlibrary(\"ctv\") \ninstall.views(\"Optimization\") \n```", "```py\n> f<-function(x)-2*x^2+3*x+1 \n> optim(13,f) \n$par \n[1] 2.352027e+75 \n$value \n[1] -1.106406e+151 \n$counts \nfunction gradient  \n     502       NA  \n$convergence \n[1] 1 \n$message \nNULL\n```", "```py\n>> pkg describe -verbose optim \n>> help leasqr \n```", "```py\n>install.packages(\"ctv\") \n>library(\"ctv\") \n>install.views(\"Optimization\") \n```"]