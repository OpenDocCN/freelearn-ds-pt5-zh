<html><head></head><body>
        

                            
                    <h1 class="header-title">Data Science and Marketing</h1>
                
            
            
                
<p class="mce-root">Welcome to the first chapter of <em>Hands-On Data Science for Marketing</em>! As you may be familiar already, the importance and application of data science in the marketing industry have been rising significantly over the past few years. Yet, marketing data science is a relatively new field and the amount of resources available for education and references lags behind the momentum. However, the amount of data gathered and available to the process has been growing exponentially each year, which opens up even more opportunities to learn and bring insight from the data.</p>
<p class="mce-root">With the growing amount of data and applications of data science in marketing, we can easily find examples of the usage of data science to marketing efforts. Companies are starting to use data science to better understand customer behaviors and identify different customer segments based on their activity patterns. Many organizations also use machine learning to predict future customer behaviors, such as what items are they likely to purchase, which websites are they likely to visit, and who are likely to churn. With endless use cases of data science for marketing, companies of all sizes can benefit from using data science and machine learning for their marketing efforts. After this brief introductory chapter, we will learn about how to apply data science and machine learning for individual marketing tasks.</p>
<p>In this chapter, we will cover the following topics:</p>
<ul>
<li>Trends in marketing</li>
<li>Applications of data science in marketing</li>
<li>Setting up the Python environment</li>
<li>Setting up the R environment</li>
</ul>
<p class="mce-root"/>
<p class="mce-root"/>


            

            
        
    

        

                            
                    <h1 class="header-title">Technical requirements</h1>
                
            
            
                
<p>You will require Python and R installed to run most of the code throughout this book, and you can find the installation code at the following link: <a href="https://github.com/PacktPublishing/Hands-On-Data-Science-for-Marketing/tree/master/Chapter01" target="_blank">https://github.com/PacktPublishing/Hands-On-Data-Science-for-Marketing/tree/master/Chapter01</a>.</p>


            

            
        
    

        

                            
                    <h1 class="header-title">Trends in marketing</h1>
                
            
            
                
<p>As the amount of data available and gathered increases exponentially every year and access to such valuable datasets becomes easier, data science and machine learning have become an integral part of marketing. The applications of data science in marketing range from building insightful reports and dashboards to utilizing complicated machine learning algorithms to predict customer behaviors or engage customers with the products and contents. The trends in marketing in recent years have been toward more data-driven target marketing. We will discuss some of the trends we see in the marketing industry:</p>
<ul>
<li class="CDPAlignLeft CDPAlign"><strong>Rising importance of digital marketing</strong>: As people spend more time online than ever before, the importance and effectiveness of digital marketing have been rising with time. Lots of marketing activities are now happening on digital channels, such as search engines, social network, email, and websites. For example, Google Ads helps your brand to get more exposure to potential customers through its search engine, Gmail, or YouTube. You can easily customize your target audience, to whom you want your advertisements to be shown. Facebook and Instagram are two of the well-known social networks, where you can post your advertisements to reach your target customers. In the era of the internet, these marketing channels have become more cost-effective than traditional marketing channels, such as television advertising. The following is an example of different digital marketing channels that Google provides (<a href="https://ads.google.com/start/how-it-works/?subid=us-en-ha-g-aw-c-dr_df_1-b_ex_pl!o2~-1072012490-284305340539-kwd-94527731">https://ads.google.com/start/how-it-works/?subid=us-en-ha-g-aw-c-dr_df_1-b_ex_pl!o2~-1072012490-284305340539-kwd-94527731</a>):</li>
</ul>
<p class="CDPAlignCenter CDPAlign"><img src="img/cec322da-75fc-44a4-b1d6-84df1155f5bc.png"/></p>
<ul>
<li><strong>Marketing analytics</strong>: Marketing analytics is a way of monitoring and analyzing the performances of marketing efforts. Not only does it help you to understand how much sales or exposure you gain from marketing, but it can also help you gain deeper insights into more individual level patterns and trends. In e-commerce businesses, you can analyze and visualize the different types and segments of customers and which type of customers drives the revenue for your business the most with marketing analytics. In media businesses, with marketing analytics, you can analyze which content attracts the users the most and what the trends in keyword searches are. Marketing analytics also helps you to understand the cost-effectiveness of your marketing campaigns. By looking into the <strong>return on investment</strong> (<strong>ROI</strong>), you can further optimize your future marketing campaigns. As the adoption and usage of marketing analytics rise, it is not difficult to find various software products for marketing analytics. </li>
<li class="CDPAlignLeft CDPAlign"><strong>Personalized and target marketing</strong>: With the rising applications of data science and machine learning in marketing, another trend in marketing is individual-level target marketing. Various organizations of different sizes utilize machine learning algorithms to learn from the user history data and apply different and specialized marketing strategies to smaller and more specific subgroups of their user base, which results in lower cost per acquisition and higher return on investment. In retail businesses, many companies implement artificial intelligence and machine learning to predict which customers are more likely to purchase and which items they are going to buy from their stores. Using these predictions, they customize the marketing messages to each of their customers. Many of media businesses also utilize artificial intelligence and machine learning to drive higher engagement from individual users to grow their user base. As these customized and target marketing result in higher ROI, there are many SaaS companies, such as Sailthru and Oracle, that provide platforms for personalized marketing. Sailthru recently published a <em>Retail Personalization Index</em> report, which analyzes how various retail companies use personalized marketing in different marketing channels. In this report, we can find that retail companies, such as Sephora, JustFab, and Walmart, use personalized marketing heavily in their websites, emails, and other marketing channels. This report can be found at this link: <a href="https://www.sailthru.com/personalization-index/sailthru100/">https://www.sailthru.com/personalization-index/sailthru100/</a>.</li>
</ul>
<p>The overall trends in marketing have been toward more data-driven and quantitative approaches. Companies of all sizes have been investing in marketing analytics and technologies more and more. According to the February 2018 CMO survey, the reliance on marketing analytics has gone up from 30% to 42% in the past 5 years. The reliance on marketing analytics is even higher for B2C companies with a 55% increase. Also, the number of firms using quantitative tools to demonstrate the impact of marketing has increased by 28% in the past 5 years. Lastly, the CMO survey suggests that the percentage of companies utilizing artificial intelligence and machine learning is expected to increase to 39% over the next 3 years. You can find more details on this February 2018 CMO survey report at the following link: <a href="https://www.forbes.com/sites/christinemoorman/2018/02/27/marketing-analytics-and-marketing-technology-trends-to-watch/#4ec8a8431b8a">https://www.forbes.com/sites/christinemoorman/2018/02/27/marketing-analytics-and-marketing-technology-trends-to-watch/#4ec8a8431b8a</a>.</p>


            

            
        
    

        

                            
                    <h1 class="header-title">Applications of data science in marketing</h1>
                
            
            
                
<p>We have discussed the trends in marketing and how the trend has been toward more data-driven and quantitative marketing, often using data science and machine learning. There are various ways to apply data science and machine learning in the marketing industry and it will be beneficial for us to discuss the typical tasks and usage of data science and machine learning.</p>
<p class="mce-root"/>
<p class="mce-root"/>
<p>In this section, we will cover the basics of machine learning, the different types of learning algorithms, and, typical data science workflow and process.</p>


            

            
        
    

        

                            
                    <h1 class="header-title">Descriptive versus explanatory versus predictive analyses</h1>
                
            
            
                
<p>As we work through the exercises and projects in the upcoming chapters, there are mainly three different types of analyses that we are going to conduct throughout this book: descriptive, explanatory, and predictive analyses:</p>
<ul>
<li><strong>Descriptive analysis:</strong> This is conducted to understand and describe the given dataset better. The purpose of this analysis is to quantitatively and statistically summarize the information that the data contains. For example, if you are conducting a descriptive analysis on user purchase history data, you will be answering such questions as <em>What is the best selling item?</em> <em>What were the monthly sales like in the past year?</em> <em>What is the average price of the items that are sold?</em> Throughout this book, we will be conducting descriptive analysis, whenever we introduce a new dataset. Especially, in <a href="1fb7a852-d8fa-43f6-9807-6e3292dfa280.xhtml" target="_blank">Chapter 2</a>, <em>Key Performance Indicators and Visualizations</em>, we will be discussing in more detail how to use descriptive analysis to analyze and compute key summary statistics, as well as visualizing the analysis results.</li>
<li><strong>Explanatory analysis</strong>: When the purpose of descriptive analysis is to answer the <em>what</em> and <em>how</em> from the data, explanatory analysis is to answer <em>why</em> using the data. This type of analysis is typically conducted when you have a specific question that you want to answer. As an example for e-commerce businesses, if you want to analyze what drives your users to make purchases, you would conduct explanatory analysis, not descriptive analysis. We will be discussing more detail about this type of analysis with examples in <a href="ce2c2775-9817-4b18-972c-db8e8c629b74.xhtml" target="_blank">Chapter 3</a>, <em>Drivers behind Marketing Engagement;</em> and <a href="a9f09970-4826-46d0-8bfd-5796702c5629.xhtml" target="_blank">Chapter 4</a>, <em>From Engagement to Conversion</em>, where we are going to use explanatory analyses to answer such questions as <em>What drives users to engage with our marketing campaigns more?</em> and <em><em>What makes users purchase items from our retail shop?</em></em></li>
<li><strong>Predictive analysis</strong>: This analysis is conducted when there is a specific future event that you would like to predict. The purpose of this analysis is to build machine learning models that learn from the historical data and make predictions about events that will happen in the future. Similar to the previous examples of e-commerce and purchase history data, one of the questions you can answer from this type of analysis may be, <em>Which user is the most likely to make a purchase within the next seven days? </em>Typically, in order to conduct predictive analysis, you will have to first run descriptive and explanatory analyses to have a better understanding of the data and generate ideas on what types of learning algorithms and approaches to use for the given project. We will be discussing in more detail predictive analysis and its applications in marketing in <a href="d3ba7047-2873-4b03-9a44-4c1d55b84178.xhtml" target="_blank">Chapter 6</a>, <em>Recommending the Right Products</em>, <a href="4f5163a1-c34a-495f-bc5f-e02f9b2a2052.xhtml" target="_blank">Chapter 8</a>, <em>Predicting the Likelihood of Marketing Engagement</em>, and <a href="3d5c7798-6874-40e9-b7e9-6fe39592cc2a.xhtml" target="_blank">Chapter 11</a>, <em>Retaining Customers</em>.</li>
</ul>


            

            
        
    

        

                            
                    <h1 class="header-title">Types of learning algorithms</h1>
                
            
            
                
<p>Let's now discuss more about machine learning and machine learning algorithms. Broadly speaking, there are three types of machine learning algorithms: supervised learning, unsupervised learning, and reinforcement learning. Let's first learn how these three different types of machine learning algorithms differ from each other:</p>
<ul>
<li><strong>Supervised learning algorithms:</strong> These algorithms are used when the prediction target or outcome is known. For example, if we want to use machine learning to predict who will make purchases in the next few days, then we will use supervised learning algorithms. Here, the prediction target or outcome is whether this person made a purchase within the given time window or not. Based on the historical purchase data, we will need to build features, which describe each data point, such as a user's age, address, last purchase date, and then supervised learning algorithms will learn from this data how to map these features to the prediction target or outcome. We will be exploring how to use such algorithms in marketing in <a href="ce2c2775-9817-4b18-972c-db8e8c629b74.xhtml" target="_blank">Chapter 3</a>, <em>Drivers behind Marketing Engagement;</em> <a href="a9f09970-4826-46d0-8bfd-5796702c5629.xhtml" target="_blank">Chapter 4</a>, <em>From Engagement to Conversion;</em> <a href="4f5163a1-c34a-495f-bc5f-e02f9b2a2052.xhtml" target="_blank">Chapter 8</a>, <em>Predicting the Likelihood of Marketing Engagement</em>, and, lastly, <a href="3d5c7798-6874-40e9-b7e9-6fe39592cc2a.xhtml" target="_blank">Chapter 11</a>, <em>Retaining Customers</em>.</li>
<li><strong>Unsupervised learning algorithms: </strong>Unlike supervised learning algorithms, unsupervised learning algorithms are used when we do not have a specific prediction target or outcome. This type of machine learning algorithm is frequently used in clustering and recommendation systems. As an example, you can use unsupervised learning algorithms to cluster your customer base into different subgroups or segments, based on their behaviors. In this case, we do not have a specific target or outcome that we want to predict. We are just grouping similar customers together into different segments. We will be exploring how to use unsupervised learning algorithms in marketing in <a href="d3ba7047-2873-4b03-9a44-4c1d55b84178.xhtml" target="_blank">Chapter 6</a>, <em>Recommending the Right Products</em>, and <a href="5955002d-2a75-4d5a-aa6a-86710a3bf00e.xhtml" target="_blank">Chapter 10</a>, <em>Data-Driven Customer Segmentation</em>.</li>
<li><strong>Reinforcement learning algorithms:</strong> These algorithms are used when we want the model to continuously learn and train itself without prior knowledge or experience. In the case of reinforcement learning, the model learns how to make predictions after lots of trials and errors. One example of the application of reinforcement learning in marketing is when there are multiple marketing strategies you'd like to test and choose the one that works the best. In this case, you can run a reinforcement learning algorithm, where it randomly picks one strategy at a time and gets rewarded when a positive outcome occurs. After multiple iterations of trials and errors, the reinforcement learning model will have learned to choose the best marketing strategy, based on the total rewards each marketing strategies have earned.</li>
</ul>


            

            
        
    

        

                            
                    <h1 class="header-title">Data science workflow</h1>
                
            
            
                
<p>Now that we have covered the basics and different types of machine learning algorithms, let's discuss the workflow in data science. A typical workflow looks like the following:</p>
<ol>
<li><strong>Problem definition</strong>: Typically, any data science and machine learning project starts with problem definition. In this first step, you need to define the problems that you are trying to solve with data science, the scope of the project, and the approaches to solving this problem. When you are thinking about some of the approaches to solving your problem, you will need to brainstorm on what types of analyses (descriptive versus explanatory versus predictive) and types of learning algorithms (supervised versus unsupervised versus reinforcement learning) that we discussed previously will be suitable for solving the given problem.</li>
</ol>
<ol start="2">
<li><strong>Data collection</strong>: Once you have a clear definition of the project, you will then move on to the data collection step. This is where you gather all the data you need to proceed with your data science project. It is not uncommon that you will need to purchase data from third-party vendors, scrape and extract data from the web, or use publicly available data. In some cases, you will also need to collect data from your internal systems for your project. Depending on the cases, the data collection step can be trivial or it can also be tedious.</li>
<li><strong>Data preparation</strong>: When you have gathered all of the data you need from the data collection step, then the next step is data preparation. The goal of this step is to transform your data and prepare it for future steps. If the formats of the data sources are different, then you will have to transform and unify the data. If the data doesn't have a certain structure, then you will have to structure the data, typically in tabular format, so that you can easily conduct different analyses and build machine learning models.</li>
<li><strong>Data analysis</strong>: When you are done with the data preparation step, then you will have to start looking into the data. In the data analysis step, typically, descriptive analyses are conducted to compute some descriptive summary statistics and build visual plots to better understand the data. Quite often, you can find some recognizable patterns and draw some insight from data during this step. You may also be able to find any anomalies in the data, such as missing values, corrupted data, or duplicate records, from this step.</li>
<li><strong>Feature engineering</strong>: Feature engineering is the most important part of data science and machine learning, as it directly affects the performance of predictive models. Feature engineering requires expertise and good domain knowledge of the data, as it requires you to transform the raw data into more informative data for your algorithms to learn from. One good example of feature engineering is transforming text data into numerical data. As the machine learning algorithms can only learn from numerical data, you will need to come up with an idea and strategy to translate textual data into numerical data. As we work through this book and as we build machine learning models, we will discuss and experiment with various feature engineering techniques.</li>
<li><strong>Model building</strong>: Once you are done with the feature engineering step, then you can start training and testing your machine learning models. In this step, you can experiment with various learning algorithms to figure out which one works the best for your use case. One thing to keep in mind in this step is the validation metrics. It is important to have a good measure of your model performance, as machine learning algorithms will try to optimize on the given performance measure. As we start building machine learning models in the following chapters, we will discuss more in detail regarding what metrics to use depending on the type of problems that we are working on.</li>
</ol>
<p class="mce-root"/>
<p>The following diagram shows the overall workflow for typical data science projects:</p>
<p class="CDPAlignCenter CDPAlign"><img src="img/dfaf7e80-93c7-41cf-8f13-3432f6b09620.png" style="width:14.83em;height:22.92em;"/></p>
<p>As you can see from this diagram, quite often, the data science work does not end in one iteration. You may have to repeat the data collection step when you notice that the model is not performing well and when you notice you can improve on the quality of the input data. You may have to revisit the feature engineering step when you come up with better ideas and strategies on building features from the raw dataset. You also may have to repeat the model building step more than once, if you think you can improve the model results by tuning the hyperparameters of the learning algorithms. As we work through the following chapters and as we work on actual projects and exercises in this book, we are going to discuss in more detail certain steps and different techniques we can use.</p>


            

            
        
    

        

                            
                    <h1 class="header-title">Setting up the Python environment</h1>
                
            
            
                
<p>Now that we have discussed some of the basics of data science and its applications to marketing, let's start getting our development environments ready for the upcoming chapters and projects. For those of you who will be using the R language for the exercises, you can skip this section and move to the <em>Setting up the R environment</em> section. For those of you who are planning to use the Python language for the exercises, it will be beneficial for you to follow these steps to install all the required Python packages and get your Python environment ready, even if you are already familiar with Python.</p>


            

            
        
    

        

                            
                    <h1 class="header-title">Installing the Anaconda distribution</h1>
                
            
            
                
<p>For data science and machine learning tasks in this book, we will be using lots of different Python packages. To name a few, we will be using the <kbd>pandas</kbd> package for data munging and data analysis. You can find more information about this package at the following link: <a href="https://pandas.pydata.org/">https://pandas.pydata.org/</a>. We will also be using the <kbd>scikit-learn</kbd> package for building machine learning models. For more information about this package, you can visit the following page: <a href="http://scikit-learn.org/stable/">http://scikit-learn.org/stable/</a>. Another Python package that we will be using frequently is <kbd>numpy</kbd>. This package will come in handy when we need to run mathematical and scientific operations on multi-dimensional data. You can find more information about this package at this page: <a href="http://www.numpy.org/">http://www.numpy.org/</a>. Aside from these three packages we just mentioned, we will be using some other Python libraries as well and will discuss them individually in more detail when we use them.</p>
<p class="CDPAlignLeft CDPAlign">Since we need various Python libraries for data science and machine learning tasks, it can sometimes be cumbersome to install them separately. Thanks to the Anaconda distribution, we can install all of the required packages at once. In order to download the Anaconda distribution, visit <a href="https://www.anaconda.com/download/">https://www.anaconda.com/download/</a> to install it. When you follow this link, the webpage should look as follows:</p>
<p class="CDPAlignCenter CDPAlign"><img class="alignnone size-full wp-image-941 image-border" src="img/f26c6554-80e1-4fc5-a888-d20a39fb9b01.png" style="width:162.50em;height:90.58em;"/></p>
<p class="mce-root"/>
<p class="mce-root"/>
<p>In this book, we will be using Anaconda 5.2 in Python 3. Once you have downloaded the Anaconda distribution, you can install all of the packages using the installer. On macOS, the installer looks as follows:</p>
<p class="CDPAlignCenter CDPAlign"><img class="alignnone size-full wp-image-930 image-border" src="img/b7fdf858-628d-46bc-8d30-0de516b96c36.png" style="width:41.33em;height:28.83em;"/></p>
<p>Once you follow the steps in the installer and finish this Anaconda distribution installation, we are now ready to start running data science and machine learning tasks. In the following section, we will build a simple logistic regression model to get familiar with how we can use the key Python libraries that we just installed for future exercises. </p>


            

            
        
    

        

                            
                    <h1 class="header-title">A simple logistic regression model in Python</h1>
                
            
            
                
<p>Now that we have all of the packages installed, let's test to see if we can use them. We will be using Jupyter Notebook for all future data analysis, data visualization, and machine learning tasks. Jupyter Notebook is an open source web application, where you can easily write code, display charts, and share notebooks with others. You can find more information about Jupyter Notebook at this link: <a href="http://jupyter.org/">http://jupyter.org/</a>.</p>
<p>As the Jupyter Notebook is part of the Anaconda distribution that we just installed in the previous section, you should have it installed in your computer already. </p>
<p class="mce-root"/>
<p class="mce-root"/>
<p class="mce-root"/>
<p class="mce-root"/>
<p>To start the Jupyter Notebook, you can open a Terminal window and type in the following command:</p>
<pre><strong>jupyter notebook</strong></pre>
<p>When you type in this command, you should see some output that looks similar to the following screenshot:</p>
<p class="CDPAlignCenter CDPAlign"><img class="alignnone size-full wp-image-933 image-border" src="img/15287607-aba6-40b9-a07e-137e5869c551.png" style="width:162.50em;height:33.42em;"/></p>
<p>In the end, it should open a web application on your browser. The web UI should look like the following:</p>
<p class="CDPAlignCenter CDPAlign"><img class="alignnone size-full wp-image-937 image-border" src="img/8c27f056-8e1b-4680-a23b-bdf5d111be94.png" style="width:50.50em;height:21.00em;"/></p>
<p>As you can see from this screenshot, you can create a new Jupyter Notebook by clicking the New button on the top-right corner and then clicking on Python 3. This will create a new empty notebook using Python 3 as the choice of programming language. The new notebook should look like the following:</p>
<p class="mce-root"/>
<p class="CDPAlignCenter CDPAlign"><img class="alignnone size-full wp-image-934 image-border" src="img/6a3af3da-81e2-4aa8-86b8-47e31a989584.png" style="width:51.67em;height:15.83em;"/></p>
<p>In order to change the name of this notebook, you can simply click on the top bar, where it says <kbd>Untitled</kbd>, and name it differently.</p>
<p>Now that we have created a notebook, let's start using some of the Python libraries to build a simple logistic regression model. In the first cell, we are going to import the <kbd>numpy</kbd> and <kbd>scikit-learn</kbd> packages. The code looks like the following:</p>
<pre>import numpy as np<br/>from sklearn.linear_model import LogisticRegression</pre>
<p>As you can see from this code snippet, we have imported the <kbd>numpy</kbd> package and given it an alias of <kbd>np</kbd>. This is a standard alias for the <kbd>numpy</kbd> library. Also, we are only importing the <kbd>LogisticRegression</kbd> module in the <kbd>scikit-learn</kbd> package's <kbd>linear_model</kbd> module (<kbd>sklearn.linear_model</kbd>).</p>
<p>In order to build a model, we need data. For demo and test purposes in this chapter, we will create two-dimensional input data and a binary output. The following code shows how we created the input and output data:</p>
<pre>input_data = np.array([<br/>    [0, 0],<br/>    [0.25, 0.25],<br/>    [0.5, 0.5],<br/>   [1, 1],<br/>])<br/><br/>output_data = [<br/>    0,<br/>    0,<br/>    1,<br/>    1<br/>]</pre>
<p>As you can see from this code snippet, we created 4 x 2 input data with the <kbd>numpy</kbd> array datatype. The output is binary, where it can only take <kbd>0</kbd> or <kbd>1</kbd>.</p>
<p>With this data, we can train a logistic regression model, as shown in the following code:</p>
<pre>logit_model = LogisticRegression()<br/>logit_model.fit(input_data, output_data)</pre>
<p>As you can see from this code, we instantiated a model object with <kbd>LogisticRegression</kbd>. Then, we used the <kbd>fit</kbd> function, where it takes the input and output data, to train a logistic regression model. You can retrieve the coefficients and intercept of this logistic regression model, as shown in the following code:</p>
<pre>logit_model.coef_    # output: array([[0.43001235, 0.43001235]])<br/>logit_model.intercept_    # output: array([-0.18498028])</pre>
<p>Our Jupyter Notebook up to this point looks as follows:</p>
<p class="CDPAlignCenter CDPAlign"><img class="alignnone size-full wp-image-929 image-border" src="img/19cab5a6-5274-480c-bd0a-0a40dcc33d59.png" style="width:44.92em;height:34.83em;"/></p>
<p class="mce-root"/>
<p class="mce-root"/>
<p>In order to make predictions on the new data, you can use the <kbd>predict</kbd> function of the logistic regression model object, <kbd>logit_model</kbd>. This function will return the predicted output class for each input. The code looks like the following:</p>
<pre>predicted_output = logit_model.predict(input_data)</pre>
<p>So far, we have experimented with how to use the <kbd>numpy</kbd> and <kbd>scikit-learn</kbd> packages for building a machine learning model. Let's familiarize ourselves with one more package for data visualization. Throughout this book's chapters, we will be heavily utilizing the <kbd>matplotlib</kbd> library to visualize any data analysis results. For more information, you can visit this page: <a href="https://matplotlib.org/">https://matplotlib.org/</a>.</p>
<p>Let's first look at the following code:</p>
<pre>import matplotlib.pyplot as plt<br/><br/>plt.scatter(<br/>    x=input_data[:,0], <br/>    y=input_data[:,1], <br/>    color=[('red' if x == 1 else 'blue') for x in output_data]<br/>)<br/>plt.xlabel('X')<br/>plt.ylabel('Y')<br/>plt.title('Actual')<br/>plt.grid()<br/>plt.show()</pre>
<p>As you can see from this code snippet, you can easily import the <kbd>matplotlib</kbd> package as in the first line of this code. In order to build a scatterplot, we are using the <kbd>scatter</kbd> function, which takes <kbd>x</kbd> and <kbd>y</kbd> values, as well as the <kbd>color</kbd> of each point. You can use the <kbd>xlabel</kbd> function to change the label of the <em>x</em>-axis and the <kbd>ylabel</kbd> function to change the label of the <em>y</em>-axis. Using the <kbd>title</kbd> function, you can change the title of the chart. The <kbd>grid</kbd> function will show grids within the plot and you will need to call the <kbd>show</kbd> function to actually display the plot.</p>
<p>The Jupyter Notebook should look like the following:</p>
<p class="CDPAlignCenter CDPAlign"><img class="alignnone size-full wp-image-942 image-border" src="img/eef5e2b7-80c5-4bd8-b0cc-01b01b54e05e.png" style="width:40.33em;height:31.92em;"/><br/></p>
<p>One thing to note here is the following code:</p>
<pre>%matplotlib inline</pre>
<p>This is required to display the plots within the web applications. Without this line of code, the plots will not be shown in the web UI. In order to compare the actual output against the model's predictions, we built another scatterplot with the predicted values.</p>
<p>The code and plot look like the following:</p>
<p class="CDPAlignCenter CDPAlign"><img class="alignnone size-full wp-image-931 image-border" src="img/4ce91ee3-c659-4da0-9e9c-6f8feb5ba05b.png" style="width:43.25em;height:32.50em;"/></p>
<p>If you compare this chart with the previous one, you can see that the model predicted the output correctly three out of four times and incorrectly predicted one point. </p>
<p>You can download the full Jupyter Notebook that we used in this section from the following link: <a href="https://github.com/yoonhwang/hands-on-data-science-for-marketing/blob/master/ch.1/python/Setting%20Up%20Python%20Environment.ipynb">https://github.com/yoonhwang/hands-on-data-science-for-marketing/blob/master/ch.1/python/Setting%20Up%20Python%20Environment.ipynb</a>.</p>
<p>We will be using these three Python libraries, which we just experimented with, frequently throughout this book. As we progress through the chapters, we will be covering more advanced features and functions of these Python libraries and how to fully utilize them for our data science and machine learning tasks.</p>


            

            
        
    

        

                            
                    <h1 class="header-title">Setting up the R environment</h1>
                
            
            
                
<p>For those of you who are planning to use the R language for the upcoming exercises and projects, we will discuss how to get your R environment ready for data science and machine learning tasks in this book. We will start by installing R and RStudio and then build a simple logistic regression model using R to familiarize ourselves with R for data science.</p>


            

            
        
    

        

                            
                    <h1 class="header-title">Installing R and RStudio</h1>
                
            
            
                
<p>Along with Python, R is one of the most frequently used languages for data science and machine learning. The fact that it is very easy to use, and that there is a large number of R libraries for machine learning, attracts many data scientists. In order to use this language, you will need to download it from the following link: <a href="https://www.r-project.org/">https://www.r-project.org/</a>. If you go to this web page, it will look something like the following screenshot:</p>
<p class="CDPAlignCenter CDPAlign"><img src="img/de2e1020-8601-4aad-ad8e-1b219960bf91.png" style="width:45.33em;height:33.58em;"/></p>
<p>You can find more information about R on this web page. In order for you to download, follow the download R link in this page. It will ask you to choose a CRAN mirror. You can choose the location that is closest to you and download R. Once you download it, you can follow the steps in the installer and install R in your computer. The installer on macOS is shown in the following screenshot:</p>
<p class="CDPAlignCenter CDPAlign"><img src="img/fda32aae-ce25-4b89-b391-08ab51fe0c7a.png" style="width:49.58em;height:31.83em;"/></p>
<p class="CDPAlignLeft CDPAlign">Once you have finished installing R, we are going to install one more thing for our R development environment. In this book, we will be using RStudio, which is a popular IDE for the R programming language. You can download RStudio at the following link: <a href="https://www.rstudio.com/products/rstudio/download/">https://www.rstudio.com/products/rstudio/download/</a>. When you go to this RStudio download page, it should look like the following screenshot:</p>
<p class="CDPAlignCenter CDPAlign"><img class="alignnone size-full wp-image-939 image-border" src="img/f300bc29-063b-43d4-a084-4f52339d760c.png" style="width:51.92em;height:36.67em;"/></p>
<p class="CDPAlignLeft CDPAlign"> We will be using the RStudio Desktop Open Source License version in this book, but feel free to use other versions if you already have a license for others. Once you download and install RStudio, you will see something like the following screenshot when you open RStudio:</p>
<p class="CDPAlignCenter CDPAlign"><img class="alignnone size-full wp-image-943 image-border" src="img/6132f932-c55e-4124-b4eb-d9efd7d92c38.png" style="width:162.50em;height:67.75em;"/></p>
<p>Now that we have our R environment ready, let's build a simple logistic regression model to familiarize ourselves with R a little more.</p>


            

            
        
    

        

                            
                    <h1 class="header-title">A simple logistic regression model in R</h1>
                
            
            
                
<p>Let's test our environment setup by building a simple logistic regression model in R. Open RStudio and create a new R Script file. You can create a data frame in R, using the following code:</p>
<pre># Input Data<br/>data &lt;- data.frame(<br/>  "X"=c(0, 0.25, 0.5, 1), <br/>  "Y"=c(0, 0.5, 0.5, 1), <br/>  "output"=c(0, 0, 1, 1)<br/>)</pre>
<p class="mce-root"/>
<p>As you can see from this code snippet, we built a dataframe with columns <kbd>X</kbd>, <kbd>Y</kbd>, and <kbd>output</kbd>. The <kbd>X</kbd> column takes values of <kbd>0</kbd>, <kbd>0.25</kbd>, <kbd>0.5</kbd>, and <kbd>1</kbd>. The <kbd>Y</kbd> column has values of <kbd>0</kbd>, <kbd>0.5</kbd>, <kbd>0.5</kbd>, and <kbd>1</kbd>. <kbd>output</kbd> is a binary class, where it can be either <kbd>0</kbd> or <kbd>1</kbd>. <kbd>data</kbd> looks as follows:</p>
<p class="CDPAlignCenter CDPAlign"><img src="img/6320e186-c7c7-478c-a7bd-cad771ff78f0.png" style="width:9.75em;height:7.42em;"/></p>
<p>Now that we have the data to train a logistic regression model with, let's take a look at the following code:</p>
<pre># Train logistic regression<br/>logit.fit &lt;- glm(<br/>  output ~ X + Y, <br/>  data = data, <br/>  family = binomial<br/>)</pre>
<p>As shown in this code snippet, we are using the <kbd>glm</kbd> function in R to fit a logistic regression model. Since the <kbd>glm</kbd> function is used to fit any linear models, we need to define the variable <kbd>family</kbd> of the model we want to train. In order to train a logistic regression, we use <kbd>binomial</kbd> for the <kbd>family</kbd> argument in the <kbd>glm</kbd> function. The first argument, <kbd>output ~ X + Y</kbd>, defines the formula for this model and the <kbd>data</kbd> argument is used to define the dataframe to use to train the model with.</p>
<p>In R, you can use the <kbd>summary</kbd> function to get the details of the fitted logistic regression model, as shown in the following code:</p>
<pre># Show Fitted Results<br/>summary(logit.fit)</pre>
<p>This will output something like the following screenshot:</p>
<p class="CDPAlignCenter CDPAlign"><img class="alignnone size-full wp-image-928 image-border" src="img/08db8d9a-38c7-407e-a559-5d43463f91bd.png" style="width:29.42em;height:25.58em;"/></p>
<p>As you can see from this output, we can easily find the coefficients and the intercept of the model. We will use this <kbd>summary</kbd> function frequently throughout this book to better understand the trained models.</p>
<p>With a trained model, we can predict on new data with the following code:</p>
<pre># Predict Class Probabilities<br/>logit.probs &lt;- predict(<br/>  logit.fit, <br/>  newdata=data, <br/>  type="response"<br/>)<br/><br/># Predict Classes<br/>logit.pred &lt;- ifelse(logit.probs &gt; 0.5, 1, 0)    <br/>logit.pred    # output: 0 0 1 1</pre>
<p class="mce-root"/>
<p>As you can see from this code snippet, we are using the <kbd>predict</kbd> function to make a prediction with the trained model, <kbd>logit.fit</kbd>, and with new data defined in the argument, <kbd>newdata</kbd>. This <kbd>predict</kbd> function will output the probabilities or likelihoods for each example in the new data; in order to transform this output into a binary class, we can use the <kbd>ifelse</kbd> function to encode any output that is above a threshold (in this case, <kbd>0.5</kbd>) as <kbd>1</kbd> and the rest as <kbd>0</kbd>.</p>
<p>Lastly, let's quickly look at how we can build plots in R. We will be using an R package, <kbd>ggplot2</kbd>, for plotting throughout this book. So, it will be beneficial for you to get familiar with how to import this plotting library and use it for data visualizations. If it is your first time using this package, then you will most likely see the following error message when you try to import the <kbd>ggplot2</kbd> package:</p>
<p class="CDPAlignCenter CDPAlign"><img class="alignnone size-full wp-image-935 image-border" src="img/9d6a11b3-b01a-4b18-b3d5-3490306685a5.png" style="width:46.50em;height:7.83em;"/></p>
<p>As the message says, the package, <kbd>ggplot2</kbd>, is not yet installed on your machine. In order to install any R package, you can simply run the following command:</p>
<pre>install.packages('ggplot2')</pre>
<p>If you run this command, you will see output like the following:</p>
<p class="CDPAlignCenter CDPAlign"><img class="alignnone size-full wp-image-936 image-border" src="img/b0ce690c-8af7-4c4b-ae9c-f53fc0944a1e.png" style="width:43.67em;height:9.67em;"/></p>
<p>Once the installation of this library is complete, then you can import and use this library. We are going to build a simple scatterplot using the <kbd>ggplot2</kbd> library, as shown in the following code snippet:</p>
<pre># Plotting Library<br/>library(ggplot2)<br/><br/># Simple Scatterplot<br/>ggplot(data, aes(x=X, y=Y, color=output)) +<br/>  geom_point(size=3, shape=19) +<br/>  ggtitle('Actual') +<br/>  theme(plot.title = element_text(hjust = 0.5))</pre>
<p>As you can see from this code snippet, you can build a scatterplot with <kbd>data</kbd>, using the <kbd>ggplot</kbd> function of <kbd>ggplot2</kbd> package. In order to change the shape and size of the points on the scatterplot, you can use the <kbd>geom_point</kbd> function. You can also use the <kbd>ggtitle</kbd> function to change the title of the plot. When you run this code, you will see the following chart:</p>
<p class="CDPAlignCenter CDPAlign"><img src="img/ac63a363-159f-4887-a7e3-2a4cc71abbbf.png" style="width:38.25em;height:27.67em;"/></p>
<p>We will run the same task for the prediction results. The code looks as follows:</p>
<pre>ggplot(data, aes(x=X, y=Y, color=logit.pred)) + <br/>  geom_point(size=3, shape=19) +<br/>  ggtitle('Predicted') +<br/>  theme(plot.title = element_text(hjust = 0.5))</pre>
<p>The output appears as follows:</p>
<p class="CDPAlignCenter CDPAlign"><img class="alignnone size-full wp-image-932 image-border" src="img/a1d9b743-6dbb-4a3d-a1e4-b3932868564b.png" style="width:38.42em;height:28.08em;"/></p>
<p>We will be heavily utilizing these functions and the plotting library, <kbd>ggplot2</kbd>, throughout this book, so you will get more and more comfortable coding in R, as well as using these other libraries, as we progress through the chapters and exercises.</p>
<p>You can view and download the full R code that was used for this section from the following link: <a href="https://github.com/yoonhwang/hands-on-data-science-for-marketing/blob/master/ch.1/R/SettingUpREnvironment.R">https://github.com/yoonhwang/hands-on-data-science-for-marketing/blob/master/ch.1/R/SettingUpREnvironment.R</a><a href="https://github.com/yoonhwang/hands-on-data-science-for-marketing/blob/master/ch.1/R/SettingUpREnvironment.R">.</a></p>


            

            
        
    

        

                            
                    <h1 class="header-title">Summary</h1>
                
            
            
                
<p>In this chapter, we discussed the overall trends in marketing and learned the rising importance of data science and machine learning in the marketing industry. As the amount of data increases and as we observe the benefits of utilizing data science and machine learning for marketing, companies of all sizes are investing in building more data-driven and quantitative marketing strategies.</p>
<p class="mce-root"/>
<p class="mce-root"/>
<p>We also learned different types of analysis methods, especially the three types of analysis that we will be using frequently in this book—descriptive, explanatory, and predictive —and different use cases of these analyses. In this chapter, we covered different types of machine learning algorithms, as well as the typical workflow in data science. Lastly, we spent some time setting up our development environments in Python and R and testing our environment setup by building a simple logistic regression model.</p>
<p>In the next chapter, we are going to go over some of the <strong>key performance indicators</strong> (<strong>KPIs</strong>) and how to visualize these key metrics. We will learn how to compute and build visual plots of these KPIs in Python, using different packages, such as <kbd>pandas</kbd>, <kbd>numpy</kbd>, and <kbd>matplotlib</kbd>. For those of you who are following the exercises in this book using the R language, we will also discuss how to use R to compute and plot these KPIs in R, using various statistical and mathematical functions in R and the <kbd>ggplot2</kbd> package for visualizations.</p>


            

            
        
    </body></html>