<html><head></head><body><div><h1 class="header-title">Managing Data Science Projects</h1>
                
            
            
                
<p class="p2">In the previous chapter, we looked at innovation management. We developed recipes that can help find ideas for data science projects and matched them with their market demand. In this chapter, we will cover the non-technical side of data science project management by looking at how data science projects stand out from general software development projects. We'll look at common reasons for their failure and develop an approach that will lower the risks of data science projects. We will conclude this chapter by diving into the art and science of project estimates.</p>
<p class="p2">In this chapter, we will look at how we can manage projects from start to end by covering the following topics:</p>
<ul>
<li class="p2">Understanding data science project failure</li>
<li class="p2">Exploring the data science project life cycle</li>
<li class="p2">Choosing a project management methodology</li>
<li>Choosing a methodology that suits your project</li>
<li class="p2">Estimating data science projects</li>
<li>Discovering the goals of the estimation process</li>
</ul>


            

            
        
    </div>
<div><h1 class="header-title">Understanding data science project failure</h1>
                
            
            
                
<p class="p2">Every data science project ends up being a software system that generates scheduled reports or operates online. The world of software engineering already provides us with a multitude of software project management methodologies, so why do we need to reinvent a special approach for data science projects? The answer is that data science projects require much more experimentation and have to tolerate far more failures than software engineering projects.</p>
<p class="mce-root"/>
<p class="p2">To see the difference between a traditional software system and a system with predictive algorithms, let's look at the common causes of failure for data science projects:</p>
<ul class="ul1">
<li class="li2"><strong>Dependence on data</strong>: A robust <strong>customer relationship management</strong> (<strong>CRM</strong>) system that organizes the sales process will work well in many organizations, independent of their business. A system that predicts the outcome of a sales process may work well in one organization, but will require a partial rewrite for another organization and may not work at all in another. The reason for this is that machine learning algorithms depend on data, and every organization will have its own data model of its customers and its own sales process.</li>
<li class="li2"><strong>Changing requirements</strong>: While software development projects often suffer from changing requirements, the changes mostly flow from the customer to the implementation team. In data science projects, new insights and research results from the implementation team can create a feedback loop. Project stakeholders can generate new requirements and change the course of the project based on the new information that's discovered by data scientists.</li>
<li class="li2"><strong>Changing data</strong>: In software development projects, the data model is mostly fixed or can be changed in a controlled manner. Data science projects often need to be integrated with new data sources for research purposes. Data is always changing and transforming, creating multiple intermediate representations inside the system. People and software components use these representations for reporting, data processing, and modeling. Software engineering projects use fixed or slowly changing data models, while data science projects use constantly evolving data pipelines.</li>
<li class="li2"><strong>Experimentation and research</strong>: Data science projects involve completing many experiments. Typically, the number ranges from hundreds to thousands. Software engineering projects limit research by designing a system architecture and evolving it in a controlled manner. In data science projects, the next experiment may turn the project in a new direction, and you never know when this will happen.</li>
</ul>
<p class="mce-root"/>
<p class="mce-root"/>


            

            
        
    </div>
<div><h1 class="header-title">Understanding data science management approaches</h1>
                
            
            
                
<p class="p3">The traditional management approach to software engineering projects was not built with these problems in mind. The key problem that most modern software project management methodologies need to solve is the issue of changing requirements. Agile methodologies focus on planning and executing fast iterations. Each iteration aims to deliver functionality to the client as fast as possible. External feedback is the primary source of changes in the project.</p>
<p class="p3">In data science projects, changes come from every direction. They spread internally from the project's team and externally from the business' customers. Metrics should always confirm progress. Getting one step closer to your goal may take tens or even hundreds of failed experiments, which makes fast iterations a must.</p>
<p class="p3">The typical iteration length of an Agile project can stretch from 2 weeks to 1 month. The project team fixes the iteration scope for this duration and delivers it under a strict timeline. In a data science project, an experiment's result in the middle of the sprint can affect the sprint's goals and make working on other planned tasks less important due to the new discovery.</p>
<p class="p3">Management must provide a safety net for common issues and problems. Methodologies that come from the software engineering domain can give you a solid foundation here, but they do not provide any tools that we can use to manage research and govern data.</p>
<p class="p3">If you develop systems that use machine learning under the hood, it is necessary to take care of the following:</p>
<ul class="ul1">
<li class="li3"><strong>Requirements for validation and alignment</strong>: You need to detect and manage requirement changes from external (customers) and internal (research team) sources.</li>
<li class="li3"><strong>Data governance</strong>: Your project will need data governance standards, which should be rigorously applied to each piece of code that works with data. Ideally, each row of data going through your pipeline should be tracked back to its data source. All incoming and outgoing datasets, including intermediate reports, should be tracked and documented.</li>
<li class="li3"><strong>Research processes</strong>: Each data science project will need to be researched extensively. Without control, research can quickly eat away at your budget without project completion being in sight. The essential components for managing a research project include the following:
<ul class="ul2">
<li class="li3"><strong>Research planning</strong>: The project team should plan and prioritize all of their research.</li>
<li class="li3"><strong>Experimentation methodology</strong>: Each experiment should conform to a set of standards such as tracking, documentation, and reproducibility.</li>
<li class="li3"><strong>Fail fast and recover early</strong>: Experiments often fail. Your management approach should make experiments fast so that your team can iterate and learn as quickly as possible.</li>
</ul>
</li>
<li class="li3"><strong>Software engineering processes</strong>: Much of your work will be in creating software. Software project management already offers great tools for this, but they need to be tightly integrated with all the other components of the management methodology.</li>
</ul>
<p>Next, we will look at common stages that arise in data science projects. We will tie those stages into a process that's comprised of the project life cycle so that we can see the whole picture behind data science projects. </p>


            

            
        
    </div>
<div><h1 class="header-title">Exploring the data science project life cycle</h1>
                
            
            
                
<p class="p6">Each data science project has several distinct states. We can structure projects in different domains and different technologies into stages that comprise the data science project life cycle, as shown in the following diagram:</p>
<p class="p6 CDPAlignCenter CDPAlign"><img class="aligncenter size-full wp-image-301 image-border" src="img/3911e318-2ed0-4e02-bec3-55e08f0d9d71.png" style="width:38.00em;height:38.25em;" width="1741" height="1753"/></p>
<p>Let's explore each stage of the life cycle in more detail.</p>


            

            
        
    </div>
<div><h1 class="header-title">Business understanding</h1>
                
            
            
                
<p class="p8">During this stage, you apply your domain expertise and research the business side of the project. You define the business requirements and confirm that their implementation would make the lives of your customers better. You should also define and document all the relevant business metrics that will allow you to measure and report on results in a way that is understandable by the business side. The output of this stage should be a business requirements specification that has been viewed, redacted, and agreed upon by the project stakeholders.</p>
<p class="mce-root"/>


            

            
        
    </div>
<div><h1 class="header-title">Data understanding</h1>
                
            
            
                
<p class="p8">During this stage, you research the data architecture of the organization you are working with. You document data sources, their owners, and the technologies they use. You should not document every available data source unless you want to mine project ideas from data (see <a href="e5f57688-4506-40ea-858e-84169c97c6ad.xhtml">Chapter 7</a>, <em>Managing Innovation</em>). Focus on data that's useful for the project.</p>
<p class="p8">After finding this data, perform an <strong>exploratory data analysis</strong> (<strong>EDA</strong>) and research the data thoroughly. Look at any anomalies and unusual artifacts in the data. Study the reasons behind their occurrence and document ways to handle them. For example, if the dataset has a lot of empty values, you should have a plan for how to deal with them, and your actions should not distort the data in an undesirable way.</p>
<p class="p8">You should also look at ideas regarding feature engineering during the EDA stage. Perform statistical analysis on the data and try to find causal relationships that will help to solve the task at hand.</p>
<p class="p8">The data understanding stage should have the following outputs:</p>
<ul class="ul1">
<li class="li9"><strong>Data source dictionary</strong>: This document briefly describes all the data sources that are relevant to your project.</li>
<li class="li9"><strong>An EDA report that shows the conclusions of your data analysis</strong>: This document should describe the approach that you will use to solve the task at hand and the strategies for handling errors that you have found in the data. You should include facts that may interest your customer.</li>
</ul>


            

            
        
    </div>
<div><h1 class="header-title">Data preparation</h1>
                
            
            
                
<p class="p7">This stage is where we start working with data. The data preparation stage involves taking raw data and changing it into a useful format. You read data from its sources and prepare it so that you can use the data to reach the project's goal. If you are solving a task based on structured data and plan to use machine learning, you will need to perform feature engineering. The previous stage should give you insights into the quirks of the data that you can fix during the data preparation stage. This stage's output is one or more reproducible data preparation jobs and a dataset that you can use to build and test models.</p>
<p class="mce-root"/>


            

            
        
    </div>
<div><h1 class="header-title">Optimizing data preparation</h1>
                
            
            
                
<p class="p7">Data preparation and data understanding are surprisingly time-consuming. These stages can take up to 80% of the project's time, so don't forget to plan in advance. Since this stage is time-consuming, optimizing the team's performance is important. Open source tools for automated EDA and feature engineering can save you a lot of time at the start of the project, so don't hesitate to use them. In the <em>Creating the Development Infrastructure</em> section of this book, we will look at several libraries that you can use to speed up the data preparation and data understanding stages.</p>
<p class="p7">To make this process less error-prone and easier to monitor, you should care about data provenance and versioning. Every dataset should be able to be traced back to its source. Take care to save all the data files, regardless of whether they're intermediate and raw. Log the inputs and outputs of every data transformation job in your code. Data processing bugs are notoriously hard to spot unless you have complete control of your data streams.</p>
<p class="p8">Another important point to make is reusability. Code your data processing jobs well. It is tempting to create a large pile of tangled code lines in a single file and let them do their job. Doing this will increase your technical debt. The code will work for a while, and then it will fail without notice. Over time, you may also want to add additional features to the code. If it is badly written, you will spend an unexpectedly large amount of time making fixes and debugging.</p>
<p class="p8">To ensure that you have robust data processing code, use the following checklist during the code review:</p>
<ul class="ul1">
<li class="li9">All the repeated code is encapsulated into functions</li>
<li class="li9">The logically connected functions are encapsulated in classes and modules</li>
<li class="li9">Your code has extensive logging</li>
<li class="li9">All the configuration parameters can be changed via the config file or command-line arguments</li>
<li class="li9">The inputs and outputs of your data job are saved somewhere</li>
<li class="li9">The code is reproducible and has documentation</li>
</ul>
<p class="mce-root"/>
<p class="mce-root"/>


            

            
        
    </div>
<div><h1 class="header-title">Modeling</h1>
                
            
            
                
<p class="p8">This topic was covered in the <em>What is Data Science?</em> section of this book. In this stage, we apply our knowledge of data science, machine learning, and deep learning to solve the task at hand. This is done in the following stages:</p>
<ol class="ol1">
<li class="li9">First, we determine the task type, that is, supervised (classification and regression), unsupervised (clustering and document topic modeling), or reinforcement learning.</li>
<li class="li9">Then, prepare a list of algorithms that are suitable for solving the task.</li>
<li class="li9">Next, come up with a model validation and testing approach.</li>
<li class="li9">Finally, optimize the parameters of the model and select the best model.</li>
</ol>


            

            
        
    </div>
<div><h1 class="header-title">Evaluation</h1>
                
            
            
                
<p class="p8">While not being separate from the modeling and deployment steps, this stage deserves to stand on its own. You must test technical and business metrics, as well as checking the individual predictions of the model at this stage. Look at the biggest errors the model made on the test set and think about the changes that you can make to your data, features, or models that can fix those errors. This is also a good way to spot data processing bugs.</p>
<p class="p8">Your project should have two evaluation strategies: online and offline. Online evaluation takes care of tracking all the metrics for the already deployed model, while offline evaluation is used to decide which model will make it to the deployment stage.</p>
<p class="p8">Typical data science projects contain hundreds of experiments with different models, data, and parameters. Each experiment generates new data in the form of metrics, code parameters, and notes. Use a specialized experiment tracking tool to decide on the success or failure of a particular experiment. These tools can automatically collect all the logs, metrics, and artifacts of the experiment to ensure their reproducibility and to ease searching the experiment results. If you don't want to or can't use a special tool, a spreadsheet can be a good substitute, although you will need to spend more time working on it. Having a complete log of all the experiments and decisions you've made regarding modeling and data preprocessing will help you compare different experiments and make conclusions about their results.</p>
<p>If you need to know about the technical details of model testing, please refer to <a href="20c52af6-9bb7-4578-9db2-6d74ac656248.xhtml">Chapter 2</a>, <em>Testing Your Models.</em></p>
<p class="p8">The modeling and evaluation stages are closely related and are often repeated several times in successive iterations before the final stage is reached.</p>
<p class="mce-root"/>


            

            
        
    </div>
<div><h1 class="header-title">Deployment</h1>
                
            
            
                
<p class="p8">At the deployment stage, you publish your best model for your end users and examine the results. At this stage, complexities are often overlooked. Production code has a separate set of strict requirements and <strong>service level agreements</strong> (<strong>SLAs</strong>) that your model needs to meet. We can separate those requirements into two categories: functional and nonfunctional. Functional requirements define your service's features, while nonfunctional requirements define your SLAs.</p>
<p class="p8">Some examples of the functional requirements for your model service are as follows:</p>
<ul class="ul1">
<li class="li9">Request/response format</li>
<li class="li9">Capability for model versioning</li>
<li class="li9">A UI for tracking deployments and request statistics</li>
</ul>
<p class="p9">Nonfunctional requirements define the quality of service and availability of your service, and some of them are as follows:</p>
<ul class="ul1">
<li class="li9">Desired request throughput (1,000 requests per second)</li>
<li class="li9">Availability schedule (24/7 and 5/8)</li>
<li class="li9">Secure communication</li>
<li class="li9">Elastic scalability so that the system will stay available when the user load peaks</li>
</ul>
<p class="p9">The requirements for model deployment are similar for different projects, so this part of the process is subject to reusability. Instead of repeating the same work for each project, you can develop your own model-serving framework or use an existing one.</p>
<p class="p9">Another important point to remember at the deployment stage is evaluation. This does not end at the previous stage; you should evaluate all of the model's metrics online. Your system may trigger alerts or compensative actions such as model retraining if the online metrics drop below a certain threshold. A/B testing and multi-armed bandits are also a part of the deployment process and can be supported as features of your model server.</p>
<p class="p9">Now, you should be familiar with the common stages of each data science project. Let's see how we can execute each stage with a proper management approach.</p>
<p class="mce-root"/>


            

            
        
    </div>
<div><h1 class="header-title">Choosing a project management methodology</h1>
                
            
            
                
<p class="p2">Project management methodologies provide a set of rules and processes that can distinguish chaotic projects from coherent ones. They provide a framework where everyone can act toward a greater goal. Laws do the same for our society. However, laws are not perfect and they often fail. There is no silver bullet in the world of software management either. Some management practices are better suited to one type of project and will let you down in another. In the following sections, we will explore the most popular ways of managing software projects and learn how to adapt them to a data science environment so that we can draw conclusions and choose the one that suits our project the best.</p>


            

            
        
    </div>
<div><h1 class="header-title">Waterfall</h1>
                
            
            
                
<p class="p2">The most intuitive way to manage a project is to approach it like you're building a house. The steps for this are as follows:</p>
<ol class="ol1">
<li class="li2">Prepare the building site</li>
<li class="li2">Lay a foundation</li>
<li class="li2">Create a framework</li>
<li class="li2">Build a roof</li>
<li class="li2">Build walls</li>
<li class="li2">Connect the electricity and water</li>
<li class="li2">Finish the exterior and interior</li>
</ol>
<p class="p11">To build a software system, you do the following:</p>
<ol class="ol1">
<li class="li2">Prepare the development environment</li>
<li class="li2">Analyze and document the requirements</li>
<li class="li2">Analyze and document the architecture and software specification</li>
<li class="li2">Build the system</li>
<li class="li2">Test that everything is working according to the requirements</li>
<li class="li2">Finish the project</li>
</ol>
<p class="p11">This management methodology is called a <strong>waterfall</strong>. It is logical on paper, but real-world applications rarely end up being very successful. The reason behind this is that all the steps are laid out sequentially and are only repeated once. If you make a single mistake, the project plan will fall apart. A single undocumented requirement, such as the one at <em>step 2</em>, can result in a disaster at <em>step 6</em>. Clients do not have a complete view of the end result and they can make mistakes too. Requirements can change after customers see the actual implementation of their requests.</p>
<p class="p11">Software project managers know that a single waterfall won't solve their issues, so they compose many smaller waterfalls into sequential iterations. This stage of evolution is called iterative and incremental software development. The iterative project is comprised of several phases that are managed in a waterfall fashion. The length of a single iteration is measured in months. At the end of each phase, the development team shows intermediate results to the end user for the purpose of collecting feedback. This feedback is used to jumpstart the next iteration. With each cycle, the understanding of the desired result evolves until it satisfies the customer's needs.</p>


            

            
        
    </div>
<div><h1 class="header-title">Agile</h1>
                
            
            
                
<p class="p11">The iterative approach is still too heavy for most software projects. They suffer from changes that pile up in a mountain of technical requirements. In 2001, some of the brightest heads of the software development world created an Agile manifesto (<a href="https://agilemanifesto.org">https://agilemanifesto.org</a>), which described a new management approach in four simple points:</p>
<ul>
<li>Individuals and interactions take precedence over processes and tools</li>
<li>Working software takes precedence over comprehensive documentation</li>
<li>Customer collaboration takes precedence over contract negotiation</li>
<li>Responding to change takes precedence over following a plan</li>
</ul>
<p class="p14">That is, while there is value in the latter of each point, we value the former of each point more.</p>
<p class="p16">Today, we associate agile with Kanban and Scrum. These methodologies take somewhere between 50 and 500 pages to explain. Nonetheless, at its core, Agile is simple. Any project can go astray with the agile manifesto, and many did. If you leave out the last sentence in the manifesto, you may end up creating a project without a plan or specification, which will inevitably end in an uncontrollable mess. People needed a more direct guide when it comes to managing software projects. This is why Kanban and Scrum were invented. </p>
<p class="mce-root"/>


            

            
        
    </div>
<div><h1 class="header-title">Kanban</h1>
                
            
            
                
<p class="p16">First, let's cover Kanban. The best metaphor for explaining Kanban is a conveyor belt. Imagine that all of your tasks go through a fixed number of stages before they're finished. The concrete definition of those stages is up to you.</p>
<p class="p16">In software projects, you may want to use the following process:</p>
<ol class="ol1">
<li class="li16">Backlog (a buffer where all incoming tasks are collected before they're processed)</li>
<li class="li16">Requirements specification</li>
<li class="li16">Development</li>
<li class="li16">Code review</li>
<li class="li16">Testing</li>
<li class="li16">Deployment</li>
</ol>
<p class="p16">Kanban visualizes each task on a board, as shown in the following diagram:</p>
<p class="CDPAlignCenter CDPAlign"><img class="aligncenter size-full wp-image-375 image-border" src="img/7d0fe435-1d6b-4ecf-94dd-6c7d89222cf9.png" style="width:36.83em;height:29.08em;" width="1581" height="1250"/></p>
<p class="p16">Each stage should have a limit regarding the tasks that can be done in parallel. Kanban purposefully limits the number of simultaneous tasks to increase throughput. If the team becomes blocked because there are too many tasks sitting in the deployment stage, then all the team members who are capable of making shipments of the end product to production should stop doing their tasks and switch to getting rid of the bottleneck. Once the problem has been resolved, the team may decide to work on other tasks according to their priority. Because of this, Kanban favors cross-functional teams where everyone can help push tasks through each stage. Kanban does not remove the concept of roles, but it states that no matter the role, each team member should be able to help in dealing with a bottleneck.</p>
<p class="p16">Kanban focuses on completing a single task from start to finish as fast as possible. The main metrics that we can use to measure the effectiveness of Kanban projects are as follows:</p>
<ul class="ul1">
<li class="li16"><strong>Lead time</strong>: The time it takes for a task to move from the backlog to being completed on average.</li>
<li class="li16"><strong>Cycle tile</strong>: The time it takes for a task to move from the starting stage to being completed on average. In our example, the cycle time would be between the requirements specification and deployment.</li>
<li class="li16"><strong>Throughput</strong>: The average number of tasks you can get done during a time interval, that is, a day, a week, or a month.</li>
</ul>
<p class="p16">In general, you don't create a fixed project plan with fixed deadlines when using Kanban. Also, you don't have to estimate each task individually since the metrics will take care of that. Measure your team's throughput for several weeks so that you have an idea of how much you will be able to deliver in the near future.</p>
<p class="p16">Kanban's powers are also its limitations, some of which are as follows:</p>
<ul class="ul1">
<li class="li16">Kanban works best when the amount of work in each of your tasks is the same. If some tasks are taking significantly longer than the others, your metrics will stop being useful.</li>
<li class="li16">If you don't want to work as a cross-functional team, your throughput will suffer from bottlenecks, which makes using Kanban worthless.</li>
<li class="li16">Kanban does not give you the tools you need to manage deadlines, project scope, and budgets. The single thing it takes care of is optimizing throughput.</li>
</ul>
<p class="mce-root"/>
<p class="mce-root"/>
<p class="mce-root"/>
<p class="p16">Kanban is a great software management approach for projects with repetitive tasks. It can also be partially applied to parts of your project where it makes sense to use it. Here are some examples of projects where using Kanban is a good idea:</p>
<ul class="ul1">
<li class="li16">In a software support project, where you should take care of deployment and fixing frequent issues.</li>
<li class="li16">If your data science project has a dedicated team that performs experiments with machine learning models, using Kanban will help increase their throughput.</li>
<li class="li16">Projects where you need to create lots of similar things, such as hundreds of web forms, data mappings, or identical machine learning models.</li>
</ul>
<p>The surprising thing about <img class="fm-editor-equation" src="img/8bde82b7-182f-46db-b1ff-c07bd4e276b7.png" style="width:2.83em;height:1.00em;" width="590" height="210"/> (Kanban) is that it was originally developed to make the car manufacturing process more efficient. Toyota invented Kanban in 1959 and integrated it into their production environment in 1962. You can see that all of Kanban's pros and cons make sense in terms of a manufacturing environment, where car parts go through different stages on a conveyor belt.</p>


            

            
        
    </div>
<div><h1 class="header-title">Scrum</h1>
                
            
            
                
<p class="p16">Another popular management methodology from the agile family is Scrum. The main idea behind Scrum is the sprint. The sprint is a set of tasks with a fixed deadline and duration. Typical sprint durations are one week, two weeks, and one month. Explaining the entirety of Scrum would take another book, so we will only present the basics here.</p>
<p class="p16">The Scrum process includes the following steps:</p>
<ol class="ol1">
<li class="li16">Backlog grooming</li>
<li class="li16">Sprint planning</li>
<li class="li16">Sprint execution</li>
<li class="li16">Retrospective</li>
</ol>
<p class="p16">Akin to other agile methodologies, all the tasks go into the project backlog. The project backlog needs periodic grooming: all of the obsolete tasks should be deleted; the rest of the tasks need to be ordered by priority.</p>
<p class="mce-root"/>
<p class="mce-root"/>
<p class="p18">The main component of Scrum is the sprint. A sprint is an iteration with a fixed deadline and a defined goal. The typical length of a sprint is 2 weeks. It always starts with a sprint planning meeting, where team members observe the project backlog and take tasks into a sprint. Each task is estimated in abstract story points. The goal of estimating in story points rather than hours is to make estimations relative rather than absolute. For example, we can consider a task with one story point trivial and a task with two story points as being slightly harder but still easy to complete. Four to six story points would indicate a normal task. Another system of story point estimates suggests using powers of 2 to 128 as task estimates. On the first sprint, the estimations are fairly approximate. On the second sprint, you compare the new tasks with the previous ones and see how many story points the task is worth. After four sprints, you can see how many story points your team can complete on average. You can also calculate an approximate hour equivalent of a single story point, although this should only be used as a reference and not as a substitute for story points during the sprint planning process.</p>
<p class="p18">During planning, each team member estimates the task on their own, and then their estimations are compared. This helps ensure everyone understands the task definition in the same way. Differences in estimates signify that the task needs a clearer explanation and evaluation in terms of the SMART criteria.</p>
<p class="p18">The sprint starts after the planning phase. When you start working on the sprint, it will be locked. You cannot change the scope you defined during the planning phase. The primary focus of the team is to complete all the tasks in the sprint before it ends. This strategy allows you to achieve your planned goals while being robust to changes. The main strength of Scrum is also its main weakness. If your customer comes into work in the middle of the week with an <em>extremely important task that needs to be done ASAP</em>, you should do your best to convince them that the team will deliver this during the next sprint. Scope locking is an essential mechanism that makes sprints work. If you depart from this rule often, Scrum will become an obstacle rather than a beneficial and effective management approach.</p>
<p class="p18">In practice, scope locking can cause problems, especially if you are working in a B2B environment. For situations where you have no options and are forced to change sprint scope, you have two options:</p>
<ul class="ol1">
<li class="li11"><strong>Trade tasks</strong>: You can remove a task from the sprint and add a new one.</li>
<li class="li11"><strong>Start a new sprint</strong>: You can stop the current sprint and plan a new one.</li>
</ul>
<p class="p11">Using these options frequently makes Scrum ineffective. Try to negotiate a fixed sprint scope with your customers and show them that it brings benefits such as planned delivery while leaving space for requirement changes.</p>
<p class="mce-root"/>
<p class="p11">A good strategy you can use to avoid unexpected scope changes is to ask your customers to take part in backlog grooming and sprint planning. Scrum experts suggest that you should assign a special product owner role for this task. The product owner should decide on task priorities, sprint goals, and negotiate all the conflicting requirements with project stakeholders.</p>
<p class="p18">Scrum came directly from the software development world, so it has fewer limitations than Kanban. The price lies in its complexity: Scrum is not an easy methodology, and it will create management overhead. Each team member should understand Scrum if you want it to work. In complex projects, you may need to give someone the dedicated role of Scrum master. This is someone who will take care of applying the methodology to one or several of your projects.</p>
<p>In the next section, we will look at choosing a methodology according to the needs of your project. </p>


            

            
        
    </div>
<div><h1 class="header-title">Choosing a methodology that suits your project</h1>
                
            
            
                
<p class="p8">Choosing a project management methodology can become a captivating and complex task. You can spend a lot of time thinking about how one approach will support your processes better than another, and what limitations it will have. Try not to spend much of your time on methodological considerations. It is much more important to choose something and stick with it unless it is clearly harming your project. To simplify this process, we will explore some simple guidelines when it comes to choosing a management approach.</p>


            

            
        
    </div>
<div><h1 class="header-title">Creating disruptive innovation</h1>
                
            
            
                
<p class="p8">If you create a solution that should disrupt the market, the only thing that matters is the efficiency of your methodology. You won't have many customers at the start of the project, so you should be able to collect feedback and perform focused work to iterate on the next version of your product. Scrum works best in such situations. You can implement new features regarding the sprint and collect feedback at the end of each sprint to start a new iteration. Kanban will work too, but it will provide fewer benefits in terms of disruptive innovation.</p>
<p class="mce-root"/>


            

            
        
    </div>
<div><h1 class="header-title">Providing a tested solution</h1>
                
            
            
                
<p class="p8">If you implement a system that resembles some of your past projects, it will presumably require much less research than in previous iterations. This is also the case for system integration projects, where you provide services that can integrate your product into the customer's IT environment. In those projects, you can define many customer-focused tasks that can be divided into three to five groups depending on the total amount of work that needs to be done. In this setting, Kanban will provide the most benefit. Using Kanban will allow you to focus on delivering more results to the customer in less time.</p>


            

            
        
    </div>
<div><h1 class="header-title">Developing a custom project for a customer</h1>
                
            
            
                
<p class="p8">Using Agile methodologies can be extremely tricky when you're working on a project for a customer. Your clients will want to have the best of both worlds: fixed deadlines with constantly changing requirements. Your job is to decide on the best approach for this project and explain its pros and cons. Many teams settle for something between Scrum and waterfall: you develop the initial scope of the project, estimate it, and show it to the client. Next, you implement the project scope piece by piece using sprints. The requirements will inevitably change during the implementation stage, so it is important that you manage these changes and keep the customer involved in sprint planning.</p>
<p>Choosing a project methodology goes hand in hand with estimating data science projects. In the next section, we will define the goals of the estimation process and learn how to make estimates.</p>


            

            
        
    </div>
<div><h1 class="header-title">Estimating data science projects</h1>
                
            
            
                
<p class="p8">If you need to explain the basic principles of forecasting to someone, ask them if they have ever worked on a software project. If so, they already know the basics of forecasting: everyone who has worked on one has estimated tasks. Everyone needs estimates. Your customers need them to plan and control when they will start to use the results of your project. The project manager needs estimates to understand the scope, amount of work, and approximate costs for individual tasks or an entire project.</p>
<p class="mce-root"/>
<p class="mce-root"/>
<p class="p8">Estimation is beneficial in several areas, such as the following:</p>
<ul class="ul1">
<li class="li9"><strong>Understanding work structure</strong>: Break down a task into multiple subtasks to view the main steps that you need to complete.</li>
<li class="li9"><strong>Understanding complexity</strong>: While it is hard to estimate a complex task by itself, estimating each individual part of the work structure is simpler. It allows you to get an idea of how complex the task is and how long it will take to finish it.</li>
<li class="li9"><strong>Understanding costs</strong>: In most businesses, you won't be able to start working on a project if you don't explain and defend its costs and required resources first.</li>
</ul>
<p class="p8">The largest problem with estimations is that they fail. Our plans are inaccurate, incomplete, and often irrelevant to how the real work will be done. Even experienced software developers struggle to estimate the total amount of hours that it will take to do a single task unless they have done it multiple times already.</p>
<p class="p8">Research shows that humans are bad at absolute estimates. Our brains are simply not suited to making accurate mental models of complex multilayered projects. For example, if we were to ask a bunch of strangers about the height of the nearest building, the majority would fail to give you the correct answer. However, if you told them the height of several buildings, their estimates would be much more accurate. This is true not only for building height estimates but for all kinds of estimation.</p>
<p class="p8">To use relative estimates in data science projects, you need two things: relevant samples and a good estimation process. We can think of relevant estimates as simple statistical estimators that average the length of all previous relevant tasks. To create such an estimator, we first need to collect a dataset. If you follow a waterfall process, then to get one new data point in your estimation dataset, you need to complete a whole project from start to end. You may need to fail estimates in many projects before you get good at estimating one particular type of project.</p>
<p class="p8">The trick is to get down to the individual task levels. Scrum suggests that you use relative story points instead of absolute hours for this reason. First, your estimates become relative at the task level, then at the sprint level, and finally at the project level. If you have no prior experience that will help you to make relative estimates, the only absolute estimate you should make is one for the first sprint of the project. From here, you should use the previous tasks as a basis for making new estimations.</p>
<p class="p8">You don't have to use Scrum to benefit from relative estimations. Scrum provides one way to make them work, but it may not be ideal for your circumstances. If that is the case, you can adapt any management methodology for relative estimation.</p>
<p class="mce-root"/>
<div><p><strong>Differentiating between business and implementation estimates:</strong></p>
We can look at estimates from two perspectives. The first one will be familiar to project managers and team leaders who are mostly concerned with project delivery: the implementation perspective. The main goal of estimates in this example is to provide correct expectations regarding how much time and money will be required to build the solution.<br/>
<br/>
Another perspective is closely related to the business goals of the project and is often unseen by the implementation team. Every project is generally backed up by a business model that fixes expectations on revenue increases, customer satisfaction, reduced costs, and so on.<br/>
<br/>
This business model should always be considered when you're creating implementation estimates. In data science projects, business estimations can be included in the project by deriving budget constraints from a business model and creating a set of business metrics that will evaluate the project's performance. </div>


            

            
        
    </div>
<div><h1 class="header-title">Learning to make time and cost estimates</h1>
                
            
            
                
<p class="p8">Using relative estimates is an effective strategy, but it becomes useless if someone asks you, <em>When exactly will you be able to finish this?</em> Scrum and Kanban do not give you project estimation tools. In fact, both methodologies argue that making such estimates is unnecessary. This line of thought is true if your goal is to efficiently complete a project with known deadlines and known budget constraints. However, there are situations where you may need to set budgeting and time constraints yourself.</p>
<p class="p8">Let's take a consulting environment as an example. We need to build a custom analytics system for a client. The main task is to estimate the probability of buying a certain product based on the user's profile. This customer needs an entirely new solution that will meet the requirements of various stakeholders from several departments. They also ask you to integrate the solution with various IT systems. They have invited several companies to compete for the project. The first thing they ask each candidate company is, <em>How much will this cost and how fast will you be able to build it?</em> <em>How can we approach this if we know the limitations of absolute estimations?</em></p>
<p class="mce-root"/>
<p class="p8">Let's start with the outline. The outline is a hierarchical list of high-level tasks that you will need to complete. The simplest outline for a waterfall project may look like this:</p>
<ol class="ol1">
<li class="li9">Collect the requirements</li>
<li class="li9">Implement the requirements</li>
<li class="li9">Test the system</li>
<li class="li9">Deploy the system</li>
</ol>
<p class="p9">Using a waterfall project is risky, so we will split the system into several stages, with each going through several successive steps. Depending on the complexity of the stage, you will need to make one or several iterations of the same stage to complete it. In theory, you could try to create an outline for every two-week sprint, but this is unrealistic because of the ever-changing nature of data science projects. </p>
<p class="p9">For example, let's look at the outline for requirements collection:</p>
<ol class="ol1">
<li class="li9">Collect the requirements:
<ul class="ul2">
<li class="li9">Software architecture:
<ul class="ul2">
<li class="li9">Nonfunctional requirements specification</li>
<li class="li9">Nonfunctional requirements implementation strategy</li>
<li class="li9">Component diagram</li>
<li class="li9">Integration diagram</li>
</ul>
</li>
<li class="li9">Functional requirements specification:
<ul class="ul2">
<li class="li9">UI:
<ul class="ul2">
<li class="li9">UI requirements</li>
<li class="li9">UI mockups</li>
</ul>
</li>
<li class="li9">Backend services</li>
<li class="li9">Data analysis and modeling:
<ul class="ul2">
<li class="li9">EDA</li>
<li class="li9">Creating an experimentation backlog</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
</ol>
<p class="p9">You should start by defining the rough steps and then detail them. If you have created similar projects before, you can look at their outlines so that you know where to start. Collecting and using data from other projects can serve as a primary source of relative estimates, so do not underestimate your prior experience.</p>
<p class="p9">You will have difficulty decomposing some tasks. Being unsure about an approach to a task is a red flag signaling that you need to communicate with your customers and figure this out. If you do not how many systems you will need to integrate with, you will have a hard time decomposing all the stages and tasks related to integration. In this case, we need to call the customer and quickly discover the necessary information. However, you may have hundreds of such questions during the estimation process, and tracking new information will quickly become ineffective. It is a good idea to prepare a numbered list of questions first. Answers can change during the estimation process, so each question should be assigned a date. Ideally, those questions should be shared in a format that makes collaboration easy.</p>
<p class="p9">When your outline is detailed enough, it is time to design a software architecture proposal. This is a crucial step because matching outlines with customer requirements is not always economically viable or even possible from a technological standpoint. You should have at least a rough idea of what technologies you will use, how they will integrate with the rest of the customer's system, and how your solution should be deployed. If there are any crucial nonfunctional requirements, such as 24/7 availability, the software architect should also think about how to implement them in terms of technology and system design. Drafting a high-level architecture vision will help explain this outline. Do not hesitate to change the outline if you think that's necessary. Software design is a complex task an experienced engineer should do, so if you do not have deep expertise in designing software solutions, ask for help from someone on your team, or even better, make software design a collaborative effort.</p>
<p class="p9">After you've completed the outline and have a software architecture vision, you can start estimating the project. I recommend using simple statistical estimation procedures such as the <strong>program evaluation and review technique</strong> (<strong>PERT</strong>).</p>
<p class="p9">In PERT, you give each task a three-point estimate:</p>
<ul class="ul1">
<li class="li9"><strong>Optimistic estimate</strong>: The time you plan to spend on the task if everything goes well; minor technical problems and requirements issues may arise.</li>
<li class="li9"><strong>Most likely estimate</strong>: The most realistic estimate you can give for the task.</li>
<li class="li9"><strong>Pessimistic estimate</strong>: The time that's required to finish the task if problems arise. This includes additional risks for dealing with experiments that have gone wrong, complex debugging sessions, and having long debates with the customer.</li>
</ul>
<p class="p9">Then, you can calculate a simple weighted average to get the final estimate:</p>
<p class="p9 CDPAlignCenter CDPAlign"><img class="fm-editor-equation" src="img/5b8ed5ce-4b32-43f4-baec-969771483465.png" style="width:41.00em;height:2.25em;" width="7590" height="420"/></p>
<p class="p9">Calculating the standard deviation is also useful when it comes to making confidence intervals:</p>
<p class="p9 CDPAlignCenter CDPAlign"><img class="fm-editor-equation" src="img/d0a5302f-0c0f-43db-b6cd-50d57bc1856b.png" style="width:34.50em;height:2.33em;" width="6210" height="420"/></p>
<p class="p9"><img class="fm-editor-equation" src="img/ffe349f6-61eb-4b27-9f13-7af82bfc0f42.png" style="width:23.50em;height:1.00em;" width="3990" height="170"/> will give you a 99.7% confidence interval, meaning that the task will end up somewhere between these numbers with a 99.7% probability. If this range is too wide for you, you can use <img class="fm-editor-equation" src="img/db37e54f-236b-4e22-8614-7a4fd948247d.png" style="width:15.17em;height:1.00em;" width="2570" height="170"/>, which will give you a 95.5% confidence interval.</p>
<p class="p8">Use data from any finished projects as a base for relative estimation. The more external resources you use for estimation, the more accurate and risk-averse your estimates will become.</p>
<p class="p8">Since we are ineluctably bad at estimation, all of the estimates are only a rough idea of your current view of the project implementation plan. Project outlines and estimates should constantly change and be adapted to the current situation. You should periodically check whether the original plan should be changed and updated. If so, convey this to the customer and work through the necessity of the changes. It may be that the customer added several new features to your backlog, thinking that they were present in the original scope. If this is not the case, negotiate a scope expansion, followed by a budget and deadline extension. If these features are not critical enough, advise the customer to remove them from the backlog. With each completed task on a particular type of project, your experience will grow. As a result, you will be able to anticipate more of the customer's needs and include them in the base plan, which will make estimates more accurate. Store all of the versions of the project estimations so that you can track all scope changes effortlessly.</p>
<p class="p8">Project architecture vision should also be robust in terms of changes. The more customized your solution is, the less likely it is that it will create an ideal architecture vision that will survive all scope changes. Plan ahead and include several variation points in the parts of your solution that are the most likely to change. A vacation point is a software component (or a set of software components) that was going to change from the start. A plugin architecture and microservices with fixed contracts are examples of variation points that allow for easy extension or substitution.</p>
<p class="mce-root"/>
<p class="mce-root"/>


            

            
        
    </div>
<div><h1 class="header-title">Discovering the goals of the estimation process</h1>
                
            
            
                
<p class="p8">It is important to keep the end goal in mind while making estimations. You can build a data science system without making a grand plan. Creating estimates and keeping them up to date requires a lot of effort and time. Data science projects are complex and unpredictable, so the more you and your customers believe in your estimates, the more likely they're going to fail. Estimates become more uncertain if your team has no prior experience in building solutions for a new business domain or if you are trying to apply new types of algorithms or use new technologies.</p>
<p class="p8">Having a fine-grained view of how to achieve the end goal is useful. In contrast, relying on the exact calculations of how long it will take you, or using extremely detailed outlines, is not. Use estimates wisely; they will help you align your implementation plans with customer demands.</p>


            

            
        
    </div>
<div><h1 class="header-title">Summary</h1>
                
            
            
                
<p class="p8">In this chapter, we looked at how to manage data science projects. We explored how analytical projects differ from software engineering projects and studied the data science project life cycle. We looked at how we can choose a project management methodology that suits our needs and uncovered practical guidelines for estimating data science projects, and also discussed the limitations of long-term plans. No matter how good your plans and estimates are, data science projects have many inherent risks that can become the failing points of your projects.</p>
<p class="p8">In the next chapter, we will look at common pitfalls of data science projects.</p>


            

            
        
    </div></body></html>