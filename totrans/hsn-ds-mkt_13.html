<html><head></head><body>
        

                            
                    <h1 class="header-title">Customer Lifetime Value</h1>
                
            
            
                
<p>In this chapter, we are going to focus on the second use case of predictive analytics in marketing, the customer lifetime value that we discussed in the previous chapter. In marketing, it is always a challenge to budget for marketing campaigns. We do not want to spend too much and result in a negative ROI. However, we also do not want to spend too little and have no visible impact or outcome. When determining the budget for a marketing strategy, it is essential to know what the expected return will be from running a given marketing campaign. Understanding what the <strong>customer lifetime value</strong> (<strong>CLV</strong>) is for individual customers can help marketers justify their marketing budget, as well as target potential high-value customers. In this chapter, we are going to discuss in more detail the concept and the advantage of calculating the CLV, as well as how to build a predictive machine learning model to predict the expected CLV for individual customers in Python and R.</p>
<p>In this chapter, we will cover the following topics:</p>
<ul>
<li>CLV</li>
<li>Evaluation metrics for regression models</li>
<li>Predicting the 3 month CLV with Python</li>
<li>Predicting the 3 month CLV with R</li>
</ul>


            

            
        
    

        

                            
                    <h1 class="header-title">CLV</h1>
                
            
            
                
<p>In marketing, the CLV is one of the key metrics to have and monitor. The CLV measures customers' total worth to the business over the course of their lifetime relationship with the company. This metric is especially important to keep track of for acquiring new customers. It is generally more expensive to acquire new customers than to keep existing customers, so knowing the lifetime value and the costs associated with acquiring new customers is essential in order to build marketing strategies with a positive ROI. For example, if the average CLV of your customer is $100 and it only costs $10 to acquire a new customer, then your business will be generating more revenue as you acquire new customers.</p>
<p class="mce-root"/>
<p class="mce-root"/>
<p>However, if it costs $150 to acquire a new customer and the average CLV of your customer is still $100, then you will be losing money for each acquisition. Simply put, if your marketing spend for new customer acquisition exceeds the CLV, you will be losing money for each acquisition, and it is better to just work with the existing customers. </p>
<p>There are multiple ways to calculate CLV. One way is to find the customer's average purchase amount, purchase frequency, and lifetime span and do a simple calculation to get the CLV. For example, think of a hypothetical case, where a customer's average purchase amount is $100 and he or she makes purchases five times every month on average. Then this customer's average value per month is $500, which is simply multiplying the average purchase amount with the average purchase frequency. Now, we need to know this customer's lifetime span. One way to estimate a customer's lifetime span is to look at the average monthly churn rate, which is the percentage of customers leaving and terminating the relationship with your business. You can estimate a customer's lifetime span by dividing one by the churn rate. Assuming 5% of the churn rate in our hypothetical case, the estimated customer's lifetime span is 20 years. Given the customer's average value per month of $500 and lifetime span of 20 years, the CLV of this customer turns out to be $120,000. This final CLV amount is calculated by multiplying $500, the average value per month, by 12 months and the lifetime span of 20 years.</p>
<p>Because we do not typically know the lifetime span of customers, we often try to estimate CLV over the course of a certain period. It can be done by estimating a customer's 12-month CLV, 24-month CLV, or can also be a 3-month CLV. Aside from the method we discussed through an example, CLV can also be estimated through building predictive models. Using machine learning algorithms and customers' purchase history data, we can build machine learning models that predict customers' CLV over the course of a certain period. In the programming exercises in this chapter, we are going to learn how to build a regression model that predicts customers' 3-month CLV.</p>


            

            
        
    

        

                            
                    <h1 class="header-title">Evaluating regression models</h1>
                
            
            
                
<p>We need to use a different set of metrics for evaluating regression models from those for classification model evaluations. This is because the prediction output of a regression model takes continuous values, meaning it can take any value and is not restricted to taking from a predefined set of values. On the other hand, as we have seen in <a href="4f5163a1-c34a-495f-bc5f-e02f9b2a2052.xhtml" target="_blank">Chapter 8</a>, <em>Predicting the Likelihood of Marketing Engagement</em>, the prediction output of a classification model can only take a certain number of values. As was the case for the engagement prediction, our classification model from the previous chapter could only take two values—zero for no engagement and one for engagement. Because of this difference, we need to use different metrics to evaluate regression models.</p>
<p>In this section, we are going to discuss four commonly used methodologies to evaluate regression models—<strong>mean squared error</strong> (<strong>MSE</strong>), <strong>median absolute error</strong> (<strong>MAE</strong>), <em>R<sup>2</sup></em>, and predicted versus actual scatter plot. As the name suggests, MSE measures the average of the squared errors, where the errors are the differences between the predicted and actual values. The equation for <em>MSE</em> looks as follows:</p>
<p class="CDPAlignCenter CDPAlign"><img class="fm-editor-equation" src="img/df961a94-c63a-455d-baaa-f02de0eb111a.png" style="width:14.00em;height:3.75em;"/></p>
<p>The <em>Y</em> values in this equation are the actual values and <em>Y' </em>values are the predicted values. Because MSE is an average of squared errors, this measure is sensitive to and highly affected by outliers. </p>
<p>The MAE, on the other hand, is less sensitive to outliers and considered more robust, as the median is affected by the outliers or values at the end tails much less than the average. The equation, borrowed from this <kbd>scikit-learn</kbd> documentation page, <a href="https://scikit-learn.org/stable/modules/model_evaluation.html#median-absolute-error">https://scikit-learn.org/stable/modules/model_evaluation.html#median-absolute-error</a>, looks as follows:</p>
<p class="CDPAlignCenter CDPAlign"><img class="fm-editor-equation" src="img/19aeba3e-bfca-4e51-b991-91e483b583ba.png" style="width:26.58em;height:1.50em;"/></p>
<p>The <em>y</em> values in this equation represent the actual values and the <img class="fm-editor-equation" src="img/961dcb23-3ac8-4cd7-b07a-e5beeaaebc0d.png" style="width:0.83em;height:1.58em;"/> values represent the predicted values.</p>
<p>Another frequently used measure for regression models is <em>R<sup>2</sup></em>, also called the coefficient of determination. <em>R<sup>2</sup></em> measures the goodness of fit. In other words, it measures how well a regression model is fitted to the data. Simply put, <em>R<sup>2</sup></em> is the percentage of the explained variability of the target variable by the regression model. The equation looks as follows:</p>
<p class="CDPAlignCenter CDPAlign"><img class="fm-editor-equation" src="img/d07966c9-3620-4cb9-a62d-eeb514756e3c.png" style="width:11.75em;height:2.17em;"/></p>
<p><em>R<sup>2</sup></em> typically ranges between zero and one. The <em>R<sup>2</sup></em> value of zero means the model does not explain or capture the target variable variability at all and is not a good fit to the data. On the other hand, the <em>R<sup>2</sup></em> value of one means that the model captures 100% of the target variable variability and is a perfect fit to the data. The closer to one the <em>R<sup>2</sup></em> value is, the better the model fit is.</p>
<p>Lastly, a scatter plot of predicted values against actual values is also used to visualize how closely the model fits. An example of this scatter plot looks like the following:</p>
<p class="CDPAlignCenter CDPAlign"><img class="alignnone size-full wp-image-1275 image-border" src="img/fb192e2b-eec1-4f51-a8c5-e0123c35a3c7.png" style="width:31.00em;height:21.08em;"/></p>
<p>For a good fit, you will see points in this scatter plot that are close to the diagonal line. If the model's <em>R<sup>2</sup></em> is high, the points will be close to the diagonal line. On the other hand, if the model's <em>R<sup>2</sup></em> is low, the points will be dispersed away from the diagonal line. In the following programming exercises, we will discuss how to compute and visualize these measures in Python and R, and will use these measures to evaluate our regression model.</p>


            

            
        
    

        

                            
                    <h1 class="header-title">Predicting the 3 month CLV with Python</h1>
                
            
            
                
<p>In this section, we are going to discuss how to build and evaluate regression models using machine learning algorithms in Python. By the end of this section, we will have built a predictive model using a linear regression algorithm to predict the CLV<strong>, </strong>more specifically, the expected 3 month customer value. We will be mainly using the <kbd>pandas</kbd>, <kbd>matplotlib</kbd>, and <kbd>scikit-learn</kbd> packages to analyze, visualize, and build machine learning models that predict the expected 3 month customer value. For those readers who would like to use R instead of Python for this exercise, you can skip to the next section.</p>
<p>For this exercise, we will be using one of the publicly available datasets from the UCI Machine Learning Repository, which can be found at this link: <a href="http://archive.ics.uci.edu/ml/datasets/online+retail">http://archive.ics.uci.edu/ml/datasets/online+retail</a>.</p>
<p class="mce-root"/>
<p class="mce-root"/>
<p>You can follow this link and download the data that is available in XLSX format, named <kbd>Online Retail.xlsx</kbd>. Once you have downloaded this data, you can load it into your Jupyter Notebook by running the following command:</p>
<pre>import pandas as pd<br/><br/>df = pd.read_excel('../data/Online Retail.xlsx', sheet_name='Online Retail')</pre>
<p>The DataFrame, <kbd>df</kbd>, looks as follows:</p>
<p class="CDPAlignCenter CDPAlign"><img class="alignnone size-full wp-image-1276 image-border" src="img/a9eb6cfd-3f17-4def-a284-75d9244a0dad.png" style="width:152.50em;height:56.83em;"/></p>
<p>As you might have noticed, we have used this dataset a few times in the previous chapters. With the knowledge we gained about this dataset from the previous chapters, we are going to first prepare our data by cleaning it up.</p>


            

            
        
    

        

                            
                    <h1 class="header-title">Data cleanup</h1>
                
            
            
                
<p>As you might recall, there are a few things we need to clean up in this dataset. The clean-up steps are as follows:</p>
<ol>
<li><strong>Handling negative quantity</strong>: There are transactions with a negative <kbd>Quantity</kbd> value, which represent canceled orders. We are going to ignore those canceled orders for this exercise, so we will need to exclude them from our <kbd>pandas</kbd> DataFrame. The code to exclude these negative values in the <kbd>Quantity</kbd> column looks as follows:</li>
</ol>
<pre>        df = df.loc[df['Quantity'] &gt; 0]</pre>
<p class="mce-root"/>
<p style="padding-left: 60px">We are simply taking all of those rows with a positive <kbd>Quantity</kbd> value and storing them back to the <kbd>df</kbd> variable. </p>
<ol start="2">
<li><strong>Dropping </strong><strong>NaN</strong><strong> records</strong>: We need to drop records with no <kbd>CustomerID</kbd>. Since we are going to build a machine learning model to predict the 3 month customer value, we need to group the data by the <kbd>CustomerID</kbd> column. Without it, we cannot properly build models for this project. The code to drop records with no <kbd>CustomerID</kbd> values looks like the following code snippet:<br/></li>
</ol>
<pre>        df = df[pd.notnull(df['CustomerID'])]</pre>
<p style="padding-left: 60px">As you can see from this code, we are using the <kbd>notnull</kbd> function in the <kbd>pandas</kbd> package. This function returns a list of arrays, where <kbd>True</kbd> values indicate that the value in the given index is not <kbd>null</kbd> and <kbd>False</kbd> values indicate that the value in the given index is <kbd>null</kbd>. We store these records with not null values in the <kbd>CustomerID</kbd> column back to the <kbd>df</kbd> variable.</p>
<ol start="3">
<li class="CDPAlignLeft CDPAlign"><strong>Handling incomplete data</strong>: Another cleanup we need to do is to handle incomplete data. If you recall from previous chapters, the transaction data for the last month is incomplete. Take a look at the following output:</li>
</ol>
<p class="CDPAlignCenter CDPAlign"><img class="alignnone size-full wp-image-1277 image-border" src="img/a3af534f-d396-4326-99bb-56e0fc12fd39.png" style="width:39.83em;height:3.67em;"/></p>
<p class="CDPAlignLeft CDPAlign" style="padding-left: 60px">As you can see from this output, the dataset has all of the transactions between December 1, 2010 and December 9, 2011. The data for the last month, December 2011, is not complete. In order to properly build a model for the 3 month customer value predictions, we are going to ignore the transactions in the last month. Take a look at the following code that shows how to drop those records from our DataFrame:<br/></p>
<pre>        df = df.loc[df['InvoiceDate'] &lt; '2011-12-01']</pre>
<p style="padding-left: 60px">We are simply taking all of the transactions that occurred before December 01, 2011 and storing them back to the <kbd>df</kbd> variable. </p>
<ol start="4">
<li><strong>Total sales value</strong>: Lastly, we need to create a column for the total sales value for each transaction. Take a look at the following code:</li>
</ol>
<pre>        df['Sales'] = df['Quantity'] * df['UnitPrice']</pre>
<p style="padding-left: 60px">We are multiplying the <kbd>Quantity</kbd> column by the <kbd>UnitPrice</kbd> column to get the total purchase amount for each transaction. Then, we store these values into a column named <kbd>Sales</kbd>. We have now completed all of the clean-up tasks. </p>
<p style="padding-left: 60px">Now we have cleaned up all of the transaction data, let's summarize this data for each order or <kbd>InvoiceNo</kbd>. Take a look at the following code:</p>
<pre>        orders_df = df.groupby(['CustomerID', 'InvoiceNo']).agg({<br/>            'Sales': sum,<br/>            'InvoiceDate': max<br/>        })</pre>
<p style="padding-left: 60px">As you can see from this code, we are grouping the <kbd>DataFrame</kbd> <kbd>df</kbd> by two columns, <kbd>CustomerID</kbd> and <kbd>InvoiceNo</kbd>. Then, we are summing up all of the <kbd>Sales</kbd> values for each customer and order, and taking the last transaction time for the given order as <kbd>InvoiceDate</kbd>. This way we now have a <kbd>DataFrame</kbd>, <kbd>orders_df</kbd>, as we need to know about each order that each customer placed. The data looks like the following:</p>
<p class="CDPAlignCenter CDPAlign"><img class="alignnone size-full wp-image-1278 image-border" src="img/ff405d41-3509-416f-a52b-97f8687aa1ff.png" style="width:31.00em;height:28.33em;"/></p>
<p>Before we dive into building models, let's take a closer look at this customer purchase history data.</p>


            

            
        
    

        

                            
                    <h1 class="header-title">Data analysis</h1>
                
            
            
                
<p>In order to calculate the CLV, we need to know the frequency, recency, and total amount of purchases by each customer. We are going to compute basic information about each customer's average and lifetime purchase amount, as well as each customer's duration and frequency of purchases. Take a look at the following code:</p>
<pre>def groupby_mean(x):<br/>    return x.mean()<br/><br/>def groupby_count(x):<br/>    return x.count()<br/><br/>def purchase_duration(x):<br/>    return (x.max() - x.min()).days<br/><br/>def avg_frequency(x):<br/>    return (x.max() - x.min()).days/x.count()<br/><br/>groupby_mean.__name__ = 'avg'<br/>groupby_count.__name__ = 'count'<br/>purchase_duration.__name__ = 'purchase_duration'<br/>avg_frequency.__name__ = 'purchase_frequency'<br/><br/>summary_df = orders_df.reset_index().groupby('CustomerID').agg({<br/>    'Sales': [min, max, sum, groupby_mean, groupby_count],<br/>    'InvoiceDate': [min, max, purchase_duration, avg_frequency]<br/>})</pre>
<p>We first group by the <kbd>CustomerID</kbd> column and aggregate the numbers by <kbd>Sales</kbd> and <kbd>InvoiceDate</kbd> columns. If you look closely at the aggregation functions, we are using four customer aggregation functions: <kbd>groupby_mean</kbd>, <kbd>groupby_count</kbd>, <kbd>purchase_duration</kbd>, and <kbd>avg_frequency</kbd>. The first function, <kbd>groupby_mean</kbd>, simply computes the average for each group and the second function, <kbd>groupby_count</kbd>, simply counts the number of records in each group. The <kbd>purchase_duration</kbd> function counts the number of days between the first and last invoice dates in each group and the <kbd>avg_frequency</kbd> function calculates the average number of days between orders by dividing <kbd>purchase_duration</kbd> by the number of orders.</p>
<p>The resulting <kbd>DataFrame</kbd> looks like the following:</p>
<p class="CDPAlignCenter CDPAlign"><img class="alignnone size-full wp-image-1279 image-border" src="img/e08ded75-3b01-4dd6-867a-70ca5df000ab.png" style="width:155.08em;height:67.00em;"/></p>
<p>This data gives us an idea of the purchases each customer has made. For example, the customer with ID <kbd>12346</kbd> only made one purchase on January 18, 2011. However, the customer with ID <kbd>12347</kbd> has made six purchases that range from December 7, 2010 to October 31, 2011, or over the course of <kbd>327</kbd> days. The average amount this customer spent on each order is <kbd>680</kbd> and, on average, this customer made a purchase every <kbd>54.5</kbd> days.</p>
<p>Let's take a closer look at the distributions of the number of purchases that the repeat customers have made.</p>
<p>Take a look at the following code:</p>
<pre>summary_df.columns = ['_'.join(col).lower() for col in summary_df.columns]<br/>summary_df = summary_df.loc[summary_df['invoicedate_purchase_duration'] &gt; 0]<br/><br/>ax = summary_df.groupby('sales_count').count()['sales_avg'][:20].plot(<br/>    kind='bar', <br/>    color='skyblue',<br/>    figsize=(12,7), <br/>    grid=True<br/>)<br/><br/>ax.set_ylabel('count')<br/><br/>plt.show()</pre>
<p class="mce-root"/>
<p class="mce-root"/>
<p>As you can see from this code, we clean up the column names of the DataFrame, <kbd>summary_df</kbd>, in the first line. Then, we are only taking the customers who have made at least two or more purchases, which represents repeat customers. Lastly, we group by the <kbd>sales_count</kbd> column and count how many customers belong to each category. The resulting plot looks as follows:</p>
<p class="CDPAlignCenter CDPAlign"><img class="alignnone size-full wp-image-1280 image-border" src="img/449becae-6f10-4e97-985c-08c3d53b7023.png" style="width:62.08em;height:37.67em;"/></p>
<p>As you can see from this plot, the majority of customers have made 10 or less purchases historically. Let's take a look at the average number of days between purchases for these repeat customers. Take a look at the following code first:</p>
<pre>ax = summary_df['invoicedate_purchase_frequency'].hist(<br/>    bins=20,<br/>    color='skyblue',<br/>    rwidth=0.7,<br/>    figsize=(12,7)<br/>)<br/><br/>ax.set_xlabel('avg. number of days between purchases')<br/>ax.set_ylabel('count')<br/><br/>plt.show()</pre>
<p>We are building a histogram with the purchase frequency data using the <kbd>hist</kbd> function in the <kbd>pandas</kbd> package. The <kbd>bins</kbd> parameter defines the number of histogram bins to build. The result looks as follows:</p>
<p class="CDPAlignCenter CDPAlign"><img class="alignnone size-full wp-image-1281 image-border" src="img/7f913c60-4b71-4ffe-aa3f-1c8c10660bbe.png" style="width:61.75em;height:36.58em;"/></p>
<p>This plot tells us the overall view of how frequently repeat customers made purchases historically. As you can see from this plot, the majority of repeat customers made purchases every 20 to 50 days. </p>


            

            
        
    

        

                            
                    <h1 class="header-title">Predicting the 3 month CLV</h1>
                
            
            
                
<p>In this section, we are going to build a model that predicts the 3 month customer value using the <kbd>pandas</kbd> and <kbd>scikit-learn</kbd> packages in Python. We are going to first slice the data into chunks of 3 months and take the last 3 months' data as the target for predictions and the rest as the features. We will first prepare our data for model building and then train a linear regression model for the 3 month customer value predictions.</p>


            

            
        
    

        

                            
                    <h1 class="header-title">Data preparation</h1>
                
            
            
                
<p>In order to build a predictive model, we need to prepare our data first, so that we can feed the relevant data into the model. Take a look at the following code:</p>
<pre>clv_freq = '3M'<br/><br/>data_df = orders_df.reset_index().groupby([<br/>    'CustomerID',<br/>    pd.Grouper(key='InvoiceDate', freq=clv_freq)<br/>]).agg({<br/>    'Sales': [sum, groupby_mean, groupby_count],<br/>})<br/><br/>data_df.columns = ['_'.join(col).lower() for col in data_df.columns]<br/>data_df = data_df.reset_index()</pre>
<p>Since we want to predict the 3 month customer value, we are breaking down the data into chunks of 3 months for each customer. As you can see in the <kbd>groupby</kbd> function, we group the previously built DataFrame <kbd>orders_df</kbd> by <kbd>CustomerID</kbd> and a custom <kbd>Grouper</kbd>, which groups <kbd>InvoiceDate</kbd> by every 3 months. Then, for each group of 3 month time windows, we sum up all of the sales to get the total purchase amount, take the average of purchase amount and the total number of purchases for the given period for each customer. This way we have aggregate data that has purchase information for each customer for every 3 months. Lastly, we do some cleanup for the column names. The data in <kbd>data_df</kbd> now looks like the following:</p>
<p class="CDPAlignCenter CDPAlign"><img class="alignnone size-full wp-image-1284 image-border" src="img/33c49877-1890-4c97-8648-38c7ad25ab60.png" style="width:31.08em;height:22.25em;"/></p>
<p>In order to make things simpler, let's encode the <kbd>InvoiceDate</kbd> column values so that they are easier to read than the current date format. Take a look at the following code:</p>
<pre>date_month_map = {<br/>    str(x)[:10]: 'M_%s' % (i+1) for i, x in enumerate(<br/>        sorted(data_df.reset_index()['InvoiceDate'].unique(), reverse=True)<br/>    )<br/>}<br/><br/>data_df['M'] = data_df['InvoiceDate'].apply(lambda x: date_month_map[str(x)[:10]])</pre>
<p>As you can see from this code, we are encoding date values into <kbd>M_1</kbd>, <kbd>M_2</kbd>, <kbd>M_3</kbd>, and so forth, where the smaller number represents more recent dates. For example, the date <kbd>2011-12-31</kbd> is now encoded as <kbd>M_1</kbd> and the date <kbd>2011-09-30</kbd> is now encoded as <kbd>M_2</kbd>. The result looks as follows:</p>
<p class="CDPAlignCenter CDPAlign"><img class="alignnone size-full wp-image-1285 image-border" src="img/379317cf-1ae3-4426-b577-ebe2c341ac7e.png" style="width:29.25em;height:19.75em;"/></p>
<p>We are now ready to build a sample set with features and target variables. As briefly mentioned before, we are going to use the last 3 months as the target variable and the rest as the features, meaning we are going to train a machine learning model that predicts the last 3 months' customer value with the rest of the data. In order to train such a model, we need to transform this data into tabular data, where the rows represent the individual customers and the columns represent each feature. Take a look at the following code:</p>
<pre>features_df = pd.pivot_table(<br/>    data_df.loc[data_df['M'] != 'M_1'], <br/>    values=['sales_sum', 'sales_avg', 'sales_count'], <br/>    columns='M', <br/>    index='CustomerID'<br/>)<br/><br/>features_df.columns = ['_'.join(col) for col in features_df.columns]</pre>
<p>As you can see from this code, we use the <kbd>pandas</kbd> function, <kbd>pivot_table</kbd>, where the index is going to be <kbd>CustomerID</kbd> and the columns are going to be <kbd>sales_sum</kbd>, <kbd>sales_avg</kbd>, and <kbd>sales_count</kbd> for each 3 month period. The DataFrame, <kbd>features_df</kbd>, that we created here looks like the following:</p>
<p class="CDPAlignCenter CDPAlign"><img class="alignnone size-full wp-image-1286 image-border" src="img/de663bc6-6fdc-42c6-896c-c7110483f16c.png" style="width:162.50em;height:60.50em;"/></p>
<p>You might notice that this data has <kbd>NaN</kbd> values. We can encode these <kbd>NaN</kbd> values with <kbd>0.0</kbd> using the following code:</p>
<pre>features_df = features_df.fillna(0)</pre>
<p>Now that we have built the features DataFrame, let's build the target variables. Take a look at the following code:</p>
<pre>response_df = data_df.loc[<br/>    data_df['M'] == 'M_1',<br/>    ['CustomerID', 'sales_sum']<br/>]<br/><br/>response_df.columns = ['CustomerID', 'CLV_'+clv_freq]</pre>
<p>As you can see from this code, we are taking the last 3 month period, the <kbd>M_1</kbd> group, as the target variable. The target column will be <kbd>sales_sum</kbd>, as we want to predict the next 3 month customer value, which is the total purchase amount that a given customer is likely to make in the next 3 months. The target variable looks like the following:</p>
<p class="CDPAlignCenter CDPAlign"><img class="alignnone size-full wp-image-1287 image-border" src="img/4340c6c8-7f71-45f5-acdd-c4f56f1823b1.png" style="width:21.92em;height:24.75em;"/></p>
<p>There is only one thing left to build, which is a sample set for building machine learning models, combining features and response data together. Take a look at the following code:</p>
<pre>sample_set_df = features_df.merge(<br/>    response_df, <br/>    left_index=True, <br/>    right_on='CustomerID',<br/>    how='left'<br/>)<br/><br/>sample_set_df = sample_set_df.fillna(0)</pre>
<p class="mce-root"/>
<p>As you can see here, we are simply joining the two <kbd>DataFrames</kbd> on <kbd>CustomerID</kbd>, using the <kbd>merge</kbd> function. By having the <kbd>how='left'</kbd> flag, we take all records in the features data, even if there is no corresponding data in the response data. This is a case where the given customer did not make any purchases in the last 3 months, so we encode them as zero. The final sample set now looks as follows:</p>
<p class="CDPAlignCenter CDPAlign"><img class="alignnone size-full wp-image-1288 image-border" src="img/15154c88-06d5-4b5a-a549-380ca1644e47.png" style="width:162.50em;height:48.08em;"/></p>
<p>With this data, we can now build a model that predicts the next 3 month customer value with historical purchase data.</p>


            

            
        
    

        

                            
                    <h1 class="header-title">Linear regression</h1>
                
            
            
                
<p>Similar to the previous chapter, we are going to split the sample set into train and test sets, using the following code:</p>
<pre>from sklearn.model_selection import train_test_split<br/><br/>target_var = 'CLV_'+clv_freq<br/>all_features = [x for x in sample_set_df.columns if x not in ['CustomerID', target_var]]<br/><br/>x_train, x_test, y_train, y_test = train_test_split(<br/>    sample_set_df[all_features], <br/>    sample_set_df[target_var], <br/>    test_size=0.3<br/>)</pre>
<p>As you can see from this code, we are taking 70% of the sample set for training the model and the remaining 30% for testing and evaluating the model performance. In this section, we will be using a linear regression model. However, we recommend experimenting with other machine learning algorithms, such as random forest and <strong>support vector machine</strong> (<strong>SVM</strong>). </p>
<p>More details on how to train these models with the <kbd>scikit-learn</kbd> package can be found at the following links: <a href="https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestRegressor.html">https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestRegressor.html</a> and <a href="https://scikit-learn.org/stable/modules/generated/sklearn.svm.SVR.html">https://scikit-learn.org/stable/modules/generated/sklearn.svm.SVR.html</a>.<a href="https://scikit-learn.org/stable/modules/generated/sklearn.svm.SVR.html"/></p>
<p>In order to train a linear regression model with our dataset, you can use the following code:</p>
<pre>from sklearn.linear_model import LinearRegression<br/><br/>reg_fit = LinearRegression()<br/>reg_fit.fit(x_train, y_train)</pre>
<p>This is as simple as it gets. You import the <kbd>LinearRegression</kbd> class of the <kbd>scikit-learn</kbd> package and initiate a <kbd>LinearRegression</kbd> object. Then, you can train a linear regression model using the <kbd>fit</kbd> function with the <kbd>x_train</kbd> features and the <kbd>y_train</kbd> targets.</p>
<p>Once a linear regression model is trained, there is some useful information that you can find in the <kbd>LinearRegression</kbd> object. First, you can get the intercept of the linear regression equation, using the <kbd>intercept_</kbd> attribute of the <kbd>LinearRegression</kbd> object, like the following:</p>
<pre>reg_fit.intercept_</pre>
<p>Also, you can find the fitted linear regression model's coefficients, using the <kbd>coef_</kbd> attribute like the following code:</p>
<pre>reg_fit.coef_</pre>
<p>The coefficients of each feature of the fitted regression model look as follows:</p>
<p class="CDPAlignCenter CDPAlign"><img class="alignnone size-full wp-image-1289 image-border" src="img/068cb89f-24b8-4507-b823-65dbb533af54.png" style="width:37.42em;height:27.75em;"/></p>
<p class="mce-root">As you can see from this coefficient output, you can easily find which features have negative correlation with the target and which features have positive correlation with the target. For example, the previous 3 month period's average purchase amount, <kbd>sales_avg_M_2</kbd>, has negative impacts on the next 3 month customer value. This means that the higher the previous 3 month period's purchase amount is, the lower the next 3 month purchase amount will be. On the other hand, the second and third most recent 3 month period's average purchase amounts, <kbd>sales_avg_M_3</kbd> and <kbd>sales_avg_M_4</kbd>, are positively correlated with the next 3 month customer value. In other words, the more a customer made purchases 3 months to 9 months ago, the higher value he or she will bring in the next 3 months. Looking at the coefficients is one way to gain insights on how the expected value will change, given certain features.</p>
<p class="mce-root"/>
<p class="mce-root"/>
<p>Using the 3 month customer value prediction output, you can custom-tailor your marketing strategies in different ways. Since you know the expected revenue or purchase amount from individual customers for the next 3 months, you can set a better informed budget for your marketing campaign. It should be set high enough to reach your target customers, but low enough to be below the expected 3 month customer value, so that you can have a positive ROI marketing campaign. On the other hand, you can also use these 3 month customer value prediction output values to specifically target these high-value customers for the next 3 months. This can help you to create marketing campaigns with a higher ROI, as those high-value customers, predicted by this model, are likely to bring in more revenue than the others.</p>


            

            
        
    

        

                            
                    <h1 class="header-title">Evaluating regression model performance</h1>
                
            
            
                
<p>Now that we have a machine learning model that is fitted to predict the 3 month customer value, let's discuss how to evaluate the performance of this model. As discussed previously, we are going to use <em>R<sup>2</sup></em>, MAE, and a scatter plot of predicted versus actual to evaluate our model. We need to get the prediction output from our model first, as shown in the following code:</p>
<pre>train_preds = reg_fit.predict(x_train)<br/>test_preds = reg_fit.predict(x_test)</pre>
<p>The <kbd>scikit-learn</kbd> package has implemented the functions to compute the <em>R<sup>2</sup></em> and the MAE in their <kbd>metrics</kbd> module. You can use these functions by importing them into your environment, like the following code:</p>
<pre>from sklearn.metrics import r2_score, median_absolute_error</pre>
<p>As the names suggest, the <kbd>r2_score</kbd> function computes the <em>R<sup>2</sup></em> and the <kbd>median_absolute_error</kbd> function computes the MAE. You can compute the <em>R</em><em><sup>2</sup></em> and MAE numbers, using the following code:</p>
<pre>r2_score(y_true=y_train, y_pred=train_preds)<br/>median_absolute_error(y_true=y_train, y_pred=train_preds)</pre>
<p>As you can see from here, both functions take two parameters, <kbd>y_true</kbd> and <kbd>y_pred</kbd>. The <kbd>y_true</kbd> parameter is for the actual target values and the <kbd>y_pred</kbd> parameter is for the predicted target values. Using these codes, the in-sample and out-of-sample values for R<sup>2</sup> and MAE in our case look like the following output:</p>
<p class="CDPAlignCenter CDPAlign"><img class="alignnone size-full wp-image-1290 image-border" src="img/eca7324c-292f-46d9-9ac2-80f1f24565af.png" style="width:139.17em;height:50.33em;"/></p>
<p>Due to the randomness in splitting the sample set into train and test sets, your might differ from these results. In our case, the in-sample R<sup>2</sup> was <kbd>0.4445</kbd> and the out-of-sample R<sup>2</sup> was <kbd>0.7947</kbd>. On the other hand, the in-sample MAE was <kbd>178.2854</kbd> and the out-of-sample MAE was <kbd>178.7393</kbd>. Looking at these numbers, we do not necessarily see a hint of overfitting or a big gap between the in-sample and out-of-sample performances. </p>
<p>Lastly, let's take a look at the scatter plot of predicted versus actual. You can use the following code for this scatter plot:</p>
<pre>plt.scatter(y_test, test_preds)<br/>plt.plot([0, max(y_test)], [0, max(test_preds)], color='gray', lw=1, linestyle='--')<br/><br/>plt.xlabel('actual')<br/>plt.ylabel('predicted')<br/>plt.title('Out-of-Sample Actual vs. Predicted')<br/>plt.grid()<br/><br/>plt.show()</pre>
<p>The resulting plot looks as follows:</p>
<p class="CDPAlignCenter CDPAlign"><img src="img/17145852-4938-4328-ae5a-9fd7ed9a18bb.png" style="width:27.25em;height:18.58em;"/></p>
<p>As you can see from this plot, the <em>x</em>-values are the actual values and the <em>y</em>-values are the predicted values. As discussed earlier, the more the points that are on the straight line, the better the predictions are. This is because points on the straight line suggest that the actual values and the predicted values are close to each other. Looking at this plot, the points seem to be positioned around the straight line, which suggests that the predictions and the actual values are not too far apart from each other.</p>
<p>The full code for this Python exercise can be found at the following repository: <a href="https://github.com/yoonhwang/hands-on-data-science-for-marketing/blob/master/ch.9/python/CustomerLifetimeValue.ipynb">https://github.com/yoonhwang/hands-on-data-science-for-marketing/blob/master/ch.9/python/CustomerLifetimeValue.ipynb</a>.<a href="https://github.com/yoonhwang/hands-on-data-science-for-marketing/blob/master/ch.9/python/CustomerLifetimeValue.ipynb"/></p>


            

            
        
    

        

                            
                    <h1 class="header-title">Predicting the 3 month CLV with R</h1>
                
            
            
                
<p>In this section, we are going to discuss how to build and evaluate regression models using machine learning algorithms in R. By the end of this section, we will have built a predictive model using a linear regression algorithm to predict the CLV, more specifically, the expected 3 month customer value. We will be using a handful of R packages, such as <kbd>dplyr</kbd>, <kbd>reshape2</kbd>, and <kbd>caTools</kbd>, to analyze, transform, and prepare the data for building machine learning models to predict the expected 3 month customer value. For those readers who would like to use Python instead of R for this exercise, you can refer to the previous section.</p>
<p class="mce-root"/>
<p>For this exercise, we will be using one of the publicly available datasets from the UCI Machine Learning Repository, which can be found at this link: <a href="http://archive.ics.uci.edu/ml/datasets/online+retail">http://archive.ics.uci.edu/ml/datasets/online+retail</a>. You can follow this link and download the data that is available in XLSX format, named <kbd>Online Retail.xlsx</kbd>. Once you have downloaded this data, you can load it into your R environment by running the following command:</p>
<pre>library(dplyr)<br/>library(readxl)<br/><br/>#### 1. Load Data ####<br/>df &lt;- read_excel(<br/>  path="~/Documents/data-science-for-marketing/ch.9/data/Online Retail.xlsx", <br/>  sheet="Online Retail"<br/>)</pre>
<p>The DataFrame, <kbd>df</kbd>, looks as follows:</p>
<p class="CDPAlignCenter CDPAlign"><img class="alignnone size-full wp-image-1295 image-border" src="img/2d1c74f8-8a70-4f8c-8529-b3997cb85879.png" style="width:157.33em;height:61.17em;"/></p>
<p>As you might have noticed, we have used this dataset a few times in the previous chapters. With the knowledge we gained about this dataset from the previous chapters, we are going to first prepare our data by cleaning up the data.</p>
<p class="mce-root"/>
<p class="mce-root"/>


            

            
        
    

        

                            
                    <h1 class="header-title">Data cleanup</h1>
                
            
            
                
<p>As you might recall, there are a few things we need to clean up in this dataset. The clean-up steps are as follows:</p>
<ol>
<li><strong>Handling negative quantity</strong>: There are transactions with a negative <kbd>Quantity</kbd> value, which represent canceled orders. We are going to ignore those canceled orders for this exercise, so we will need to exclude them from our <kbd>DataFrame</kbd>. The code to exclude these negative values in the <kbd>Quantity</kbd> column looks as follows:</li>
</ol>
<pre>        df &lt;- df[which(df$Quantity &gt; 0),]</pre>
<p style="padding-left: 60px">We are simply taking all of those rows with a positive <kbd>Quantity</kbd> value and storing them back to the variable <kbd>df</kbd>. </p>
<ol start="2">
<li><strong>Dropping NA r</strong><strong>ecords</strong>: We need to drop records with no value in the <kbd>CustomerID</kbd> column. Since we are going to build a machine learning model to predict the 3 month customer value, we need to group the data by the <kbd>CustomerID</kbd> column. Without it, we cannot properly build models for this project. The code to drop records with null values looks like the following code snippet: </li>
</ol>
<pre>        df &lt;- na.omit(df)</pre>
<p style="padding-left: 60px">As you can see from this code, we are using the <kbd>na.omit</kbd> function in R. This function returns an object with <kbd>null</kbd> or <kbd>NA</kbd> values removed. Then, we store the output back to the original DataFrame, <kbd>df</kbd> variable.</p>
<ol start="3">
<li class="CDPAlignLeft CDPAlign"><strong>Handling incomplete data</strong>: If you recall from previous chapters, the transaction data for the last month is incomplete. Take a look at the following output:</li>
</ol>
<p class="CDPAlignCenter CDPAlign"><img class="alignnone size-full wp-image-1296 image-border" src="img/aaa9c600-f132-4fee-90ec-67411a59dd9c.png" style="width:38.17em;height:2.58em;"/></p>
<p class="CDPAlignLeft CDPAlign" style="padding-left: 60px">As you can see from this output, the dataset has all the transactions between December 1st, 2010 and December 9, 2011. The data for the last month, December of 2011, is not complete. In order to properly build a model for the 3 month customer value predictions, we are going to ignore the transactions in the last month. Take a look at the following code on how to drop those records from our DataFrame:<br/></p>
<pre>        df &lt;- df[which(df$InvoiceDate &lt; '2011-12-01'),]</pre>
<p style="padding-left: 60px">We are simply taking all of the transactions that occurred before December 1, 2011 and storing them back to the variable, <kbd>df</kbd>. </p>
<ol start="4">
<li><strong>Total sales value</strong>: Lastly, we need to create a column for the total sales value for each transaction. Take a look at the following code:</li>
</ol>
<pre>        df$Sales &lt;- df$Quantity * df$UnitPrice</pre>
<p>We are simply multiplying the <kbd>Quantity</kbd> column by the <kbd>UnitPrice</kbd> column to get the total purchase amount for each transaction. Then, we store these values into a column named <kbd>Sales</kbd>. We have now completed all the cleanup tasks. </p>
<p>Now we have cleaned up all the transaction data, let's summarize this data for each order or <kbd>InvoiceNo</kbd>. Take a look at the following code:</p>
<pre># per order data<br/>ordersDF &lt;- df %&gt;% <br/>  group_by(CustomerID, InvoiceNo) %&gt;% <br/>  summarize(Sales=sum(Sales), InvoiceDate=max(InvoiceDate))</pre>
<p>As you can see from this code, we are grouping <kbd>df</kbd> by two columns, <kbd>CustomerID</kbd> and <kbd>InvoiceNo</kbd>. Then, we are summing up all the <kbd>Sales</kbd> values for each customer and order, and taking the last transaction time for the given order as the <kbd>InvoiceDate</kbd>. This way we now have a DataFrame, <kbd>ordersDF</kbd>, that we need to know about each order that each customer placed. The data looks like the following:</p>
<p class="CDPAlignCenter CDPAlign"><img class="alignnone size-full wp-image-1298 image-border" src="img/0232f5d8-47e5-426d-97f4-0d2f72b64178.png" style="width:26.92em;height:24.08em;"/></p>
<p>Before we dive into building models, let's take a closer look at this customer purchase history data.</p>


            

            
        
    

        

                            
                    <h1 class="header-title">Data analysis</h1>
                
            
            
                
<p>In order to calculate the CLV, we need to know the frequency, recency, and total amount of purchases by each customer. We are going to compute basic information about each customer's average and lifetime purchase amount, as well as each customer's duration and frequency of purchases. Take a look at the following code:</p>
<pre># order amount &amp; frequency summary<br/>summaryDF &lt;- ordersDF %&gt;%<br/>  group_by(CustomerID) %&gt;%<br/>  summarize(<br/>    SalesMin=min(Sales), SalesMax=max(Sales), SalesSum=sum(Sales), <br/>    SalesAvg=mean(Sales), SalesCount=n(),<br/>    InvoiceDateMin=min(InvoiceDate), InvoiceDateMax=max(InvoiceDate), <br/>    PurchaseDuration=as.double(floor(max(InvoiceDate)-min(InvoiceDate))),<br/>    PurchaseFrequency=as.double(floor(max(InvoiceDate)-min(InvoiceDate)))/n()<br/>  )</pre>
<p>We first group by the <kbd>CustomerID</kbd> column and aggregate the numbers by <kbd>Sales</kbd> and <kbd>InvoiceDate</kbd> columns. Using the <kbd>min</kbd>, <kbd>max</kbd>, <kbd>sum</kbd>, <kbd>mean</kbd>, and <kbd>n</kbd> functions in R, we can compute the minimum, maximum, and total purchase amount, as well as the average amount and the number of purchases for each customer. We also use the <kbd>min</kbd> and <kbd>max</kbd> functions to get the first and last order dates for each customer. For <kbd>PurchaseDuration</kbd>, we are taking the number of days between the last and the first order dates. For <kbd>PurchaseFrequency</kbd>, we are dividing the <kbd>PurchaseDuration</kbd> number by the number of orders to get the average number of days between purchases.</p>
<p class="mce-root"/>
<p class="mce-root"/>
<p>The resulting DataFrame, <kbd>summaryDF</kbd>, looks like the following:</p>
<p class="CDPAlignCenter CDPAlign"><img class="alignnone size-full wp-image-1301 image-border" src="img/a3175c13-7c99-4c44-ae47-f08ac0948bf4.png" style="width:51.08em;height:17.33em;"/></p>
<p>This data gives us an idea of the purchases each customer has made. For example, the customer with ID <kbd>12346</kbd> only made one purchase on January 18, 2011. However, the customer with ID <kbd>12347</kbd> has made six purchases that range from December 7, 2010 to October 31, 2011, or over the course of <kbd>327</kbd> days. The average amount this customer spent on each order is about <kbd>681</kbd> and, on average, this customer made a purchase every <kbd>54.5</kbd> days.</p>
<p>Let's take a closer look at the distributions of the number of purchases that the repeat customers have made. Take a look at the following code:</p>
<pre>summaryDF &lt;- summaryDF[which(summaryDF$PurchaseDuration &gt; 0),]<br/><br/>salesCount &lt;- summaryDF %&gt;% <br/>  group_by(SalesCount) %&gt;% <br/>  summarize(Count=n())<br/><br/>ggplot(salesCount[1:19,], aes(x=SalesCount, y=Count)) +<br/>  geom_bar(width=0.5, stat="identity") +<br/>  ggtitle('') +<br/>  xlab("Sales Count") +<br/>  ylab("Count") +<br/>  theme(plot.title = element_text(hjust = 0.5))</pre>
<p>We first exclude customers with only one purchase from our analysis in the first line of code. Then, we count the number of customers for each <kbd>SalesCount</kbd>. Lastly, we create a bar plot using <kbd>ggplot</kbd> and <kbd>geom_bar</kbd> to display this data. The result looks as follows:</p>
<p class="CDPAlignCenter CDPAlign"><img class="alignnone size-full wp-image-1303 image-border" src="img/dbf9950d-c0b6-4061-9472-fd93bc4cebce.png" style="width:31.58em;height:28.17em;"/></p>
<p>As you can see from this plot, the majority of customers have made 10 or less purchases historically. Let's take a look at the average number of days between purchases for these repeat customers. Take a look at the following code first:</p>
<pre>hist(<br/>  summaryDF$PurchaseFrequency, <br/>  breaks=20,<br/>  xlab='avg. number of days between purchases',<br/>  ylab='count',<br/>  main=''<br/>)</pre>
<p class="mce-root"/>
<p>We are building a histogram with the purchase frequency data using the <kbd>hist</kbd> function in R. The <kbd>breaks</kbd> parameter defines the number of histogram bins to build. The result looks as follows:</p>
<p class="CDPAlignCenter CDPAlign"><img class="alignnone size-full wp-image-1304 image-border" src="img/6031bee7-adc4-4f42-918c-e2d66dbe8c27.png" style="width:29.67em;height:20.50em;"/></p>
<p>This plot tells us the overall view of how frequently repeat customers made purchases historically. As you can see from this plot, the majority of repeat customers made purchases every 20 to 50 days. </p>


            

            
        
    

        

                            
                    <h1 class="header-title">Predicting the 3 month CLV</h1>
                
            
            
                
<p>In this section, we are going to build a model that predicts the 3 month customer value in R. We are going to first slice the data into chunks of 3 months and take the last 3 month data as the target for predictions and the rest as the features. We will first prepare our data for model building and then train a linear regression model for the 3 month customer value predictions.</p>


            

            
        
    

        

                            
                    <h1 class="header-title">Data preparation</h1>
                
            
            
                
<p>In order to build a predictive model, we need to prepare our data first, so that we can feed in the relevant data into the model. Take a look at the following code:</p>
<pre># group data into every 3 months<br/>library(lubridate)<br/><br/>ordersDF$Quarter = as.character(round_date(ordersDF$InvoiceDate, '3 months'))<br/><br/>dataDF &lt;- ordersDF %&gt;%<br/>  group_by(CustomerID, Quarter) %&gt;%<br/>  summarize(SalesSum=sum(Sales), SalesAvg=mean(Sales), SalesCount=n())</pre>
<p>As you can see from this code, we are using the <kbd>lubridate</kbd> package that is going to help us to handle data with dates more easily. Using the <kbd>round_date</kbd> function in the <kbd>lubridate</kbd> package, we first round <kbd>InvoiceDate</kbd> to the nearest quarter. Then, we group the data by <kbd>CustomerID</kbd> and the newly-created column, <kbd>Quarter</kbd>, to get the quarterly sales data for each customer. For each group of 3 month time window, we sum up all of the sales to get the total purchase amount and take the average of purchase amount, and the total number of purchases for the given period for each customer. This way we have aggregate data that has purchase information for each customer for every 3 months. The data in <kbd>dataDF</kbd> now looks like the following:</p>
<p class="CDPAlignCenter CDPAlign"><img class="alignnone size-full wp-image-1309 image-border" src="img/8fbd0c64-17c6-4532-9e93-045b613adbc8.png" style="width:29.92em;height:22.67em;"/></p>
<p>In order to make things simpler, let's encode the <kbd>Quarter</kbd> column values to make them easier to read than the current date format. Take a look at the following code:</p>
<pre>dataDF$Quarter[dataDF$Quarter == "2012-01-01"] &lt;- "Q1"<br/>dataDF$Quarter[dataDF$Quarter == "2011-10-01"] &lt;- "Q2"<br/>dataDF$Quarter[dataDF$Quarter == "2011-07-01"] &lt;- "Q3"<br/>dataDF$Quarter[dataDF$Quarter == "2011-04-01"] &lt;- "Q4"<br/>dataDF$Quarter[dataDF$Quarter == "2011-01-01"] &lt;- "Q5"</pre>
<p>As you can see from this code, we are encoding the date values into <kbd>Q1</kbd>, <kbd>Q2</kbd>, <kbd>Q3</kbd>, and so forth, where the smaller number represents more recent dates. For example, the date <kbd>2012-01-01</kbd> is now encoded as <kbd>Q1</kbd> and the date <kbd>2011-10-01</kbd> is now encoded as <kbd>Q2</kbd>. The result looks as follows:</p>
<p class="CDPAlignCenter CDPAlign"><img src="img/6c559f4b-73bd-49e1-82d2-f9c8e9ee2cca.png" style="width:32.50em;height:25.50em;"/></p>
<p>We are now ready to build a sample set with features and target variables. As briefly mentioned before, we are going to use the last 3 months as the target variable and the rest as the features, meaning we are going to train a machine learning model that predicts the last 3 month customer value with the rest of the data. In order to train such a model, we need to transform this data into tabular data, where the rows represent the individual customers and the columns represent each feature. Take a look at the following code:</p>
<pre># install.packages('reshape2')<br/>library(reshape2)<br/><br/>salesSumFeaturesDF &lt;- dcast(<br/>  dataDF[which(dataDF$Quarter != "Q1"),], <br/>  CustomerID ~ Quarter, <br/>  value.var="SalesSum"<br/>)<br/>colnames(salesSumFeaturesDF) &lt;- c("CustomerID", "SalesSum.Q2", "SalesSum.Q3", "SalesSum.Q4", "SalesSum.Q5")<br/><br/>salesAvgFeaturesDF &lt;- dcast(<br/>  dataDF[which(dataDF$Quarter != "Q1"),], <br/>  CustomerID ~ Quarter, <br/>  value.var="SalesAvg"<br/>)<br/>colnames(salesAvgFeaturesDF) &lt;- c("CustomerID", "SalesAvg.Q2", "SalesAvg.Q3", "SalesAvg.Q4", "SalesAvg.Q5")<br/><br/>salesCountFeaturesDF &lt;- dcast(<br/>  dataDF[which(dataDF$Quarter != "Q1"),], <br/>  CustomerID ~ Quarter, <br/>  value.var="SalesCount"<br/>)<br/>colnames(salesCountFeaturesDF) &lt;- c("CustomerID", "SalesCount.Q2", "SalesCount.Q3", "SalesCount.Q4", "SalesCount.Q5")<br/><br/>featuresDF &lt;- merge(<br/>  merge(salesSumFeaturesDF, salesAvgFeaturesDF, by="CustomerID"),<br/>  salesCountFeaturesDF, by="CustomerID"<br/>)<br/>featuresDF[is.na(featuresDF)] &lt;- 0</pre>
<p>As you can see from this code, we are using the <kbd>reshape2</kbd> package to pivot the data. For example, using the <kbd>dcast</kbd> function in the <kbd>reshape2</kbd> package, we first transform the <kbd>SalesSum</kbd> data, where the row index represents each customer or <kbd>CustomerID</kbd>, the columns are each quarter, and the values are the total sales or purchase amount for the given customer and quarter. We repeat this process three times for <kbd>SalesSum</kbd>, <kbd>SalesAvg</kbd>, and <kbd>SalesCount</kbd> columns and merge the data in the end. Using the <kbd>merge</kbd> function, we can merge these DataFrames by the <kbd>CustomerID</kbd> index. Lastly, we encode the <kbd>null</kbd> or <kbd>NA</kbd> values with 0, by using the <kbd>is.na</kbd> function. The result looks like the following:</p>
<p class="CDPAlignCenter CDPAlign"><img class="alignnone size-full wp-image-1322 image-border" src="img/90c833e6-f5c6-499c-bedb-e46a4836123f.png" style="width:162.50em;height:51.83em;"/></p>
<p>Now that we have built the features <kbd>DataFrame</kbd>, let's build the target variables. Take a look at the following code:</p>
<pre>responseDF &lt;- dataDF[which(dataDF$Quarter == "Q1"),] %&gt;% <br/>    select(CustomerID, SalesSum)<br/><br/>colnames(responseDF) &lt;- c("CustomerID", "CLV_3_Month")</pre>
<p>As you can see from this code, we are taking the last 3 month period, <kbd>Q1</kbd> group, as the target variable. The target column will be <kbd>SalesSum</kbd>, as we want to predict the next 3 month customer value, which is the total purchase amount that a given customer is likely to make in the next 3 months. The result looks like the following:</p>
<p class="CDPAlignCenter CDPAlign"><img class="alignnone size-full wp-image-1325 image-border" src="img/612c5361-629a-43f7-8728-81b3cf31d43c.png" style="width:15.42em;height:24.00em;"/></p>
<p>There is only one thing left to build, which is a sample set for building machine learning models, combining features and response data together. Take a look at the following code:</p>
<pre>sampleDF &lt;- merge(featuresDF, responseDF, by="CustomerID", all.x=TRUE)<br/>sampleDF[is.na(sampleDF)] &lt;- 0</pre>
<p>As you can see here, we are simply joining the two <kbd>DataFrames</kbd> on <kbd>CustomerID</kbd> using the <kbd>merge</kbd> function. By having the <kbd>all.x=TRUE</kbd> flag, we take all records in the features data, even if there is no corresponding data in the response data. This is a case where the given customer did not make any purchases in the last 3 months, so we encode them as 0. The final sample set now looks as follows:</p>
<p class="CDPAlignCenter CDPAlign"><img class="alignnone size-full wp-image-1327 image-border" src="img/18c944a9-5933-4b2a-ab76-20467400ca57.png" style="width:162.50em;height:58.67em;"/></p>
<p>With this data, we can now build a model that predicts the next 3 month customer value with historical purchase data.</p>


            

            
        
    

        

                            
                    <h1 class="header-title">Linear regression</h1>
                
            
            
                
<p>Similar to the previous chapter, we are going to split the sample set into train and test sets using the following code:</p>
<pre># train/test set split<br/>library(caTools)<br/><br/>sample &lt;- sample.split(sampleDF$CustomerID, SplitRatio = .8)<br/><br/>train &lt;- as.data.frame(subset(sampleDF, sample == TRUE))[,-1]<br/>test &lt;- as.data.frame(subset(sampleDF, sample == FALSE))[,-1]</pre>
<p>As you can see from this code, we are taking 80% of the sample set for training the model and the remaining 20% for testing and evaluating the model performance. In this section, we will be using a linear regression model. However, we recommend experimenting with other machine learning algorithms, such as <strong>random forest</strong> and <strong>support vector machine (SVM)</strong>. You can train a random forest model with the <kbd>randomForest</kbd> package and an SVM model with the <kbd>e1071</kbd> package. We highly recommend taking a look at their documentation on the usage.</p>
<p>In order to train a linear regression model with our dataset, you can use the following code:</p>
<pre># Linear regression model<br/>regFit &lt;- lm(CLV_3_Month ~ ., data=train)</pre>
<p>This is as simple as it gets. You simply supply a formula, which is <kbd>CLV_3_Month ~ .</kbd> in our case, and the data to train with, which is the <kbd>train</kbd> variable in our case, to the <kbd>lm</kbd> function. This will instruct your machine to train a linear regression model with the given data.</p>
<p>Once a linear regression model is trained, there is some useful information you can find in the model object. You can use the following command to get detailed information about the model:</p>
<pre>summary(regFit)</pre>
<p>The output looks as follows:</p>
<p class="CDPAlignCenter CDPAlign"><img class="alignnone size-full wp-image-1328 image-border" src="img/3553d6a1-54c6-4672-bc4b-27bb187be74a.png" style="width:30.00em;height:32.67em;"/></p>
<p class="mce-root"/>
<p class="mce-root">As you can see from this output, you can easily find the coefficients of each feature and which features have negative or positive correlation with the target. For example, the previous 3 month period's aggregate purchase amount, <kbd>SalesSum.Q2</kbd>, has positive impacts on the next 3 month customer value. This means that the higher the previous 3 month period's total purchase amount is, the higher the next 3 month purchase amount will be. On the other hand, the second and fourth most recent 3 month period's aggregate purchase amounts, <kbd>SalesSum.Q3</kbd> and <kbd>SalesSum.Q5</kbd>, are negatively correlated with the next 3 month customer value. In other words, the more a customer made purchases two quarters or four quarters ago, the lower the value he or she will bring in the next 3 months. Looking at the coefficients is one way to gain insights on how the expected value will change, given certain features.</p>
<p>Using the 3 month customer value prediction output, you can custom-tailor your marketing strategies in different ways. Since you know the expected revenue or purchase amount from individual customers for the next 3 months, you can set a better informed budget for your marketing campaign. It should be set high enough to reach your target customers, but low enough to be below the expected 3 month customer value, so that you can have a positive ROI marketing campaign. On the other hand, you can also use these 3 month customer value prediction outputs to specifically target these high-value customers for the next 3 months. This can help you to create marketing campaigns with a higher ROI, as those high-value customers, predicted by this model, are likely to bring in more revenue than the others.</p>


            

            
        
    

        

                            
                    <h1 class="header-title">Evaluating regression model performance</h1>
                
            
            
                
<p>Now that we have a machine learning model that is trained to predict the 3 month customer value, let's discuss how to evaluate the performance of this model. As discussed previously, we are going to use R2, MAE, and a scatter plot of predicted versus actual to evaluate our model. We first need to get the prediction output from our model, like the following code:</p>
<pre>train_preds &lt;- predict(regFit, train)<br/>test_preds &lt;- predict(regFit, test)</pre>
<p> </p>
<p>We are going to use the <kbd>miscTools</kbd> package to compute the in-sample and out-of-sample R<sup>2</sup> values. Take a look at the following code:</p>
<pre># R-squared<br/># install.packages('miscTools')<br/>library(miscTools)<br/><br/>inSampleR2 &lt;- rSquared(train$CLV_3_Month, resid=train$CLV_3_Month - train_preds)<br/>outOfSampleR2 &lt;- rSquared(test$CLV_3_Month, resid=test$CLV_3_Month - test_preds)</pre>
<p>The R<sup>2</sup> values, in our case, look like the following output:</p>
<p class="CDPAlignCenter CDPAlign"><img class="alignnone size-full wp-image-1329 image-border" src="img/446db2ee-cf0e-4c18-bc01-bc97fdbb3225.png" style="width:29.17em;height:4.75em;"/></p>
<p>Due to the randomness in splitting the sample set into train and test sets, your results might differ from these results. In our case, the in-sample R<sup>2</sup> was <kbd>0.4557</kbd> and the out-of-sample R<sup>2</sup> was <kbd>0.1235</kbd>. The rather big gap between the in-sample and out-of-sample R<sup>2</sup> values suggests that there is some overfitting happening, where the model performs significantly better in the train set and worse in the test set. In case of overfitting, you can try different combinations of features or use more samples for training.</p>
<p>Next, let's take a look at the MAE for in-sample and out-of-sample predictions. Take a look at the following code:</p>
<pre># Median Absolute Error<br/>inSampleMAE &lt;- median(abs(train$CLV_3_Month - train_preds))<br/>outOfSampleMAE &lt;- median(abs(test$CLV_3_Month - test_preds))</pre>
<p>As you can see from this code, we are using the <kbd>median</kbd> and <kbd>abs</kbd> functions to get the median of absolute errors in the in-sample and out-of-sample predictions. The result in our case looks like the following:</p>
<p class="CDPAlignCenter CDPAlign"><img class="alignnone size-full wp-image-1330 image-border" src="img/8956d3d9-c5d5-4ca6-9f0d-964a9eb69a2f.png" style="width:25.08em;height:4.50em;"/></p>
<p>Lastly, let's take a look at the scatter plot of predicted versus actual. You can use the following code for this scatter plot:</p>
<pre>plot(<br/>  test$CLV_3_Month, <br/>  test_preds, <br/>  xlab='actual', <br/>  ylab='predicted', <br/>  main='Out-of-Sample Actual vs. Predicted'<br/>)<br/>abline(a=0, b=1)</pre>
<p>The resulting plot looks as follows:</p>
<p class="CDPAlignCenter CDPAlign"><img class="alignnone size-full wp-image-1331 image-border" src="img/df0b8b7c-13e9-46b2-a9f0-ed8f14d5c050.png" style="width:30.67em;height:20.50em;"/></p>
<p>As you can see from this plot, the <em>x</em>-values are the actual values and the <em>y</em>-values are the predicted values. As discussed earlier, the more the points are on the straight line, the better the predictions are. This is because points on the straight line suggest that the actual values and the predicted values are close to each other. Looking at this plot, the points do not seem to be spread around the straight line, which suggest that the predictions are rather poor. This is in line with the low out-of-sample <em>R<sup>2</sup></em> value that we observed previously. Scatter plot of predicted versus actual values is a good way to visualize the model performance.</p>
<p>The full code for this R exercise can be found at the following repo: <a href="https://github.com/yoonhwang/hands-on-data-science-for-marketing/blob/master/ch.9/R/CustomerLifetimeValue.R">https://github.com/yoonhwang/hands-on-data-science-for-marketing/blob/master/ch.9/R/CustomerLifetimeValue.R</a></p>
<p class="mce-root"/>
<p class="mce-root"/>


            

            
        
    

        

                            
                    <h1 class="header-title">Summary</h1>
                
            
            
                
<p>In this chapter, we have learned what CLV is and its importance and usage in marketing. Particularly for justifying the cost of customer acquisition, it is crucial to have a good understanding of how much value each new customer is going to bring to the company. We discussed how CLV calculations can help marketers to develop positive ROI marketing strategies. Then, we went through a hypothetical example to show how we can calculate the CLV, using average purchase amount, purchase frequency, and customer lifetime span. We also mentioned another approach of using machine learning and predictive models to estimate the CLV.</p>
<p>During the programming exercises, we have learned how to build regression models that predict the CLV over the course of a 3 month period. In Python, we used the <kbd>scikit-learn</kbd> package to build a <kbd>LinearRegression</kbd> model. In R, we used the built-in <kbd>lm</kbd> function to train a linear regression model with our data. For regression model evaluations, we have discussed four commonly used measures, MSE, MAE, R<sup>2</sup>, and predicted versus actual scatter plot, and what each of these metrics measures and tells us about the performance of regression models. In our programming exercises, we discussed how to compute and visualize MAE, R<sup>2</sup>, and predicted versus actual scatter plot in Python and R.</p>
<p>In the following chapter, we are going to cover customer segmentation. We will discuss how segmenting the customer base can help marketers better understand their customers and come up with more efficient marketing strategies.</p>


            

            
        
    </body></html>