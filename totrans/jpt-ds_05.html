<html><head></head><body><div id="sbo-rt-content" class="calibre1"><section class="calibre2">

                            <header class="calibre2">
                    <h1 class="header-title">R with Jupyter</h1>
                </header>
            
            <article class="calibre2">
                
<p class="calibre5">In this chapter we will be using R coding within Jupyter. I think R is one of the primary languages expected to be used within Jupyter. The full extent of the language is available to Jupyter users.</p>


            </article>

            
        </section>
    </div>



  
<div id="sbo-rt-content" class="calibre1"><section class="calibre2">

                            <header class="calibre2">
                    <h1 class="header-title">How to set up R for Jupyter</h1>
                </header>
            
            <article class="calibre2">
                
<p class="calibre5">In the past, it was necessary to install the separate components of Jupyter, Python, and so on to have a working system. With Continuum Analytics, the process of installing Jupyter and adding the R engine to the solution set for Jupyter is easy and works on both Windows and Mac.</p>
<p class="calibre5">Assuming you have installed conda already, we have one command to add support for R programming to Jupyter:</p>
<pre class="commandlinepackt"><strong class="calibre3">conda install -c r r-essentials</strong>  </pre>
<div class="packt_infobox">At this point, when you start Jupyter, one of the kernels listed will now be <span class="calibre4">R</span>.</div>


            </article>

            
        </section>
    </div>



  
<div id="sbo-rt-content" class="calibre1"><section class="calibre2">

                            <header class="calibre2">
                    <h1 class="header-title">R data analysis of the 2016 US election demographics</h1>
                </header>
            
            <article class="calibre2">
                
<p class="calibre5">To get a flavor of the resources available to R developers, we can look at the 2016 election data. In this case, I am drawing from Wikipedia (<a href="https://en.wikipedia.org/wiki/United_States_presidential_election,_2016" class="pcalibre pcalibre3 pcalibre2 pcalibre1 calibre9">https://en.wikipedia.org/wiki/United_States_presidential_election,_2016</a>), specifically the table named 2016 presidential vote by demographic subgroup. We have the following coding below.</p>
<p class="calibre5">Define a helper function so we can print out values easily. The new <kbd class="calibre21">printf</kbd> function takes any arguments passed <kbd class="calibre21">(...)</kbd> and passes them along to <kbd class="calibre21">sprintf</kbd>:</p>
<pre class="commandlinepackt"><strong class="calibre3">printf &lt;- function(...)print(sprintf(...))</strong>  </pre>
<p class="calibre5">I have stored the separate demographic statistics into different <strong class="calibre7">TSV</strong> (<strong class="calibre7">tab-separated value)</strong> files, which can be read in using the following coding. For each table, we use the <kbd class="calibre21">read.csv</kbd> function and specify the field separator as a tab instead of the default comma. We then use the <kbd class="calibre21">head</kbd> function to display information about the data frame that was loaded:</p>
<pre class="commandlinepackt"><strong class="calibre3">age &lt;- read.csv("Documents/B05238_05_age.tsv", sep="\t")</strong>
<strong class="calibre3">head(age)</strong>

<strong class="calibre3">education &lt;- read.csv("Documents/B05238_05_education.tsv", sep="\t")</strong>
<strong class="calibre3">head(education)</strong>

<strong class="calibre3">gender &lt;- read.csv("Documents/B05238_05_gender.tsv", sep="\t")</strong>
<strong class="calibre3">head(gender)</strong>

<strong class="calibre3">ideology &lt;- read.csv("Documents/B05238_05_ideology.tsv", sep="\t")</strong>
<strong class="calibre3">head(ideology)</strong>

<strong class="calibre3">income &lt;- read.csv("Documents/B05238_05_income.tsv", sep="\t")</strong>
<strong class="calibre3">head(income)</strong>

<strong class="calibre3">orientation &lt;- read.csv("Documents/B05238_05_orientation.tsv", sep="\t")</strong>
<strong class="calibre3">head(orientation)</strong>

<strong class="calibre3">party &lt;- read.csv("Documents/B05238_05_party.tsv", sep="\t")</strong>
<strong class="calibre3">head(party)</strong>

<strong class="calibre3">race &lt;- read.csv("Documents/B05238_05_race.tsv", sep="\t")</strong>
<strong class="calibre3">head(race)</strong>

<strong class="calibre3">region &lt;- read.csv("Documents/B05238_05_region.tsv", sep="\t")</strong>
<strong class="calibre3">head(region)</strong>

<strong class="calibre3">religion &lt;- read.csv("Documents/B05238_05_religion.tsv", sep="\t")</strong>
<strong class="calibre3">head(religion)</strong>  </pre>
<p class="calibre5">Across the top is a display of the columns. Every row displays the values for those columns in that row. Each of these <kbd class="calibre21">read</kbd> operations results in a display as follows:</p>
<div class="title-page-name">
<div class="packt_figure"><img class="image-border68" src="Images/97bf88f3-65a1-4bf4-b964-990935c907dc.png"/></div>
</div>
<p class="calibre5">Now, we can find the dominant characteristics of each turnout:</p>
<pre class="commandlinepackt"><strong class="calibre3">printf("Most Clinton voters from %s",age[which.max(age$Clinton),'age'])</strong>
<strong class="calibre3">printf("Most Clinton voters from %s",education[which.max(education$Clinton),'education'])</strong>
<strong class="calibre3">printf("Most Clinton voters from %s",gender[which.max(gender$Clinton),'gender'])</strong>
<strong class="calibre3">printf("Most Clinton voters from %s",ideology[which.max(ideology$Clinton),'ideology'])</strong>
<strong class="calibre3">printf("Most Clinton voters from %s",income[which.max(income$Clinton),'income'])</strong>
<strong class="calibre3">printf("Most Clinton voters from %s",orientation[which.max(orientation$Clinton),'orientation'])</strong>
<strong class="calibre3">printf("Most Clinton voters from %s",party[which.max(party$Clinton),'party'])</strong>
<strong class="calibre3">printf("Most Clinton voters from %s",race[which.max(race$Clinton),'race'])</strong>
<strong class="calibre3">printf("Most Clinton voters from %s",region[which.max(region$Clinton),'region'])</strong>
<strong class="calibre3">printf("Most Clinton voters from %s",religion[which.max(religion$Clinton),'religion'])</strong>

<strong class="calibre3">printf("Most Trump voters from %s",age[which.max(age$Trump),'age'])</strong>
<strong class="calibre3">printf("Most Trump voters from %s",education[which.max(education$Trump),'education'])</strong>
<strong class="calibre3">printf("Most Trump voters from %s",gender[which.max(gender$Trump),'gender'])</strong>
<strong class="calibre3">printf("Most Trump voters from %s",ideology[which.max(ideology$Trump),'ideology'])</strong>
<strong class="calibre3">printf("Most Trump voters from %s",income[which.max(income$Trump),'income'])</strong>
<strong class="calibre3">printf("Most Trump voters from %s",orientation[which.max(orientation$Trump),'orientation'])</strong>
<strong class="calibre3">printf("Most Trump voters from %s",party[which.max(party$Trump),'party'])</strong>
<strong class="calibre3">printf("Most Trump voters from %s",race[which.max(race$Trump),'race'])</strong>
<strong class="calibre3">printf("Most Trump voters from %s",region[which.max(region$Trump),'region'])</strong>
<strong class="calibre3">printf("Most Trump voters from %s",religion[which.max(religion$Trump),'religion'])</strong>  </pre>
<p class="calibre5">The results are as follows for Clinton:</p>
<div class="title-page-name">
<div class="packt_figure"><img class="image-border69" src="Images/47a91a28-2e1f-4db3-be52-54682ae116d1.png"/></div>
</div>
<p class="calibre5">The results for Trump are as follows:</p>
<div class="title-page-name">
<div class="packt_figure"><img class="image-border70" src="Images/2a472ea5-a9e7-4038-98f8-1e9d1eaed4e2.png"/></div>
</div>
<p class="calibre5">It's interesting that there was no overlap between the majority groups supporting the two candidates. I think the parties targeted different groups on purpose so as not to overlap. There must be a guideline for spending money, by advertising to known, interested groups and not contend for population segments that are ambiguous.</p>


            </article>

            
        </section>
    </div>



  
<div id="sbo-rt-content" class="calibre1"><section class="calibre2">

                            <header class="calibre2">
                    <h1 class="header-title">Analyzing 2016 voter registration and voting</h1>
                </header>
            
            <article class="calibre2">
                
<p class="calibre5">Similarly, we can look at voter registration versus actual voting (using census data from <a href="https://www.census.gov/data/tables/time-series/demo/voting-and-registration/p20-580.html" class="pcalibre pcalibre3 pcalibre2 pcalibre1 calibre9">https://www.census.gov/data/tables/time-series/demo/voting-and-registration/p20-580.html</a>).</p>
<p class="calibre5">First, we load our dataset and display head information to visually check for accurate loading:</p>
<pre class="commandlinepackt"><strong class="calibre3">df &lt;- read.csv("Documents/B05238_05_registration.csv")</strong>
<strong class="calibre3">summary(df)</strong>  </pre>
<div class="title-page-name">
<div class="packt_figure"><img class="image-border71" src="Images/4618fa6a-47ba-4cf5-a0d7-678c92197df2.png"/></div>
</div>
<p class="calibre5">So, we have some registration and voting information by state. Use R to automatically plot all the data in <em class="calibre18">x</em> and <em class="calibre18">y</em> format using the <kbd class="calibre21">plot</kbd> command:</p>
<pre class="commandlinepackt"><strong class="calibre3">plot(df)</strong>  </pre>
<p class="calibre5">We are specifically looking at the relationship between registering to vote and actually voting. We can see in the following graphic that most of the data is highly correlated (as evidenced by the 45 degree angles of most of the relationships):</p>
<div class="title-page-name">
<div class="packt_figure"><img class="image-border72" src="Images/4bf0119d-9dd8-4bc4-9c76-aac73e2f99bb.png"/></div>
</div>
<p class="calibre5">We can produce somewhat similar results using Python, but the graphic display is not even close.</p>
<p class="calibre5">Import all of the packages we are using for the example:</p>
<pre class="commandlinepackt"><strong class="calibre3">from numpy import corrcoef, sum, log, arange<br class="calibre2"/></strong><strong class="calibre3">from numpy.random import rand<br class="calibre2"/></strong><strong class="calibre3">from pylab import pcolor, show, colorbar, xticks, yticks<br class="calibre2"/></strong><strong class="calibre3">import pandas as pd<br class="calibre2"/></strong><strong class="calibre3">import matplotlib<br class="calibre2"/></strong><strong class="calibre3">from matplotlib import pyplot as plt 
</strong></pre>
<p class="calibre5">Reading a CSV file in Python is very similar. We call upon pandas to read in the file:</p>
<pre class="commandlinepackt"><strong class="calibre3">df</strong> </pre>
<p class="calibre5">pandas will throw an error if there is string data in the data frame, so just delete the column (with state names):</p>
<pre class="commandlinepackt"><strong class="calibre3">del df['state'] #pandas do not deal well with strings</strong> </pre>
<p class="calibre5">One approximate Python function is the <kbd class="calibre21">corr()</kbd> function, which prints out the numeric values for all of the cross-correlations among the items in the data frame. It is up to you to scan through the data, looking for correlation values close to <kbd class="calibre21">1.0</kbd>:</p>
<pre class="commandlinepackt"><strong class="calibre3">#print cross-correlation matrix<br class="calibre2"/></strong><strong class="calibre3">print(df.corr())</strong> </pre>
<p class="calibre5">Similarly, we have the <kbd class="calibre21">corrcoef()</kbd> function, which provides color intensity to similarly correlated items within the data frame. I did not find a way to label the correlated items:</p>
<pre class="commandlinepackt"><strong class="calibre3">#graph same<br class="calibre2"/></strong><strong class="calibre3">fig = plt.gcf()<br class="calibre2"/></strong><strong class="calibre3">fig.set_size_inches(10, 10)<br class="calibre2"/></strong><strong class="calibre3">         <br class="calibre2"/></strong><strong class="calibre3"># plotting the correlation matrix<br class="calibre2"/></strong><strong class="calibre3">R = corrcoef(df)<br class="calibre2"/></strong><strong class="calibre3">pcolor(R)<br class="calibre2"/></strong><strong class="calibre3">colorbar()<br class="calibre2"/></strong><strong class="calibre3">yticks(arange(0.5,10.5),range(0,10))<br class="calibre2"/></strong><strong class="calibre3">xticks(arange(0.5,10.5),range(0,10))<br class="calibre2"/></strong><strong class="calibre3">show()</strong></pre>
<div class="packt_figure"><img class="image-border73" src="Images/2a1a9c23-f2cb-49ba-b7e1-896badf30c62.png"/></div>
<p class="calibre5">We want to see the actual numeric value of the correlation between registration and voting. We can do that by calling the <kbd class="calibre21">cor</kbd> function to pass in the two data points of interest, as in:</p>
<pre class="commandlinepackt"><strong class="calibre3">cor(df$voted,df$registered)</strong>
<strong class="calibre3">0.998946393424037</strong></pre>
<div class="packt_infobox">The actual correlation value may be different from one machine class to another. This would have a trickling affect to follow-on values as well.</div>
<p class="calibre5">With a correlation of 99 percent, we are almost perfect.</p>
<p class="calibre5">We can use the data points to arrive at a regression line using the <kbd class="calibre21">lm</kbd> function, where we are stating <em class="calibre18">lm(y ~ (predicted by) x)</em>:</p>
<pre class="commandlinepackt"><strong class="calibre3">fit &lt;- lm(df$voted ~ df$registered)</strong>
<strong class="calibre3">fit</strong>
<strong class="calibre3">Call:</strong>
<strong class="calibre3">lm(formula = df$voted ~ df$registered)</strong>

<strong class="calibre3">Coefficients:</strong>
<strong class="calibre3">  (Intercept)  df$registered  </strong>
<strong class="calibre3">      -4.1690         0.8741  </strong>  </pre>
<p class="calibre5">From this output, given a registered number, we multiply it by 87 percent and subtract 4 to get the number of actual voters. Again, the data is correlated.</p>
<p class="calibre5">We can display the characteristics of the regression line by calling the <kbd class="calibre21">plot</kbd> function and passing in the <kbd class="calibre21">fit</kbd> object (the <kbd class="calibre21">par</kbd> function is used to lay out the output—in this case a 2x2 matrix-like display of the four graphics):</p>
<pre class="commandlinepackt"><strong class="calibre3">par(mfrow=c(2,2))</strong>
<strong class="calibre3">plot(fit)</strong>  </pre>
<div class="packt_figure"><img class="image-border74" src="Images/39c72cf4-b879-43c8-814a-2d0a63c48aff.png"/></div>
<p class="calibre5">Then, in the second part of the 2x2 display, we have these two graphics:</p>
<div class="packt_figure"><img class="image-border75" src="Images/1f8e2def-3158-412a-822b-a97743829b63.png"/></div>
<p class="calibre5">From the preceding plots we can see the following:</p>
<ul class="calibre19">
<li class="calibre20">The residual values are close to zero until we get to very large numbers</li>
<li class="calibre20">The theoretical quantiles versus standardized residuals line up very well for most of the range</li>
<li class="calibre20">The fitted values versus standardized residuals are not as close as I would have expected</li>
<li class="calibre20">The standardized residuals versus leverage show the same tight configuration among most of the values.</li>
</ul>
<p class="calibre5">Overall, we still have a very good model for the data. We can see what the residuals look like for the regression calling the <kbd class="calibre21">residuals</kbd> function, as follows:</p>
<div class="title-page-name">
<div class="packt_figure"><img class="image-border76" src="Images/621e7eff-331b-49b4-9a4e-a3261f032a4a.png"/></div>
</div>
<pre class="commandlinepackt"><strong class="calibre3">... (for all 50 states)</strong>  </pre>
<p class="calibre5">The residual values are bigger than I expected for such highly correlated data. I had expected to see very small numbers as opposed to values in the hundreds.</p>
<p class="calibre5">As always, let's display a summary of the model that we arrived at:</p>
<pre class="commandlinepackt"><strong class="calibre3">summary(fit)</strong>
<strong class="calibre3">Call:</strong>
<strong class="calibre3">lm(formula = df$voted ~ df$registered)</strong>

<strong class="calibre3">Residuals:</strong>
<strong class="calibre3">    Min      1Q  Median      3Q     Max </strong>
<strong class="calibre3">-617.33  -29.69    0.83   30.70  351.27 </strong>

<strong class="calibre3">Coefficients:</strong>
<strong class="calibre3">               Estimate Std. Error t value Pr(&gt;|t|)    </strong>
<strong class="calibre3">(Intercept)   -4.169018  25.201730  -0.165    0.869    </strong>
<strong class="calibre3">df$registered  0.874062   0.005736 152.370   &lt;2e-16 ***</strong>
<strong class="calibre3">---</strong>
<strong class="calibre3">Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1</strong>

<strong class="calibre3">Residual standard error: 127.9 on 49 degrees of freedom</strong>
<strong class="calibre3">Multiple R-squared:  0.9979,  Adjusted R-squared:  0.9979 </strong>
<strong class="calibre3">F-statistic: 2.322e+04 on 1 and 49 DF,  p-value: &lt; 2.2e-16</strong>  </pre>
<div class="packt_infobox">You may see different results based on the machine class that you are running your script on.</div>
<p class="calibre5">There are many data points associated with the model in this display:</p>
<ul class="calibre19">
<li class="calibre20">Again, residuals are showing quite a range</li>
<li class="calibre20">Coefficients are as we saw them earlier, but the standard error is high for the intercept</li>
<li class="calibre20">R squared of close to 1 is expected</li>
<li class="calibre20"><em class="calibre28">p</em> value minimal is expected</li>
</ul>
<p class="calibre5">We can also use Python to arrive at a linear regression model using:</p>
<pre class="commandlinepackt"><strong class="calibre3">import numpy as np</strong>
<strong class="calibre3">import statsmodels.formula.api as sm</strong>

<strong class="calibre3">model = sm.ols(formula='voted ~ registered', data=df)</strong>
<strong class="calibre3">fitted = model.fit()</strong>
<strong class="calibre3">print (fitted.summary())</strong>  </pre>
<p class="calibre5">We see the regression results in standard fashion as follows:</p>
<div class="title-page-name">
<div class="packt_figure"><img class="image-border77" src="Images/e6fd7aec-ffea-45b8-bd85-da4ec60a339a.png"/></div>
</div>
<p class="calibre5">The warnings infer some issues with the data:</p>
<ul class="calibre19">
<li class="calibre20">We are using the covariance matrix directly, so it is unclear how we would specify this otherwise</li>
<li class="calibre20">I imagine there is strong multicollinearity as the data only has the two items</li>
</ul>
<p class="calibre5">We can also plot the actual versus fitted values in Python using a script:</p>
<pre class="commandlinepackt"><strong class="calibre3">plt.plot(df['voted'], df['registered'], 'ro')</strong>
<strong class="calibre3">plt.plot(df['voted'], fitted.fittedvalues, 'b')</strong>
<strong class="calibre3">plt.legend(['Data', 'Fitted model'])</strong>
<strong class="calibre3">plt.xlabel('Voted')</strong>
<strong class="calibre3">plt.ylabel('Registered')</strong>
<strong class="calibre3">plt.title('Voted vs Registered')</strong>
<strong class="calibre3">plt.show()</strong>  </pre>
<div class="packt_figure"><img class="image-border78" src="Images/4d56bfe5-424a-45ef-b46d-a4c5ecc6ed63.png"/></div>
<p class="calibre5">I think I like this version of the graph from Python better than the display from R. The added intensity circle on the bottom left is confusing.</p>


            </article>

            
        </section>
    </div>



  
<div id="sbo-rt-content" class="calibre1"><section class="calibre2">

                            <header class="calibre2">
                    <h1 class="header-title">Analyzing changes in college admissions</h1>
                </header>
            
            <article class="calibre2">
                
<p class="calibre5">We can look at trends in college admissions acceptance rates over the last few years. For this analysis, I am using the data on <a href="https://www.ivywise.com/ivywise-knowledgebase/admission-statistics" class="pcalibre pcalibre3 pcalibre2 pcalibre1 calibre9">https://www.ivywise.com/ivywise-knowledgebase/admission-statistics</a>.</p>
<p class="calibre5">First, we read in our dataset and show the summary points, from head to validate:</p>
<pre class="commandlinepackt"><strong class="calibre3">df &lt;- read.csv("Documents/acceptance-rates.csv")</strong>
<strong class="calibre3">summary(df)</strong>
<strong class="calibre3">head(df)</strong>  </pre>
<p class="calibre5">We see the summary data for school acceptance rates as follows:</p>
<div class="title-page-name">
<div class="packt_figure"><img class="image-border79" src="Images/a014b6a0-5c99-4f42-93e2-d3a6497eeedd.png"/></div>
</div>
<p class="calibre5">It's interesting to note that the acceptance rate varies so widely, from a low of 5 percent to a high of 41 percent in 2017.</p>
<p class="calibre5">Let us look at the data plots, again, to validate that the data points are correct:</p>
<pre class="commandlinepackt"><strong class="calibre3">plot(df)</strong>  </pre>
<div class="title-page-name">
<div class="packt_figure"><img class="image-border80" src="Images/4b197f6e-c19c-4981-acd3-1094da8791f0.png"/></div>
</div>
<p class="calibre5">From the correlation graphics shown, it does not look like we can use the data points from 2007. The graphs show a big divergence between 2007 and the other years, whereas the other three have good correlations.</p>
<p class="calibre5">So, we have 3 consecutive years of data from 25 major US universities. We can convert the data into a time series using a few steps.</p>
<p class="calibre5">First, we create a vector of the average acceptance rates for these colleges over the years 2015-2017. We use the mean function to determine the average across all colleges in our data frame. We have some <kbd class="calibre21">NA</kbd> values in our data frame, so we need to tell the mean function to ignore those values (<kbd class="calibre21">na.rm=TRUE</kbd>):</p>
<pre class="commandlinepackt"><strong class="calibre3">myvector &lt;- c(mean(df[["X2015"]],na.rm=TRUE),</strong>
<strong class="calibre3">    mean(df[["X2016"]],na.rm=TRUE),</strong>
<strong class="calibre3">    mean(df[["X2017"]],na.rm=TRUE))</strong>  </pre>
<p class="calibre5">Next, we convert the vector points into a time series. A time series is passed in the vector to use the start and end points, and the frequency of the data points. In our case, the frequency is yearly, so <kbd class="calibre21">frequency = 1</kbd>:</p>
<pre class="commandlinepackt"><strong class="calibre3">ts &lt;- ts(myvector, start=c(2015), end=c(2017), frequency=1)</strong>  </pre>
<p class="calibre5">Then plot the time series to get a good visual:</p>
<pre class="commandlinepackt"><strong class="calibre3">plot(ts)</strong>  </pre>
<div class="title-page-name">
<div class="packt_figure"><img class="image-border81" src="Images/89722722-b336-4205-aae9-f1796b62006f.png"/></div>
</div>
<p class="calibre5">So, the clear trend is to drop acceptance rates across the board, as we see the initial acceptance rate at <kbd class="calibre21">.15</kbd> dropping steadily to <kbd class="calibre21">.14</kbd> in 2017.</p>
<p class="calibre5">The data looks very good and well-fitting, as data points are lining up in clean lines. We can use this time series to predict the next few years. There are versions of the Holt-Winters algorithm that can predict based on level data, level data plus a trend component, and level data plus a trend component plus a seasonality component. We have a trend, but no seasonality:</p>
<pre class="commandlinepackt"><strong class="calibre3"># double exponential - models level and trend</strong>
<strong class="calibre3">fit &lt;- HoltWinters(ts, gamma=FALSE)</strong>
<strong class="calibre3">fit</strong>
<strong class="calibre3">Holt-Winters exponential smoothing with trend and without seasonal component.</strong>

<strong class="calibre3">Call:</strong>
<strong class="calibre3">HoltWinters(x = ts, gamma = FALSE)</strong>

<strong class="calibre3">Smoothing parameters:</strong>
<strong class="calibre3"> alpha: 0.3</strong>
<strong class="calibre3"> beta : 0.1</strong>
<strong class="calibre3"> gamma: FALSE</strong>

<strong class="calibre3">Coefficients:</strong>
<strong class="calibre3">         [,1]</strong>
<strong class="calibre3">a  0.14495402</strong>
<strong class="calibre3">b -0.00415977</strong>  </pre>
<p class="calibre5">Our coefficients for the exponential smoothing of one-seventh and close to zero mean we aren't aggressively dropping acceptance rates, but they are dropping.</p>
<p class="calibre5">Now that we have a good time series model of the existing data, we can produce a forecast of the next three years and plot it:</p>
<pre class="commandlinepackt"><strong class="calibre3">install.packages("forecast", repos="http://cran.us.r-project.org")<br class="calibre2"/>library(forecast)</strong>
<strong class="calibre3">forecast(fit, 3)</strong>
<strong class="calibre3">plot(forecast(fit, 3))</strong>  </pre>
<div class="title-page-name">
<div class="packt_figure"><img class="image-border82" src="Images/36892259-bcc9-40ab-b060-abcc4cabde7b.png"/></div>
</div>
<p class="calibre5">The trend is clearly negative, but as mentioned earlier, it is not a dramatic drop-about half a percent a year. We can also look at similar coding from Python that could be used as follows. Import all of the Python packages we will be using:</p>
<pre class="commandlinepackt"><strong class="calibre3">import pandas as pd</strong>
<strong class="calibre3">import numpy as np</strong>
<strong class="calibre3">import matplotlib.pylab as plt</strong>
<strong class="calibre3">%matplotlib inline</strong>
<strong class="calibre3">from matplotlib.pylab import rcParams</strong>
<strong class="calibre3">rcParams['figure.figsize'] = 15, 6</strong>  </pre>
<p class="calibre5">Read in the college acceptance to a data frame:</p>
<pre class="commandlinepackt"><strong class="calibre3">data = pd.read_csv('Documents/acceptance-rates.csv')</strong>
<strong class="calibre3">print (data.head())</strong>
<strong class="calibre3">                School  2017  2016  2015  2007</strong>
<strong class="calibre3">0      Amherst College   NaN  0.14  0.14  0.18</strong>
<strong class="calibre3">1       Boston College  0.32  0.32  0.28  0.27</strong>
<strong class="calibre3">2     Brown University  0.08  0.09  0.09  0.15</strong>
<strong class="calibre3">3  Columbia University  0.06  0.06  0.06  0.12</strong>
<strong class="calibre3">4   Cornell University  0.13  0.14  0.15  0.21</strong>  </pre>
<p class="calibre5">Remove the <kbd class="calibre21">School</kbd> column as Python cannot calculate from strings:</p>
<pre class="commandlinepackt"><strong class="calibre3">del data['School']</strong>
<strong class="calibre3">print (data.head())</strong>
<strong class="calibre3">   2017  2016  2015  2007</strong>
<strong class="calibre3">0   NaN  0.14  0.14  0.18</strong>
<strong class="calibre3">1  0.32  0.32  0.28  0.27</strong>
<strong class="calibre3">2  0.08  0.09  0.09  0.15</strong>
<strong class="calibre3">3  0.06  0.06  0.06  0.12</strong>
<strong class="calibre3">4  0.13  0.14  0.15  0.21</strong>  </pre>
<p class="calibre5">Convert the data to sets by year:</p>
<pre class="commandlinepackt"><strong class="calibre3">data = data.transpose()</strong>
<strong class="calibre3">print (data.head())</strong></pre>
<p class="calibre5">We see the dataset transposed to our desired shape as follows:</p>
<div class="packt_figure"><img class="image-border83" src="Images/a7d30ed7-ed83-43eb-943e-d02215fdaa82.png"/></div>
<p class="calibre5">See what the data looks like:</p>
<pre class="commandlinepackt"><strong class="calibre3">plt.plot(data);</strong>  </pre>
<div class="title-page-name">
<div class="packt_figure"><img class="image-border84" src="Images/da35730e-65ed-43af-803a-1c2ff0a54640.png"/></div>
</div>
<p class="calibre5">We see the same slight downtrend for acceptance.</p>
<p class="calibre5">Using Holt-Winters forecasting in Python was problematic as it required transforming the data further. Overall, it is much more complicated to do the same processing that was straightforward in R in the preceding section.</p>


            </article>

            
        </section>
    </div>



  
<div id="sbo-rt-content" class="calibre1"><section class="calibre2">

                            <header class="calibre2">
                    <h1 class="header-title">Predicting airplane arrival time</h1>
                </header>
            
            <article class="calibre2">
                
<p class="calibre5">R has built-in functionality for splitting up a data frame between training and testing sets, building a model based on the training set, predicting results using the model and the testing set, and then visualizing how well the model is working.</p>
<p class="calibre5">For this example, I am using airline arrival and departure times versus scheduled arrival and departure times from <a href="http://stat-computing.org/dataexpo/2009/the-data.html" target="_blank" class="pcalibre pcalibre3 pcalibre2 pcalibre1 calibre9">http://stat-computing.org/dataexpo/2009/the-data.html</a> for 2008. The dataset is distributed as a <kbd class="calibre21">.bz2</kbd> file that unpacks into a CSV file. I like this dataset, as the initial row count is over 7 million and it all works nicely in Jupyter.</p>
<p class="calibre5">We first read in the airplane data and display a summary. There are additional columns in the dataset that we are not using:</p>
<pre class="commandlinepackt"><strong class="calibre3">df &lt;- read.csv("Documents/2008-airplane.csv")</strong>
<strong class="calibre3">summary(df)</strong>
<strong class="calibre3">...</strong>
<strong class="calibre3">CRSElapsedTime      AirTime          ArrDelay          DepDelay      </strong>
<strong class="calibre3"> Min.   :-141.0   Min.   :   0     Min.   :-519.00   Min.   :-534.00  </strong>
<strong class="calibre3"> 1st Qu.:  80.0   1st Qu.:  55     1st Qu.: -10.00   1st Qu.:  -4.00  </strong>
<strong class="calibre3"> Median : 110.0   Median :  86     Median :  -2.00   Median :  -1.00  </strong>
<strong class="calibre3"> Mean   : 128.9   Mean   : 104     Mean   :   8.17   Mean   :   9.97  </strong>
<strong class="calibre3"> 3rd Qu.: 159.0   3rd Qu.: 132     3rd Qu.:  12.00   3rd Qu.:   8.00  </strong>
<strong class="calibre3"> Max.   :1435.0   Max.   :1350     Max.   :2461.00   Max.   :2467.00  </strong>
<strong class="calibre3"> NA's   :844      NA's   :154699   NA's   :154699    NA's   :136246   </strong>
<strong class="calibre3">     Origin             Dest            Distance          TaxiIn      </strong>
<strong class="calibre3"> ATL    : 414513   ATL    : 414521   Min.   :  11.0   Min.   :  0.00  </strong>
<strong class="calibre3"> ORD    : 350380   ORD    : 350452   1st Qu.: 325.0   1st Qu.:  4.00  </strong>
<strong class="calibre3"> DFW    : 281281   DFW    : 281401   Median : 581.0   Median :  6.00  </strong>
<strong class="calibre3"> DEN    : 241443   DEN    : 241470   Mean   : 726.4   Mean   :  6.86  </strong>
<strong class="calibre3"> LAX    : 215608   LAX    : 215685   3rd Qu.: 954.0   3rd Qu.:  8.00  </strong>
<strong class="calibre3"> PHX    : 199408   PHX    : 199416   Max.   :4962.0   Max.   :308.00  </strong>
<strong class="calibre3"> (Other):5307095   (Other):5306783                    NA's   :151649  </strong>
<strong class="calibre3">    TaxiOut         Cancelled       CancellationCode    Diverted       </strong>
<strong class="calibre3"> Min.   :  0.00   Min.   :0.00000    :6872294        Min.   :0.000000  </strong>
<strong class="calibre3"> 1st Qu.: 10.00   1st Qu.:0.00000   A:  54330        1st Qu.:0.000000  </strong>
<strong class="calibre3"> Median : 14.00   Median :0.00000   B:  54904        Median :0.000000  </strong>
<strong class="calibre3"> Mean   : 16.45   Mean   :0.01961   C:  28188        Mean   :0.002463  </strong>
<strong class="calibre3"> 3rd Qu.: 19.00   3rd Qu.:0.00000   D:     12        3rd Qu.:0.000000  </strong>
<strong class="calibre3"> Max.   :429.00   Max.   :1.00000                    Max.   :1.000000  </strong>
<strong class="calibre3"> NA's   :137058                                                        </strong>
<strong class="calibre3">  CarrierDelay      WeatherDelay        NASDelay       SecurityDelay    </strong>
<strong class="calibre3"> Min.   :   0      Min.   :   0      Min.   :   0      Min.   :  0      </strong>
<strong class="calibre3"> 1st Qu.:   0      1st Qu.:   0      1st Qu.:   0      1st Qu.:  0      </strong>
<strong class="calibre3"> Median :   0      Median :   0      Median :   6      Median :  0      </strong>
<strong class="calibre3"> Mean   :  16      Mean   :   3      Mean   :  17      Mean   :  0      </strong>
<strong class="calibre3"> 3rd Qu.:  16      3rd Qu.:   0      3rd Qu.:  21      3rd Qu.:  0      </strong>
<strong class="calibre3"> Max.   :2436      Max.   :1352      Max.   :1357      Max.   :392      </strong>
<strong class="calibre3"> NA's   :5484993   NA's   :5484993   NA's   :5484993   NA's   :5484993  </strong>
<strong class="calibre3"> LateAircraftDelay</strong>
<strong class="calibre3"> Min.   :   0     </strong>
<strong class="calibre3"> 1st Qu.:   0     </strong>
<strong class="calibre3"> Median :   0     </strong>
<strong class="calibre3"> Mean   :  21     </strong>
<strong class="calibre3"> 3rd Qu.:  26     </strong>
<strong class="calibre3"> Max.   :1316     </strong>
<strong class="calibre3"> NA's   :5484993  </strong></pre>
<div class="packt_infobox">Many of the data points have <kbd class="calibre21">NA</kbd> values. We need to remove these in order to build an accurate model:</div>
<pre class="commandlinepackt"><strong class="calibre3"># eliminate rows with NA values</strong>
<strong class="calibre3">df &lt;- na.omit(df)</strong></pre>
<p class="calibre5">Let's create our partitions:</p>
<pre class="commandlinepackt"><strong class="calibre3"># for partitioning to work data has to be ordered</strong>
<strong class="calibre3">times &lt;- df[order(df$ArrTime),]</strong>
<strong class="calibre3">nrow(times)</strong>
<strong class="calibre3">1524735</strong>

<strong class="calibre3"># partition data - 75% training</strong>
<strong class="calibre3">library(caret)</strong>
<strong class="calibre3">set.seed(1337)</strong>
<strong class="calibre3">trainingIndices &lt;- createDataPartition(df$ArrTime,p=0.75,list=FALSE)</strong>
<strong class="calibre3">trainingSet &lt;- df[trainingIndices,]</strong>
<strong class="calibre3">testingSet &lt;- df[-trainingIndices,]</strong>
<strong class="calibre3">nrow(trainingSet)</strong>
<strong class="calibre3">nrow(testingSet)</strong>
<strong class="calibre3">1143553</strong>
<strong class="calibre3">381182</strong>  </pre>
<p class="calibre5">Let's build our model of the arrival time (<kbd class="calibre21">ArrTime</kbd>) based on the fields:</p>
<ul class="calibre19">
<li class="calibre20"><kbd class="calibre21">CRSArrTime</kbd>: Scheduled arrival time</li>
<li class="calibre20"><kbd class="calibre21">ArrDelay</kbd>: Arrival delay</li>
<li class="calibre20"><kbd class="calibre21">DepDelay</kbd>: Departure delay</li>
<li class="calibre20"><kbd class="calibre21">Diverted</kbd>: Whether the plane used a diverted route</li>
<li class="calibre20"><kbd class="calibre21">CarrierDelay</kbd>: Delay by the carrier systems</li>
<li class="calibre20"><kbd class="calibre21">WeatherDelay</kbd>: Delay due to weather</li>
<li class="calibre20"><kbd class="calibre21">NASDelay</kbd>: Delay due to NAS</li>
<li class="calibre20"><kbd class="calibre21">SecurityDelay</kbd>: Delay due to security</li>
<li class="calibre20"><kbd class="calibre21">LateAircraftDelay</kbd>: Plane arrived late due to other delay</li>
</ul>
<div class="packt_figure"><img class="image-border85" src="Images/26026249-083f-40ea-adc1-49a714edff55.png"/></div>
<p class="calibre5">Two of the data items are just flags (0/1), unfortunately. The greatest predictor appears to be the scheduled arrival time. The other various delay factors have small effects. I think it just feels as if it's taking an extra 20 minutes for a security check or the like; it's a big deal when you are traveling.</p>
<p class="calibre5">Now that we have a model, let's use the testing set to make predictions:</p>
<pre class="commandlinepackt"><strong class="calibre3">predicted &lt;- predict(model, newdata=testingSet)</strong>
<strong class="calibre3">summary(predicted)</strong>
<strong class="calibre3">summary(testingSet$ArrTime)</strong>
<strong class="calibre3">   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. </strong>
<strong class="calibre3">   -941    1360    1629    1590    1843    2217 </strong>
<strong class="calibre3">   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. </strong>
<strong class="calibre3">      1    1249    1711    1590    2034    2400 </strong>  </pre>
<p class="calibre5"/>
<p class="calibre5">Plot out the predicted versus actual data to get a sense of the model's accuracy:</p>
<pre class="commandlinepackt"><strong class="calibre3">plot(predicted,</strong><strong class="calibre3">testingSet$ArrTime)</strong>  </pre>
<div class="title-page-name">
<div class="packt_figure"><img class="image-border86" src="Images/80044d12-8cb5-408f-a16c-db4f00043dec.png"/></div>
</div>
<p class="calibre5">Visually, the predictions match up well with the actuals as shown by the almost 45 degree line. That whole set of predicted points on the lower-right portion of the graphic is troublesome. There appears to be many predictions that are well below the actuals. There must be additional factors involved, as I would have expected all of the data to plot in one area rather than two.</p>


            </article>

            
        </section>
    </div>



  
<div id="sbo-rt-content" class="calibre1"><section class="calibre2">

                            <header class="calibre2">
                    <h1 class="header-title">Summary</h1>
                </header>
            
            <article class="calibre2">
                
<p class="calibre5">In this chapter, we first set up R as one of the engines available for a notebook. Then we used some rudimentary R to analyze voter demographics for the presidential election. We looked at voter registration versus actual voting. Next, we analyzed the trend in college admissions. Finally, we looked at using a predictive model to determine whether flights would be delayed or not.</p>
<p class="calibre5">In the next chapter, we will look into wrangling data in different ways under Jupyter.</p>
<p class="calibre5"/>
<p class="calibre5"/>
<p class="calibre5"/>


            </article>

            
        </section>
    </div>



  </body></html>