<html><head></head><body>
        

                            
                    <h1 class="header-title">Making Predictive Models in Healthcare</h1>
                
            
            
                
<p>This chapter is intended for all audiences and is an integral part of this book. We will demonstrate how to build predictive models for healthcare using example data and an example machine learning problem. We will preprocess the data one feature at a time. By the end of this chapter, you will understand how to prepare and fit a machine learning model to a clinical dataset.</p>


            

            
        
    

        

                            
                    <h1 class="header-title">Introduction to predictive analytics in healthcare</h1>
                
            
            
                
<p>In <a href="b15b2b73-d2bb-410f-ab55-5f0f1e91730e.xhtml" target="_blank">Chapter 1</a>, <em>Introduction to Healthcare Analytics,</em> we discussed the three subcomponents of analytics: descriptive analytics, predictive analytics, and prescriptive analytics. Predictive and prescriptive analytics form the heart of healthcare's mission to improve care, cost, and outcomes. That is because if we can predict that an adverse event is likely in the future, we can divert our scarce resources toward preventing the adverse event from occurring.</p>
<p>What are some of the adverse events we can predict (and then prevent) in healthcare?</p>
<ul>
<li><strong>Deaths</strong>: Obviously, any death that is preventable or foreseeable should be avoided. Once a death is predicted to occur, preventative actions may include directing more nurses toward that patient, hiring more consultants for the case, or speaking to the family about options earlier rather than later.</li>
<li><strong>Adverse clinical events</strong>: These are events that are not synonymous with deaths, but highly increase the chances of morbidity and mortality. Morbidity refers to complications, while mortality refers to death. Examples of adverse clinical events include heart attacks, heart failure exacerbations, COPD exacerbations, pneumonia, and falls. Patients in which adverse events are likely could be candidates for more nursing care or for prophylactic therapies.</li>
<li><strong>Readmissions</strong>: Readmissions don't present an obvious danger to patients; however, they are costly, so preventable readmissions should, therefore, be avoided. Furthermore, readmission reduction is highly incentivized by the Centers for Medicare and Medicaid Services, as we saw in <a href="023c1d7e-f3f0-42e6-a2be-64bd5ba4ab80.xhtml" target="_blank">Chapter 6</a>, <em>Measuring Healthcare Quality</em>. Preventative actions include assigning social workers and case managers to high-risk patients to assure that they are following up with outpatient providers and buying needed prescriptions.</li>
<li><strong>High utilization</strong>: Predicting patients who are likely to incur high amounts of medical spending again could potentially reduce costs by assigning more care members to their team and ensuring frequent outpatient check-ins and follow-ups.</li>
</ul>
<p>Now that we've answered the "What?" question, the next question is, "How?" In other words, how do we make predictions about which care providers can act?</p>
<ul>
<li><strong>First, we need data</strong>: The provider should send you their historical patient data. The data can be claims data, clinical transcripts, a dump of EHR records, or some combination of these. Whatever the type of data, it should eventually be able to be molded into a tabular format, in which each row represents a patient/encounter and each column represents a particular feature of that patient/encounter.</li>
<li><strong>Using some of the data, we train a predictive model</strong>: In <a href="46c83498-cb6e-45b4-ac39-6875a8d32400.xhtml" target="_blank">Chapter 3</a>, <em>Machine Learning Foundations</em>, we learned about what exactly we are doing when we train predictive models, and how the general modeling pipeline works.</li>
<li><strong>Using some of the data, we test our model's performance</strong>: Assessing the performance of our model is important for setting the expectations of the provider as to how accurate the model is.</li>
<li><strong>We then deploy the model into a production environment and provide live predictions for patients on a routine basis</strong>: At this stage, there should be a periodic flow of data from the provider to the analytics firm. The firm then responds with regularly scheduled predictions on those patients.</li>
</ul>
<p>In the remainder of the chapter, we will go through the "How?" of building a predictive model for healthcare. First, we will describe our mock modeling task. Then, we will describe and obtain the publicly available dataset. After that, we will preprocess the dataset and train predictive models using different machine learning algorithms. Finally, we will assess the performance of our model. While we will not be using our models to make actual predictions on live data, we will describe the steps necessary for doing so.</p>
<p class="mce-root"/>
<p class="mce-root"/>
<p class="mce-root"/>
<p class="mce-root"/>
<p class="mce-root"/>
<p class="mceNonEditable"/>


            

            
        
    

        

                            
                    <h1 class="header-title">Our modeling task – predicting discharge statuses for ED patients</h1>
                
            
            
                
<p>Every year, millions of patients use emergency department facilities across the nation. The resources of these facilities have to be managed properly—if there is a large influx of patients at any given time, the staff and the available rooms should be increased accordingly. The mismatch between resources and patient influx could lead to wasted money and suboptimal care.</p>
<p>In this context, we introduce our example modeling task —predicting discharge statuses for patients presenting to the emergency room. The discharge status refers to whether patients are admitted to the hospital or sent home. Usually, the more serious cases are admitted to the hospital. Therefore, we are attempting to predict the outcome of the ED visit early on in the patient stay.</p>
<p>With such a model, the workflow of the hospital could be greatly improved, as well as resource flow. Many previous academic studies have looked at this problem (for an example, see Cameron et al., 2015).</p>
<p>You may be wondering why we didn't pick a different modeling task, such as readmission modeling or predicting CHF exacerbations. For one thing, the publicly available clinical data is very limited. The dataset that we chose is an ED dataset; there are no publicly available inpatient datasets available that are free to download without registering. Nevertheless, the task that we have chosen will serve our purposes in demonstrating how predictive healthcare models can be built.</p>


            

            
        
    

        

                            
                    <h1 class="header-title">Obtaining the dataset</h1>
                
            
            
                
<p>In this section, we will provide step-by-step instructions for obtaining the data and its associated documentation.</p>
<p class="mce-root"/>


            

            
        
    

        

                            
                    <h1 class="header-title">The NHAMCS dataset at a glance</h1>
                
            
            
                
<p>The dataset we have chosen for this book is part of the <strong>National Hospital Ambulatory Medical Care Survey</strong> (<strong>NHAMCS</strong>) public use data. It is survey data published and maintained by the US <strong>Center for Disease Control and Prevention</strong> (<strong>CDC</strong>). The home page for this data set is <a href="https://www.cdc.gov/nchs/ahcd/ahcd_questionnaires.htm">https://www.cdc.gov/nchs/ahcd/ahcd_questionnaires.htm</a>.</p>
<ul>
<li>The NHAMCS data is survey-based data; it is populated by surveys sent to patients and healthcare providers that were seen in the hospital for encounters.</li>
<li>The data files are in fixed-width format. In other words, they are text files in which each row is on a distinct line, and columns are each a set number of characters long. Information about the character length of each feature is available in the corresponding NHAMCS documentation.</li>
<li>There are different sets of files depending on whether the data is from outpatient encounters or emergency department visits. We will be using the ED format in this chapter.</li>
<li>The data comes with detailed documentation about the content of each feature.</li>
<li>Each row of the data represents a distinct ED patient encounter.</li>
</ul>
<p>See the following table for a summary of the emergency department data files from NHAMCS that we will be using throughout this book:</p>
<table border="1" style="border-collapse: collapse;width: 100%">
<tbody>
<tr>
<td style="width: 9.04585%"><strong>Filename</strong></td>
<td style="width: 13.4242%"><strong>Data type and year</strong></td>
<td style="width: 11.3589%"><strong>Number of rows (encounters)</strong></td>
<td style="width: 10.1611%"><strong>Number of columns (features)</strong></td>
<td style="width: 52.4164%"><strong>Broad feature categories</strong></td>
</tr>
<tr>
<td style="width: 9.04585%">ED2013</td>
<td style="width: 13.4242%">ED Encounters; 2013</td>
<td style="width: 11.3589%">24,777</td>
<td style="width: 10.1611%">579</td>
<td style="width: 52.4164%">Visit date and information, Demographics, Tobacco, Arrival means, Payment, Vital signs, Triage, ED relationship, Reason for visit, Injury, Diagnoses, Chronic conditions, Services performed, Providers seen, Disposition, Hospital admission, Imputed data, ED information, Socioeconomic data</td>
</tr>
</tbody>
</table>
<p class="mce-root"/>


            

            
        
    

        

                            
                    <h1 class="header-title">Downloading the NHAMCS data</h1>
                
            
            
                
<p>The raw data files and supporting documentation are accessible from the CDC NHAMCS home page: <a href="https://www.cdc.gov/nchs/ahcd/ahcd_questionnaires.htm">https://www.cdc.gov/nchs/ahcd/ahcd_questionnaires.htm</a> (the following screenshot). We recommend downloading all of the files into a directory dedicated to this book and its associated files. Also, remember which directories where they are downloaded to:</p>
<div><img src="img/e9ddefe9-bdc0-4a36-970d-4274b7783b58.png"/></div>


            

            
        
    

        

                            
                    <h1 class="header-title">Downloading the ED2013 file</h1>
                
            
            
                
<p>The ED2013 file contains the raw data.  To download it:</p>
<ol>
<li>Navigate to the CDC NHAMCS homepage: <a href="https://www.cdc.gov/nchs/ahcd/ahcd_questionnaires.htm">https://www.cdc.gov/nchs/ahcd/ahcd_questionnaires.htm</a>.</li>
<li>Scroll to the middle of the page, to the Public-use Data Files: Downloadable Data Files heading.</li>
<li>Click on the link for NHAMCS. It should take you to the CDC's FTP website (<a href="ftp://ftp.cdc.gov/pub/Health_Statistics/NCHS/Datasets/NHAMCS">ftp://ftp.cdc.gov/pub/Health_Statistics/NCHS/Datasets/NHAMCS</a>). This website is pictured in the following screenshot.</li>
<li>Find the file named <kbd>ED2013.zip</kbd>. Click on it. The file will start to download.</li>
<li>Navigate to the file in your File Explorer and unzip it. In the unzipped directory, you should see a file named <kbd>ED2013</kbd> with no extension. This is the data file.</li>
</ol>
<p> </p>
<ol start="6">
<li>Move the ED2013 data file to the directory associated with the book-related files:</li>
</ol>
<div><img src="img/d5e8aec1-9f4a-443b-8e4f-9fe145de903b.png" style="width:53.75em;height:37.50em;"/></div>
<p class="mce-root"/>


            

            
        
    

        

                            
                    <h1 class="header-title">Downloading the list of survey items – body_namcsopd.pdf</h1>
                
            
            
                
<ol>
<li>Navigate to the CDC NHAMCS home page: <a href="https://www.cdc.gov/nchs/ahcd/ahcd_questionnaires.htm">https://www.cdc.gov/nchs/ahcd/ahcd_questionnaires.htm</a>.</li>
<li>Scroll to the middle of the page, to the List of Survey Items, 1973-2012 heading.</li>
<li>Click on the link labeled NAMCS and NHAMCS Survey Content Brochure [Revised 11/2012].</li>
</ol>
<p> </p>
<ol start="4">
<li>The link should take you to a PDF page at the <a href="https://www.cdc.gov/nchs/data/ahcd/body_namcsopd.pdf">https://www.cdc.gov/nchs/data/ahcd/body_namcsopd.pdf</a> URL. This is the list of survey items.</li>
<li>Use your browser to download the file. Then use your File Explorer to move it to the desired directory.</li>
</ol>


            

            
        
    

        

                            
                    <h1 class="header-title">Downloading the documentation file – doc13_ed.pdf</h1>
                
            
            
                
<ol>
<li>Navigate to the CDC NHAMCS home page: <a href="https://www.cdc.gov/nchs/ahcd/ahcd_questionnaires.htm">https://www.cdc.gov/nchs/ahcd/ahcd_questionnaires.htm</a>.</li>
<li>Scroll to the middle of the page, to the Downloadable Documentation heading.</li>
<li>Click on the link for NHAMCS (1992-2014). It should take you to the CDC's documentation FTP website (<a href="ftp://ftp.cdc.gov/pub/Health_Statistics/NCHS/Dataset_Documentation/NHAMCS">ftp://ftp.cdc.gov/pub/Health_Statistics/NCHS/Dataset_Documentation/NHAMCS</a>). This website is pictured in the following screenshot.</li>
<li>Find the file named <kbd>doc13_ed.pdf</kbd>. Click on it. A PDF should open in your browser. This PDF file contains the documentation for the ED2013 data file.</li>
<li>Use your browser to download the file. Then use your File Explorer to move it to the desired directory:</li>
</ol>
<div><img src="img/afd9e727-52c1-4415-8ffa-4cdd7004fb3d.png" style="width:58.25em;height:33.92em;"/></div>
<p class="mce-root"/>
<p class="mce-root"/>
<p class="mce-root"/>


            

            
        
    

        

                            
                    <h1 class="header-title">Starting a Jupyter session</h1>
                
            
            
                
<p>Next, we will start a Jupyter session so that we can import our data into Python and make a machine learning model. A detailed example of creating a new Jupyter Notebook was presented in <a href="b15b2b73-d2bb-410f-ab55-5f0f1e91730e.xhtml" target="_blank">Chapter 1</a>, <em>Introduction to Healthcare Analytics</em>. Here are the steps:</p>
<ol>
<li>Locate the Jupyter application on your computer and start it.</li>
<li>In the new Jupyter tab that was opened in your default browser, navigate to the directory where you wish to save the notebook.</li>
<li>Locate the New drop-down menu on the upper right of the console, click it, and select Python 3.</li>
<li>You should see a new notebook, named Untitled.</li>
<li>To rename your notebook, click on the name of the notebook in the upper left. A cursor should appear. Type in the desired name. We have named our notebook <kbd>ED_predict</kbd>.</li>
</ol>
<p>You are now ready to import the dataset into Jupyter.</p>


            

            
        
    

        

                            
                    <h1 class="header-title">Importing the dataset</h1>
                
            
            
                
<p>Before we load the dataset, there are some important facts about the data that must be acknowledged:</p>
<ul>
<li>The data is in a fixed-width format, meaning that there is no delimiter. Column widths will have to be specified manually.</li>
<li>There is no header row that has column names.</li>
<li>If you were to open the data file using a text editor, you would see rows of data simply containing numbers.</li>
</ul>
<p>Because column widths are necessary for importing <kbd>.fwf</kbd> files, we must import those <em>first</em> into our session. We have therefore made a helper <kbd>.csv</kbd> file, titled <kbd>ED_metadata.csv</kbd>, that contains the width, name, and variable type of each column. Our data only has 579 columns, so making such a file only took a couple of hours. If you have a bigger dataset, you may have to rely on automated width detection methods and/or more team members to do the grunt work of creating a schema for your data.</p>


            

            
        
    

        

                            
                    <h1 class="header-title">Loading the metadata</h1>
                
            
            
                
<p>With our first cell, let's import the metadata and print a small preview of it:</p>
<pre>import pandas as pd<br/>pd.set_option('mode.chained_assignment',None)<br/><br/>HOME_PATH = 'C:\\Users\\Vikas\\Desktop\\Bk\\health-it\\ed_predict\\data\\'<br/><br/>df_helper = pd.read_csv(<br/>    HOME_PATH + 'ED_metadata.csv',<br/>    header=0, <br/>    dtype={'width': int, 'column_name': str, 'variable_type': str}<br/>)<br/><br/>print(df_helper.head(n=5))</pre>
<p>You should see the following output:</p>
<pre>   width column_name  variable_type
0      2      VMONTH    CATEGORICAL
1      1       VDAYR    CATEGORICAL
2      4     ARRTIME  NONPREDICTIVE
3      4    WAITTIME     CONTINUOUS
4      4         LOV  NONPREDICTIVE</pre>
<p>So the <kbd>ED_metadata.csv</kbd> file simply is a comma-separated values file containing the width, column name, and variable type as specified in the documentation. This file can be downloaded from the code repository for this book.</p>
<p>In the next cell, we convert the columns of the pandas DataFrame we imported into separate lists:</p>
<pre>width = df_helper['width'].tolist()<br/>col_names = df_helper['column_name'].tolist()<br/>var_types = df_helper['variable_type'].tolist()</pre>
<p class="mce-root"/>
<p class="mce-root"/>
<p class="mce-root"/>
<p class="mce-root"/>
<p class="mceNonEditable"/>
<p class="mceNonEditable"/>


            

            
        
    

        

                            
                    <h1 class="header-title">Loading the ED dataset</h1>
                
            
            
                
<p>Next, we import the contents of the fixed-width data file into Python as a pandas DataFrame composed of string columns, using the <kbd>widths</kbd> list created in the previous cell. We then name the columns using the <kbd>col_names</kbd> list:</p>
<div><div><div><div><div><pre>df_ed = pd.read_fwf(
    HOME_PATH + 'ED2013',
    widths=width,
    header=None,
    dtype='str'  
)<br/><br/>df_ed.columns = col_names</pre></div>
</div>
</div>
</div>
</div>
<p>Let's print a preview of our dataset to confirm it was imported correctly:</p>
<pre>print(df_ed.head(n=5))</pre>
<p>The output should look similar to the following:</p>
<pre>  VMONTH VDAYR ARRTIME WAITTIME   LOV  AGE AGER AGEDAYS RESIDNCE SEX ...   \
0     01     3    0647     0033  0058  046    4     -07       01   2 ...    
1     01     3    1841     0109  0150  056    4     -07       01   2 ...    
2     01     3    1333     0084  0198  037    3     -07       01   2 ...    
3     01     3    1401     0159  0276  007    1     -07       01   1 ...    
4     01     4    1947     0114  0248  053    4     -07       01   1 ...    <br/>  <br/>  RX12V3C1 RX12V3C2 RX12V3C3 RX12V3C4 SETTYPE  YEAR   CSTRATM   CPSUM   PATWT  \
0      nan      nan      nan      nan       3  2013  20113201  100020  002945   
1      nan      nan      nan      nan       3  2013  20113201  100020  002945   
2      nan      nan      nan      nan       3  2013  20113201  100020  002945   
3      nan      nan      nan      nan       3  2013  20113201  100020  002945   
4      nan      nan      nan      nan       3  2013  20113201  100020  002945</pre>
<p class="mce-root"/>
<p class="mce-root"/>
<p class="mce-root"/>
<p class="mce-root"/>
<p class="mceNonEditable"/>
<p class="mceNonEditable"/>
<p class="mceNonEditable"/>
<pre>  EDWT  
0  nan  
1  nan  
2  nan  
3  nan  
4  nan  

[5 rows x 579 columns]</pre>
<p>Looking at the column values and their meanings in the documentation confirm that the data has been imported correctly. The <kbd>nan</kbd> values correspond to blank spaces in the data file.</p>
<p>Finally, as another check, let's count the dimensions of the data file and confirm that there are 24,777 rows and 579 columns:</p>
<pre>print(df_ed.shape)</pre>
<p>The output should look similar to the following:</p>
<pre>(24777, 579)</pre>
<p>Now that the data has been imported correctly, let's set up our response variable.</p>


            

            
        
    

        

                            
                    <h1 class="header-title">Making the response variable</h1>
                
            
            
                
<p>In some cases, the response variable that we are trying to predict may already be a separate well-defined column. In those cases, simply converting the response from a string to a numeric type before splitting the data into train and test sets will suffice.</p>
<p>In our specific modeling task, we are trying to predict which patients presenting to the ED will eventually be hospitalized. In our case, hospitalization encompasses:</p>
<ul>
<li>Those admitted to an inpatient ward for further evaluation and treatment</li>
<li>Those transferred to a different hospital (either psychiatric or non-psychiatric) for further treatment</li>
<li>Those admitted to the observation unit for further evaluation (whether they are eventually admitted or discharged after their observation unit stay)</li>
</ul>
<p class="mce-root"/>
<p>Accordingly, we must do some data wrangling to assemble all of these various outcomes into a single response variable:</p>
<pre>response_cols = ['ADMITHOS','TRANOTH','TRANPSYC','OBSHOS','OBSDIS']

df_ed.loc[:, response_cols] = df_ed.loc[:, response_cols].apply(pd.to_numeric)

df_ed['ADMITTEMP'] = df_ed[response_cols].sum(axis=1)
df_ed['ADMITFINAL'] = 0
df_ed.loc[df_ed['ADMITTEMP'] &gt;= 1, 'ADMITFINAL'] = 1

df_ed.drop(response_cols, axis=1, inplace=True)
df_ed.drop('ADMITTEMP', axis=1, inplace=True)</pre>
<p>Let's discuss the previous code example in detail:</p>
<ul>
<li>The first line identifies the columns we would like to include in our final target variable by name. The target should equal <kbd>1</kbd> if the values for any of those columns is <kbd>1</kbd>.</li>
<li>In Line 2, we convert the columns from the string to the numeric type.</li>
<li>In Lines 3-5, we create a column called <kbd>ADMITTEMP</kbd> that contains the row-wise sum of the five target columns. We then create our final target column, <kbd>ADMITFINAL</kbd>, and set it equal to <kbd>1</kbd> when <kbd>ADMITTEMP</kbd> is <kbd>&gt;= 1</kbd>.</li>
<li>In Lines 6-7, we drop the five original response columns as well as the <kbd>ADMITTEMP</kbd> column since we now have our final response column.</li>
</ul>


            

            
        
    

        

                            
                    <h1 class="header-title">Splitting the data into train and test sets</h1>
                
            
            
                
<p>Now that we have our response variable, the next step is to split the dataset into train and test sets. In data science, the <strong>training set</strong> is the data that is used to determine the model coefficients. In the training phase, the model takes into account the predictor variable values together with the response value to "discover" the rules and the weights that will guide the prediction of new data. The <strong>testing set</strong> is then used to measure our model performance, as we discussed in <a href="46c83498-cb6e-45b4-ac39-6875a8d32400.xhtml" target="_blank">Chapter 3</a>, <em>Machine Learning Foundations</em>. Typical splits use 70-80% for the training data and 20-30% for the testing data (unless the dataset is very large, in which case a smaller percentage can be allotted toward the testing set).</p>
<p>Some practitioners also have a validation set that is used to train model parameters, such as the tree size in the random forest model or the lasso parameter in regularized logistic regression.</p>
<p>Fortunately, the <kbd>scikit-learn</kbd> library has a handy function called <kbd>train_test_split()</kbd> that takes care of the random splitting for us, when given the test set percentage. To use this function, we must first separate the target variable from the rest of the data, we do so as follows:</p>
<pre>def split_target(data, target_name):<br/>    target = data[[target_name]]<br/>    data.drop(target_name, axis=1, inplace=True)<br/>    return (data, target)<br/><br/>X, y = split_target(df_ed, 'ADMITFINAL')</pre>
<p>After running the preceding code, <kbd>y</kbd> holds our response variable and <kbd>X</kbd> holds our dataset. We feed these two variables to the <kbd>train_test_split()</kbd> function, along with <kbd>0.25</kbd> for the <kbd>test_size</kbd> and a random state for reproducibility:</p>
<pre>from sklearn.model_selection import train_test_split<br/><br/>X_train, X_test, y_train, y_test = train_test_split(<br/>    X, y, test_size=0.25, random_state=1234<br/>)</pre>
<p>The result is a 2 x 2 split: <kbd>X_train</kbd>, <kbd>X_test</kbd>, <kbd>y_train</kbd>, and <kbd>y_test</kbd>. We can now use <kbd>X_train</kbd> and <kbd>y_train</kbd> to train the model, and <kbd>X_test</kbd> and <kbd>y_test</kbd> to test the model performance.</p>
<p>An important thing to remember is that during the preprocessing phase, any transformation made to the training set must also be performed on the testing set at test time, or otherwise, the model's output for the new data will be incorrect.</p>
<p>As a sanity check and also to detect any target variable imbalance, let's check the number of positive and negative responses in the response variable:</p>
<pre>print(y_train.groupby('ADMITFINAL').size())</pre>
<p>The output is as follows:</p>
<pre>ADMITFINAL
0    15996
1     2586
dtype: int64</pre>
<p class="mce-root"/>
<p class="mce-root"/>
<p class="mce-root"/>
<p class="mceNonEditable"/>
<p>Our result indicates that approximately 1 out of 7 observations in the test set have a positive response. While it is not a perfectly balanced dataset (in which case the ratio would be 1 out of 2), it is not so imbalanced that we need to do any upsampling or downsampling of the data. Let's proceed with preprocessing the predictors.</p>


            

            
        
    

        

                            
                    <h1 class="header-title">Preprocessing the predictor variables</h1>
                
            
            
                
<p>Let's take a look at specific groups of predictor variables that commonly pop up in healthcare data.</p>


            

            
        
    

        

                            
                    <h1 class="header-title">Visit information</h1>
                
            
            
                
<p>The first feature category in the ED2013 dataset contains information about the timing of the visit. Variables such as month, day of week, and arrival time are included here. Also included are the waiting time and length of visit variables (both in minutes).</p>


            

            
        
    

        

                            
                    <h1 class="header-title">Month</h1>
                
            
            
                
<p>Let's analyze the <kbd>VMONTH</kbd> predictor in more detail. The following code prints all the values in the training set and their counts:</p>
<pre>print(X_train.groupby('VMONTH').size())</pre>
<p>The output is as follows:</p>
<pre>VMONTH
01    1757
02    1396
03    1409
04    1719
05    2032
06    1749
07    1696
08    1034
09    1240
10    1306
11    1693
12    1551
dtype: int64</pre>
<p>We can now see that the months are numbered from <kbd>01</kbd> to <kbd>12</kbd>, as it says in the documentation, and that each month has representation.</p>
<p>One part of preprocessing the data is performing <strong>feature engineering </strong>– that is, combining or transforming the features in some way to come up with new features that are more predictive than the previous ones. For example, suppose we had a hypothesis that ED visitors tend to be admitted more often during the winter months. We could make a predictor called <kbd>WINTER</kbd> that is a combination of the <kbd>VMONTH</kbd> predictor such that the value is <kbd>1</kbd> only if the patient came during December, January, February, or March. We have done that in the following cell. Later on, we can test this hypothesis when we assess variable importance while making our machine learning models:</p>
<pre>def is_winter(vmonth):<br/>    if vmonth in ['12','01','02','03']:<br/>        return 1<br/>    else:<br/>        return 0<br/>    <br/>X_train.loc[:,'WINTER'] = df_ed.loc[:,'VMONTH'].apply(is_winter)<br/>X_test.loc[:,'WINTER'] = df_ed.loc[:,'VMONTH'].apply(is_winter)</pre>
<p>As an informal test, let's print out the distribution of the <kbd>WINTER</kbd> variable and confirm that it is the sum of the preceding four winter months:</p>
<pre>X_train.groupby('WINTER').size()</pre>
<p>The output is as follows:</p>
<pre>WINTER
0    12469
1     6113
dtype: int64</pre>
<p>Sure enough, we get <kbd>6113 = 1551 + 1757 + 1396 + 1409</kbd>, confirming that we engineered the feature correctly. We will see other examples of feature engineering throughout this chapter.</p>


            

            
        
    

        

                            
                    <h1 class="header-title">Day of the week</h1>
                
            
            
                
<p>As a sanity check that the data was imported correctly, let's also explore the <kbd>VDAYR</kbd> variable, which indicates the day of the week that the patient visit occurred:</p>
<pre>X_train.groupby('VDAYR').size()</pre>
<p class="mce-root"/>
<p class="mce-root"/>
<p class="mce-root"/>
<p class="mceNonEditable"/>
<p>The output is as follows:</p>
<pre>VDAYR
1    2559
2    2972
3    2791
4    2632
5    2553
6    2569
7    2506
dtype: int64</pre>
<p>As we would expect, there are seven possible values, and the observations are relatively uniformly distributed across the possible values. We could get fancy and engineer a <kbd>WEEKEND</kbd> feature, but engineering additional features can be very time-consuming and memory-consuming, often for minimal gain. We'll leave that exercise up to the reader.</p>


            

            
        
    

        

                            
                    <h1 class="header-title">Arrival time</h1>
                
            
            
                
<p>The arrival time is another visit information variable included in the data. However, in its raw form, it will probably be unhelpful, since it can be an integer between 0 and 2,359. Let's make a <kbd>NIGHT</kbd> variable that is only positive when the patient comes in between 8 PM and 8 AM. Our reasoning behind creating this variable is the hypothesis that patients arriving at the ED outside of regular hours have more serious illnesses and will, therefore, be admitted more often to the hospital. We can use the following code to make the <kbd>NIGHT</kbd> variable:</p>
<pre>def is_night(arrtime):<br/>    arrtime_int = int(arrtime)<br/>    if ((arrtime_int &gt;= 0) &amp; (arrtime_int &lt; 800)):<br/>        return 1<br/>    elif ((arrtime_int &gt;= 2000) &amp; (arrtime_int &lt; 2400)):<br/>        return 1<br/>    else:<br/>        return 0<br/>    <br/>X_train.loc[:,'NIGHT'] = df_ed.loc[:,'ARRTIME'].apply(is_night)<br/>X_test.loc[:,'NIGHT'] = df_ed.loc[:,'ARRTIME'].apply(is_night)<br/><br/>X_train.drop('ARRTIME', axis=1, inplace=True)<br/>X_test.drop('ARRTIME', axis=1, inplace=True)</pre>
<p>In the preceding example, we first code a function that returns <kbd>1</kbd> if the patient has arrived between 8 PM and 8 AM, and returns <kbd>0</kbd> otherwise. We then use the <kbd>apply()</kbd> function of pandas to "apply" this function to the <kbd>ARRTIME</kbd> column and make the <kbd>NIGHT</kbd> column. We then drop the original <kbd>ARRTIME</kbd> column since it is not useful in its raw form.</p>
<p class="mce-root"/>


            

            
        
    

        

                            
                    <h1 class="header-title">Wait time</h1>
                
            
            
                
<p>The wait time spent in the ED is yet another visit information variable that could reasonably be correlated with the target variable. Hypothetically, patients with more serious illnesses could appear to be more symptomatic to the triage nurse and therefore assigned more critical triage scores, causing them to have smaller waiting times than people with less serious illnesses.</p>
<p>In the documentation, it states that the <kbd>WAITTIME</kbd> variable may take values of <kbd>-9</kbd> and <kbd>-7</kbd> when blank and not applicable, respectively. Whenever a continuous variable has a placeholder value like this, we <em>must</em> do some sort of imputation to remove the placeholder values. Otherwise, the model will think that the patient had a wait time of <kbd>-7</kbd> minutes, and the whole model will be adjusted adversely.</p>
<p>In this case, mean imputation is the appropriate action. <strong>Mean imputation</strong> replaces those negative values with the mean of the rest of the dataset, so that during modeling time those observations will have no effect in determining the coefficient for this variable.</p>
<p>To perform mean imputation, we first convert the columns to the numeric type:</p>
<pre>X_train.loc[:,'WAITTIME'] = X_train.loc[:,'WAITTIME'].apply(pd.to_numeric)<br/>X_test.loc[:,'WAITTIME'] = X_test.loc[:,'WAITTIME'].apply(pd.to_numeric)</pre>
<p>Next, we write a function, called <kbd>mean_impute_values()</kbd>, that removes values of <kbd>-7</kbd> and <kbd>-9</kbd> from the column and replaces them with the mean of the column. We make the function generalizable so that it may be used later on in our preprocessing for other columns:</p>
<pre>def mean_impute_values(data,col): <br/>    temp_mean = data.loc[(data[col] != -7) &amp; (data[col] != -9), col].mean()<br/>    data.loc[(data[col] == -7) | (data[col] == -9), col] = temp_mean <br/>    return data<br/><br/>X_train = mean_impute_values(X_train,'WAITTIME')<br/>X_test = mean_impute_values(X_test,'WAITTIME')</pre>
<p>We then call the function on the data, and we are finished. Following that, we will confirm that this function has been applied correctly, but first, let's go over a few more variables.</p>
<p class="mce-root"/>


            

            
        
    

        

                            
                    <h1 class="header-title">Other visit information</h1>
                
            
            
                
<p>The final visit information variable in this dataset is the length of the visit variable (<kbd>LOV</kbd>). However, the length of visit is determined only after the entire ED visit, and by that time, the decision whether to admit or discharge will have already been made. It is important to drop variables that won't be available during the time of the prediction, and for that reason, we must drop <kbd>LOV</kbd>. We do so as shown in the following code:</p>
<pre>X_train.drop('LOV', axis=1, inplace=True)<br/>X_test.drop('LOV', axis=1, inplace=True)</pre>
<p>Now that we've finished tackling the visit information, let's move on to demographic variables.</p>


            

            
        
    

        

                            
                    <h1 class="header-title">Demographic variables</h1>
                
            
            
                
<p>In healthcare, demographic variables are usually associated with outcomes. Age, sex, and race are major demographic variables in healthcare. In this dataset, ethnicity and residence type have also been included. Let's sort out these variables as follows.</p>


            

            
        
    

        

                            
                    <h1 class="header-title">Age</h1>
                
            
            
                
<p>As people get older, one can expect them to be sicker and to be admitted to the hospital more frequently. This hypothesis will be tested once we see the variable importance results of our model.</p>
<p>There are three variables that reflect the age in the dataset. <kbd>AGE</kbd> is an integer value that gives the age in years. <kbd>AGEDAYS</kbd> is an integer value that gives the age in days if the patient is less than 1 year old. <kbd>AGER</kbd> is the age variable, except that it has been converted to a categorical variable. Let's convert the <kbd>AGE</kbd> variable to a numeric type, leave the <kbd>AGER</kbd> variable as is, and remove the <kbd>AGEDAYS</kbd> variable since it will be not applicable in the vast majority of cases:</p>
<pre>X_train.loc[:,'AGE'] = X_train.loc[:,'AGE'].apply(pd.to_numeric)<br/>X_test.loc[:,'AGE'] = X_test.loc[:,'AGE'].apply(pd.to_numeric)<br/><br/>X_train.drop('AGEDAYS', axis=1, inplace=True)<br/>X_test.drop('AGEDAYS', axis=1, inplace=True)</pre>
<p class="mce-root"/>
<p class="mce-root"/>
<p class="mce-root"/>
<p class="mceNonEditable"/>


            

            
        
    

        

                            
                    <h1 class="header-title">Sex</h1>
                
            
            
                
<p>In healthcare, women have often been found to have longer life expectancies and be healthier overall than men, so let's include the <kbd>SEX</kbd> variable in our model. It is already categorical, so we can leave it as is.</p>


            

            
        
    

        

                            
                    <h1 class="header-title">Ethnicity and race</h1>
                
            
            
                
<p>Ethnicity (Hispanic/Latino versus non-Hispanic/Latino) and race are also included in the data. Often, races that are prone to poor socioeconomic status have worse outcomes in healthcare. Let's leave the unimputed ethnicity and race variables (<kbd>ETHUN</kbd> and <kbd>RACEUN</kbd>) as is. We can remove the redundant <kbd>RACER</kbd> variable as well as the imputed versions of ethnicity and race (<kbd>ETHIM</kbd> and <kbd>RACERETH</kbd>):</p>
<pre>X_train.drop(['ETHIM','RACER','RACERETH'], axis=1, inplace=True)<br/>X_test.drop(['ETHIM','RACER','RACERETH'], axis=1, inplace=True)</pre>


            

            
        
    

        

                            
                    <h1 class="header-title">Other demographic information</h1>
                
            
            
                
<p>The patient residence is included in the data. Since it is categorical, there is no need to alter it.</p>
<p>Let's see what we have so far and print the first five rows using the <kbd>head()</kbd> function:</p>
<pre>X_train.head(n=5)</pre>
<p>Scrolling horizontally through the output, you should confirm that all of our transformations and variable drops have been done correctly.</p>


            

            
        
    

        

                            
                    <h1 class="header-title">Triage variables</h1>
                
            
            
                
<p>Triage variables are important for emergency department modeling tasks. Triage encompasses assigning a risk score to a patient based on their initial presentation and vital signs. It is usually completed by a nurse specialized to perform triage and encompasses both subjective and objective information. Triage scores usually range from 1 (critical) to 5 (non-urgent). The <kbd>IMMEDR</kbd> variable (item number 34 in the documentation) is the triage score in this dataset. We will certainly include it.</p>
<p class="mce-root"/>
<p>Other variables we can categorize as triage variables include whether or not the patient arrived via EMS (<kbd>ARREMS</kbd>; usually correlated with worse outcomes) and whether or not the patient has been seen and discharged within the last 72 hours (<kbd>SEEN72</kbd>). We will also include these variables in our model.</p>


            

            
        
    

        

                            
                    <h1 class="header-title">Financial variables</h1>
                
            
            
                
<p>The method of payment of the patient is commonly included in healthcare datasets and usually, certain payment types are associated with better or worse outcomes. Patients with no expected source of payment (<kbd>NOPAY</kbd>), or with Medicaid (<kbd>PAYMCAID</kbd>) or Medicare (<kbd>PAYMCARE</kbd>), typically are less healthy than patients with private insurance (<kbd>PAYPRIV</kbd>) or who are paying on their own (<kbd>PAYSELF</kbd>). Let's include all of the financial variables except for the <kbd>PAYTYPER</kbd> variable, which is just a nonbinary expansion of the other payment variables:</p>
<pre>X_train.drop('PAYTYPER', axis=1, inplace=True)<br/>X_test.drop('PAYTYPER', axis=1, inplace=True)</pre>


            

            
        
    

        

                            
                    <h1 class="header-title">Vital signs</h1>
                
            
            
                
<p>Vital signs are an important source of information for patients in healthcare modeling, for many reasons:</p>
<ul>
<li>They are easy to collect.</li>
<li>They are typically available at the beginning of the clinical encounter.</li>
<li>They are objective.</li>
<li>They are numerical indicators of patient health.</li>
</ul>
<p>The vital signs included in this dataset are temperature, pulse, respiratory rate, blood pressure (systolic and diastolic), oxygen saturation percentage, and whether they are on oxygen. Height and weight are commonly also categorized as vital signs, but they are not included in our data. Let's take a look at each vital sign in turn.</p>
<p class="mce-root"/>


            

            
        
    

        

                            
                    <h1 class="header-title">Temperature</h1>
                
            
            
                
<p><strong>Temperature</strong> is usually measured using a thermometer early during the patient encounter and can be recorded in degrees Celsius or Fahrenheit. A temperature of 98.6° F (37.1° C) is usually considered a normal body temperature. Temperatures markedly above this range can be termed as <strong>fever</strong> or <strong>hyperthermia</strong> and usually reflect infection, inflammation, or environmental overexposure to the sun. Temperatures below normal by a certain amount are termed <strong>hypothermia</strong> and usually reflect environmental exposure to cold. The more the temperature deviates from normal, usually the more serious the illness is.</p>
<p>In our dataset, the <kbd>TEMPF</kbd> temperature has been multiplied by 10 and stored as an integer. Also, some values are blank (indicated by <kbd>-9</kbd>) and we must impute those, since temperature is a continuous variable. Following that, we first convert the temperature to a numeric type, use our previously written <kbd>mean_impute_values()</kbd> function to impute the missing values in <kbd>TEMPF</kbd>, and then use a lambda function to divide all temperatures by <kbd>10</kbd>:</p>
<pre>X_train.loc[:,'TEMPF'] = X_train.loc[:,'TEMPF'].apply(pd.to_numeric)<br/>X_test.loc[:,'TEMPF'] = X_test.loc[:,'TEMPF'].apply(pd.to_numeric)<br/><br/>X_train = mean_impute_values(X_train,'TEMPF')<br/>X_test = mean_impute_values(X_test,'TEMPF')<br/><br/>X_train.loc[:,'TEMPF'] = X_train.loc[:,'TEMPF'].apply(lambda x: float(x)/10)<br/>X_test.loc[:,'TEMPF'] = X_test.loc[:,'TEMPF'].apply(lambda x: float(x)/10)</pre>
<p>Let's print out 30 values of just this column to confirm that our processing was performed correctly:</p>
<pre>X_train['TEMPF'].head(n=30)</pre>
<p>The output is as follows:</p>
<pre>15938     98.200000
5905      98.100000
4636      98.200000
9452      98.200000
7558      99.300000
17878     99.000000
21071     97.800000
20990     98.600000
4537      98.200000
7025      99.300000
2134      97.500000
5212      97.400000
9213      97.900000
2306      97.000000
6106      98.600000
2727      98.282103
4098      99.100000
5233      98.800000
5107     100.000000
18327     98.900000
19242     98.282103
3868      97.900000
12903     98.600000
12763     98.700000
8858      99.400000
8955      97.900000
16360     98.282103
6857      97.100000
6842      97.700000
22073     97.900000
Name: TEMPF, dtype: float64</pre>
<p>We can see that the temperatures are now of the float type and that they are not multiplied by 10. Also, we see that the mean value, <kbd>98.282103</kbd>, has been substituted where values were previously blank. Let's move on to the next variable.</p>


            

            
        
    

        

                            
                    <h1 class="header-title">Pulse</h1>
                
            
            
                
<p><strong>Pulse</strong> measures the frequency of the heartbeat in the patient. The normal range is 60-100. Having a pulse faster than <kbd>100</kbd> is termed <strong>tachycardia</strong> and usually indicates some underlying cardiac dysfunction, volume depletion, or infection (sepsis). A pulse lower than <kbd>60</kbd> is termed <strong>bradycardia</strong>.</p>
<p>We must use mean imputation to impute the missing values. First, we convert the pulse to a numeric type:</p>
<pre>X_train.loc[:,'PULSE'] = X_train.loc[:,'PULSE'].apply(pd.to_numeric)<br/>X_test.loc[:,'PULSE'] = X_test.loc[:,'PULSE'].apply(pd.to_numeric)</pre>
<p>Then, we write a <kbd>mean_impute_vitals()</kbd> function that is similar to our <kbd>mean_impute_values()</kbd> function, except that the placeholder values have been changed from <kbd>-7</kbd> and <kbd>-9</kbd> to <kbd>-998</kbd> and <kbd>-9</kbd>:</p>
<pre>def mean_impute_vitals(data,col): <br/>    temp_mean = data.loc[(data[col] != 998) &amp; (data[col] != -9), col].mean()<br/>    data.loc[(data[col] == 998) | (data[col] == -9), col] = temp_mean <br/>    return data<br/><br/>X_train = mean_impute_vitals(X_train,'PULSE')<br/>X_test = mean_impute_vitals(X_test,'PULSE')</pre>


            

            
        
    

        

                            
                    <h1 class="header-title">Respiratory rate</h1>
                
            
            
                
<p>The respiratory rate indicates the rate at which the person takes breaths. 18-20 is considered normal. Tachypnea (abnormally elevated respiratory rate) is seen commonly in clinical practice and indicates an oxygen shortage in the body, usually due to either a cardiac or pulmonary cause. Bradypnea is an abnormally low respiratory rate.</p>
<p>In the following code, we convert the <kbd>RESPR</kbd> variable to a numeric type and then perform a mean imputation of the missing values:</p>
<pre>X_train.loc[:,'RESPR'] = X_train.loc[:,'RESPR'].apply(pd.to_numeric)<br/>X_test.loc[:,'RESPR'] = X_test.loc[:,'RESPR'].apply(pd.to_numeric)<br/><br/>X_train = mean_impute_values(X_train,'RESPR')<br/>X_test = mean_impute_values(X_test,'RESPR')</pre>


            

            
        
    

        

                            
                    <h1 class="header-title">Blood pressure</h1>
                
            
            
                
<p>The blood pressure measures the amount of force per unit area that the blood exerts on the blood vessel walls. Blood pressure consists of two numbers – the <strong>systolic blood pressure</strong> (blood pressure during the systolic phase of the heartbeat) and the <strong>diastolic blood pressure</strong> (blood pressure during the diastolic phase). Normal blood pressure is usually somewhere between 110 to 120 mmHg for the systolic blood pressure and 70 to 80 mmHg for the diastolic blood pressure. Elevated blood pressure is called <strong>hypertension</strong>. The most common cause of elevated blood pressure is essential hypertension, which is primarily genetic (but multifactorial). Low blood pressure is called <strong>hypotension</strong>. Both hypertension and hypotension have complex etiologies that are often difficult to identify.</p>
<p>In our dataset, systolic and diastolic blood pressure are in separate columns (<kbd>BPSYS</kbd> and <kbd>BPDIAS</kbd>, respectively). First, we process the systolic blood pressure by converting it to a numeric type and mean imputing the missing values as we have done already for other columns:</p>
<pre>X_train.loc[:,'BPSYS'] = X_train.loc[:,'BPSYS'].apply(pd.to_numeric)<br/>X_test.loc[:,'BPSYS'] = X_test.loc[:,'BPSYS'].apply(pd.to_numeric)<br/><br/>X_train = mean_impute_values(X_train,'BPSYS')<br/>X_test = mean_impute_values(X_test,'BPSYS')</pre>
<p class="mce-root"/>
<p class="mce-root"/>
<p class="mce-root"/>
<p class="mce-root"/>
<p class="mce-root"/>
<p class="mce-root"/>
<p class="mce-root"/>
<p class="mceNonEditable"/>
<p>Diastolic blood pressure is a bit more complex. The value <kbd>998</kbd> means that the pressure was <kbd>PALP</kbd>, meaning that it was too low to be detected by a sphygmamometer but high enough to feel by touch (palpation). After we convert it to a numeric type, we will substitute a numeric value of <kbd>40</kbd> for the <kbd>PALP</kbd> values:</p>
<pre>X_train.loc[:,'BPDIAS'] = X_train.loc[:,'BPDIAS'].apply(pd.to_numeric)<br/>X_test.loc[:,'BPDIAS'] = X_test.loc[:,'BPDIAS'].apply(pd.to_numeric)</pre>
<p>We write a new function called <kbd>mean_impute_bp_diast()</kbd> that does the conversion of <kbd>PALP</kbd> values to <kbd>40</kbd> and the missing values to the mean:</p>
<pre>def mean_impute_bp_diast(data,col): <br/>    temp_mean = data.loc[(data[col] != 998) &amp; (data[col] != -9), col].mean()<br/>    data.loc[data[col] == 998, col] = 40<br/>    data.loc[data[col] == -9, col] = temp_mean <br/>    return data<br/><br/>X_train = mean_impute_values(X_train,'BPDIAS')<br/>X_test = mean_impute_values(X_test,'BPDIAS')</pre>


            

            
        
    

        

                            
                    <h1 class="header-title">Oxygen saturation</h1>
                
            
            
                
<p>Oxygen saturation measures the oxygen level in the blood. It is reported as a percentage, with higher values being more healthy. We convert it to a numeric type and perform mean imputation as follows:</p>
<pre>X_train.loc[:,'POPCT'] = X_train.loc[:,'POPCT'].apply(pd.to_numeric)<br/>X_test.loc[:,'POPCT'] = X_test.loc[:,'POPCT'].apply(pd.to_numeric)<br/><br/>X_train = mean_impute_values(X_train,'POPCT')<br/>X_test = mean_impute_values(X_test,'POPCT')</pre>
<p>Let's examine the vital sign transformations we've done so far by selecting those columns and using the <kbd>head()</kbd> function:</p>
<pre>X_train[['TEMPF','PULSE','RESPR','BPSYS','BPDIAS','POPCT']].head(n=20)</pre>
<p>The output is as follows:</p>
<table border="1" class="dataframe" style="border-collapse: collapse;width: 100%">
<thead>
<tr>
<th/>
<th>TEMPF</th>
<th>PULSE</th>
<th>RESPR</th>
<th>BPSYS</th>
<th>BPDIAS</th>
</tr>
</thead>
<tbody>
<tr>
<th>15938</th>
<td>98.200000</td>
<td>101.000000</td>
<td>22.0</td>
<td>159.000000</td>
<td>72.000000</td>
<td>98.000000</td>
</tr>
<tr>
<th>5905</th>
<td>98.100000</td>
<td>70.000000</td>
<td>18.0</td>
<td>167.000000</td>
<td>79.000000</td>
<td>96.000000</td>
</tr>
<tr>
<th>4636</th>
<td>98.200000</td>
<td>85.000000</td>
<td>20.0</td>
<td>113.000000</td>
<td>70.000000</td>
<td>98.000000</td>
</tr>
<tr>
<th>9452</th>
<td>98.200000</td>
<td>84.000000</td>
<td>20.0</td>
<td>146.000000</td>
<td>72.000000</td>
<td>98.000000</td>
</tr>
<tr>
<th>7558</th>
<td>99.300000</td>
<td>116.000000</td>
<td>18.0</td>
<td>131.000000</td>
<td>82.000000</td>
<td>96.000000</td>
</tr>
<tr>
<th>17878</th>
<td>99.000000</td>
<td>73.000000</td>
<td>16.0</td>
<td>144.000000</td>
<td>91.000000</td>
<td>99.000000</td>
</tr>
<tr>
<th>21071</th>
<td>97.800000</td>
<td>88.000000</td>
<td>18.0</td>
<td>121.000000</td>
<td>61.000000</td>
<td>98.000000</td>
</tr>
<tr>
<th>20990</th>
<td>98.600000</td>
<td>67.000000</td>
<td>16.0</td>
<td>112.000000</td>
<td>65.000000</td>
<td>95.000000</td>
</tr>
<tr>
<th>4537</th>
<td>98.200000</td>
<td>85.000000</td>
<td>20.0</td>
<td>113.000000</td>
<td>72.000000</td>
<td>99.000000</td>
</tr>
<tr>
<th>7025</th>
<td>99.300000</td>
<td>172.000000</td>
<td>40.0</td>
<td>124.000000</td>
<td>80.000000</td>
<td>100.000000</td>
</tr>
<tr>
<th>2134</th>
<td>97.500000</td>
<td>91.056517</td>
<td>18.0</td>
<td>146.000000</td>
<td>75.000000</td>
<td>94.000000</td>
</tr>
<tr>
<th>5212</th>
<td>97.400000</td>
<td>135.000000</td>
<td>18.0</td>
<td>125.000000</td>
<td>71.000000</td>
<td>99.000000</td>
</tr>
<tr>
<th>9213</th>
<td>97.900000</td>
<td>85.000000</td>
<td>18.0</td>
<td>153.000000</td>
<td>96.000000</td>
<td>99.000000</td>
</tr>
<tr>
<th>2306</th>
<td>97.000000</td>
<td>67.000000</td>
<td>20.0</td>
<td>136.000000</td>
<td>75.000000</td>
<td>99.000000</td>
</tr>
<tr>
<th>6106</th>
<td>98.600000</td>
<td>90.000000</td>
<td>18.0</td>
<td>109.000000</td>
<td>70.000000</td>
<td>98.000000</td>
</tr>
<tr>
<th>2727</th>
<td>98.282103</td>
<td>83.000000</td>
<td>17.0</td>
<td>123.000000</td>
<td>48.000000</td>
<td>92.000000</td>
</tr>
<tr>
<th>4098</th>
<td>99.100000</td>
<td>147.000000</td>
<td>20.0</td>
<td>133.483987</td>
<td>78.127013</td>
<td>100.000000</td>
</tr>
<tr>
<th>5233</th>
<td>98.800000</td>
<td>81.000000</td>
<td>16.0</td>
<td>114.000000</td>
<td>78.000000</td>
<td>97.311242</td>
</tr>
<tr>
<th>5107</th>
<td>100.000000</td>
<td>95.000000</td>
<td>24.0</td>
<td>133.000000</td>
<td>75.000000</td>
<td>94.000000</td>
</tr>
<tr>
<th>18327</th>
<td>98.900000</td>
<td>84.000000</td>
<td>16.0</td>
<td>130.000000</td>
<td>85.000000</td>
<td>98.000000</td>
</tr>
</tbody>
</table>
<p> </p>
<p>Examining the preceding table, it looks like we are in good shape. We can see the imputed mean values for each column (values having extra precision). Let's move onto the last vital sign we have in our data, the pain level.</p>
<p class="mce-root"/>


            

            
        
    

        

                            
                    <h1 class="header-title">Pain level</h1>
                
            
            
                
<p><strong>Pain</strong> is a common indication that something is wrong with the human body, and pain level is usually asked in every medical interview, whether it is the initial history and physical or the daily SOAP note. Pain levels are usually reported on a scale from 0 (non-existent) to 10 (unbearable). Let's first convert the <kbd>PAINSCALE</kbd> column to the numeric type:</p>
<pre>X_train.loc[:,'PAINSCALE'] = X_train.loc[:,'PAINSCALE'].apply(pd.to_numeric)<br/>X_test.loc[:,'PAINSCALE'] = X_test.loc[:,'PAINSCALE'].apply(pd.to_numeric)</pre>
<p>Now, we have to write a separate function for mean-imputing pain values, since it uses <kbd>-8</kbd> as a placeholder value instead of <kbd>-7</kbd>:</p>
<pre>def mean_impute_pain(data,col): <br/>    temp_mean = data.loc[(data[col] != -8) &amp; (data[col] != -9), col].mean()<br/>    data.loc[(data[col] == -8) | (data[col] == -9), col] = temp_mean <br/>    return data<br/><br/>X_train = mean_impute_pain(X_train,'PAINSCALE')<br/>X_test = mean_impute_pain(X_test,'PAINSCALE')</pre>
<p>Together, vital signs provide an important picture of the health of the patient. In the end, we will see how important a role these variables play when we do the variable importance.</p>
<p>Now, we can move on to the next variable category.</p>


            

            
        
    

        

                            
                    <h1 class="header-title">Reason-for-visit codes</h1>
                
            
            
                
<p>The reason-for-visit variables encode the reason for the patient visit, which can be seen as the chief complaint of the visit (we talked about chief complaints in <a href="71c31b0a-fa9e-4b31-8b58-f563a815e338.xhtml" target="_blank">Chapter 2</a>, <em>Healthcare Foundations</em>). In this dataset, these reasons are coded using a code set called <em>A Reason for Visit Classification for Ambulatory Care</em> (refer to <em>Page 16</em> and <em>Appendix II</em> of the 2011 documentation for further information; a screenshot of the first page of the <em>Appendix</em> is provided at the end of the chapter). While the exact code may not be determined early during the patient encounter, we include it here because:</p>
<ul>
<li>It reflects information available early during the patient encounter.</li>
<li>We would like to demonstrate how to process a coded variable (all the other coded variables occur too late in the patient encounter to be of use for this modeling task):</li>
</ul>
<div><img src="img/c468e8f7-db28-46d9-8d7a-814054403ffc.png" style="width:36.67em;height:25.92em;"/></div>
<p class="mce-root"/>
<p>Coded variables require special attention for the following reasons:</p>
<ul>
<li>Often there are multiple entries designated in the table for more than one code, and the reason-for-visit codes are no exception. Notice that this dataset contains three RFV columns (<kbd>RFV1</kbd>, <kbd>RFV2</kbd>, and <kbd>RFV3</kbd>). A code for asthma, for example, may appear in any of these columns. Therefore, it is not enough to do one-hot encoding for these columns. We must detect the presence of each code in <em>any</em> of the three columns, and we must write a special function to do that.</li>
<li>Codes are categorical, but the numbers themselves usually carry no meaning. For easier interpretation, we must name the columns accordingly, using suitable descriptions. To do this, we have put together a special <kbd>.csv</kbd> file that contains the typed description for each code (available for download at the book's GitHub repository).</li>
<li>One output format possibility is a column for each code, where a <kbd>1</kbd> indicates the presence of that code and a <kbd>0</kbd> indicates its absence (as done in Futoma et al., 2015). Any desired combinations/transformations can then be performed. We have used that format here.</li>
</ul>
<p>Without further ado, let's start transforming our reason-for-visit variables. First, we import the RFV code descriptions:</p>
<pre>rfv_codes_path = HOME_PATH + 'RFV_CODES.csv'<br/><br/>rfv_codes = pd.read_csv(rfv_codes_path,header=0,dtype='str')</pre>
<p>Now we will do our RFV code processing.</p>
<p>First, to name the columns properly, we import the <kbd>sub()</kbd> function from the <kbd>re</kbd> module (<kbd>re</kbd> stands for regular expression).</p>
<p>Then we write a function that scans any given RFV columns for the presence of an indicated code, and returns the dataset with a new column, with a <kbd>1</kbd> if the code is present and a <kbd>0</kbd> if the code is absent.</p>
<p>Next, we use a <kbd>for</kbd> loop to iterate through every code in the <kbd>.csv</kbd> file, effectively adding a binary column for every possible code. We do this for both the training and testing sets.</p>
<p>Finally, we drop the original RFV columns, since we no longer need them. The full code is as follows:</p>
<pre>from re import sub<br/><br/>def add_rfv_column(data,code,desc,rfv_columns):<br/>    column_name = 'rfv_' + sub(" ", "_", desc)<br/>    data[column_name] = (data[rfv_columns] == rfv_code).any(axis=1).astype('int')<br/>    return data<br/><br/>rfv_columns = ['RFV1','RFV2','RFV3']<br/>for (rfv_code,rfv_desc) in zip(<br/>    rfv_codes['Code'].tolist(),rfv_codes['Description'].tolist()<br/>):<br/>    X_train = add_rfv_column(<br/>        X_train,<br/>        rfv_code,<br/>        rfv_desc,<br/>        rfv_columns<br/>    )<br/>    X_test = add_rfv_column(<br/>        X_test,<br/>        rfv_code,<br/>        rfv_desc,<br/>        rfv_columns <br/>    )<br/>    <br/># Remove original RFV columns<br/>X_train.drop(rfv_columns, axis=1, inplace=True)<br/>X_test.drop(rfv_columns, axis=1, inplace=True)</pre>
<p>Let's take a look at our transformed dataset with the <kbd>head()</kbd> function:</p>
<pre>X_train.head(n=5)</pre>
<p>Notice that there are now 1,264 columns. While the full DataFrame has been truncated, if you scroll horizontally, you should see some of the new <kbd>rfv_</kbd> columns appended to the end of the DataFrame.</p>


            

            
        
    

        

                            
                    <h1 class="header-title">Injury codes</h1>
                
            
            
                
<p>Injury codes are also included in the data. While the reason-for-visit codes apply to all visits, injury codes only apply if the patient has undergone either physical injury, poisoning, or adverse effects of medical treatment (including suicide attempts). Because the exact reason for injury may not be known until a full workup has been performed, and that workup usually occurs after a decision to admit has already been made. Therefore, we will remove the injury code variables, since they potentially contain future information that will not be available at prediction time. However, if you wish to use such codes for your modeling task, remember that coded data can be processed in a manner similar to that shown earlier. Refer to the documentation for additional details on injury variables:</p>
<pre>inj_cols = [<br/>    'INJURY','INJR1','INJR2','INJPOISAD','INJPOISADR1',<br/>    'INJPOISADR2','INTENT','INJDETR','INJDETR1','INJDETR2',<br/>    'CAUSE1','CAUSE2','CAUSE3','CAUSE1R','CAUSE2R','CAUSE3R'<br/>]<br/><br/>X_train.drop(inj_cols, axis=1, inplace=True)<br/>X_test.drop(inj_cols, axis=1, inplace=True)</pre>
<p class="mce-root"/>
<p class="mce-root"/>
<p class="mce-root"/>
<p class="mce-root"/>
<p class="mce-root"/>
<p class="mce-root"/>
<p class="mce-root"/>
<p class="mceNonEditable"/>


            

            
        
    

        

                            
                    <h1 class="header-title">Diagnostic codes</h1>
                
            
            
                
<p>The dataset also contains ICD-9-DM codes to classify diagnoses associated with each visit. Notice that there are three diagnostic code columns. This is consistent with what we said about coded variables in the <em>Reason-for-Visit codes</em> section. Because ICD-9 codes are usually assigned to visits after the workup has been performed and the cause of the symptoms determined, we will have to omit them from this modeling task:</p>
<pre>diag_cols= [<br/>    'DIAG1','DIAG2','DIAG3',<br/>    'PRDIAG1','PRDIAG2','PRDIAG3',<br/>    'DIAG1R','DIAG2R','DIAG3R'<br/>]<br/><br/>X_train.drop(diag_cols, axis=1, inplace=True)<br/>X_test.drop(diag_cols, axis=1, inplace=True)</pre>


            

            
        
    

        

                            
                    <h1 class="header-title">Medical history</h1>
                
            
            
                
<p class="mce-root">As we discussed in <a href="71c31b0a-fa9e-4b31-8b58-f563a815e338.xhtml" target="_blank">Chapter 2</a>, <em>Healthcare Foundations</em>, individuals that have chronic conditions are usually less healthy and have poorer health outcomes than those who do not have chronic health conditions. The dataset includes information on the presence of 11 common chronic conditions for each visit. These conditions are cancer, cerebrovascular disease, chronic obstructive pulmonary disease, a condition requiring dialysis, congestive heart failure, dementia, diabetes, history of myocardial infarction, history of pulmonary embolism or deep vein thrombosis, and HIV/AIDS. Because past medical history is often available electronically for previously seen patients and is usually established early during patient triage, we have decided to include these variables here. Because they are already binary, no processing of these variables is needed.</p>
<p>There is also a continuous variable, called <kbd>TOTCHRON</kbd>, that tallies the total number of chronic disease for each patient, which we mean-impute as follows:</p>
<pre>X_train.loc[:,'TOTCHRON'] = X_train.loc[:,'TOTCHRON'].apply(pd.to_numeric)<br/>X_test.loc[:,'TOTCHRON'] = X_test.loc[:,'TOTCHRON'].apply(pd.to_numeric)<br/><br/>X_train = mean_impute_values(X_train,'TOTCHRON')<br/>X_test = mean_impute_values(X_test,'TOTCHRON')</pre>
<p class="mce-root"/>
<p class="mce-root"/>
<p class="mce-root"/>
<p class="mceNonEditable"/>


            

            
        
    

        

                            
                    <h1 class="header-title">Tests</h1>
                
            
            
                
<p>Medical tests, while important, occur post-prediction time and must be omitted for this use case. They may be used for other modeling tasks, such as readmission prediction or mortality:</p>
<pre>testing_cols = [<br/>    'ABG','BAC','BLOODCX','BNP','BUNCREAT',<br/>    'CARDENZ','CBC','DDIMER','ELECTROL','GLUCOSE',<br/>    'LACTATE','LFT','PTTINR','OTHERBLD','CARDMON',<br/>    'EKG','HIVTEST','FLUTEST','PREGTEST','TOXSCREN',<br/>    'URINE','WOUNDCX','URINECX','OTHRTEST','ANYIMAGE',<br/>    'XRAY','IVCONTRAST','CATSCAN','CTAB','CTCHEST',<br/>    'CTHEAD','CTOTHER','CTUNK','MRI','ULTRASND',<br/>    'OTHIMAGE','TOTDIAG','DIAGSCRN'<br/>]<br/><br/>X_train.drop(testing_cols, axis=1, inplace=True)<br/>X_test.drop(testing_cols, axis=1, inplace=True)</pre>


            

            
        
    

        

                            
                    <h1 class="header-title">Procedures</h1>
                
            
            
                
<p>We omit procedures because, similar to the tests, they often occur post-prediction time:</p>
<pre>proc_cols = [<br/>    'PROC','BPAP','BLADCATH','CASTSPLINT','CENTLINE',<br/>    'CPR','ENDOINT','INCDRAIN','IVFLUIDS','LUMBAR',<br/>    'NEBUTHER','PELVIC','SKINADH','SUTURE','OTHPROC',<br/>    'TOTPROC'<br/>]<br/><br/>X_train.drop(proc_cols, axis=1, inplace=True)<br/>X_test.drop(proc_cols, axis=1, inplace=True)</pre>


            

            
        
    

        

                            
                    <h1 class="header-title">Medication codes</h1>
                
            
            
                
<p>The data includes ample information on medications given in the ED and/or prescribed at discharge. In fact, information on up to 12 medications is allotted in various columns. Obviously, medication administration occurs after the decision to admit the patient has been made, so we cannot use these columns for this use case.</p>
<p class="mce-root"/>
<p>Nevertheless, we encourage you to peruse the documentation and read about the coding systems used for medications if you wish to use such information in your own predictive modeling:</p>
<pre>med_cols = [<br/>    'MED1','MED2','MED3','MED4','MED5',<br/>    'MED6','MED7','MED8','MED9','MED10',<br/>    'MED11','MED12','GPMED1','GPMED2','GPMED3',<br/>    'GPMED4','GPMED5','GPMED6','GPMED7','GPMED8',<br/>    'GPMED9','GPMED10','GPMED11','GPMED12','NUMGIV',<br/>    'NUMDIS','NUMMED',<br/>]<br/><br/>X_train.drop(med_cols, axis=1, inplace=True)<br/>X_test.drop(med_cols, axis=1, inplace=True)</pre>


            

            
        
    

        

                            
                    <h1 class="header-title">Provider information</h1>
                
            
            
                
<p>Provider columns indicate which type(s) of medical providers participated in the medical encounter. We have omitted these variables:</p>
<pre>prov_cols = [<br/>    'NOPROVID','ATTPHYS','RESINT','CONSULT','RNLPN',<br/>    'NURSEPR','PHYSASST','EMT','MHPROV','OTHPROV'<br/>]<br/><br/>X_train.drop(prov_cols, axis=1, inplace=True)<br/>X_test.drop(prov_cols, axis=1, inplace=True)</pre>


            

            
        
    

        

                            
                    <h1 class="header-title">Disposition information</h1>
                
            
            
                
<p>Because disposition variables are directly related to the outcome, we cannot leave them in the data. We omit them here (recall that we previously removed several of the disposition variables right after we created our final target column):</p>
<pre>disp_cols = [<br/>    'NODISP','NOFU','RETRNED','RETREFFU','LEFTBTRI',<br/>    'LEFTAMA','DOA','DIEDED','TRANNH','OTHDISP',<br/>    'ADMIT','ADMTPHYS','BOARDED','LOS','HDDIAG1',<br/>    'HDDIAG2','HDDIAG3','HDDIAG1R','HDDIAG2R','HDDIAG3R',<br/>    'HDSTAT','ADISP','OBSSTAY','STAY24'<br/>]<br/><br/>
X_train.drop(disp_cols, axis=1, inplace=True)<br/>X_test.drop(disp_cols, axis=1, inplace=True)</pre>


            

            
        
    

        

                            
                    <h1 class="header-title">Imputed columns</h1>
                
            
            
                
<p>These columns indicate those that contain imputed data. For the most part, we have included the unimputed counterparts in our data and therefore do not need the imputed columns, so we remove them:</p>
<pre>imp_cols = [<br/>    'AGEFL','BDATEFL','SEXFL','ETHNICFL','RACERFL'<br/>]<br/><br/>X_train.drop(imp_cols, axis=1, inplace=True)<br/>X_test.drop(imp_cols, axis=1, inplace=True)</pre>


            

            
        
    

        

                            
                    <h1 class="header-title">Identifying variables</h1>
                
            
            
                
<p>When combined, the identifying variables provide a unique key for each encounter. While this may come in handy in many situations, fortunately, <kbd>pandas</kbd> DataFrames already uniquely assign an integer to each row, so we can remove the ID variables:</p>
<pre>id_cols = [<br/>    'HOSPCODE','PATCODE'<br/>]<br/><br/>X_train.drop(id_cols, axis=1, inplace=True)<br/>X_test.drop(id_cols, axis=1, inplace=True)</pre>


            

            
        
    

        

                            
                    <h1 class="header-title">Electronic medical record status columns</h1>
                
            
            
                
<p>The dataset includes dozens of columns that indicate the technological level of the facility at which the patient was seen. We discussed this in the <em>EHR technology and meaningful use</em> section in <a href="71c31b0a-fa9e-4b31-8b58-f563a815e338.xhtml" target="_blank">Chapter 2</a>, <em>Healthcare Foundations</em>. We omit these columns since they are valued on a per-hospital basis rather than a per-encounter basis:</p>
<pre>emr_cols = [<br/>    'EBILLANYE','EMRED','HHSMUE','EHRINSE','EDEMOGE',<br/>    'EDEMOGER','EPROLSTE','EPROLSTER','EVITALE','EVITALER',<br/>    'ESMOKEE','ESMOKEER','EPNOTESE','EPNOTESER','EMEDALGE',<br/>    'EMEDALGER','ECPOEE','ECPOEER','ESCRIPE','ESCRIPER',<br/>    'EWARNE','EWARNER','EREMINDE','EREMINDER','ECTOEE',<br/>    'ECTOEER','EORDERE','EORDERER','ERESULTE','ERESULTER',<br/>    'EGRAPHE','EGRAPHER','EIMGRESE','EIMGRESER','EPTEDUE',<br/>    'EPTEDUER','ECQME','ECQMER','EGENLISTE','EGENLISTER',<br/>    'EIMMREGE','EIMMREGER','ESUME','ESUMER','EMSGE',<br/>    'EMSGER','EHLTHINFOE','EHLTHINFOER','EPTRECE','EPTRECER',<br/>    'EMEDIDE','EMEDIDER','ESHAREE','ESHAREEHRE','ESHAREWEBE',<br/>    'ESHAREOTHE','ESHAREUNKE','ESHAREREFE','LABRESE1','LABRESE2',<br/>    'LABRESE3','LABRESE4','LABRESUNKE','LABRESREFE','IMAGREPE1',<br/>    'IMAGREPE2','IMAGREPE3','IMAGREPE4','IMAGREPUNKE','IMAGREPREFE',<br/>    'PTPROBE1','PTPROBE2','PTPROBE3','PTPROBE4','PTPROBUNKE',<br/>    'PTPROBREFE','MEDLISTE1','MEDLISTE2','MEDLISTE3','MEDLISTE4',<br/>    'MEDLISTUNKE','MEDLISTREFE','ALGLISTE1','ALGLISTE2','ALGLISTE3',<br/>    'ALGLISTE4','ALGLISTUNKE','ALGLISTREFE','EDPRIM','EDINFO',<br/>    'MUINC','MUYEAR'<br/>]<br/><br/>X_train.drop(emr_cols, axis=1, inplace=True)<br/>X_test.drop(emr_cols, axis=1, inplace=True)</pre>


            

            
        
    

        

                            
                    <h1 class="header-title">Detailed medication information</h1>
                
            
            
                
<p>More detailed drug information is available in these columns. These columns include information on drug categories, which is coded. We must omit these columns because they represent future information. However, this information could be immensely useful in other machine learning problems:</p>
<pre>drug_id_cols = [<br/>    'DRUGID1','DRUGID2','DRUGID3','DRUGID4','DRUGID5',<br/>    'DRUGID6','DRUGID7','DRUGID8','DRUGID9','DRUGID10',<br/>    'DRUGID11','DRUGID12'<br/>]<br/><br/>drug_lev1_cols = [<br/>    'RX1V1C1','RX1V1C2','RX1V1C3','RX1V1C4',<br/>    'RX2V1C1','RX2V1C2','RX2V1C3','RX2V1C4',<br/>    'RX3V1C1','RX3V1C2','RX3V1C3','RX3V1C4',<br/>    'RX4V1C1','RX4V1C2','RX4V1C3','RX4V1C4',<br/>    'RX5V1C1','RX5V1C2','RX5V1C3','RX5V1C4',<br/>    'RX6V1C1','RX6V1C2','RX6V1C3','RX6V1C4',<br/>    'RX7V1C1','RX7V1C2','RX7V1C3','RX7V1C4',<br/>    'RX8V1C1','RX8V1C2','RX8V1C3','RX8V1C4',<br/>    'RX9V1C1','RX9V1C2','RX9V1C3','RX9V1C4',<br/>    'RX10V1C1','RX10V1C2','RX10V1C3','RX10V1C4',<br/>    'RX11V1C1','RX11V1C2','RX11V1C3','RX11V1C4',<br/>    'RX12V1C1','RX12V1C2','RX12V1C3','RX12V1C4'<br/>]<br/><br/>drug_lev2_cols = [<br/>    'RX1V2C1','RX1V2C2','RX1V2C3','RX1V2C4',<br/>    'RX2V2C1','RX2V2C2','RX2V2C3','RX2V2C4',<br/>    'RX3V2C1','RX3V2C2','RX3V2C3','RX3V2C4',<br/>    'RX4V2C1','RX4V2C2','RX4V2C3','RX4V2C4',<br/>    'RX5V2C1','RX5V2C2','RX5V2C3','RX5V2C4',<br/>    'RX6V2C1','RX6V2C2','RX6V2C3','RX6V2C4',<br/>    'RX7V2C1','RX7V2C2','RX7V2C3','RX7V2C4',<br/>    'RX8V2C1','RX8V2C2','RX8V2C3','RX8V2C4',<br/>    'RX9V2C1','RX9V2C2','RX9V2C3','RX9V2C4',<br/>    'RX10V2C1','RX10V2C2','RX10V2C3','RX10V2C4',<br/>    'RX11V2C1','RX11V2C2','RX11V2C3','RX11V2C4',<br/>    'RX12V2C1','RX12V2C2','RX12V2C3','RX12V2C4'<br/>]<br/><br/>drug_lev3_cols = [<br/>    'RX1V3C1','RX1V3C2','RX1V3C3','RX1V3C4',<br/>    'RX2V3C1','RX2V3C2','RX2V3C3','RX2V3C4',<br/>    'RX3V3C1','RX3V3C2','RX3V3C3','RX3V3C4',<br/>    'RX4V3C1','RX4V3C2','RX4V3C3','RX4V3C4',<br/>    'RX5V3C1','RX5V3C2','RX5V3C3','RX5V3C4',<br/>    'RX6V3C1','RX6V3C2','RX6V3C3','RX6V3C4',<br/>    'RX7V3C1','RX7V3C2','RX7V3C3','RX7V3C4',<br/>    'RX8V3C1','RX8V3C2','RX8V3C3','RX8V3C4',<br/>    'RX9V3C1','RX9V3C2','RX9V3C3','RX9V3C4',<br/>    'RX10V3C1','RX10V3C2','RX10V3C3','RX10V3C4',<br/>    'RX11V3C1','RX11V3C2','RX11V3C3','RX11V3C4',<br/>    'RX12V3C1','RX12V3C2','RX12V3C3','RX12V3C4'<br/>]<br/><br/>addl_drug_cols = [<br/>    'PRESCR1','CONTSUB1','COMSTAT1','RX1CAT1','RX1CAT2',<br/>    'RX1CAT3','RX1CAT4','PRESCR2','CONTSUB2','COMSTAT2',<br/>    'RX2CAT1','RX2CAT2','RX2CAT3','RX2CAT4','PRESCR3','CONTSUB3',<br/>    'COMSTAT3','RX3CAT1','RX3CAT2','RX3CAT3','RX3CAT4','PRESCR4',<br/>    'CONTSUB4','COMSTAT4','RX4CAT1','RX4CAT2','RX4CAT3',<br/>    'RX4CAT4','PRESCR5','CONTSUB5','COMSTAT5','RX5CAT1',<br/>    'RX5CAT2','RX5CAT3','RX5CAT4','PRESCR6','CONTSUB6',<br/>    'COMSTAT6','RX6CAT1','RX6CAT2','RX6CAT3','RX6CAT4','PRESCR7',<br/>    'CONTSUB7','COMSTAT7','RX7CAT1','RX7CAT2','RX7CAT3',<br/>    'RX7CAT4','PRESCR8','CONTSUB8','COMSTAT8','RX8CAT1',<br/>    'RX8CAT2','RX8CAT3','RX8CAT4','PRESCR9','CONTSUB9',<br/>    'COMSTAT9','RX9CAT1','RX9CAT2','RX9CAT3','RX9CAT4',<br/>    'PRESCR10','CONTSUB10','COMSTAT10','RX10CAT1','RX10CAT2',<br/>    'RX10CAT3','RX10CAT4','PRESCR11','CONTSUB11','COMSTAT11',<br/>    'RX11CAT1','RX11CAT2','RX11CAT3','RX11CAT4','PRESCR12',<br/>    'CONTSUB12','COMSTAT12','RX12CAT1','RX12CAT2','RX12CAT3',<br/>    'RX12CAT4'<br/>]<br/><br/>X_train.drop(drug_id_cols, axis=1, inplace=True)<br/>X_train.drop(drug_lev1_cols, axis=1, inplace=True)<br/>X_train.drop(drug_lev2_cols, axis=1, inplace=True)<br/>X_train.drop(drug_lev3_cols, axis=1, inplace=True)<br/>X_train.drop(addl_drug_cols, axis=1, inplace=True)<br/><br/>X_test.drop(drug_id_cols, axis=1, inplace=True)<br/>X_test.drop(drug_lev1_cols, axis=1, inplace=True)<br/>X_test.drop(drug_lev2_cols, axis=1, inplace=True)<br/>X_test.drop(drug_lev3_cols, axis=1, inplace=True)<br/>X_test.drop(addl_drug_cols, axis=1, inplace=True)</pre>


            

            
        
    

        

                            
                    <h1 class="header-title">Miscellaneous information</h1>
                
            
            
                
<p>Finally, there are several columns at the end that are irrelevant for our purposes, so we remove them:</p>
<pre>design_cols = ['CSTRATM','CPSUM','PATWT','EDWT']<br/><br/>X_train.drop(design_cols, axis=1, inplace=True)<br/>X_test.drop(design_cols, axis=1, inplace=True)</pre>


            

            
        
    

        

                            
                    <h1 class="header-title">Final preprocessing steps</h1>
                
            
            
                
<p>Now that we have gone through all of the variable groups, we are almost ready to build our predictive models. But first, we must expand all of our categorical variables into binary variables (also known as one-hot encoding or a 1-of-K representation) and convert our data into a format suitable for input into the <kbd>scikit-learn</kbd> methods. Let's do that next.</p>


            

            
        
    

        

                            
                    <h1 class="header-title">One-hot encoding</h1>
                
            
            
                
<p>Many classifiers of the scikit-learn library require categorical variables to be one-hot encoded. <strong>One-hot encoding</strong>, or a <strong>1-of-K representation</strong>, is when a categorical variable that has more than two possible values is recorded as multiple variables each having two possible values.</p>
<p>For example, let's say that we have five patients in our dataset and we wish to one-hot encode a column that encodes the primary visit diagnosis. Before one-hot encoding, the column looks like this:</p>
<table border="1" style="border-collapse: collapse;width: 100%">
<tbody>
<tr>
<td><kbd>patient_id</kbd></td>
<td><kbd>primary_dx</kbd></td>
</tr>
<tr>
<td>1</td>
<td>copd</td>
</tr>
<tr>
<td>2</td>
<td>hypertension</td>
</tr>
<tr>
<td>3</td>
<td>copd</td>
</tr>
<tr>
<td>4</td>
<td>chf</td>
</tr>
<tr>
<td>5</td>
<td>asthma</td>
</tr>
</tbody>
</table>
<p> </p>
<p class="mce-root">After one-hot encoding, this column would be split into <em>K</em> columns, where <em>K</em> is the number of possible values, and each column takes a value of 0 or 1 depending on whether the observation takes the value corresponding to that column:</p>
<table border="1" style="border-collapse: collapse;width: 100%">
<tbody>
<tr>
<td><kbd>patient_id</kbd></td>
<td><kbd>primary_dx_copd</kbd></td>
<td><kbd>primary_dx_hypertension</kbd></td>
<td><kbd>primary_dx_chf</kbd></td>
<td><kbd>primary_dx_asthma</kbd></td>
</tr>
<tr>
<td>1</td>
<td>1</td>
<td>0</td>
<td>0</td>
<td>0</td>
</tr>
<tr>
<td>2</td>
<td>0</td>
<td>1</td>
<td>0</td>
<td>0</td>
</tr>
<tr>
<td>3</td>
<td>1</td>
<td>0</td>
<td>0</td>
<td>0</td>
</tr>
<tr>
<td>4</td>
<td>0</td>
<td>0</td>
<td>1</td>
<td>0</td>
</tr>
<tr>
<td>5</td>
<td>0</td>
<td>0</td>
<td>0</td>
<td>1</td>
</tr>
</tbody>
</table>
<p> </p>
<p>Note that we have converted the strings of the previous column into an integer representation. This makes sense since machine learning algorithms are trained on numbers, not words! This is why one-hot encoding is necessary.</p>
<p><kbd>scikit-learn</kbd> has a <kbd>OneHotEncoder</kbd> class in its <kbd>preprocessing</kbd> module. However, <kbd>pandas</kbd> has a <kbd>get_dummies()</kbd> function that accomplishes one-hot encoding in a single line. Let's use the <kbd>pandas</kbd> function. Before we do that, we must identify the columns that are categorical in our dataset to be passed to the function. We do this by using the metadata to identify the categorical columns and seeing which of those columns intersect with the columns that remain in our data:</p>
<pre>categ_cols = df_helper.loc[<br/>    df_helper['variable_type'] == 'CATEGORICAL', 'column_name'<br/>]<br/><br/>one_hot_cols = list(set(categ_cols) &amp; set(X_train.columns))<br/><br/>X_train = pd.get_dummies(X_train, columns=one_hot_cols)</pre>
<p>We must also one-hot encode the test data:</p>
<pre>X_test = pd.get_dummies(X_test, columns=one_hot_cols)</pre>
<p>As a final note, we should mention that there is the possibility that the testing set will contain categorical values that haven't been seen in the training data. This may cause an error when assessing the performance of the model using the testing set. To prevent this, you may have to write some extra code that sets any missing columns in the testing set to zero. Fortunately, we do not have to worry about that with our dataset.</p>


            

            
        
    

        

                            
                    <h1 class="header-title">Numeric conversion</h1>
                
            
            
                
<p>Let's now convert all of the columns into numeric format:</p>
<pre>X_train.loc[:,X_train.columns] = X_train.loc[:,X_train.columns].apply(pd.to_numeric)<br/>X_test.loc[:,X_test.columns] = X_test.loc[:,X_test.columns].apply(pd.to_numeric)</pre>


            

            
        
    

        

                            
                    <h1 class="header-title">NumPy array conversion</h1>
                
            
            
                
<p>The final step is taking the NumPy array of the pandas DataFrame that will be passed directly into the machine learning algorithm. First, we save the final column names, which will assist us when we assess variable importance later on:</p>
<pre>X_train_cols = X_train.columns<br/>X_test_cols = X_test.columns</pre>
<p>Now, we use the <kbd>values</kbd> attribute of the <kbd>pandas</kbd> DataFrames to access the underlying NumPy array for each DataFrame:</p>
<pre>X_train = X_train.values<br/>X_test = X_test.values</pre>
<p>Now, we are ready for to build the models.</p>


            

            
        
    

        

                            
                    <h1 class="header-title">Building the models</h1>
                
            
            
                
<p>In this section, we'll build three types of classifiers and assess their performance: a logistic regression classifier, a random forest, and a neural network.</p>
<p class="mce-root"/>


            

            
        
    

        

                            
                    <h1 class="header-title">Logistic regression</h1>
                
            
            
                
<p>We discussed the intuition behind and basics of logistic regression models in <a href="46c83498-cb6e-45b4-ac39-6875a8d32400.xhtml" target="_blank">Chapter 3</a>, <em>Machine Learning Foundations</em>. To build a model on our training set, we use the following code:</p>
<pre>from sklearn.linear_model import LogisticRegression<br/><br/>clfs = [LogisticRegression()]<br/><br/>for clf in clfs:<br/>    clf.fit(X_train, y_train.ravel())<br/>    print(type(clf))<br/>    print('Training accuracy: ' + str(clf.score(X_train, y_train)))<br/>    print('Validation accuracy: ' + str(clf.score(X_test, y_test)))<br/>    <br/>    coefs = {<br/>        'column': [X_train_cols[i] for i in range(len(X_train_cols))],<br/>        'coef': [clf.coef_[0,i] for i in range(len(X_train_cols))]<br/>    }<br/>    df_coefs = pd.DataFrame(coefs)<br/>    print(df_coefs.sort_values('coef', axis=0, ascending=False))</pre>
<p>Prior to the <kbd>for</kbd> loop, we import the <kbd>LogisticRegression</kbd> class and set <kbd>clf</kbd> equal to a <kbd>LogisticRegression</kbd> instance. The training and testing occur in the <kbd>for</kbd> loop. First, we use the <kbd>fit()</kbd> method to fit the model (for example, to determine the optimal coefficients) using the training data. Next, we use the <kbd>score()</kbd> method to assess the model performance on both the training data and the testing data.</p>
<p>In the second half of the <kbd>for</kbd> loop, we print out the coefficient values of each feature. In general, features with coefficients that are farther from zero are the most positively/negatively correlated with the outcome. However, we did not scale the data prior to training, so it is possible that more important predictors that are not scaled appropriately will have lower coefficients.</p>
<p>The output of the code should look like the following:</p>
<pre>&lt;class 'sklearn.linear_model.logistic.LogisticRegression'&gt;
Training accuracy: 0.888978581423
Validation accuracy: 0.884261501211
         coef                                             column
346  2.825056                     rfv_Symptoms_of_onset_of_labor
696  1.618454                   rfv_Adverse_effect_of_drug_abuse
95   1.467790                    rfv_Delusions_or_hallucinations
108  1.435026  rfv_Other_symptoms_or_problems_relating_to_psy...
688  1.287535                                rfv_Suicide_attempt
895  1.265043                                          IMMEDR_01
520  1.264023  rfv_General_psychiatric_or_psychological_exami...
278  1.213235                                       rfv_Jaundice
712  1.139245         rfv_For_other_and_unspecified_test_results
469  1.084806                            rfv_Other_heart_disease<br/>...</pre>
<p>First, let's discuss the performance of the training and testing sets. They are close together, which indicates the model did not overfit to the training set. The accuracy is approximately 88%, which is on par with performance in research studies (Cameron et al., 2015) for predicting emergency department status.</p>
<p>Looking at the coefficients, we can confirm that they make intuitive sense. The feature with the highest coefficient is related to the onset of labor in pregnancy; we all know that labor results in a hospital admission. Many of the features pertaining to severe psychiatric disease, which almost always result in an admission due to the risk the patient poses to themselves or to others. The <kbd>IMMEDR_1</kbd> feature also has a high coefficient; remember that this feature corresponds to a value of 1 on the triage scale, which is the most critical value:</p>
<pre>...<br/>898 -0.839861                                          IMMEDR_04
823 -0.848631                                         BEDDATA_03
625 -0.873828                               rfv_Hand_and_fingers
371 -0.960739                                      rfv_Skin_rash
188 -0.963524                                  rfv_Earache_pain_
217 -0.968058                                       rfv_Soreness
899 -1.019763                                          IMMEDR_05
604 -1.075670                      rfv_Suture__insertion_removal
235 -1.140021                                      rfv_Toothache
30  -1.692650                                           LEFTATRI</pre>
<p>In contrast, scrolling to the bottom reveals some of the features that are negatively correlated with an admission. Having a toothache and needing sutures to be removed show up here, and they are not likely to result in admissions since they are not urgent complaints.</p>
<p>We've trained our first model. Let's see whether some of the more complex models will improve.</p>
<p class="mce-root"/>
<p class="mce-root"/>


            

            
        
    

        

                            
                    <h1 class="header-title">Random forest</h1>
                
            
            
                
<p>A convenient feature of <kbd>scikit-learn</kbd> is that many of the classifiers have identical methods so that models can be built interchangeably. We see that in the following code, when we use the <kbd>fit()</kbd> and <kbd>score()</kbd> methods of the <kbd>RandomForestClassifier</kbd> class to train the model and assess its performance, respectively:</p>
<pre>from sklearn.ensemble import RandomForestClassifier<br/><br/>clfs_rf = [RandomForestClassifier(n_estimators=100)]<br/><br/>for clf in clfs_rf:<br/>    clf.fit(X_train, y_train.ravel())<br/>    print(type(clf))<br/>    print('Training accuracy: ' + str(clf.score(X_train, y_train)))<br/>    print('Validation accuracy: ' + str(clf.score(X_test, y_test)))<br/>    <br/>    imps = {<br/>        'column': [X_train_cols[i] for i in range(len(X_train_cols))],<br/>        'imp': [clf.feature_importances_[i] for i in range(len(X_train_cols))]<br/>    }<br/>    df_imps = pd.DataFrame(imps)<br/>    print(df_imps.sort_values('imp', axis=0, ascending=False))</pre>
<p>The output should look similar to the following:</p>
<pre>&lt;class 'sklearn.ensemble.forest.RandomForestClassifier'&gt;
Training accuracy: 1.0
Validation accuracy: 0.885391444713
                                                column       imp
1                                                  AGE  0.039517
13                                               PULSE  0.028348
15                                               BPSYS  0.026833
12                                               TEMPF  0.025898
16                                              BPDIAS  0.025844
0                                             WAITTIME  0.025111
14                                               RESPR  0.021329
17                                               POPCT  0.020407
29                                            TOTCHRON  0.018417
896                                          IMMEDR_02  0.016714<br/>...</pre>
<p>This time the validation accuracy was similar to that of the logistic regression model, approximately 88%. However, the accuracy on the training data was 100%, indicating that we overfit the model to the training data. We'll discuss potential ways of improving our models at the end of this chapter.</p>
<p class="mce-root"/>
<p class="mce-root"/>
<p class="mce-root"/>
<p class="mce-root"/>
<p class="mce-root"/>
<p class="mceNonEditable"/>
<p>Looking at the feature importance, again the results make sense. This time the vital signs seem to be the most important predictors, along with the age predictor. Scrolling to the bottom reveals those features that had no impact on predictability. Note that in contrast to regression coefficients, with the variable importance of random forest, the frequency with which the variable was positive plays a role in the importance; this may explain why <kbd>IMMEDR_02</kbd> is ranked as more important than <kbd>IMMEDR_01</kbd>.</p>


            

            
        
    

        

                            
                    <h1 class="header-title">Neural network</h1>
                
            
            
                
<p>Finally, we arrive at the neural network model. Note that our training set only has approximately 18,000 observations; the most successful neural network models (for example, "deep learning" models) typically use millions or even billions of observations. Nevertheless, let's see how our neural network model fares. For neural networks, it is recommended that the data is scaled appropriately (for example, having a <strong>standard distribution</strong> with a mean equal to 0 and a standard deviation equal to 1). We use the <kbd>StandardScaler</kbd> class to accomplish this:</p>
<pre>from sklearn.preprocessing import StandardScaler<br/>from sklearn.neural_network import MLPClassifier <br/><br/># Scale data<br/>scaler = StandardScaler() <br/>scaler.fit(X_train) <br/>X_train_Tx = scaler.transform(X_train) <br/>X_test_Tx = scaler.transform(X_test) <br/><br/># Fit models that require scaling (e.g. neural networks)<br/>hl_sizes = [150,100,80,60,40,20]<br/>nn_clfs = [MLPClassifier(hidden_layer_sizes=(size,), random_state=2345, verbose=True) for size in hl_sizes]<br/><br/>for num, nn_clf in enumerate(nn_clfs):<br/>    print(str(hl_sizes[num]) + '-unit network:')<br/>    nn_clf.fit(X_train_Tx, y_train.ravel())<br/>    print('Training accuracy: ' + str(nn_clf.score(X_train_Tx, y_train)))<br/>    print('Validation accuracy: ' + str(nn_clf.score(X_test_Tx, y_test)))</pre>
<p>Once you run the preceding cell, you will see iterations being completed, and once the iterations fail to result in improvements to the model, the training will stop and the accuracies will be printed. In our run, the validation accuracy of the model having 150 cells in its hidden layer was 87%, higher than the other hidden layer sizes.</p>
<p class="mce-root"/>


            

            
        
    

        

                            
                    <h1 class="header-title">Using the models to make predictions</h1>
                
            
            
                
<p>We have finished preprocessing the data, and making and scoring the model. The AUC is similar to that reported in previous academic studies that predict ED outcomes (see Cameron et al., 2015 for an example).</p>
<p>The next step would be to save and deploy the model and use it to make live predictions. Fortunately, all of the classifiers in the scikit-learn library include several functions for making predictions:</p>
<ul>
<li>For most classifiers, the <kbd>predict()</kbd> function takes a matrix, <em>X</em>, that contains unlabeled data as input and simply returns the class predictions with no further information.</li>
<li>The <kbd>predict_proba()</kbd> function takes a matrix, <em>X</em>, that contains unlabeled data as input and returns the probabilities with which the observations belong to each class. These should add up to <kbd>1</kbd> for each observation.</li>
<li>The <kbd>predict_log_proba()</kbd> function is similar to the <kbd>predict_proba()</kbd> function except that it returns the log probabilities with which the observations belong to each class.</li>
</ul>
<p>Keep the following important fact in mind: <em>When making predictions, the unlabeled data must be preprocessed identically to the manner in which the training data was preprocessed</em>. This includes:</p>
<ul>
<li>Column additions and deletions</li>
<li>Column transformations</li>
<li>Imputation of missing values</li>
<li>Scaling and centering</li>
<li>One-hot encoding</li>
</ul>
<p>Just one column that is not preprocessed properly can have an extremely negative impact on the model predictions.</p>


            

            
        
    

        

                            
                    <h1 class="header-title">Improving our models</h1>
                
            
            
                
<p>Although in this chapter we have built a rudimentary model that matches the performance of academic research studies, there is certainly room for improvement. The following are some ideas for how the model can be improved, and we leave it to the reader to implement these suggestions and any other tricks or techniques the reader might know to improve performance. How high will your performance go?</p>
<p class="mce-root"/>
<p>First and foremost, the current training data has a large number of columns. Some sort of feature selection is almost always performed, particularly for logistic regression and random forest models. For logistic regression, common methods of performing feature selection include:</p>
<ul>
<li>Using a certain number of predictors that have the highest coefficients</li>
<li>Using a certain number of predictors that have the lowest <em>p</em>-values</li>
<li>Using lasso regularization and removing predictors whose coefficients become zero</li>
<li>Using a greedy algorithm such as forward- or backward-stepwise logistic regression that removes/adds predictors systematically according to rules</li>
<li>Using a brute-force algorithm, such as best subset logistic regression, that tests every predictor permutation/combination for a given number of predictors</li>
</ul>
<p>For random forests, using the variable importance and selecting a certain number of predictors with the highest importance is very common, as is performing grid searches.</p>
<p>Neural networks have their own unique improvement techniques.</p>
<ul>
<li>For one thing, more data is always good, particularly with neural networks.</li>
<li>The specific optimization algorithm used can factor into the performance.</li>
<li>In this example, our neural networks only had one hidden layer. In the industry, models with multiple hidden layers are becoming increasingly common (although they may take a long time to train).</li>
<li>The specific nonlinear activation function used may also impact the model's performance.</li>
</ul>


            

            
        
    

        

                            
                    <h1 class="header-title">Summary</h1>
                
            
            
                
<p>In this chapter, we have built a predictive model for predicting outcomes in the emergency department. While there are many machine learning problems in healthcare, this exercise has demonstrated the issues typically faced as one preprocesses healthcare data, trains and scores models, and makes predictions with unlabeled data. This chapter marks the end of the coding portion of this book.</p>
<p>Now that we have seen the construction of a predictive model firsthand, the next logical question to ask is how predictive models have fared when compared with traditional statistical risk scores in predicting clinical outcomes. We explore that question in the next chapter.</p>
<p class="mce-root"/>
<p class="mce-root"/>


            

            
        
    

        

                            
                    <h1 class="header-title">References and further reading</h1>
                
            
            
                
<p class="highwire-cite-authors">Cameron A, Rodgers K, Ireland A, et al. (2015). A simple tool to predict admission at the time of triage. <em>Emerg Med J</em> 2015;32:174-179.</p>
<p>Futoma J, Morris J, Lucas J (2015). A comparison of models for predicting early hospital readmissions. Journal of Biomedical Informatics 56: 229-238.</p>


            

            
        
    </body></html>