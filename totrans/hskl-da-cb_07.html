<html><head></head><body><div class="chapter" title="Chapter&#xA0;7.&#xA0;Statistics and Analysis"><div class="titlepage"><div><div><h1 class="title"><a id="ch07"/>Chapter 7. Statistics and Analysis</h1></div></div></div><p>One core motivation to analyze big data is to find intrinsic patterns. This chapter contains recipes that answer questions about data deviation from the norm, existence of linear and quadratic trends, and probabilistic values of a network. Some of the most fascinating results can be uncovered by the following recipes:</p><div class="itemizedlist"><ul class="itemizedlist"><li class="listitem" style="list-style-type: disc">Calculating a moving average</li><li class="listitem" style="list-style-type: disc">Calculating a moving median</li><li class="listitem" style="list-style-type: disc">Approximating a linear regression</li><li class="listitem" style="list-style-type: disc">Approximating a quadratic regression</li><li class="listitem" style="list-style-type: disc">Obtaining the covariance matrix from samples</li><li class="listitem" style="list-style-type: disc">Finding all unique pairings in a list</li><li class="listitem" style="list-style-type: disc">Using the Pearson correlation coefficient</li><li class="listitem" style="list-style-type: disc">Evaluating a Bayesian network</li><li class="listitem" style="list-style-type: disc">Creating a data structure for playing cards</li><li class="listitem" style="list-style-type: disc">Using a Markov chain to generate text</li><li class="listitem" style="list-style-type: disc">Creating <span class="emphasis"><em>n</em></span>-grams from a list</li><li class="listitem" style="list-style-type: disc">Constructing a neural network perception</li></ul></div><div class="section" title="Introduction"><div class="titlepage"><div><div><h1 class="title"><a id="ch07lvl1sec85"/>Introduction</h1></div></div></div><div class="mediaobject"><img src="graphics/ch07.jpg" alt="Introduction"/></div><p>The first two recipes deal with summarizing a series of data. For example, assume someone asks, "How old is everyone?". A valid response could be to enumerate through the age of each person, but depending on the number of people, this could take minutes if not hours. Instead, we can answer in terms of the average or in terms of the median to summarize all the age values in one simple number.</p><p>The next two recipes are about approximating an equation that most closely fits a collection of points. Given two series of coordinates, we can use a linear or quadratic approximation to predict other points.</p><p>We can detect relationships between numerical data through covariance matrices and Pearson correlation calculations as demonstrated in the corresponding recipes.</p><p>The <code class="literal">Numeric.Probability.Distribution</code> library <a id="id402" class="indexterm"/>has many useful functions for deeper statistical understanding as demonstrated in the Bayesian network and playing cards recipes.</p><p>We will also use Markov chains and <span class="emphasis"><em>n</em></span>-grams for further interesting results.</p><p>Finally, we will create a neural network from scratch to learn a labelled set of data.</p></div></div>
<div class="section" title="Calculating a moving average"><div class="titlepage"><div><div><h1 class="title"><a id="ch07lvl1sec86"/>Calculating a moving average</h1></div></div></div><p>Summarizing a list of numbers<a id="id403" class="indexterm"/> into one representative number can be done by calculating the average. The equation for the arithmetic mean is to add up all the values and divide by the number of values. However, if the values being summed over are extremely large, the total sum may overflow.</p><p>In Haskell, the range for<a id="id404" class="indexterm"/> <code class="literal">Int</code> is at least from <span class="emphasis"><em>-2^29</em></span> to <span class="emphasis"><em>2^29-1</em></span>. Implementations are allowed to have an <code class="literal">Int</code> type with a larger range. If we try to naively average the numbers <span class="emphasis"><em>2^29-2</em></span> and <span class="emphasis"><em>2^29-3</em></span> by first calculating their sum, the sum may overflow, producing an incorrect calculation for the average.</p><p>A moving average (or running average) tries to escape this drawback. We will use an exponential smoothing strategy, which means numbers that were seen previously contribute exponentially less to the value of the running mean. An exponential moving average reacts faster to recent data. It can be used in situations for detecting price oscillations or spiking a neuron in a neural network.</p><p>The equation of a running mean is as follows, where <span class="strong"><strong>α</strong></span> is a smoothening constant, <span class="strong"><strong>s<sub>t</sub></strong></span> is the moving average value at time <span class="emphasis"><em>t</em></span>, and <span class="emphasis"><em>x</em></span> is the value of the raw data:</p><div class="mediaobject"><img src="graphics/6331OS_07_01.jpg" alt="Calculating a moving average"/></div><div class="section" title="Getting ready"><div class="titlepage"><div><div><h2 class="title"><a id="ch07lvl2sec233"/>Getting ready</h2></div></div></div><p>Create an <code class="literal">input.txt</code> file with a list of numbers separated by lines. We will be computing the moving average over these numbers:</p><div class="informalexample"><pre class="programlisting">
<span class="strong"><strong>$ cat input.txt</strong></span>

<span class="strong"><strong>4</strong></span>
<span class="strong"><strong>3</strong></span>
<span class="strong"><strong>2</strong></span>
<span class="strong"><strong>5</strong></span>
<span class="strong"><strong>3</strong></span>
<span class="strong"><strong>4</strong></span>
<span class="strong"><strong>1</strong></span>
<span class="strong"><strong>3</strong></span>
<span class="strong"><strong>12</strong></span>
<span class="strong"><strong>3</strong></span>
</pre></div></div><div class="section" title="How to do it…"><div class="titlepage"><div><div><h2 class="title"><a id="ch07lvl2sec234"/>How to do it…</h2></div></div></div><div class="orderedlist"><ol class="orderedlist arabic"><li class="listitem">Create a helper <a id="id405" class="indexterm"/>function to convert the raw text input into a list of <code class="literal">Double</code> as follows:<div class="informalexample"><pre class="programlisting">clean raw = map (\s -&gt; read s :: Double) (lines raw)</pre></div></li><li class="listitem">Calculate the moving average of a list of numbers using an exponential smoothing technique. We <span class="strong"><strong>hardcode</strong></span><a id="id406" class="indexterm"/> the smoothening constant <code class="literal">a</code> to be <code class="literal">0.95</code> as shown here:<div class="informalexample"><pre class="programlisting">avg :: [Double] -&gt; Double
avg (x:xs) = a*x + (1-a)*(avg xs)
where a = 0.95
avg [] = 0</pre></div></li><li class="listitem">Compute the true arithmetic mean to compare differences in the following manner:<div class="informalexample"><pre class="programlisting">mean xs = (sum xs) / (fromIntegral (length xs))</pre></div></li><li class="listitem">Print out the results of computing the moving average and arithmetic mean to notice how the values are not equal, but reasonably close:<div class="informalexample"><pre class="programlisting">main = do
rawInput &lt;- readFile "input.txt"
let input = clean rawInput
print input
putStrLn $  "mean is " ++ (show.mean) input
putStrLn $  "moving average is " ++ (show.avg) input</pre></div></li><li class="listitem">We will see the following output:<div class="informalexample"><pre class="programlisting">$ runhaskell Main.hs

[4.0,3.0,2.0,5.0,3.0,4.0,1.0,3.0,12.0,3.0]
mean is 4.0
moving average is 3.9478627675211913</pre></div></li></ol></div></div><div class="section" title="There's more…"><div class="titlepage"><div><div><h2 class="title"><a id="ch07lvl2sec235"/>There's more…</h2></div></div></div><p>The smoothening<a id="id407" class="indexterm"/> constant should be changed according to the fluctuation of the data. A small smoothening constant<a id="id408" class="indexterm"/> remembers previous values better and produces an average influenced by the grander structure of the data. On the other hand, a larger value of the smoothening constant puts superior emphasis on recent data, and easily forgets stale data. We should use a larger smoothening constant if we want our average to be more sensitive to new data.</p></div><div class="section" title="See also"><div class="titlepage"><div><div><h2 class="title"><a id="ch07lvl2sec236"/>See also</h2></div></div></div><p>Another way to summarize a list of numbers is explained in the <span class="emphasis"><em>Calculating a moving median</em></span> recipe.</p></div></div>
<div class="section" title="Calculating a moving median"><div class="titlepage"><div><div><h1 class="title"><a id="ch07lvl1sec87"/>Calculating a moving median</h1></div></div></div><p>The median <a id="id409" class="indexterm"/>of a list of numbers has an equal number of values less than and greater than it. The naive approach of calculating the median is to simply sort the list and pick the middle number. However, on a very large dataset, such a computation would be inefficient.</p><p>Another approach of finding a moving median is to use a combination of a <span class="strong"><strong>minheap</strong></span><a id="id410" class="indexterm"/> and a <span class="strong"><strong>maxheap</strong></span><a id="id411" class="indexterm"/> to sort the values while running through the data. We can insert numbers in either heap as they are seen, and whenever needed, the median can be calculated by adjusting the heaps to be of equal or near equal size. When the heaps are of equal size, it is simple to find the middle number, which is the median.</p><div class="section" title="Getting ready"><div class="titlepage"><div><div><h2 class="title"><a id="ch07lvl2sec237"/>Getting ready</h2></div></div></div><p>Create a file, <code class="literal">input.txt</code>, with some numbers:</p><div class="informalexample"><pre class="programlisting">
<span class="strong"><strong>$ cat input.txt</strong></span>

<span class="strong"><strong>3</strong></span>
<span class="strong"><strong>4</strong></span>
<span class="strong"><strong>2</strong></span>
<span class="strong"><strong>5</strong></span>
<span class="strong"><strong>6</strong></span>
<span class="strong"><strong>4</strong></span>
<span class="strong"><strong>2</strong></span>
<span class="strong"><strong>6</strong></span>
<span class="strong"><strong>4</strong></span>
<span class="strong"><strong>1</strong></span>
</pre></div><p>Also, install a library for dealing with heaps using Cabal as follows:</p><div class="informalexample"><pre class="programlisting">
<span class="strong"><strong>$ cabal install heap</strong></span>
</pre></div></div><div class="section" title="How to do it…"><div class="titlepage"><div><div><h2 class="title"><a id="ch07lvl2sec238"/>How to do it…</h2></div></div></div><div class="orderedlist"><ol class="orderedlist arabic"><li class="listitem">Import the heap data structure:<div class="informalexample"><pre class="programlisting">import Data.Heap
import Data.Maybe (fromJust)</pre></div></li><li class="listitem">Convert the raw input as a list of numbers as follows:<div class="informalexample"><pre class="programlisting">clean raw = map (\s -&gt; read s :: Int) (lines raw)</pre></div></li><li class="listitem">Segregate <a id="id412" class="indexterm"/>the numbers in the list into the appropriate heaps. Put small numbers in the maxheap, and big numbers in the minheap, as shown in the following code snippet:<div class="informalexample"><pre class="programlisting">median (x:xs) maxheap minheap = case viewHead maxheap of
  Just theMax  -&gt; if x &lt; theMax
             then median xs (insert x maxheap) minheap
             else median xs maxheap (insert x minheap)
  Nothing -&gt; median xs (insert x maxheap) minheap</pre></div></li><li class="listitem">When there are no more numbers to read, start manipulating the heaps until both are of equal size. The median will be the number between the values in both heaps, as presented in the following code snippet:<div class="informalexample"><pre class="programlisting">median [] maxheap minheap
  | size maxheap + 1 &lt; size minheap = 
                 median [] (insert minelem maxheap) $ 
       (snd.fromJust.view) minheap
  | size minheap + 1 &lt; size maxheap = 
              median [] ((snd.fromJust.view) maxheap) $ 
              insert maxelem minheap
  | size maxheap == size minheap = 
    (fromIntegral maxelem + fromIntegral minelem)/2.0
  | size maxheap &gt; size minheap = fromIntegral maxelem
  | otherwise = fromIntegral minelem
  where maxelem = fromJust (viewHead maxheap)
        minelem = fromJust (viewHead minheap)</pre></div></li><li class="listitem">Test out the code in <code class="literal">main</code> as follows:<div class="informalexample"><pre class="programlisting">main = do
  rawInput &lt;- readFile "input.txt"
  let input = clean rawInput
 print $ input
print $ median input 
       (empty :: MaxHeap Int) (empty :: MinHeap Int)</pre></div></li><li class="listitem">The output is as follows:<div class="informalexample"><pre class="programlisting">
<span class="strong"><strong>$ runhaskell Main.hs</strong></span>

<span class="strong"><strong>[3,4,2,5,6,4,2,6,4,1]</strong></span>
<span class="strong"><strong>4.0</strong></span>
</pre></div></li></ol></div></div><div class="section" title="How it works…"><div class="titlepage"><div><div><h2 class="title"><a id="ch07lvl2sec239"/>How it works…</h2></div></div></div><p>First, we traverse <a id="id413" class="indexterm"/>the list of numbers to build up a minheap and maxheap in an attempt to efficiently separate the stream of incoming numbers. Then we move values between the minheap and maxheap until their sizes differ by at most one item. The median is the extra item, or otherwise the average of the minheap and maxheap values.</p></div><div class="section" title="See also"><div class="titlepage"><div><div><h2 class="title"><a id="ch07lvl2sec240"/>See also</h2></div></div></div><p>For summarizing a list of numbers differently, refer to the <span class="emphasis"><em>Calculating a moving average</em></span> recipe.</p></div></div>
<div class="section" title="Approximating a linear regression"><div class="titlepage"><div><div><h1 class="title"><a id="ch07lvl1sec88"/>Approximating a linear regression</h1></div></div></div><p>Given a list of points, we <a id="id414" class="indexterm"/>can estimate the best fit line using a handy library, <code class="literal">Statistics.LinearRegression</code>.</p><p>It computes the least square difference between points to estimate the best fit line. An example of a linear regression of points can be seen in the following figure:</p><div class="mediaobject"><img src="graphics/6331OS_07_02.jpg" alt="Approximating a linear regression"/><div class="caption"><p>A best-fit line is drawn through five points using linear regression</p></div></div><div class="section" title="Getting ready"><div class="titlepage"><div><div><h2 class="title"><a id="ch07lvl2sec241"/>Getting ready</h2></div></div></div><p>Install the <a id="id415" class="indexterm"/>appropriate library<a id="id416" class="indexterm"/> using cabal as follows:</p><div class="informalexample"><pre class="programlisting">
<span class="strong"><strong>$ cabal install statistics-linreg</strong></span>
</pre></div></div><div class="section" title="How to do it…"><div class="titlepage"><div><div><h2 class="title"><a id="ch07lvl2sec242"/>How to do it…</h2></div></div></div><div class="orderedlist"><ol class="orderedlist arabic"><li class="listitem">Import the following packages:<div class="informalexample"><pre class="programlisting">import Statistics.LinearRegression
import qualified Data.Vector.Unboxed as U</pre></div></li><li class="listitem">Create a series of points from their coordinates, and feed it to the <code class="literal">linearRegression</code> function, as shown in the following code snippet:<div class="informalexample"><pre class="programlisting">main = do
  let xs =
    U.fromList [1.0, 2.0, 3.0, 4.0, 5.0] :: U.Vector Double
  let ys = 
    U.fromList [1.0, 2.0, 1.3, 3.75, 2.25]::U.Vector Double

  let (b, m) = linearRegression xs ys

  print $ concat ["y = ", show m, " x + ", show b]</pre></div></li><li class="listitem">The resulting linear equation will be as follows:<div class="informalexample"><pre class="programlisting">
<span class="strong"><strong>$ runhaskell Main.hs</strong></span>

<span class="strong"><strong>"y = 0.425 x + 0.785"</strong></span>
</pre></div></li></ol></div></div><div class="section" title="How it works…"><div class="titlepage"><div><div><h2 class="title"><a id="ch07lvl2sec243"/>How it works…</h2></div></div></div><p>We can look up the source code for the <code class="literal">linearRegression</code> function from the <code class="literal">Statistics.LinearRegression</code> library, <a class="ulink" href="http://hackage.haskell.org/package/statistics-linreg-0.2.4/docs/Statistics-LinearRegression.html">http://hackage.haskell.org/package/statistics-linreg-0.2.4/docs/Statistics-LinearRegression.html</a>.</p><p>The Wikipedia article on least square approximations (<a class="ulink" href="http://en.wikipedia.org/wiki/Linear_least_squares_(mathematics)">http://en.wikipedia.org/wiki/Linear_least_squares_(mathematics)</a>) puts it best in writing:</p><div class="blockquote"><blockquote class="blockquote"><p><span class="emphasis"><em>"The least squares approach to solving this problem is to try to make as small as possible the sum of squares of "errors" between the right- and left-hand sides of these equations, that is, to find the minimum of the function"</em></span></p></blockquote></div><p>The core calculations <a id="id417" class="indexterm"/>involve finding the mean and variance of the two random variables, as well as the covariance between them. Thorough mathematics behind the algorithm is detailed in <a class="ulink" href="http://www.dspcsp.com/pubs/euclreg.pdf">http://www.dspcsp.com/pubs/euclreg.pdf</a>.</p><p>If we take a look at the library's source code, we can discover the underling equations:</p><p>
<span class="emphasis"><em>α = µY - β * µX</em></span>
</p><p>
<span class="emphasis"><em>β = covar(X,Y)/σ2X</em></span>
</p><p>
<span class="emphasis"><em>f(x) = βx + α</em></span>
</p></div><div class="section" title="See also"><div class="titlepage"><div><div><h2 class="title"><a id="ch07lvl2sec244"/>See also</h2></div></div></div><p>If the data does not follow a linear trend, try the <span class="emphasis"><em>Approximating a quadratic regression</em></span> recipe.</p></div></div>
<div class="section" title="Approximating a quadratic regression"><div class="titlepage"><div><div><h1 class="title"><a id="ch07lvl1sec89"/>Approximating a quadratic regression</h1></div></div></div><p>Given a <a id="id418" class="indexterm"/>collection of points, this recipe will try to find a best fit quadratic equation. In the following figure, the curve is a best fit quadratic regression of the points:</p><div class="mediaobject"><img src="graphics/6331OS_07_03.jpg" alt="Approximating a quadratic regression"/></div><div class="section" title="Getting ready"><div class="titlepage"><div><div><h2 class="title"><a id="ch07lvl2sec245"/>Getting ready</h2></div></div></div><p>Install the <code class="literal">dsp</code> package<a id="id419" class="indexterm"/> to use <code class="literal">Matrix.LU</code> as follows:</p><div class="informalexample"><pre class="programlisting">
<span class="strong"><strong>$ cabal install dsp</strong></span>
</pre></div><p>In order to perform <a id="id420" class="indexterm"/>a quadratic regression, we will use the least square polynomial fitting algorithm described in Wolfram MathWorld available at <a class="ulink" href="http://mathworld.wolfram.com/LeastSquaresFittingPolynomial.html">http://mathworld.wolfram.com/LeastSquaresFittingPolynomial.html</a>.</p></div><div class="section" title="How to do it…"><div class="titlepage"><div><div><h2 class="title"><a id="ch07lvl2sec246"/>How to do it…</h2></div></div></div><div class="orderedlist"><ol class="orderedlist arabic"><li class="listitem">Import the following packages:<div class="informalexample"><pre class="programlisting">import Data.Array (listArray, elems)
import Matrix.LU (solve)</pre></div></li><li class="listitem">Implement the quadratic regression algorithm, as shown in the following code snippet:<div class="informalexample"><pre class="programlisting">fit d vals = elems $ solve mat vec  
where mat = listArray ((1,1), (d,d)) $ matrixArray
   vec = listArray (1,d) $ take d vals
   matrixArray = concat [ polys x d 
                                | x &lt;- [0..fromIntegral (d-1)]]
         polys x d = map (x**) [0..fromIntegral (d-1)]</pre></div></li><li class="listitem">Test out the function as follows, using some <span class="strong"><strong>hardcoded</strong></span> data:<div class="informalexample"><pre class="programlisting">main = print $ fit 3 [1,6,17,34,57,86,121,162,209,262,321]</pre></div></li><li class="listitem">The following values of the quadratic equation <span class="emphasis"><em>3x<sup>2</sup> + 2x + 1</em></span> is printed:<div class="informalexample"><pre class="programlisting">
<span class="strong"><strong>  $ runhaskell Main.hs</strong></span>

<span class="strong"><strong>  [1.0,2.0,3.0]</strong></span>
</pre></div></li></ol></div></div><div class="section" title="How it works…"><div class="titlepage"><div><div><h2 class="title"><a id="ch07lvl2sec247"/>How it works…</h2></div></div></div><p>In this recipe, a <a id="id421" class="indexterm"/>design matrix, <code class="literal">mat</code>, multiplied with a parameter vector that we desire to find produces the response vector, <code class="literal">vec</code>. We can visualize each of these arrays and matrices in the following equation:</p><div class="mediaobject"><img src="graphics/6331OS_07_04.jpg" alt="How it works…"/></div><p>After constructing the design matrix and the response vector, we use the <code class="literal">dsp</code> library to solve this matrix equation and obtain a list of coefficients for our polynomial.</p></div><div class="section" title="See also"><div class="titlepage"><div><div><h2 class="title"><a id="ch07lvl2sec248"/>See also</h2></div></div></div><p>If the data follows a linear trend, refer to the <span class="emphasis"><em>Approximating a linear regression</em></span> recipe.</p></div></div>
<div class="section" title="Obtaining the covariance matrix from samples"><div class="titlepage"><div><div><h1 class="title"><a id="ch07lvl1sec90"/>Obtaining the covariance matrix from samples</h1></div></div></div><p>A <a id="id422" class="indexterm"/>covariance matrix<a id="id423" class="indexterm"/> is a symmetric square matrix whose elements in row <span class="emphasis"><em>i</em></span> and column <span class="emphasis"><em>j</em></span> correspond to how related they are. More specifically, each element is the covariance of the variables represented by its row and column. Variables that move together in the same direction have a positive covariance, and variables with the opposite behavior have a negative covariance.</p><p>Let's assume we are given four sets of data of three variables as shown in the following table:</p><div class="mediaobject"><img src="graphics/6331OS_07_05.jpg" alt="Obtaining the covariance matrix from samples"/></div><p>Notice how <span class="strong"><strong>Feature 1</strong></span> and <span class="strong"><strong>Feature 3</strong></span> appear to be similar in their patterns, yet <span class="strong"><strong>Feature 1</strong></span> and <span class="strong"><strong>Feature 2</strong></span> appear to be <a id="id424" class="indexterm"/>uncorrelated. Similarly, <span class="strong"><strong>Feature 2</strong></span> and <span class="strong"><strong>Feature 3</strong></span> are significantly correlated.</p><p>The covariance matrix will be a 3 x 3 symmetric matrix with the following elements:</p><div class="mediaobject"><img src="graphics/6331OS_07_06.jpg" alt="Obtaining the covariance matrix from samples"/></div><div class="section" title="Getting ready"><div class="titlepage"><div><div><h2 class="title"><a id="ch07lvl2sec249"/>Getting ready</h2></div></div></div><p>Install the <code class="literal">hstats</code> library<a id="id425" class="indexterm"/> using cabal as follows:</p><div class="informalexample"><pre class="programlisting">
<span class="strong"><strong>$ cabal install hstats</strong></span>
</pre></div><p>Alternatively, install the package by performing the following steps:</p><div class="orderedlist"><ol class="orderedlist arabic"><li class="listitem">Download the source code of the package from <a class="ulink" href="http://hackage.haskell.org/package/hstats-0.3/hstats-0.3.tar.gz">http://hackage.haskell.org/package/hstats-0.3/hstats-0.3.tar.gz</a>.</li><li class="listitem">Remove the <code class="literal">haskell98</code> dependency from the cabal file, <code class="literal">hstats.cabal</code>.</li><li class="listitem">In the same directory, run the following command line:<div class="informalexample"><pre class="programlisting">
<span class="strong"><strong>$ cabal install</strong></span>
</pre></div></li></ol></div></div><div class="section" title="How to do it…"><div class="titlepage"><div><div><h2 class="title"><a id="ch07lvl2sec250"/>How to do it…</h2></div></div></div><div class="orderedlist"><ol class="orderedlist arabic"><li class="listitem">Import the <code class="literal">hstats</code> package as follows:<div class="informalexample"><pre class="programlisting">import Math.Statistics</pre></div></li><li class="listitem">Create a matrix out of a list of lists, and run the <code class="literal">covMatrix</code> function on it using the following code snippet:<div class="informalexample"><pre class="programlisting">main = do print $ covMatrix matrixArray
  where matrixArray = [ [1,1,0,0] 
                      , [0,1,0,1] 
                      , [1,1,0,1] ]</pre></div></li><li class="listitem">Check the output:<div class="informalexample"><pre class="programlisting">
<span class="strong"><strong>$ runhaskell Main.hs</strong></span>

<span class="strong"><strong>[ [ 0.333, 0.000, 0.167]</strong></span>
<span class="strong"><strong>, [ 0.000, 0.333, 0.167]</strong></span>
<span class="strong"><strong>, [ 0.167, 0.167, 0.250] ]</strong></span>
</pre></div></li></ol></div><p>Notice how the <a id="id426" class="indexterm"/>uncorrelated features have a zero value, as we expected.</p></div></div>
<div class="section" title="Finding all unique pairings in a list"><div class="titlepage"><div><div><h1 class="title"><a id="ch07lvl1sec91"/>Finding all unique pairings in a list</h1></div></div></div><p>Comparing all pairs of items is a common idiom in data analysis. This recipe will cover how to create a list of element pairs<a id="id427" class="indexterm"/> out of a list of elements. For example, if there is a list [1, 2, 3], we will create a list of every possible pair-ups [(1, 2), (1, 3), (2, 3)].</p><p>Notice that the order of pairing does not matter. We will create a list of unique tuple pairs so that we can compare each item to every other item in the list.</p><div class="section" title="How it works…"><div class="titlepage"><div><div><h2 class="title"><a id="ch07lvl2sec251"/>How it works…</h2></div></div></div><p>Create a new file, which we call <code class="literal">Main.hs</code>, and insert the code explained in the following steps:</p><div class="orderedlist"><ol class="orderedlist arabic"><li class="listitem">Import the following packages:<div class="informalexample"><pre class="programlisting">import Data.List (tails, nub, sort)</pre></div></li><li class="listitem">Construct all unique pairs from a list of items as follows:<div class="informalexample"><pre class="programlisting">pairs xs = [(x, y) | (x:ys) &lt;- tails (nub xs), y &lt;- ys]</pre></div></li><li class="listitem">Print out all unique pairings of the following list:<div class="informalexample"><pre class="programlisting">main = print $ pairs [1,2,3,3,4]</pre></div></li><li class="listitem">The output will be as follows:<div class="informalexample"><pre class="programlisting">
<span class="strong"><strong>[(1,2),(1,3),(1,4),(2,3),(2,4),(3,4)]</strong></span>
</pre></div></li></ol></div></div><div class="section" title="See also"><div class="titlepage"><div><div><h2 class="title"><a id="ch07lvl2sec252"/>See also</h2></div></div></div><p>We can apply the <code class="literal">pairs</code> algorithm to the <span class="emphasis"><em>Using the Pearson correlation coefficient</em></span> recipe.</p></div></div>
<div class="section" title="Using the Pearson correlation coefficient"><div class="titlepage"><div><div><h1 class="title"><a id="ch07lvl1sec92"/>Using the Pearson correlation coefficient</h1></div></div></div><p>The Pearson correlation coefficient<a id="id428" class="indexterm"/> is a number that ranges between -1.0 and 1.0, signifying the linear relationship of two numerical series. A <a id="id429" class="indexterm"/>value of 1.0 means strong linear correlation, a -1.0 is a strong negative correlation, and a 0.0 means the series is uncorrelated.</p><p>A brilliantly informative diagram was created by Kiatdd on <a class="ulink" href="http://en.wikipedia.org/wiki/File:Correlation_coefficient.gif">http://en.wikipedia.org/wiki/File:Correlation_coefficient.gif</a>, which is shown in the following figure:</p><div class="mediaobject"><img src="graphics/6331OS_07_07.jpg" alt="Using the Pearson correlation coefficient"/></div><p>For example, Nick is quite a generous movie critic who consistently awards movies with high ratings. His friend John might be a more dramatic critic who offers a wider range of ratings, yet the two friends tend to always agree on which movies they prefer.</p><p>We can use the Pearson correlation coefficient to detect that there is a strong linear correspondence between how these two rate movies.</p><div class="section" title="Getting ready"><div class="titlepage"><div><div><h2 class="title"><a id="ch07lvl2sec253"/>Getting ready</h2></div></div></div><p>Install the <code class="literal">hstats</code> library<a id="id430" class="indexterm"/> using cabal as follows:</p><div class="informalexample"><pre class="programlisting">
<span class="strong"><strong>$ cabal install hstats</strong></span>
</pre></div><p>Create a file with five star rating values on each line, corresponding to the rating given by different people.</p><p>In our example, three people have given five ratings each, using the following command:</p><div class="informalexample"><pre class="programlisting">
<span class="strong"><strong>$ cat ratings.csv</strong></span>
<span class="strong"><strong>4,5,4,4,3</strong></span>
<span class="strong"><strong>2,5,4,3,1</strong></span>
<span class="strong"><strong>5,5,5,5,5</strong></span>
</pre></div><p>Notice how the first <a id="id431" class="indexterm"/>two people rate in similar trends, but the third person has a very different rating trend. The algorithm in this recipe will compute the Pearson correlation coefficient pairwise and sort the results to find the two people who rate most similarly.</p></div><div class="section" title="How to do it…"><div class="titlepage"><div><div><h2 class="title"><a id="ch07lvl2sec254"/>How to do it…</h2></div></div></div><div class="orderedlist"><ol class="orderedlist arabic"><li class="listitem">Import the following packages:<div class="informalexample"><pre class="programlisting">import Math.Statistics (pearson)
import Text.CSV
import Data.List (tails, nub, sort)</pre></div></li><li class="listitem">Create a function as follows to calculate the similarities from a list of lists:<div class="informalexample"><pre class="programlisting">calcSimilarities (Left err) = error "error parsing"
calcSimilarities (Right csv) = head $ reverse $ sort $ zip 
  [ pearson (convertList a) (convertList b) 
  | (a,b) &lt;- pairs csv]
  $ (pairs csv)</pre></div></li><li class="listitem">Convert a list of <code class="literal">String</code> to a list of <code class="literal">Double</code> as follows:<div class="informalexample"><pre class="programlisting">convertList :: [String] -&gt; [Double]

convertList = map read</pre></div></li><li class="listitem">Create all possible pairs from a list of items as follows:<div class="informalexample"><pre class="programlisting">pairs xs = [(x, y) | (x:ys) &lt;- tails (nub xs), y &lt;- ys]</pre></div></li><li class="listitem">Test the code by finding the two people who rate items most similarly to each other, as shown in the following code snippet:<div class="informalexample"><pre class="programlisting">main = do
  let fileName = "ratings.csv"
  input &lt;- readFile filename

  let csv = parseCSV fileName input

  print $ calcSimilarities csv</pre></div></li><li class="listitem">The output <a id="id432" class="indexterm"/>will be as follows:<div class="informalexample"><pre class="programlisting">
<span class="strong"><strong>$ runhaskell Main.hs</strong></span>

<span class="strong"><strong>(0.89442719909999159,(["4","5","4","4","3"],["2","5","4","3","1"]))</strong></span>
</pre></div></li></ol></div></div></div>
<div class="section" title="Evaluating a Bayesian network"><div class="titlepage"><div><div><h1 class="title"><a id="ch07lvl1sec93"/>Evaluating a Bayesian network</h1></div></div></div><p>A Bayesian network<a id="id433" class="indexterm"/> is a graph of probabilistic dependencies. Nodes <a id="id434" class="indexterm"/>in the graph are events, and edges represent conditional dependence. We can build a network from prior knowledge to find out new probabilistic properties of the events.</p><p>We will use Haskell's probabilistic functional programming library to evaluate such a network and find interesting probabilities.</p><div class="section" title="Getting ready"><div class="titlepage"><div><div><h2 class="title"><a id="ch07lvl2sec255"/>Getting ready</h2></div></div></div><p>Install the <code class="literal">probability</code> library<a id="id435" class="indexterm"/> using cabal as follows:</p><div class="informalexample"><pre class="programlisting">
<span class="strong"><strong>$ cabal install probability</strong></span>
</pre></div><p>We will be representing the following network. Internalize the following figure to get an intuitive grasp of the variable names:</p><div class="mediaobject"><img src="graphics/6331OS_07_08.jpg" alt="Getting ready"/></div><p>Event <span class="strong"><strong>C</strong></span> depends on events <span class="strong"><strong>A</strong></span> and <span class="strong"><strong>B</strong></span>. Meanwhile, events <span class="strong"><strong>D</strong></span> and <span class="strong"><strong>E</strong></span> depend on event <span class="strong"><strong>C</strong></span>. Through the <a id="id436" class="indexterm"/>power of the Probabilistic Functional Programming library, in this recipe, we will find the probability of event <span class="strong"><strong>E</strong></span> given only information about event <span class="strong"><strong>D</strong></span>.</p></div><div class="section" title="How to do it…"><div class="titlepage"><div><div><h2 class="title"><a id="ch07lvl2sec256"/>How to do it…</h2></div></div></div><div class="orderedlist"><ol class="orderedlist arabic"><li class="listitem">Import the following packages:<div class="informalexample"><pre class="programlisting">import qualified Numeric.Probability.Distribution as Dist
import Numeric.Probability.Distribution ((??), (?=&lt;&lt;), )</pre></div></li><li class="listitem">Create a helper function to define conditional probabilities as follows:<div class="informalexample"><pre class="programlisting">prob p = Dist.choose p True False</pre></div></li><li class="listitem">Define the probability of variable A, P(A) as follows:<div class="informalexample"><pre class="programlisting">a :: Dist.T Rational Bool
a = prob 0.2</pre></div></li><li class="listitem">Define the probability of variable B, P(B) as follows:<div class="informalexample"><pre class="programlisting">b :: Dist.T Rational Bool
b = prob 0.05</pre></div></li><li class="listitem">Define the probability of variable C given A and B, P(C | AB) as follows:<div class="informalexample"><pre class="programlisting">c :: Bool -&gt; Bool -&gt; Dist.T Rational Bool
c False False = prob 0.9
c False True = prob 0.5
c True False = prob 0.3
c True True = prob 0.1</pre></div></li><li class="listitem">Define the probability of D given C, P(D | C) as follows:<div class="informalexample"><pre class="programlisting">d :: Bool -&gt; Dist.T Rational Bool
d False = prob 0.1
d True = prob 0.4</pre></div></li><li class="listitem">Define the probability of E given C, P(E | C) as follows:<div class="informalexample"><pre class="programlisting">e :: Bool -&gt; Dist.T Rational Bool
e False = prob 0.5
e True = prob 0.2</pre></div></li><li class="listitem">Define a data structure for the network as follows:<div class="informalexample"><pre class="programlisting">data Network = N {aVal :: Bool
, bVal :: Bool
, cVal :: Bool
, dVal :: Bool
, eVal :: Bool }
deriving (Eq, Ord, Show)</pre></div></li><li class="listitem">Construct the network according to the preceding figure:<div class="informalexample"><pre class="programlisting">bNetwork :: Dist.T Rational Network
bNetwork = do a' &lt;- a
              b' &lt;- b
              c' &lt;- c a' b'
              d' &lt;- d c'
              e' &lt;- e c'
              return (N a' b' c' d' e')</pre></div></li><li class="listitem">Calculate <a id="id437" class="indexterm"/>the probability of E given D, P(E | D) as follows:<div class="informalexample"><pre class="programlisting">main = print $ eVal ?? dVal ?=&lt;&lt; bNetwork</pre></div></li><li class="listitem">The output represented as a fraction is as follows:<div class="informalexample"><pre class="programlisting">
<span class="strong"><strong>$ runhaskell Main.hs</strong></span>

<span class="strong"><strong>3643 % 16430</strong></span>
</pre></div></li></ol></div></div></div>
<div class="section" title="Creating a data structure for playing cards"><div class="titlepage"><div><div><h1 class="title"><a id="ch07lvl1sec94"/>Creating a data structure for playing cards</h1></div></div></div><p>Many probability and statistic problems <a id="id438" class="indexterm"/>are posed using playing cards. In this recipe, we will create a data structure and useful functions for the cards.</p><p>There are a total of 52 playing cards in a standard deck. Each card has one of the following four suits:</p><div class="itemizedlist"><ul class="itemizedlist"><li class="listitem" style="list-style-type: disc">Spades</li><li class="listitem" style="list-style-type: disc">Hearts</li><li class="listitem" style="list-style-type: disc">Diamonds</li><li class="listitem" style="list-style-type: disc">Clubs</li></ul></div><p>Also, each card has one out of 13 ranks as follows:</p><div class="itemizedlist"><ul class="itemizedlist"><li class="listitem" style="list-style-type: disc">Integers between 2 and 10 inclusive</li><li class="listitem" style="list-style-type: disc">Jack</li><li class="listitem" style="list-style-type: disc">Queen</li><li class="listitem" style="list-style-type: disc">King</li><li class="listitem" style="list-style-type: disc">Ace</li></ul></div><div class="section" title="Getting ready"><div class="titlepage"><div><div><h2 class="title"><a id="ch07lvl2sec257"/>Getting ready</h2></div></div></div><p>Install the <code class="literal">probability</code> library<a id="id439" class="indexterm"/> using cabal as follows:</p><div class="informalexample"><pre class="programlisting">
<span class="strong"><strong>$ cabal install probability</strong></span>
</pre></div><p>Review the sample code on the <code class="literal">probability</code> package about collections at <a class="ulink" href="http://hackage.haskell.org/package/probability-0.2.4/docs/src/Numeric-Probability-Example-Collection.html">http://hackage.haskell.org/package/probability-0.2.4/docs/src/Numeric-Probability-Example-Collection.html</a>. </p><p>The recipe is based heavily on the probability example given in the link.</p></div><div class="section" title="How to do it…"><div class="titlepage"><div><div><h2 class="title"><a id="ch07lvl2sec258"/>How to do it…</h2></div></div></div><div class="orderedlist"><ol class="orderedlist arabic"><li class="listitem">Import the following packages:<div class="informalexample"><pre class="programlisting">import qualified Numeric.Probability.Distribution as Dist
import Numeric.Probability.Distribution ((??))
import Control.Monad.Trans.State (StateT(StateT, runStateT), evalStateT)
import Control.Monad (replicateM)
import Data.List (delete)</pre></div></li><li class="listitem">Create a data structure of the suits on a card as follows:<div class="informalexample"><pre class="programlisting">data Suit = Club | Spade | Heart | Diamond
  deriving (Eq,Ord,Show,Enum)</pre></div></li><li class="listitem">Create a data structure for the ranks of a card as follows:<div class="informalexample"><pre class="programlisting">data Rank = Plain Int | Jack | Queen | King | Ace
  deriving (Eq,Ord,Show)</pre></div></li><li class="listitem">Define<a id="id440" class="indexterm"/> a shortcut type for a card to be a tuple of a rank and a suit as follows:<div class="informalexample"><pre class="programlisting">type Card = (Rank,Suit)</pre></div></li><li class="listitem">Describe the plain cards as follows:<div class="informalexample"><pre class="programlisting">plains :: [Rank]
plains = map Plain [2..10]</pre></div></li><li class="listitem">Describe the face cards as follows:<div class="informalexample"><pre class="programlisting">faces :: [Rank]
faces = [Jack,Queen,King,Ace]</pre></div></li><li class="listitem">Create a helper function as follows to detect whether it is a face card:<div class="informalexample"><pre class="programlisting">isFace :: Card -&gt; Bool
isFace (r,_) = r `elem` faces</pre></div></li><li class="listitem">Create a helper function as follows to detect whether it is a plain card:<div class="informalexample"><pre class="programlisting">isPlain :: Card -&gt; Bool
isPlain (r,_) = r `elem` plains</pre></div></li><li class="listitem">Define all the rank cards as follows:<div class="informalexample"><pre class="programlisting">ranks :: [Rank]
ranks = plains ++ faces</pre></div></li><li class="listitem">Define the suit cards as follows:<div class="informalexample"><pre class="programlisting">suits :: [Suit]
suits = [Club, Spade, Heart, Diamond]</pre></div></li><li class="listitem">Create a deck of cards out of ranks and suits as follows:<div class="informalexample"><pre class="programlisting">deck :: [Card]
deck = [ (r,s) | r &lt;- ranks, s &lt;- suits ]</pre></div></li><li class="listitem">Create a helper function as follows to select an item from a list for probability measurements:<div class="informalexample"><pre class="programlisting">selectOne :: (Fractional prob, Eq a) =&gt;
   StateT ([a]) (Dist.T prob) a
selectOne =
   StateT $ Dist.uniform . removeEach</pre></div></li><li class="listitem">Create a <a id="id441" class="indexterm"/>function as follows to select some cards from the deck:<div class="informalexample"><pre class="programlisting">select :: (Fractional prob, Eq a) =&gt; Int -&gt; [a] -&gt; Dist.T prob [a]
select n = evalStateT (replicateM n selectOne)</pre></div></li><li class="listitem">Create a helper function as follows to remove each of the items from a list:<div class="informalexample"><pre class="programlisting">removeEach xs = zip xs (map (flip delete xs) xs)</pre></div></li><li class="listitem">Test out the deck of cards as follows with the probability functions created:<div class="informalexample"><pre class="programlisting">main = print $ 
Dist.just [(Plain 3, Heart), (Plain 3, Diamond)] ?? select 2 deck</pre></div></li><li class="listitem">The probability of selecting those two cards from the deck is as follows:<div class="informalexample"><pre class="programlisting">
<span class="strong"><strong>3.770739064856712e-4</strong></span>
</pre></div></li></ol></div></div></div>
<div class="section" title="Using a Markov chain to generate text"><div class="titlepage"><div><div><h1 class="title"><a id="ch07lvl1sec95"/>Using a Markov chain to generate text</h1></div></div></div><p>A Markov chain<a id="id442" class="indexterm"/> is a system that predicts future outcomes of a system given current conditions. We can train a <a id="id443" class="indexterm"/>Markov chain on a corpus of data to generate new text by following the states.</p><p>A graphical representation of a chain is shown in the following figure:</p><div class="mediaobject"><img src="graphics/6331OS_07_10.jpg" alt="Using a Markov chain to generate text"/><div class="caption"><p>Node E has a 70% probability to end up on node A, and a 30% probability to remain in place</p></div></div><div class="section" title="Getting ready"><div class="titlepage"><div><div><h2 class="title"><a id="ch07lvl2sec259"/>Getting ready</h2></div></div></div><p>Install the <code class="literal">markov-chain</code> library<a id="id444" class="indexterm"/> using cabal as follows:</p><div class="informalexample"><pre class="programlisting">
<span class="strong"><strong>$ cabal install markov-chain</strong></span>
</pre></div><p>Download a big<a id="id445" class="indexterm"/> corpus of text, and name it <code class="literal">big.txt</code>. In this recipe, we will be using the text downloaded from <a class="ulink" href="http://norvig.com/big.txt">http://norvig.com/big.txt</a>.</p></div><div class="section" title="How to do it…"><div class="titlepage"><div><div><h2 class="title"><a id="ch07lvl2sec260"/>How to do it…</h2></div></div></div><div class="orderedlist"><ol class="orderedlist arabic"><li class="listitem">Import the following packages:<div class="informalexample"><pre class="programlisting">import Data.MarkovChain
import System.Random (mkStdGen)</pre></div></li><li class="listitem">Train a Markov chain on a big input of text and then run it as follows:<div class="informalexample"><pre class="programlisting">main = do
rawText &lt;- readFile "big.txt"
let g = mkStdGen 100
putStrLn $ "Character by character: \n"
putStrLn $ take 100 $ run 3 rawText 0 g
putStrLn $ "\nWord by word: \n"
putStrLn $ unwords $ take 100 $ run 2 (words rawText)0 g</pre></div></li><li class="listitem">We can run the Markov chain and see the output as follows:<div class="informalexample"><pre class="programlisting">
<span class="strong"><strong>$ runhaskell Main.hs</strong></span>

<span class="strong"><strong>Generated character by character: </strong></span>

<span class="strong"><strong>The evaturn bring everice Ana Paciously skuling from to was</strong></span>
<span class="strong"><strong>fing, of rant of and sway.</strong></span>

<span class="strong"><strong>5. Whendent </strong></span>

<span class="strong"><strong>Generated word by word: </strong></span>

<span class="strong"><strong>The Project gratefully accepts contributions of money, though there was a brief word, showing that he would do so. He could hear all that she had to reply; the room scanned Princess Mary's heartbeat so violently at this age, so dangerous to life, by the friends of the Russians, was trying to free his serfs--and that till the eggs mature, when by their Creator with certain small vessels but no me...." And the cavalry, Colonel, but I don't wish to know which it has a fit, and there was a very large measure, attributed to eating this root. But</strong></span>
</pre></div></li></ol></div></div><div class="section" title="How it works…"><div class="titlepage"><div><div><h2 class="title"><a id="ch07lvl2sec261"/>How it works…</h2></div></div></div><p>The code prints our text trained by the corpus, which is fed into the Markov chain.</p><p>In the first <a id="id446" class="indexterm"/>character-by-character Markov chain, it tries to generate the next letter based on the previous three letters. Notice how most phrases don't make sense and some tokens aren't even English words.</p><p>The second Markov chain is generated word by word and only infers based on the previous two words. As we see, it emulates English phrases a bit more naturally.</p><p>These texts are purely generated by evaluating probabilities.</p></div></div>
<div class="section" title="Creating n-grams from a list"><div class="titlepage"><div><div><h1 class="title"><a id="ch07lvl1sec96"/>Creating n-grams from a list</h1></div></div></div><p>An <span class="emphasis"><em>n</em></span>-gram<a id="id447" class="indexterm"/> is a sequence of <span class="emphasis"><em>n</em></span> items that occur adjacently. For example, in the following sequence of number [1, 2, 5, 3, 2], a possible 3-gram is [5, 3, 2].</p><p>
<span class="emphasis"><em>n</em></span>-grams are useful<a id="id448" class="indexterm"/> in computing probability tables to predict the next item. In this recipe, we will be creating all possible <span class="emphasis"><em>n</em></span>-grams from a list of items. A Markov chain can easily be trained by using <span class="emphasis"><em>n</em></span>-gram computation from this recipe.</p><div class="section" title="How to do it…"><div class="titlepage"><div><div><h2 class="title"><a id="ch07lvl2sec262"/>How to do it…</h2></div></div></div><div class="orderedlist"><ol class="orderedlist arabic"><li class="listitem">Define the <span class="emphasis"><em>n</em></span>-gram function as follows to produce all possible <span class="emphasis"><em>n</em></span>-grams from a list:<div class="informalexample"><pre class="programlisting">ngram :: Int -&gt; [a] -&gt; [[a]]
ngram n xs 
  | n &lt;= length xs = take n xs : ngram n (drop 1 xs)
  | otherwise = []</pre></div></li><li class="listitem">Test it out on a sample list as follows:<div class="informalexample"><pre class="programlisting">main = print $ ngram 3 "hello world"</pre></div></li><li class="listitem">The printed 3-gram is as follows:<div class="informalexample"><pre class="programlisting">
<span class="strong"><strong>["hel","ell","llo","lo ","o w"," wo","wor","orl","rld"]</strong></span>
</pre></div></li></ol></div></div></div>
<div class="section" title="Creating a neural network perceptron"><div class="titlepage"><div><div><h1 class="title"><a id="ch07lvl1sec97"/>Creating a neural network perceptron</h1></div></div></div><p>A perceptron<a id="id449" class="indexterm"/> is a linear classifier that uses labelled data to converge to its answer. Given a set of inputs and their <a id="id450" class="indexterm"/>corresponding expected output, a perceptron tries to linearly separate the input values. If the input is not linearly separable, then the algorithm may not converge.</p><p>In this recipe, we will deal with the following list of data:</p><p>[(0,0), (0,1), (1,0), (1,1)].</p><p>Each item is labelled with an expected output as follows:</p><div class="itemizedlist"><ul class="itemizedlist"><li class="listitem" style="list-style-type: disc"><code class="literal">(0,0)</code> is expected to output a <code class="literal">0</code></li><li class="listitem" style="list-style-type: disc"><code class="literal">(0,1)</code> is expected to output a <code class="literal">0</code></li><li class="listitem" style="list-style-type: disc"><code class="literal">(1,0)</code> is expected to output a <code class="literal">0</code></li><li class="listitem" style="list-style-type: disc"><code class="literal">(1,1)</code> is expected to output a <code class="literal">1</code></li></ul></div><p>Graphically, we are trying to find a line that separates these points:</p><div class="mediaobject"><img src="graphics/6331OS_07_11.jpg" alt="Creating a neural network perceptron"/></div><div class="section" title="Getting ready"><div class="titlepage"><div><div><h2 class="title"><a id="ch07lvl2sec263"/>Getting ready</h2></div></div></div><p>Review the <a id="id451" class="indexterm"/>concept of a perceptron by:</p><div class="itemizedlist"><ul class="itemizedlist"><li class="listitem" style="list-style-type: disc">Reading the Wikipedia article <a id="id452" class="indexterm"/>on the perceptron available at <a class="ulink" href="http://en.wikipedia.org/wiki/Perceptron">http://en.wikipedia.org/wiki/Perceptron</a></li><li class="listitem" style="list-style-type: disc">Skimming the Haskell implementation<a id="id453" class="indexterm"/> by Moresmau available at <a class="ulink" href="http://jpmoresmau.blogspot.com/2007/05/perceptron-in-haskell.html">http://jpmoresmau.blogspot.com/2007/05/perceptron-in-haskell.html</a></li></ul></div></div><div class="section" title="How to do it…"><div class="titlepage"><div><div><h2 class="title"><a id="ch07lvl2sec264"/>How to do it…</h2></div></div></div><div class="orderedlist"><ol class="orderedlist arabic"><li class="listitem">Import <code class="literal">replicateM</code>, <code class="literal">randomR</code>, and <code class="literal">getStdRandom</code> for handling random number generation in our neural network as follows:<div class="informalexample"><pre class="programlisting">import Control.Monad (replicateM)
import System.Random (randomR, getStdRandom)</pre></div></li><li class="listitem">Define types to help describe the variables fed into each helper method as follows:<div class="informalexample"><pre class="programlisting">type Inputs = [Float]
type Weights = [Float]
type Threshold = Float
type Output = Float
type Expected = Float
type Actual = Float
type Delta = Float
type Interval = Int
type Step = (Weights, Interval)</pre></div></li><li class="listitem">Create a function to generate an output value of a neuron that takes in a series of inputs, corresponding weights, and a threshold value. The neuron fires a <code class="literal">1</code> if the dot product of the weight vector with the input vector is above the threshold, and <code class="literal">0</code> otherwise, as presented in the following code snippet:<div class="informalexample"><pre class="programlisting">output :: Inputs -&gt; Weights -&gt; Threshold -&gt; Output
output xs ws t 
  | (dot xs ws) &gt; t = 1
  | otherwise = 0
  where dot as bs = sum $ zipWith (*) as bs</pre></div></li><li class="listitem">Create a <a id="id454" class="indexterm"/>function to adjust weights of a neuron given expected and actual results. The weights are updated using a learning rule, as presented in the following code snippet:<div class="informalexample"><pre class="programlisting">adjustWeights :: Inputs -&gt; Weights -&gt; Expected -&gt; Actual -&gt; Weights
adjustWeights xs ws ex ac = add ws delta
  where delta = map (err * learningRate *) xs
        add = zipWith (+)
        err = ex - ac
        learningRate = 0.1</pre></div></li><li class="listitem">Step through one iteration of the perceptron cycle to update weights as follows. For this recipe, assume each neuron has a threshold of 0.2:<div class="informalexample"><pre class="programlisting">step :: Inputs -&gt; Weights -&gt; Expected -&gt; Weights
step xs ws ex = adjustWeights xs ws ex (output xs ws t)
  where t = 0.2</pre></div></li><li class="listitem">Create a helper function as follows to compute weight changes per step:<div class="informalexample"><pre class="programlisting">epoch :: [(Inputs, Expected)] -&gt; Weights -&gt; (Weights, Delta)
epoch inputs ws = (newWeights, delta)
  where newWeights = foldl 
    (\acc (xs, ex) -&gt; step xs acc ex) ws inputs
    delta = (sum (absSub newWeights ws)) / length' ws
    absSub as bs = map abs $ zipWith (-) as bs
    length' = fromIntegral . length</pre></div></li><li class="listitem">Run through the steps using <code class="literal">epoch</code> until the weights converge. Weight convergence is detected simply by noticing the first instance when weights no longer significantly change values. This is presented in the following code snippet:<div class="informalexample"><pre class="programlisting">run :: [(Inputs, Expected)] -&gt; Weights -&gt; Interval -&gt; Step
run inputs ws n
  | delta == 0.0 = (newWeights, n)
  | otherwise = run inputs newWeights (n+1)
  where (newWeights, delta) = epoch inputs ws</pre></div></li><li class="listitem">Initialize a weight vector as follows:<div class="informalexample"><pre class="programlisting">initialWeights :: Int -&gt; IO [Float]
initialWeights nb = do
  let interval = randomR (-0.5,0.5)
  (replicateM nb (getStdRandom interval))        </pre></div></li><li class="listitem">Test the <a id="id455" class="indexterm"/>perceptron network to separate an AND Boolean structure as follows:<div class="informalexample"><pre class="programlisting">main :: IO ()
main = do
  w &lt;- initialWeights 2
  let (ws,i) = run [ ([0,0],0)
                   , ([0,1],0)
                   , ([1,0],0)
                   , ([1,1],1) ] w 1
  print (ws,i)</pre></div></li><li class="listitem">A valid output may be:<div class="informalexample"><pre class="programlisting">
<span class="strong"><strong>([0.17867908,3.5879448e-1],8)</strong></span>
</pre></div></li></ol></div><p>We can verify that this output is correct since the weights sum to a value greater than the threshold value of 0.2, while each weight value individually is less than the threshold of 0.2. Therefore, the output will trigger only when the input is (1, 1) as desired.</p></div></div></body></html>