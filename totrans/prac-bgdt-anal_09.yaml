- en: Enterprise Data Science
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: We have thus far discussed various topics regarding both data mining and machine
    learning. Most of the examples shown were designed so that anyone with a standard
    computer would be able to run them and complete the exercises. In real-world situations,
    datasets would be much larger than those encountered in general home use.
  prefs: []
  type: TYPE_NORMAL
- en: Traditionally, we have relied on well-known database technologies such as SQL
    Server, Oracle, and others for organizational data warehouse and data management.
    The advent of NoSQL and Hadoop-based solutions made a significant change to this
    model of operation. Although companies were at first reluctant, the popular appeal
    of these tools became too large to ignore, and today, most, if not all, large
    organizations leverage one or more non-traditional contemporary solution for their
    enterprise data requirements.
  prefs: []
  type: TYPE_NORMAL
- en: Furthermore, the advent of cloud computing has transformed most businesses,
    and in-house data centers are being rapidly replaced by cloud-based infrastructures.
    The primary market leaders in the cloud space are Amazon (Amazon Web Services),
    Microsoft (Azure), and, to a lesser extent, Google (Google Compute Engine).
  prefs: []
  type: TYPE_NORMAL
- en: Data warehousing, data science, and machine learning needs are being delivered
    primarily on such platforms.
  prefs: []
  type: TYPE_NORMAL
- en: In this section, we will look at the various technical platforms that are prevalent
    in the corporate/enterprise market, their strengths, use cases, and potential
    pitfalls. In addition, we will also complete a tutorial using AWS to launch new
    instances on-demand using a trial account.
  prefs: []
  type: TYPE_NORMAL
- en: 'We will cover the following topics in this chapter:'
  prefs: []
  type: TYPE_NORMAL
- en: Enterprise data science overview
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Enterprise data mining
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Enterprise AI and machine learning
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Enterprise infrastructure
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Other considerations, such as data strategy, governance, and tool selection
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Amazon Web Services tutorial
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Enterprise data science overview
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Data science is a relatively new topic in terms of enterprise IT and analytics.
    Traditionally, researchers and analysts belonged broadly to one of two categories:'
  prefs: []
  type: TYPE_NORMAL
- en: Highly technical researchers who used complex computing languages and/or hardware
    for their professional tasks
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Analysts who could use tools such as Excel and BI platforms in order to perform
    both simple and complex data analysis
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Organizations started looking into **Big Data** and, more generally, data science
    platforms in the late 2000s. It had gained immense momentum by 2013, when solutions
    such as Hadoop and NoSQL platforms were released. The following table shows the
    developments in data science:'
  prefs: []
  type: TYPE_NORMAL
- en: '| **Year** | **Developments** |'
  prefs: []
  type: TYPE_TB
- en: '| 1970s to late 1990s | Widespread use of relational database management systems.
    Entity relationship model, structured query language (SQL), and other developments
    eventually led to a rapid expansion of databases in the late 90s. |'
  prefs: []
  type: TYPE_TB
- en: '| Early 2000s | The anti-climatic, yet expensive, non-event of Y2K, coupled
    with the collapse of the dot-com `bubble` led to a period of stagnation. In terms
    of databases, or more generally, data mining platforms, this meant that companies
    were less focused on new innovations than they were on keeping the business running.
    |'
  prefs: []
  type: TYPE_TB
- en: '| 2005-2010 | The industry slowly recovered, but it was not until 2005 that
    newer developments began to emerge. Some notable events included:'
  prefs: []
  type: TYPE_NORMAL
- en: '2006: GoogleBigTable paper published'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '2006: Amazon Web Services cloud platform launched'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '2007: Amazon Dynamo paper published'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '2008: Facebook makes Cassandra open source'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '2009: MongoDB released'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '2009: Redis released'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '|'
  prefs: []
  type: TYPE_NORMAL
- en: '| 2010-2012 | 2010: NoSQL conferences and related events start gaining popularity and
    *NoSQL* becomes a commonly accepted technical term. At the same time, Hadoop becomes
    widely popular, and nearly all major companies begin the process of implementing
    Hadoop-related technologies.2011: Market leaders start adopting Big Data and forming
    Big Data strategies. Numerous articles and research papers claiming the huge potential
    of Big Data makes it very popular. McKinsey publishes a paper on Big Data and
    calls it the next frontier of *innovation, competition, and productivity*. The
    October 2012 edition of, *Harvard Business Review* includes a very positive outlook
    on data scientists, which becomes immediately popular. |'
  prefs: []
  type: TYPE_TB
- en: '| 2013-2015 | The growth of Big Data technologies leads to the development
    of a concept called data science, which moves the focus from just the data to
    the value of the data. Coupled with developments in machine learning and the rise
    of the popularity of R, Python, and other data science-oriented platforms, the
    industry shifts attention to getting insights from data as opposed to merely managing
    data. Machine learning is the new buzzphrase. |'
  prefs: []
  type: TYPE_TB
- en: '| 2016- | The evolution of smart devices, wearables, AI-enabled cell phones,
    autonomous driving cars, and other such innovative solutions adds a new component
    of artificial intelligence to the existing trend of Big Data and machine learning.
    Manufacturers start broadly advertising the intelligent capabilities, as opposed
    to merely the machine learning capabilities, of technical solutions. |'
  prefs: []
  type: TYPE_TB
- en: The responsibility for implementing a Big Data platform or, more generally,
    a Big Data Initiative, is generally delegated to the IT or Analytics Department
    of a company, if such a department exists.
  prefs: []
  type: TYPE_NORMAL
- en: 'In a general survey of Big Data and data science delegations in organizations,
    we observed that, in most cases, the Chief Information Officer or the Chief Data/Digital
    Officer was responsible for the **Enterprise Big Data Strategy**, as shown in
    the following figure:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/d6322402-7a21-4d28-8865-5a2f9453c557.png)'
  prefs: []
  type: TYPE_IMG
- en: Although analytics and IT teams played a significant role, not surprisingly,
    the final responsibility was delegated to the C-level management of the company.
  prefs: []
  type: TYPE_NORMAL
- en: 'Investment in Big Data within the enterprise was also varied, with most organizations
    in the $100k to $1M range. An analysis of mid/large-scale organizations produced
    an expected result. What was evident, though, was that nearly *all respondents
    had made at least some investment in Big Data*:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/4425642a-c9be-4dd1-99cd-66e6a8872cb8.png)'
  prefs: []
  type: TYPE_IMG
- en: Most organizations also reported having a corporate mandate for **Advanced Analytics**.
    This helped in securing the required budget to implement and advance the state
    of analytics within the organization.
  prefs: []
  type: TYPE_NORMAL
- en: Furthermore, the predicted forecast of the revenue potential of data science
    greatly helped in making the case to senior management that a suitable investment
    in Big Data was essential to the future growth of a company.
  prefs: []
  type: TYPE_NORMAL
- en: With a current Big Data and Business Analytics revenue that has grown exponentially
    to more than $150 billion, the pressure on corporations to implement such capabilities,
    at least at a preliminary level, has been immense.
  prefs: []
  type: TYPE_NORMAL
- en: 'Another aspect of organizational awareness and acceptance of Big Data as a
    corporate mandate is the cultural perception of the utility of such tools. In
    a survey conducted with C-level management at large companies, most respondents
    stated that analytics was being used by managers in their departments, but there
    wasn''t a uniform level of engagement across all departments, as shown in the
    following figure:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/b4978e01-1aed-45c0-88a6-44e624bc627b.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Furthermore, it appeared that the partnership strategies for Big Data across
    the organization were also not structured to the extent needed for commercial
    success. Respondents to the survey indicated that the partnership, as in, the
    cross-functional collaboration of analytics initiatives, was loosely defined:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/686fd5cb-7dbe-4acf-ae1b-853413bc5548.png)'
  prefs: []
  type: TYPE_IMG
- en: 'While the responses to some of the questions were skewed, with one category
    being the overwhelming majority, the feedback on organizational challenges with
    Big Data and analytics in general had a broad uniform consensus. The following
    chart shows the feedback on analytics challenges from each participant in the
    survey:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/ef198cfa-17c6-4049-9889-55400a56e12a.png)'
  prefs: []
  type: TYPE_IMG
- en: 'All of this leads to an interesting but paradoxical analytics dilemma in the
    enterprise. Although the merit of Big Data and analytics is widely understood
    and accepted, there is a sense of ambiguity regarding the appropriate approach,
    as shown in the following diagram:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/adfd631c-ebf5-4f65-8972-cd946165e092.png)'
  prefs: []
  type: TYPE_IMG
- en: A roadmap to enterprise analytics success
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In our experience, analytics, which is a fairly recent term compared to well-established
    terms such as data warehouse and others, requires a careful approach in order
    to ensure both immediate success and the consequent longevity of the initiative.
  prefs: []
  type: TYPE_NORMAL
- en: Projects that prematurely attempt to complete an initial analytics project with
    large-scale, high-budget engagement run the risk of jeopardizing the entire initiative
    if the project does not turn out as expected.
  prefs: []
  type: TYPE_NORMAL
- en: Moreover, in such projects, the outcome measures are not clearly defined. In
    other words, measuring the value of the outcome is ambiguous. Sometimes, it cannot
    be quantified either. This arises because the success of an analytics initiative
    has benefits beyond simply the immediate monetary or technical competencies. A
    successful analytics project often helps to foster executive confidence in the
    department's ability to conduct said projects, which in turn may lead to bigger
    endeavors.
  prefs: []
  type: TYPE_NORMAL
- en: 'The **general challenges** associated with Big Data analytics are as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: Nearly every company is investing in Big Data, machine learning, and AI
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Often, the company has a corporate mandate
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Finding the right use cases can be challenging
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Even after you *find* them, the outcome may be uncertain (will this resonate,
    how long will it take, and so on)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Even after you *achieve* them, whether or not the optimal targets have been
    identified can be elusive (for example, when using HDFS for storing only data)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Now, let''s look at some **general guidelines** for data science and analytics
    initiatives:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Conduct meetings and one-on-one reviews with business partners** in the organization
    to review their workflows and get feedback on where analytics and/or data mining
    would provide the most value'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Identify specific aspects of business operations** that are important and
    related to the firm''s *revenue stream; *the use case would have a measurable
    impact once completed'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The use cases do not have to be *complex*; they can be simple tasks, such as
    ML or Data Mining
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Intuitive, easily understood, you can explain it to friends and family
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Ideally the use case takes effort to accomplish today using conventional means.
    The solution should not only benefit a **range of users**, but also have **executive
    visibility**
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Identify **Low Difficulty - High Value** (**Short**) vs **High Difficulty -
    High Value** (**Long**) use cases
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Educate business sponsors, share ideas, show **enthusiasm** (like a long job
    interview)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Score **early wins** for **Low Difficulty - High Value**, create **Minimum Viable
    Solutions**, and get management to buy in before further enhancing the use solutions
    developed. (takes time)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Early wins act as a **catalyst** to a) foster executive confidence, and b) also
    makes it easier to justify budgets, which then makes it easier to move onto High
    Difficulty - High Value tasks.
  prefs: []
  type: TYPE_NORMAL
- en: The last two points are important as it is essential to identify Low Difficulty
    - High Value projects. This could be a task that appears *basic* to an experienced
    practitioner but is very valuable to the end user.
  prefs: []
  type: TYPE_NORMAL
- en: One of the executives of an analytics group in a large enterprise organization
    once remarked that the most successful project of the year was the *change of
    timing of an email report*. Instead of sending the report in the morning, the
    timing was changed to late afternoon. It appeared that engagement with the report
    became more active after the timing was changed. Morning schedules tend to be
    very busy and afternoon reports, on the other hand, provide recipients with the
    time to review the report at a more relaxed pace.
  prefs: []
  type: TYPE_NORMAL
- en: 'A few examples of *low* *difficulty* but *p**otentially h**igh value* projects
    could be:'
  prefs: []
  type: TYPE_NORMAL
- en: Automating manual tasks conducted on a frequent basis by a business group; for
    instance, reports that are created in Excel may be easily automated using a combination
    of open source tools and databases.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Converting manual stock analytics to automated versions using programming scripts.
    This could involve tasks such as creating regular tables, pivot tables, and charts
    that are created in Excel but can be converted into automated processes.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Creating web interfaces using R Shiny for business applications and implementing
    predictive analytics functionalities.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Moving certain parts of the IT infrastructure to a cloud platform. This may
    seem counter-intuitive, especially if the organization is not used to working
    in cloud environments. However, the ease and simplicity of managing cloud deployments
    can mean an overall reduction in the total cost of ownership and operational overhead.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The ultimate choice of the use case would depend on various factors, and the
    previous ones have been mentioned to set an approximate idea of the type of projects
    that may be attempted, and the workflows that may yield positive results. In the
    next section, we will look at some of the specific software and hardware solutions
    used in the industry for data science.
  prefs: []
  type: TYPE_NORMAL
- en: Data science solutions in the enterprise
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'As discussed before, in general, we can broadly categorize data science into
    two primary sections:'
  prefs: []
  type: TYPE_NORMAL
- en: Enterprise data warehouse and data mining
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Enterprise data science: machine learning, artificial intelligence'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: In this section, we will look at each of these individually and discuss both
    the software and hardware solutions used in the industry for delivering these
    capabilities.
  prefs: []
  type: TYPE_NORMAL
- en: Enterprise data warehouse and data mining
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Today, there are scores of databases available in the industry that are marketed
    as NoSQL systems capable of running complex analytical queries. Most of them have
    one or more features of typical NoSQL systems, such as columnar, in-memory, key-value,
    document-oriented, graph-based, and so on. The next section highlights some of
    the key enterprise NoSQL systems in use today.
  prefs: []
  type: TYPE_NORMAL
- en: Traditional data warehouse systems
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Traditional data warehouses might be a misnomer, since most of the *traditional*
    systems have also incorporated core concepts of NoSQL. However, in this case,
    the term is intended to indicate databases that existed well before the advent
    of NoSQL systems, and that have also added features that make them aligned with
    the requirements of Enterprise data science.
  prefs: []
  type: TYPE_NORMAL
- en: Oracle Exadata, Exalytics, and TimesTen
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Oracle Exadata, Exalytics, and Exalogic belong to Oracle's Exa family of products.
    **Exadata** is Oracle's high performance *Engineered Database Platform* that is
    designed for resource intensive queries. In general, it is expected to significantly
    improve query performance over non-Exadata systems, and supports advanced software
    features such as in-memory computing, independent row and column-based filtering,
    and other hardware features such as support for the latest storage devices, including
    NVMe, in-memory fault tolerance, and others.
  prefs: []
  type: TYPE_NORMAL
- en: '**Exalytics** is a complementary solution that is intended primarily for **BI**
    workloads. The Exa family of products are considered *engineered systems* as opposed
    to *appliances*. Whereas the latter may indicate preset and pre-loaded software-hardware
    stacks, an engineered system is expected to support a higher level of flexibility
    regarding the choice of installed components which are installed selectively depending
    on client needs. One of the key components of Exalytics commonly found in enterprise
    installations is **OBIEE** (**Oracle Business Intelligence Enterprise Edition**).
    This is a complete BI suite and benefits from an underlying in-memory database
    called **Times Ten**, which is also a part of the Exalytics ecosystem.'
  prefs: []
  type: TYPE_NORMAL
- en: '**Business use case**: Oracle Exadata is used for OLTP transactional workloads
    where speed and performance is critical.'
  prefs: []
  type: TYPE_NORMAL
- en: Exalytics, on the other hand, is used for analytical workloads. The integrated
    OBIEE interface together with TimesTen provides a strongly coupled analytics environment.
    Oracle Exadata is also available as a cloud-based service.
  prefs: []
  type: TYPE_NORMAL
- en: HP Vertica
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Vertica from HP is a column-oriented, massively parallel processing database
    system with key software features such as support for in-database machine learning,
    and native integration to open source systems such as Apache Kafka and Apache
    Spark, and is generally deployed on a multi-node hardware architecture. Vertica
    is supported on popular cloud environments such as **Amazon Web Services** (**AWS**),
    Google, and Azure. Vertica supports a standard interactive SQL interface, thus
    making it readily compatible with most contemporary BI tools.
  prefs: []
  type: TYPE_NORMAL
- en: HP Vertica, interestingly, is one of the few enterprise databases that is also
    available as a Community Edition. This means that users who are interested in
    trying out Vertica (within the scope of its licensing), or who are simply learning
    more about the platform can leverage the Community Edition, which can be downloaded
    from HP Vertica's website at no charge.
  prefs: []
  type: TYPE_NORMAL
- en: '**Business use case**: Similar to the other databases indicated in this section,
    Vertica incorporates several notable features such as in-database processing,
    parallel processing capabilities, and others. Vertica supports a wide range of
    analytical workloads and comes with associated commercial licensing fees (as do
    all the other commercial database products). The availability of a Community Edition,
    along with HP''s willingness, in most cases, to engage in proof of concept for
    large deployments provides ample opportunities for business to try and test the
    platform with company-specific use cases prior to making a decision.'
  prefs: []
  type: TYPE_NORMAL
- en: Teradata
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Teradata is widely recognized as a leader in enterprise database technology.
    Its database, which also goes by the same name, shares several of the same features
    as other competitor products. Some key features of Teradata include native integration
    with many open source solutions, such as R, RStudio, Jupyter, and SAS; time series
    support; built-in analytic functions for machine learning and AI; support for
    a wide range of data types, such as CSV, JSON, and text, and spatial/temporal
    data.
  prefs: []
  type: TYPE_NORMAL
- en: The analytics platform, also known as Aster Analytics, is available as a Community
    Edition from [https://aster-community.teradata.com/community/download](https://aster-community.teradata.com/community/download).
  prefs: []
  type: TYPE_NORMAL
- en: While, traditionally, Teradata was available as an appliance solution, as in
    both the database as well as the hardware were available as a single integrated
    unit, today, it is also possible to use Teradata in the cloud using Teradata Everywhere.
    The software can be deployed in a hybrid architecture (both on-premises as well
    as in the cloud), as well as in public cloud environments such as AWS and Microsoft
    Azure. Bundled services, subscription-based services, and as-a-service options
    are available. Teradata Intellicloud is a subscription-based cloud offering from
    Teradata that includes several products from the Teradata ecosystem in a managed
    environment.
  prefs: []
  type: TYPE_NORMAL
- en: '**Business use case**: Teradata has been a popular enterprise database for
    several decades and has strong credibility with large organizations. In recent
    years, Teradata''s proactive integration with open source systems such as R, Jupyter,
    and other products made it more appealing and arguably helped increase its visibility.
    Teradata appliances can be relatively expensive and, as with other commercial
    options, require proper POCs to assess suitability for use cases specific to the
    organization.'
  prefs: []
  type: TYPE_NORMAL
- en: IBM data warehouse systems (formerly Netezza appliances)
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: IBM Netezza used to be sold as a separate data warehouse appliance, in some
    ways similar to how Teradata was also marketed. Recently, Netezza has been moved
    under the broader categorization of IBM Data Warehouse systems which is more aligned
    with the contemporary Big Data requirements for managing very large volumes of
    data. IBM Pure Systems, PureSystems for Analytics, and IBM Integrated Analytics
    System are some of the newer solutions that provide essentially the same functionalities
    of Netezza in an integrated ecosystem.
  prefs: []
  type: TYPE_NORMAL
- en: The Integrated Analytics environment includes embedded Apache Spark for machine
    learning, Jupyter Notebooks for data science workloads, a common SQL engine that
    connects to other NoSQL and Hadoop implementations, and support for deployments
    on high performance architecture with the option of managed, cloud-based environments
  prefs: []
  type: TYPE_NORMAL
- en: '**Business use case**: Netezza has been favored by firms that have traditionally
    had strong dependency on IBM-related technologies, such as DB2, AIX, and other
    products from IBM. The new integrated product environment provides an opportunity
    to continue using whilst adding data science capabilities to existing IBM investments
    in the organization.'
  prefs: []
  type: TYPE_NORMAL
- en: PostgreSQL
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: PostgreSQL is an interesting choice in this section because, technically, there
    is no separate NoSQL version of PostgreSQL, but rather PostgreSQL has added various
    features in recent releases that have added NoSQL capabilities to the existing
    Postgres implementation.
  prefs: []
  type: TYPE_NORMAL
- en: Proponents of PostgreSQL rightly point out that it is a much older, and, by
    extension tested technology, having been first released in the mid-1990s. **Postgres**
    now supports hierarchical document data storage, JSON, a key-value store (called
    **HStore**), and sharding, and includes interfaces for various programming languages
    as well as diverse data sources. In other words, PostgreSQL has been extended
    to support NoSQL-like functionalities while maintaining its existing capabilities
    as a traditional RDBMS.
  prefs: []
  type: TYPE_NORMAL
- en: PostgreSQL is available as a fully-functional, open source product.
  prefs: []
  type: TYPE_NORMAL
- en: '**Business use cases**: While most of the technologies in this section are
    available under commercial licensing (to get access to all their capabilities),
    PostgreSQL, being open source, is a very cost-effective way to try out a mature
    database without making large initial investments. It can also serve as a testing
    platform for trying out NoSQL features, such as handling JSON data prior to making
    a final decision. In either case, PostgreSQL is a formidable platform and can
    support enterprise needs. There are also commercial derivatives of PostgreSQL—databases
    that build on top of PostgreSQL such as Greenplum, which is also available as
    an open source product.'
  prefs: []
  type: TYPE_NORMAL
- en: Greenplum
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: '**Greenplum Database**® is built on top of PostgreSQL, and adds a number of
    significant analytic capabilities. These include an innovative cost-based query
    optimizer, integration with Apache MADlib, and choices for row or columnar storage.
    It has native interfaces for popular programming languages such as R, Python,
    and Java, and supports massively-parallel architectures. Greenplum is available
    for download at no charge from [http://greenplum.org/download/](http://greenplum.org/download/).'
  prefs: []
  type: TYPE_NORMAL
- en: '**Business use cases**: A commercial distribution of Greenplum with full support
    is available from **Pivotal**. Greenplum has been very successful, not least because
    of its proven performance for large enterprise workloads. The availability of
    commercial support has been beneficial to organizations who require dedicated
    support and service-level agreements (**SLA**) that guarantee critical business
    operations.'
  prefs: []
  type: TYPE_NORMAL
- en: SAP Hana
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: SAP Hana is a columnar, in-memory database from SAP with support for NoSQL features.
    Hana supports multicore parallel operations, multi-tenancy, and is fully **ACID**
    compliant and can handle a diverse range of analytical workloads including predictive
    modelling, streaming analytics, time series analysis, and spatial, text, and graph-based
    analysis. You can also manage JSON based unstructured data within an SAP Hana
    system.
  prefs: []
  type: TYPE_NORMAL
- en: Hana also works natively with other SAP products such as SAP Fiori, which includes
    a wide range of SAP UX applications used in HR, finance, accounting, and other
    departments.
  prefs: []
  type: TYPE_NORMAL
- en: '**Business use cases**: SAP has been a mainstay for enterprise organizations
    for several decades and is used for a wide range of applications, most notably
    perhaps for manufacturing and financial/accounting requirements. SAP Hana adds
    a formidable high-performance database to existing SAP installations. In general,
    due to the high cost involved with enterprise-grade deployments, SAP is used mainly
    for business-critical needs. The benefits of Hana for large organizations that
    are dependent on SAP may outweigh the costs. Furthermore, while Hana can deliver
    a wide range of NoSQL capabilities, companies may find that they will end up with
    two or more different solutions based on budget, performance needs, and other
    factors.'
  prefs: []
  type: TYPE_NORMAL
- en: Enterprise and open source NoSQL Databases
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The prior section outlined some of the well-known traditional database/RDBMS
    solutions that have added enterprise-grade NoSQL capabilities. This upcoming sections
    looks at some of the more niche business use cases specific to database solutions.
  prefs: []
  type: TYPE_NORMAL
- en: Kdb+
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The **kdb+** from Kx Systems is one of the fastest, most efficient and lightweight
    databases that has been used in high-frequency trading and other similar environments
    for almost two decades. Its popularity outside of finance has been much less pronounced,
    but nevertheless, it is arguably one of the most efficiently designed and optimized
    systems in the world of databases.
  prefs: []
  type: TYPE_NORMAL
- en: Kdb+ supports in-memory columnar storage from the outset and is technically
    an extension of the **q** programming language. A table in kdb+ is in essence
    a data structure in the q language. However, unlike similar concepts in other
    programming languages, a kdb+ table is enterprise-grade and can easily handle
    terabytes and petabytes of data.
  prefs: []
  type: TYPE_NORMAL
- en: Due to its inherent programming language, code that is written in q can be run
    against data stored in kdb+, so a custom *function* can be run in-database with
    very minimal effort.
  prefs: []
  type: TYPE_NORMAL
- en: Additionally, the size of the kdb+ binary is about 500 to 600KB, small enough
    to fit in the L3 cache of most modern CPUs.
  prefs: []
  type: TYPE_NORMAL
- en: Kdb+ also includes built-in MapReduce capabilities so that queries are automatically
    executed in parallel across muticore CPUs.
  prefs: []
  type: TYPE_NORMAL
- en: '**Business use case**: Kdb+ is one of the most formidable databases to have
    existed in an enterprise setting. It was traditionally available only for perpetual
    core-based licensing, but in recent days, the company has added support for subscription-based
    and on-demand licensing. Its low footprint and simplicity of use makes it well
    suited for enterprise needs. However, this comes with a caveat. The q language
    is very terse and can appear cryptic to new users. The language, arguably, has
    a slightly steeper learning curve than others and requires practice and first-hand
    experience. That said, there are ample online resources to learn and utilize the
    features of the database. Native interfaces for R, Python, C, Java, and other
    programming languages, along with libraries used for machine learning, make it
    particularly well suited for data science workloads involving large datasets.'
  prefs: []
  type: TYPE_NORMAL
- en: 'While kdb+ is not available as an open source product, it is generally available
    for personal use at no charge from: [https://kx.com/download/](https://kx.com/download/).'
  prefs: []
  type: TYPE_NORMAL
- en: MongoDB
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: '**MongoDB** is a market leader in the space of document-oriented databases
    for the storage of data in JSON format. It supports on-demand querying, indexing,
    and aggregations, and has a rich interface for Python, Java, and JavaScript, among
    other languages. Other features, such as horizontal scaling and sharding, high
    availability, an integrated data exploration tool called Compass, and others,
    add to the existing capabilities of the database.'
  prefs: []
  type: TYPE_NORMAL
- en: '**Business use cases**: Companies considering databases for storing unstructured
    or semi-structured data may find the features of MongoDB well suited for querying
    such datasets. The database does not require a fixed schema to be defined at the
    onset, making it flexible and extensible to support new attributes that are added
    to existing data. MongoDB is available as a free open source download from [https://www.mongodb.com/download-center](https://www.mongodb.com/download-center)
    and can also be implemented as a managed and hosted cloud solution via MongoDB
    Atlas. An enterprise version that supports features such as in-memory and encrypted
    storage is also available on a subscription basis.'
  prefs: []
  type: TYPE_NORMAL
- en: Cassandra
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: '**Cassandra** is one of the most successful and widely used enterprise NoSQL
    systems. It incorporates both columnar and key-value concepts and stores data
    in row-based partitions. Each partition is in turn a primary key. Rows can have
    multiple columns and the number of columns may differ from one row to another.'
  prefs: []
  type: TYPE_NORMAL
- en: Cassandra databases can be queries done via CQL, which uses a SQL-like syntax
    and makes the process of data querying, saving, and other common tasks much easier.
    Cassandra also uses a decentralized architecture; it does not have any single
    point of failure and supports multi-node architecture.
  prefs: []
  type: TYPE_NORMAL
- en: In addition to the standard horizontal scalability of Cassandra DBMS, the platform
    also supports Elastic scalability and is able to transparently allocate and de-allocate
    nodes depending upon needs. On the whole, Cassandra is one of the most formidable
    options for enterprise NoSQL systems and is used in production environment across
    multiple large firms globally.
  prefs: []
  type: TYPE_NORMAL
- en: '**Business use case**: Cassandra is a fully open source solution and implements
    multiple key features of NoSQL systems. It is used in production workloads globally
    and has matured into a stable, enterprise-grade, open source platform. In other
    words, Cassandra is well suited for managing large organizational needs and does
    not incur any additional licensing costs. A commercial, licensed, and paid version
    of Cassandra is also available from Datastax: [https://www.datastax.com/products/datastax-enterprise](https://www.datastax.com/products/datastax-enterprise).
    It is known as **DSE** (**Datastax** **Enterprise**). DSE incorporates various
    enterprise features such as security and search, and can also be accessed via
    the Datastax Managed Cloud environment using popular cloud providers such as AWS.'
  prefs: []
  type: TYPE_NORMAL
- en: Neo4j
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: '**Neo4j** is a graph-based database that is used to model relationships between
    different entities. The database uses familiar concepts in graph theory to create
    tree-based representations (with nodes and relationships) of interconnected subjects.
    It is used most commonly in conjunction with recommendation engines. Conceptually,
    a Neo4j graph database could represent individuals as nodes who are connected
    to one another by, say, their degree of separation. This would hypothetically
    allow an end user to trace the degrees of separation between any arbitrary node
    or one individual to another.'
  prefs: []
  type: TYPE_NORMAL
- en: Various graph-based representations such as weighted, directed, unidirectional,
    and labelled are available in the Neo4j platform.
  prefs: []
  type: TYPE_NORMAL
- en: '**Business use case**: Companies that require deep customer-level or user-level
    analysis such as social networks or recommendation systems (such as Netflix),
    stand to gain an immense benefit from deploying graph-based databases such as
    Neo4j. Today, the platform supports AI and machine learning, iOT, real-time recommendations,
    and many other useful characteristics used in enterprise.'
  prefs: []
  type: TYPE_NORMAL
- en: Although Neo4j is available as open source software from [https://neo4j.com/download/?ref=hro](https://neo4j.com/download/?ref=hro),
    there is also a commercial licensed version known as Neo4j Enterprise Edition.
  prefs: []
  type: TYPE_NORMAL
- en: Cloud databases
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Cloud databases, as the name suggests refers to data warehouse or database systems
    available from cloud vendors such as Amazon, Google, and Microsoft.
  prefs: []
  type: TYPE_NORMAL
- en: Amazon Redshift, Redshift Spectrum, and Athena databases
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: One of the most commonly used cloud-based data warehouse platforms is **Amazon
    Redshift**. It is the most prominent platform for data management in the cloud-based
    ecosystem. It is based on PostgreSQL and is intended mainly for analytical workloads.
    Redshift is highly scalable and requires significantly less effort relative to
    on-premises databases with similar characteristics. It can be deployed directly
    from the AWS console (after signing up for an AWS account). Nodes can be added
    or removed seamlessly via the AWS Console to increase and/or decrease capacities
    respectively.
  prefs: []
  type: TYPE_NORMAL
- en: A more recent release of Redshift known as **Redshift Spectrum** permits the
    querying of data that has been stored in Amazon S3, the standard storage layer
    in AWS. This means that users can directly query data stored on disk without having
    to load it into a Redshift-specific instance. Overall, Redshift is relatively
    fast, inexpensive, and more importantly easy to use and deploy. Redshift Spectrum
    uses a pay-per-query model—users pay only for the queries that are executed at
    a nominal charge for each terabyte of data scanned.
  prefs: []
  type: TYPE_NORMAL
- en: '**Amazon Athena** is in many respects similar to Amazon Redshift Spectrum,
    in that it is also used to query data that is stored on S3\. However, while the
    features of Amazon Redshift Spectrum cannot be used without first purchasing Amazon
    Redshift, users can leverage Amazon Athena on-demand and do not need to reserve
    any additional hardware. On the other hand, because Amazon Redshift Spectrum is
    closely integrated with the Redshift ecosystem, users can distribute their workload
    on either of the two solutions. Data that needs faster processing can remain on
    Amazon Redshift, whereas less frequently used/less critical data can be stored
    on S3 and queried using Redshift Spectrum:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/9d66f408-9391-48c2-bf53-db4b4cfb1510.png)'
  prefs: []
  type: TYPE_IMG
- en: You can learn more about Amazon Redshift Spectrum at [https://aws.amazon.com/redshift/spectrum/](https://aws.amazon.com/redshift/spectrum/).
  prefs: []
  type: TYPE_NORMAL
- en: Google BigQuery and other cloud services
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: '**Google BigQuery** is similar to Amazon Redshift, in that it is also a large-scale
    data warehouse system that is fully cloud-based. However, while Redshift requires
    separate provisioning (of an AWS cluster and Redshift resources), Google BigQuery
    is the *plug-and-play* equivalent of the same. To use BigQuery, the user simply
    needs to create an account at [https://bigquery.cloud.google.com](https://bigquery.cloud.google.com)
    and begin running queries after loading their datasets.'
  prefs: []
  type: TYPE_NORMAL
- en: The charging method of BigQuery is also quite different in comparison to Redshift.
    Users can query a cumulative of 1 terabyte of data at no charge per month. BigQuery
    uses a pay-per-use model whereby queries have allocated costs. In essence, BigQuery
    abstracts the complexity of setting up a database and allows the end user to dedicate
    time to writing queries and/or performing analytics without the overhead of setting
    up an infrastructure. Scaling queries, allocating resources, and tasks that may
    have otherwise required manual intervention (by a DBA for example), hence become
    redundant.
  prefs: []
  type: TYPE_NORMAL
- en: 'Google also has a set of other NoSQL products on its cloud platform, including
    Google Cloud Datastore, a NoSQL document-based database; Google BigTable; Google
    Spanner; and several others. The following figure shows the Google BigQuery database:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/b4680c31-ff0b-4125-8dec-08423dae22ab.png)'
  prefs: []
  type: TYPE_IMG
- en: Azure CosmosDB
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The **Azure CosmosDB** is one of Microsoft's NoSQL cloud-based databases. Other
    NoSQL systems in Azure include Table Storage, Azure Redis Cache, and others. CosmosDB
    is considered a *multi-model* database; it can support key-value pairs, document-based
    queries, graph-based models, and also relational database queries.
  prefs: []
  type: TYPE_NORMAL
- en: 'Traditional Microsoft databases, such as, SQL Server are also available and
    are supported as fully managed and hosted solutions on the Azure platform. You
    can learn more about the Azure platform at [https://azure.microsoft.com/en-in/services/cosmos-db/](https://azure.microsoft.com/en-in/services/cosmos-db/).
    The following figure shows the Microsoft Azure platform''s Solutions window:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/51d4d481-2a5e-4be5-bd01-a20636a11c9c.png)'
  prefs: []
  type: TYPE_IMG
- en: GPU databases
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: '**GPU databases** are a more recent development that came with the growth of
    Graphics Processing Unit cards for data science related tasks, such as machine
    learning. GPUs work best when the query can be parallelized. This is due to the
    fact that GPUs contain thousands of cores. By delegating each core to work on
    a small subset of the data, a GPU can often calculate at an impressively fast
    rate that far exceeds the CPU-based query performance.'
  prefs: []
  type: TYPE_NORMAL
- en: Brytlyt
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: '**Brytlyt** is a recent entrant in the space of GPU databases. It is complemented
    by a visualization product called **Spotlyt**. Early testing has shown that Brytlyt
    surpasses several challenging benchmarks. However, how well it generalizes in
    other use cases remains to be seen.'
  prefs: []
  type: TYPE_NORMAL
- en: Brytlyt is available in the Amazon AWS Marketplace ([https://aws.amazon.com/marketplace/pp/B074JZNSWZ?qid=1513342415797&sr=0-1&ref_=srh_res_product_title](https://aws.amazon.com/marketplace/pp/B074JZNSWZ?qid=1513342415797&sr=0-1&ref_=srh_res_product_title))
    for those wish to try it.
  prefs: []
  type: TYPE_NORMAL
- en: MapD
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: '**MapD** was one of the early developers of a commercial GPU database platform.
    Similarly to Brytlyt, it has also shown impressive early results. Nevertheless,
    as GPU-based databases are still in their early stages, popular use and adoption
    will ultimately determine whether they will become commonplace in enterprise.'
  prefs: []
  type: TYPE_NORMAL
- en: One of the primary challenges of GPU-based databases is the need to configure
    a GPU-based system properly. This can require specialized skills, as using GPU
    cards for computation is quite different than using GPU cards for common tasks
    such as rendering images. Due to this, users wishing to try out GPU-based databases
    prior to adopting a formal version would find it easier to leverage a pre-configured
    image in AWS (AMI Image), which would require minimal system configuration.
  prefs: []
  type: TYPE_NORMAL
- en: Other common databases
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: There are various other types of databases, such as ones that are used for analyzing
    streaming data (Amazon Kinesis), and those that process data using specialized
    Accelerator Cards using FPGAs from Baidu.
  prefs: []
  type: TYPE_NORMAL
- en: Enterprise data science – machine learning and AI
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: '**Data science solutions** have matured rapidly over the past 4 - 5 years,
    similar to the movement in other areas of data science such as NoSQL, Hadoop,
    and other data mining solutions. Although many of the prior database systems also
    incorporate key features of *data science*, such as machine learning and others,
    this section highlights some of the solutions at a high level that are primarily
    used for machine learning and/or AI, as opposed to data management.'
  prefs: []
  type: TYPE_NORMAL
- en: Indeed, the distinction between *Big Data* products and *data science* products
    has become blurred, since products that were originally intended for Big Data
    handling have incorporated key features of data science, and vice versa.
  prefs: []
  type: TYPE_NORMAL
- en: The R programming language
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: '**R**, as we have seen in prior chapters, is an environment originally designed
    for statistical programming. It emerged out of a project at the University of
    New Zealand, where *Ross Ihanka* and *Robert Gentleman* developed R as a variation
    of the S programming language developed by John Chambers in Bell Labs. Although
    R was initially intended for *statistical programming*, over the last 7 to 8 years
    it has evolved into a mature, multifaceted language with enhanced support for
    a diverse range of related disciplines such as machine learning, high performance
    computing, visualization, econometrics, TimeSeries analysis, and much more. Some
    of these areas are also described with accompanying information at [https://cran.r-project.org/web/views/](https://cran.r-project.org/web/views/).'
  prefs: []
  type: TYPE_NORMAL
- en: A commercial version of R with enterprise support was available from Revolution
    Analytics. In 2015, it was rebranded as **Microsoft R Open** (open-source version)
    and **Microsoft R Server** (commercial version).
  prefs: []
  type: TYPE_NORMAL
- en: Although marketed under the Microsoft brand, note that Microsoft R is also available
    for Linux and Mac OS.
  prefs: []
  type: TYPE_NORMAL
- en: Popular machine learning packages in R include `e1071`, `randomForest`, `gbm`,
    `kernlab`, `arules`, and many more. These are listed at [https://cran.r-project.org/web/views/MachineLearning.html](https://cran.r-project.org/web/views/MachineLearning.html).
    Another popular package, called caret, acts as a wrapper around various algorithm
    packages and provides a useful unified interface to run algorithms without having
    to conform to the nuances of the packages individually.
  prefs: []
  type: TYPE_NORMAL
- en: R also supports multicore programming via packages such as `multicore`, `doMC`,
    and others. These are listed at [https://cran.r-project.org/web/views/HighPerformanceComputing.html](https://cran.r-project.org/web/views/HighPerformanceComputing.html).
  prefs: []
  type: TYPE_NORMAL
- en: Python
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'The `scikit-learn` package in Python is arguably the most comprehensive machine
    learning package among all platforms that incorporates an extensive list of machine
    learning algorithms. It is also considered to be faster compared to R, and is
    the tool of choice for various enterprise organizations. The following screenshot
    shows the web page from which we can download the `scikit-learn` package:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/da0de066-9015-40f0-997b-f340cac4dcf1.png)'
  prefs: []
  type: TYPE_IMG
- en: A commercially supported enterprise version of Python that comes pre-configured
    with useful machine learning and data mining packages is `Anaconda`, available
    from Continuum Analytics. A cloud version of Anaconda called **Anaconda Cloud**
    allows new users to start leveraging the features of Anaconda Python without the
    overhead of downloading and installing it separately.
  prefs: []
  type: TYPE_NORMAL
- en: OpenCV, Caffe, and others
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Image recognition is one of the more successful areas of machine learning. While
    most machine learning tasks require a relatively long period of time before their
    true benefits can be measured and quantified, image recognition is a familiar
    subject area that can be readily understood. In essence, it involves identifying
    objects and correctly categorizing them. It has several applications, ranging
    from identifying license plate numbers to face recognition, and is available in
    mobile devices and robotics.
  prefs: []
  type: TYPE_NORMAL
- en: OpenCV provides a standard interface for various image recognition tasks, and
    can also leverage hardware acceleration features to optimize performance.
  prefs: []
  type: TYPE_NORMAL
- en: Other well-known machine learning software for image processing include Caffe,
    cuDNN, TensorFlow, and others. Note that these packages are not limited to simply
    image recognition, but can be also used for other deep learning use cases.
  prefs: []
  type: TYPE_NORMAL
- en: Spark
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The MLlib library in Spark provides a formal implementation of various machine
    learning algorithms that can be used in a Spark platform. The availability of
    pySpark makes the process of using the functionality easier for those with Python
    programming knowledge. If the organization had an existing Spark platform, it
    would be worth exploring the machine learning capabilities in MLlib.
  prefs: []
  type: TYPE_NORMAL
- en: 'The following screenshot gives you a brief overview of MLlib:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/44661322-2958-4356-8f9a-012617e4ca8f.png)'
  prefs: []
  type: TYPE_IMG
- en: Deep learning
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Neural Networks with multiple hidden layers (generally more than two) and/or
    nodes are generally categorized as **deep learning**. Several contemporary advances
    in machine learning, such as autonomously driving cars, are a direct result of
    the use of deep learning for practical day-to-day tasks.
  prefs: []
  type: TYPE_NORMAL
- en: 'There are various deep learning frameworks/packages, and some notable ones
    include:'
  prefs: []
  type: TYPE_NORMAL
- en: TensorFlow
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: cuDNN
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Theano
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Torch
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: PaddlePaddle, from Baidu
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: H2O and Driverless AI
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: A popular platform for Kaggle competitions, **H2O** provides a massively scalable,
    real-time machine learning interface with native integration for R, Python, Spark,
    and much more. It is available for download, at no charge, from [https://www.h2o.ai/h2o/](https://www.h2o.ai/h2o/).
  prefs: []
  type: TYPE_NORMAL
- en: '**Driverless AI** is a recent addition to the H2O line of products. It aims
    to make machine learning easier for practitioners by implementing an automated
    interface that attempts to create models and optimize accuracy by building and
    evaluating multiple models in an automated manner. The following screenshot shows
    the homepage of the H2O platform:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/c14b6afd-caa7-46dd-acdb-bc040231968e.png)'
  prefs: []
  type: TYPE_IMG
- en: Datarobot
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Conceptually, Dataro**b**ot is similar to H2O's Driverless AI in that it also
    attempts to build machine learning models in an automated manner by creating and
    evaluating multiple models against a given dataset.
  prefs: []
  type: TYPE_NORMAL
- en: However, unlike H2O, although it can be very powerful, Datarobot requires a
    licensing fee and can be expensive for smaller firms.
  prefs: []
  type: TYPE_NORMAL
- en: Command-line tools
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'There are multiple machine learning tools that are executed at the Unix command-line.
    There are existing interfaces for some of these tools in R, Python, and other
    languages that permit users to leverage their capabilities without having to use
    them from the Unix terminal. Some of the popular command-line utilities include:'
  prefs: []
  type: TYPE_NORMAL
- en: LIBSVM
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: LIBLINEAR
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Vowpal Wabbit
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: MLPACK
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: libFM
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Apache MADlib
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: One of the lesser-known but feature-rich platforms is **Apache MADlib**, which
    aims to perform analytics and run algorithms *in-database*, as in, it can execute
    functions locally without requiring an external programming interface. It supports
    parallel processing and can work seamlessly with multiple data sources such as
    Greenplum, PostgreSQL, and others.
  prefs: []
  type: TYPE_NORMAL
- en: As an example, an apriori model can be created by simply running an SQL command,
    as shown here, from [http://madlib.apache.org/docs/latest/group__grp__assoc__rules.html:](http://madlib.apache.org/docs/latest/group__grp__assoc__rules.html)
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: Further information about Apache MADlib (screenshot of site shown below) is
    available at [http://madlib.apache.org.](http://madlib.apache.org)
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/5201727e-95e6-438f-90eb-fa83a92ef87f.png)'
  prefs: []
  type: TYPE_IMG
- en: Machine learning as a service
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Cloud-based machine learning platforms that integrate with other cloud resources
    have also proliferated. Some of the well-known platforms include AzureML, BigML,
    IBM Watson, and others.
  prefs: []
  type: TYPE_NORMAL
- en: The screenshot below is from IBM Watson, one of the most well-known platforms
    for machine learning and artificial intelligence. The platform gained prominence
    after it won the Jeopardy championship in 2011 [Source: [https://www.techrepublic.com/article/ibm-watson-the-inside-story-of-how-the-jeopardy-winning-supercomputer-was-born-and-what-it-wants-to-do-next/](https://www.techrepublic.com/article/ibm-watson-the-inside-story-of-how-the-jeopardy-winning-supercomputer-was-born-and-what-it-wants-to-do-next/)].
    At the time, the Machine Learning trend was in a nascent state and Watson was
    one of the first AI technologies that took the world by surprise. It proved that
    AI can be powerful and capable asset. Users can today leverage some of the same
    computing capabilities of IBM Watson by signing up for an account on the site [https://www.ibm.com/watson/](https://www.ibm.com/watson/).
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/3cd0d41a-b5d0-4825-8a94-3d4700617fcf.png)'
  prefs: []
  type: TYPE_IMG
- en: Enterprise infrastructure solutions
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The proper choice of infrastructure also plays a key role in determining the
    efficiency of the organization's data science platform. Too little, and the algorithms
    will take too long to execute; too much and you may have a lot of resources remaining
    unutilized. As such, the latter is preferable to having too little, which thwarts
    progress and the ability of any machine learning researcher to efficiently perform
    his or her tasks.
  prefs: []
  type: TYPE_NORMAL
- en: Cloud computing
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Over the past 5 - 7 years, organizations have gradually shifted their resources
    to cloud-based platforms such as Amazon Web Services, Microsoft Azure, and Google
    Compute Engine. Today, all of these contain extremely sophisticated and extensive
    architecture to support machine learning, data mining, and in general *data science*
    at an enterprise level to meet the needs of organizations of all sizes.
  prefs: []
  type: TYPE_NORMAL
- en: In addition, the concept of *images*, such as AMI images in Amazon's AWS, allows
    users to initiate a pre-built snapshot of an OS with pre-installed components.
    As a result, users can almost entirely avoid the setup overhead prior to trying
    out new platforms.
  prefs: []
  type: TYPE_NORMAL
- en: Hadoop and map-reduce operations in general are also supported extensively in
    AWS. The **EMR**, or **Elastic Map Reduce **in AWS, and HDInsight in Azure, are
    two well-known and very popular Big Data frameworks.
  prefs: []
  type: TYPE_NORMAL
- en: The tutorial at the end of this chapter will demonstrate how to set up an AWS
    account and start using a sample AMI Image.
  prefs: []
  type: TYPE_NORMAL
- en: Virtualization
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: '**Virtualization**—the process of creating isolated, self-contained environments
    within a larger host, has allowed organizations to consolidate servers and dramatically
    reduce data center footprints. If, say, an organization leverages six servers
    for their websites, and of those, two get utilized frequently whereas the others
    have relatively lower loads most of the time, it may be possible to consolidate
    all the servers into one or two servers at most. In this regard, technologies
    from Dell EMC, such as VxBLOCK, are well-known enterprise virtualization hardware
    used in physical data centers. This also allows companies to create their own
    private cloud infrastructure. However, it can be fairly expensive and requires
    the proper assessment of the cost-to-benefit ratio.'
  prefs: []
  type: TYPE_NORMAL
- en: An open source software used for creating public and private clouds is Openstack.
    It is an enterprise-grade ecosystem with multiple products that works seamlessly
    within the Openstack platform. Further details about Openstack are available at
    [https://www.openstack.org:](https://www.openstack.org)
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/13b666d0-dff7-45ec-92ea-c7e3a7d54b3d.png)'
  prefs: []
  type: TYPE_IMG
- en: Users may be familiar with Oracle Virtualbox, which, in essence, is also a type
    of virtualization software that permits users to create isolated environments.
    This allows users to run Linux within Windows, and vice versa.
  prefs: []
  type: TYPE_NORMAL
- en: Specialized software or hardware, known as hypervisors, are used to manage and
    administer virtual machines.
  prefs: []
  type: TYPE_NORMAL
- en: Containers – Docker, Kubernetes, and Mesos
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Containers, like virtualization, create isolated guest systems, but, while Virtual
    Machines create a completely separate environment, containers share the same kernel
    as the host system and hence are considered to be closer to the hardware. Both
    virtualization and containers incur performance penalties due to multiple layers
    of abstraction—the translation of functionalities between a host and guest OS.
    However, containers in general have a higher level of performance because they
    rely on and directly use features of the guest OS instead of creating a separate
    OS ecosystem.
  prefs: []
  type: TYPE_NORMAL
- en: 'Popular containers include Docker, CoreOS, and many others. Today, containers
    are used for the large-scale management of mainly web-related services. Containers
    can be started up and shut down on demand much more readily than VMs, and popular
    cloud providers have added dedicated support for containers, making it easy to
    start up thousands of containers to service web requests with simply a few lines
    of code. Orchestration software such as Kubernetes provide enterprise-grade capabilities
    for managing containers. Furthermore, platforms, such as Mesos, not only provide
    support for managing containers, but also add the capability of managing other
    legacy hardware for application-aware scheduling and other services:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/db50058b-25b9-4515-9e3d-9af6f877efc5.png)'
  prefs: []
  type: TYPE_IMG
- en: On-premises hardware
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Finally, on-premises hardware, such as the traditional data center, still has
    a place in modern-day computing. With a physical data center, users do not have
    to pay recurring fees for cloud-based services. For small to mid-sized organizations
    that do not have large administrative overhead, or for organizations that do not
    require high-performance/specialized computing capabilities, on-premises systems
    are fully capable of delivering cost-efficient, permanent solutions.
  prefs: []
  type: TYPE_NORMAL
- en: 'Companies such as ScaleMP provide specialized hardware that is used for high-performance
    computing. Consumers of such hardware usually have specific requirements that
    cannot be provided by cloud-based vendors:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/e4320051-00a4-434e-bc8a-d36f5fc84a68.png)'
  prefs: []
  type: TYPE_IMG
- en: 'A summary of some of the differences between on-premises and cloud-based systems
    is shown below:'
  prefs: []
  type: TYPE_NORMAL
- en: '| **On-premises** | **Cloud** |'
  prefs: []
  type: TYPE_TB
- en: '| You own the hardware | You lease the hardware |'
  prefs: []
  type: TYPE_TB
- en: '| Requires full maintenance | Maintenance is managed by a cloud-hosting provider
    |'
  prefs: []
  type: TYPE_TB
- en: '| Requires IT resources for managing computing hardware resources | Much less
    overhead in terms of managing computing hardware resources, as they can be added
    on-demand in the cloud |'
  prefs: []
  type: TYPE_TB
- en: '| Cost efficient for small to mid-sized environments with low or no data center
    operation cost | Cost efficient for large organizations that are looking to simplify
    data center operation costs |'
  prefs: []
  type: TYPE_TB
- en: '| No recurring cost for using hardware other than resources required to manage
    them | Recurring cost to use the hardware; uses a subscription model for pricing
    |'
  prefs: []
  type: TYPE_TB
- en: '| Mainly static architecture; new requirements for Hadoop will require a complete
    range of new purchases | Extremely flexible; companies can provision thousands
    of servers in multiple operating systems on-demand |'
  prefs: []
  type: TYPE_TB
- en: '| Are readily accepted by organizational, legal, and associated departments
    | Faces obstacles, in particular from legal departments, due to the delegation
    of management to a third-party/cloud-hosting provider |'
  prefs: []
  type: TYPE_TB
- en: Enterprise Big Data
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The overall strategy of Big Data implementation in large organizations depends
    on the particular needs of the organization. Today, there are hundreds of options
    to choose from between Big Data, data science, machine learning and, of late,
    AI providers.
  prefs: []
  type: TYPE_NORMAL
- en: 'As such, there are two main considerations while implementing Big Data in large
    organizations:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Technical**: The selection of the proper software and hardware stack'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Operational**: Management of the organizational data, creating a formal data
    governance strategy, and creating an adequate data management framework'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Apart from these, hiring the right talent and possibly creating well-defined
    roles for the company's Big Data/data science implementations are additional but
    equally essential tasks.
  prefs: []
  type: TYPE_NORMAL
- en: 'Some key questions in the creation of such a strategy include:'
  prefs: []
  type: TYPE_NORMAL
- en: Is the software/hardware licensing based on size or cores? If it is based on
    the size of data and my data size increases, what will be my 3 year/5 year cost?
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Does the solution have enterprise support?
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Do we need to hire external resources?
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: What business questions will the new capabilities answer?
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Have we done short and long-term cost-benefit analysis?
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: What are the present unmet needs of the organization that the new solutions
    can answer?
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Is the solution scalable enough to meet my potential future needs?
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: In terms of technical needs, although there are many solutions in the marketplace,
    it is extremely essential in practice to conduct testing or proof of concept using
    real-world/actual data that the solution will be used for. It is not uncommon
    to find solutions that claim grand capabilities but do not deliver expectations.
    **In other words, it is crucial to gather thorough empirical results and not purchase
    solely on the basis of a marketing pitch.**
  prefs: []
  type: TYPE_NORMAL
- en: Lastly, as Big Data/data science is constantly evolving, the long-term scalability
    and adaptability of the solution needs to be properly evaluated. The cloud-based
    option should be considered in light of the fact that it provides an efficient
    medium to access and use new and emerging solutions in an easy and affordable
    manner.
  prefs: []
  type: TYPE_NORMAL
- en: Tutorial – using RStudio in the cloud
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The following tutorial will demonstrate how to create an account on **AWS**
    (Amazon Web Services), load an AMI Image for RStudio, and thereafter use RStudio,
    all at *no charge*. Readers who are experienced in using cloud platforms may find
    the instructions quite basic. For other users, the tutorial should provide helpful
    initial guidance on using AWS.
  prefs: []
  type: TYPE_NORMAL
- en: Please read the **Warning** message below prior to proceeding.
  prefs: []
  type: TYPE_NORMAL
- en: '***Warning**: Note that AWS requires a credit card for signup. Users must be
    careful and select only the options for the FREE TIER. The AWS agreement permits
    Amazon to bill users for incurred charges. Due to this reason, users should use
    the platform judiciously to avoid potentially expensive unexpected charges from
    servers or services that are left running***.**'
  prefs: []
  type: TYPE_NORMAL
- en: As of this time, Azure and Google Cloud offer user signups with provisions to
    avoid inadvertent charges. However, AWS has the highest market share among all
    cloud vendors, and users are likely to encounter AWS in most workplace situations.
    Hence, this tutorial focuses on AWS rather than the alternatives.
  prefs: []
  type: TYPE_NORMAL
- en: 'Instructions on how to close your account have also been provided at the end
    of the tutorial, should you wish to discontinue your use of AWS (and thus also
    prevent any charges):'
  prefs: []
  type: TYPE_NORMAL
- en: 'Go to [https://aws.amazon.com/](https://aws.amazon.com/)and click on the **Create
    an AWS Account** button at the top-right:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![](img/db605921-3e54-4530-9ee5-307af2704617.png)'
  prefs: []
  type: TYPE_IMG
- en: 'An AWS account generally includes 12 months of initial free tier access. Enter
    your information and click on Continue:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![](img/a5ea69aa-1d38-4fb7-a7f3-be6f10812805.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Select your **Account type** (such as Personal) and enter your contact information:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![](img/870f14c0-4125-45d4-b82a-b9cec57db03c.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Enter the payment information. AWS requires a credit card for signup. Note
    that users must utilize AWS resources very carefully and judiciously in order
    to ensure that there are no inadvertent charges:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![](img/7ac30d10-8413-4be2-8f37-7245d004fee7.png)'
  prefs: []
  type: TYPE_IMG
- en: 'You''ll receive a confirmation once the payment information has been verified:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![](img/3648ca3b-044c-43b2-88f4-e5d096ddf622.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Select the Basic Plan (Free):'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![](img/d1f2b414-286f-4a4f-8e23-33db8af59332.png)'
  prefs: []
  type: TYPE_IMG
- en: 'The confirmation page after selecting the **Basic Plan** is as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/fa0ef62e-36db-4cb2-ab65-6cc84e89a4d7.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Log in to AWS with your credentials:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '**![](img/7c88a880-7e82-4015-b46f-1c8c96067d86.png)**'
  prefs: []
  type: TYPE_NORMAL
- en: 'The first page shows some of the services in AWS. The top-right shows the region
    of your instance. AWS supports multiple regions, and users can select from a range
    of geographically-dispersed locations:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![](img/91261eb1-5550-42c5-be3f-d821080b605d.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Clicking on the top-left drop-down menu for **Services** will bring up the
    different services available. Some of the important ones are highlighted here:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![](img/5b6d713e-dc10-4839-915e-2cabfb2d357d.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Click on EC2:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![](img/0f53486c-da5e-4eb7-98d5-471da09f36dc.png)'
  prefs: []
  type: TYPE_IMG
- en: 'AWS provides the option to launch multiple different OSs. While we can start
    a new instance afresh with a selected OS, we will be instead using an AMI image.
    AMIs are preconfigured images with installed software. Note that using an AMI
    image is **not** required, but one is being used here for the tutorial:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '**![](img/e6cef2d9-33da-42c1-b9f9-dd361a3fb11e.png)**'
  prefs: []
  type: TYPE_NORMAL
- en: 'Click on **Community AMIs** on the left menu bar and search for **RStudio**.
    Select the first option and click on the Select button:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![](img/23a8a6e5-a9f3-4853-84d4-a55775c978a6.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Select the free tier option (t2.micro) and click Next: Configure Instance Details:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![](img/9da49526-d171-49f3-ac57-b008a05340ce.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Select the default options on the next page and click **Next:**Add Storage:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '**![](img/93604a2c-0b31-4db1-b763-68b54b728221.png)**'
  prefs: []
  type: TYPE_NORMAL
- en: 'Select the default storage options and click on Add Tags:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '**![](img/40244e19-6e3b-4284-805f-a4ae1646e9d8.png)**'
  prefs: []
  type: TYPE_NORMAL
- en: 'Click **Next:**Configure Security Group:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '**![](img/fcd90f09-627e-4686-888a-c079e729fc38.png)**'
  prefs: []
  type: TYPE_NORMAL
- en: 'Security groups specify the network access rules for the server. For our tutorial,
    we will select All TCP and click Review and Launch:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![](img/e66665c3-a7d9-4a4b-b925-b74fd4ac6db3.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Click Launch:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![](img/715bf058-18f3-4ff5-9542-873dfdcd7c18.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Select Create a new key pair, and click Download Key Pair. Once the key finishes
    downloading, click on the Launch Instances button:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![](img/c0d8e61d-eb02-4db2-95c9-7e7787798247.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Click on the instance ID:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![](img/d8ba5b7e-5da6-4eaf-b9dc-4c1d8ec44844.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Once the status of the instance ID is displayed as running, copy the name of
    the server, which can be viewed in the bottom panel:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![](img/872d860f-47a9-4570-a61e-102b36d18f7f.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Open a new browser, enter the name of the server as the URL, and hit Enter.
    This will bring up RStudio. Log in with the ID **rstudio** and password **rstudio**:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![](img/b27e31e8-6033-4c00-add7-2dea324aaf4c.png)'
  prefs: []
  type: TYPE_IMG
- en: 'This will bring up the RStudio console. This is a complete R environment and
    you can execute R code just as you would in a local installation of R and RStudio:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![](img/3edebd0b-3abd-4851-ade0-3afd02918e99.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Once you have finished using R Studio, make sure that you `terminate` the instance.
    Termination stops the billing process. Even though we are using the free tier
    account, it is good practice to stop or terminate the instance once you have finished
    your work:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![](img/2ac27a33-994d-4e0e-80ed-9ad936ccc048.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Click Sign Out to log out of the AWS console:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![](img/9ea90e86-5ad4-4b13-8e49-31659d81cfc0.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Azure also offers free account signups at [https://azure.microsoft.com/en-us/free/](https://azure.microsoft.com/en-us/free/),
    as shown in the following screenshot:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/d516e3b3-725a-4b0b-9769-0c4e9932df38.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Google''s free cloud signup form is available at [https://cloud.google.com/free/](https://cloud.google.com/free/),
    as shown in the following screenshot:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/e1d4fb13-1e0f-4c6e-9c0d-805ed107499a.png)'
  prefs: []
  type: TYPE_IMG
- en: Summary
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this chapter, we discussed the requirements for deploying enterprise-scale
    data science infrastructures, both at a software as well as a hardware level.
    We shared key common questions around such initiatives at a management level.
    This was followed by an extensive section on key enterprise solutions that are
    being used for data mining and machine learning in large organizations.
  prefs: []
  type: TYPE_NORMAL
- en: The tutorial involved launching an RStudio Server on Amazon Web Services (a
    cloud-based system). AWS has become the leading provider of cloud services in
    the world today, and the exercise showed how simple it can be to launch entire
    machines in a few seconds. Appropriate pros and cons about the judicious and careful
    use of AWS to prevent very expensive charges were mentioned.
  prefs: []
  type: TYPE_NORMAL
- en: The next and final chapter will include some closing thoughts, the next steps,
    and links to useful resources you can use to learn more about the topics that
    have been discussed in this book.
  prefs: []
  type: TYPE_NORMAL
