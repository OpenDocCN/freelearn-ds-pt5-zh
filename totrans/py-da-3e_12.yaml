- en: Supervised Learning - Regression Analysis
  prefs: []
  type: TYPE_NORMAL
- en: Regression is the most popular algorithm in statistics and machine learning.
    In the machine learning and data science field, regression analysis is a member
    of the supervised machine learning domain that helps us to predict continuous
    variables such as stock prices, house prices, sales, rainfall, and temperature.
    As a sales manager at an electronic store, for example, say you need to predict
    the sales of upcoming weeks for all types of products, such as televisions, air
    conditioners, laptops, refrigerators, and many more. Lots of factors can affect
    your sales, such as weather conditions, festivals, promotion strategy, competitor
    offers, and so on. Regression analysis is one of the tools that can help you to
    identify the importance of such factors that are important to make decisions at
    the store.
  prefs: []
  type: TYPE_NORMAL
- en: Regression analysis identifies how the dependent variable depends upon independent
    variables. For example, say as an education officer you want to identify the impact
    of sports activities, smart classes, teacher-student ratio, extra classes, and
    teachers' training on students' results. **Ordinary Least Square** (**OLS**) minimizes
    the sum of squares error (or error variance) to find out the best fit function.
    It predicts the most probable outcome under the given conditions. The main objective
    of this chapter is to learn the fundamentals of **Multiple Linear Regression**
    (**MLR**), multicollinearity, dummy variables, regression, and model evaluation
    measures such as R-squared, **Mean Squared Error** (**MSE**), **Mean Absolute
    Error** (**MAE**), and **Root Mean Square Error** (**RMSE**). Another objective
    is creating a logistic regression classification model.
  prefs: []
  type: TYPE_NORMAL
- en: 'The topics covered in this chapter are listed as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: Linear regression
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Understanding multicollinearity
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Dummy variables
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Developing a linear regression model
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Evaluating regression model performance
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Fitting polynomial regression
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Regression models for classification
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Logistic regression
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Implementing logistic regression using scikit-learn
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Technical requirements
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'This chapter has the following technical requirements:'
  prefs: []
  type: TYPE_NORMAL
- en: 'You can find the code and the datasets at the following GitHub link: [https://github.com/PacktPublishing/Python-Data-Analysis-Third-Edition/tree/master/Chapter09](https://github.com/PacktPublishing/Python-Data-Analysis-Third-Edition/tree/master/Chapter09)[.](https://github.com/PacktPublishing/Python-Data-Analysis-Third-Edition/tree/master/Chapter09)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: All the code blocks are available in the `ch9.ipynb` file.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: This chapter uses three CSV files (`Advertising.csv`, `bloodpress.txt`, and
    `diabetes.csv`) for practice purposes.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: In this chapter, we will use the Matplotlib, `pandas`, Seaborn, and scikit-learn
    Python libraries.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Linear regression
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Linear regression is a kind of curve-fitting and prediction algorithm. It is
    used to discover the linear association between a dependent (or target) column
    and one or more independent columns (or predictor variables). This relationship
    is deterministic, which means it predicts the dependent variable with some amount
    of error. In regression analysis, the dependent variable is continuous and independent
    variables of any type are continuous or discrete. Linear regression has been applied
    to various kinds of business and scientific problems, for example, stock price,
    crude oil price, sales, property price, and GDP growth rate predictions. In the
    following graph, we can see how linear regression can fit data in two-dimensional
    space:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/95977f0e-4614-4e71-828e-8884f82c697d.png)'
  prefs: []
  type: TYPE_IMG
- en: 'The main objective is to find the best-fit line to understand the relationship
    between variables with minimum error. Error in regression is the difference between
    the forecasted and actual values. Coefficients of regression are estimated using
    the OLS method. OLS tries to minimize the sum of squares residuals. Let''s see
    the equation for the regression model:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/2b803453-31a3-48d7-80db-daf0360d947e.png)'
  prefs: []
  type: TYPE_IMG
- en: Here, *x* is the independent variable and *y* is a dependent variable. ![](img/10a567ab-2ffc-4cad-a44d-4f55a7de63ce.png)
    intercepts are the coefficient of *x*, and ![](img/31dddf97-8805-43a1-9041-8ba8eefe5a4c.png)
    (the Greek letter pronounced as epsilon) is an error term that will act as a random
    variable.
  prefs: []
  type: TYPE_NORMAL
- en: The parameters of linear regression are estimated using OLS. OLS is a method
    that is widely used to estimate the regression intercept and coefficients. It
    reduces the sum of squares of residuals (or error), which is the difference between
    the predicted and actual.
  prefs: []
  type: TYPE_NORMAL
- en: After getting an idea about linear regression, it's now time to learn about
    MLR.
  prefs: []
  type: TYPE_NORMAL
- en: Multiple linear regression
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'MLR is a generalized form of simple linear regression. It is a statistical
    method used to predict the continuous target variable based on multiple features
    or explanatory variables. The main objective of MLR is to estimate the linear
    relationship between the multiple features and the target variable. MLR has a
    wide variety of applications in real-life scenarios. The MLR model can be represented
    as a mathematical equation:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/9c36b729-f849-4365-aace-147be7590523.png)'
  prefs: []
  type: TYPE_IMG
- en: Here, [![](img/7f873b49-b78d-4bdf-b9c0-53bb40257a87.jpg)] are the independent
    variables and ![](img/e3c23ddd-8528-4d2e-b4dd-6f2a6bd07539.png)is a dependent
    variable. ![](img/2842199b-fd9f-4687-8dba-118ffaa33717.png) intercepts are coefficients
    of *x* and ![](img/31dddf97-8805-43a1-9041-8ba8eefe5a4c.png) (the Greek letter
    pronounced as epsilon) is an error term that will act as a random variable.
  prefs: []
  type: TYPE_NORMAL
- en: Now that we know what linear regression is, let's move on to multicollinearity.
  prefs: []
  type: TYPE_NORMAL
- en: Understanding multicollinearity
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Multicollinearity represents the very high intercorrelations or inter-association
    among the independent (or predictor) variables.
  prefs: []
  type: TYPE_NORMAL
- en: 'Multicollinearity takes place when independent variables of multiple regression
    analysis are highly associated with each other. This association is caused by
    a high correlation among independent variables. This high correlation will trigger
    a problem in the linear regression model prediction results. It''s the basic assumption
    of linear regression analysis to avoid multicollinearity for better results:'
  prefs: []
  type: TYPE_NORMAL
- en: It occurs due to the inappropriate use of dummy variables.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: It also occurs due to the repetition of similar variables.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: It is also caused due to synthesized variables from other variables in the data.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: It can occur due to high correlation among variables.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Multicollinearity causes the following problems:'
  prefs: []
  type: TYPE_NORMAL
- en: It causes difficulty in estimating the regression coefficients precisely and
    coefficients become more susceptible to minor variations in the model.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: It can also cause a change in the signs and magnitudes of the coefficient.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: It causes difficulty in assessing the relative importance of independent variables.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Removing multicollinearity
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Multicollinearity can be detected using the following:'
  prefs: []
  type: TYPE_NORMAL
- en: The correlation coefficient (or correlation matrix) between independent variables
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Variance Inflation Factor** (**VIF**)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Eigenvalues
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Correlation coefficients or correlation matrices will help us to identify a
    high correlation between independent variables. Using the correlation coefficient,
    we can easily detect the multicollinearity by checking the correlation coefficient
    magnitude:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: 'This results in the following output:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/d8b82130-814f-4543-8efc-62d31d07cf02.png)'
  prefs: []
  type: TYPE_IMG
- en: 'In the preceding code block, we read the `bloodpress.txt` data using the `read_csv()`
    function. We also checked the initial records of the dataset. This dataset has
    `BP`, `Age`, `Weight`, `BSA`, `Dur`, `Pulse`, and `Stress` fields. Let''s check
    the multicollinearity in the dataset using the correlation matrix:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: 'This results in the following output:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/3a140469-91e5-4f42-8f4e-ea89d8e9ddae.png)'
  prefs: []
  type: TYPE_IMG
- en: In the preceding example, we are finding the correlation between multiple variables
    using the correlation matrix. We loaded the `bloodpress.txt` file and found the
    correlation using the `corr()` function. Finally, we visualized the correlation
    matrix using the `heatmap()` function.
  prefs: []
  type: TYPE_NORMAL
- en: Here, **BP** (**Blood** **Pressure**) is the dependent or target variable, and
    the rest of the columns are independent variables or features. We can see that
    **Weight** and **BSA** (**Body** **Surface** **Area**) have a high correlation.
    We need to remove one variable (either **Weight** or **BSA**) to remove the multicollinearity.
    In our case, weight is easier to measure compared to BSA, so experts will choose
    the weight and remove the BSA.
  prefs: []
  type: TYPE_NORMAL
- en: Dummy variables
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Dummy variables are categorical independent variables used in regression analysis.
    It is also known as a Boolean, indicator, qualitative, categorical, and binary
    variable. Dummy variables convert a categorical variable with *N* distinct values
    into *N*–1 dummy variables. It only takes the 1 and 0 binary values, which are
    equivalent to existence and nonexistence.
  prefs: []
  type: TYPE_NORMAL
- en: '`pandas` offers the `get_dummies()` function to generate the dummy values.
    Let''s understand the `get_dummies()` function through an example:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: 'This results in the following output:'
  prefs: []
  type: TYPE_NORMAL
- en: '|  | **Gender** |'
  prefs: []
  type: TYPE_TB
- en: '| 0 | F |'
  prefs: []
  type: TYPE_TB
- en: '| 1 | M |'
  prefs: []
  type: TYPE_TB
- en: '| 2 | M |'
  prefs: []
  type: TYPE_TB
- en: '| 3 | F |'
  prefs: []
  type: TYPE_TB
- en: '| 4 | M |'
  prefs: []
  type: TYPE_TB
- en: 'In the preceding code block, we have created the DataFrame with the `Gender`
    column and generated the dummy variable using the `get_dummies()` function. Let''s
    see an example in the following code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: 'This results in the following output:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: Here, in the preceding example, the `get_dummies()` function is generating two
    columns, which means a separate column for each value.
  prefs: []
  type: TYPE_NORMAL
- en: 'We can remove one column to avoid collinearity using the `drop_first=True`
    argument and drop first the *N*–1 dummies out of *N* categorical levels by removing
    the first level:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: 'This results in the following output:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: In the preceding code block, we have created the dummy variables for the `Gender`
    column using the `get_dummies()` function with the `drop_first=True` parameter.
    This has removed the first column and leaves *N–*1 columns. Let's now learn how
    to implement the linear regression model using the `scikit-learn` library.
  prefs: []
  type: TYPE_NORMAL
- en: Developing a linear regression model
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'After understanding the concepts of regression analysis, multicollinearity,
    and dummy variables, it''s time to get some hands-on experience with regression
    analysis. Let''s learn how to build the regression model using the scientific
    toolkit for machine learning (scikit-learn):'
  prefs: []
  type: TYPE_NORMAL
- en: 'We will first load the dataset using the `read_csv()` function:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: 'This results in the following output:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/38b6e58b-5433-427c-9cf8-b4e8aa015617.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Now that we have loaded the `Advertising.csv` dataset using `read_csv()` and
    checked the initial records using the `head()` function, we will split the data
    into two parts: dependent or target variable and independent variables or features.'
  prefs: []
  type: TYPE_NORMAL
- en: 'In this step, we will split the data two times:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Split into two parts: dependent or target variable and independent variables
    or features.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Split data into training and test sets. This can be done using the following
    code:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs: []
  type: TYPE_PRE
- en: 'After splitting the columns into dependent and independent variable parts,
    we will split the data into train and test sets in a 75:25 ratio using `train_test_split()`.
    The ratio can be specified using the `test_size` parameter and `random_state`
    is used as a seed value for reproducing the same data split each time. If `random_state`
    is `None`, then it will randomly split the records each time, which will give
    different performance measures:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs: []
  type: TYPE_PRE
- en: In the preceding code block, we have divided the data into two parts – train
    and test sets – in a 75:25 or 3:1 ratio.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let''s import the `LinearRegression` model, create its object, and fit it to
    the training dataset (`X_train`, `y_train`). After fitting the model, we can predict
    the values for testing data (`X_test`). We can see the intercept and coefficient
    of the regression equation using the `intercept_` and `coef_` attributes:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE10]'
  prefs: []
  type: TYPE_PRE
- en: 'This results in the following output:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE11]'
  prefs: []
  type: TYPE_PRE
- en: In the preceding code, we have prepared the linear regression model, performed
    the predictions on test sets, and displayed the intercepts and coefficients. In
    the upcoming section, we will assess the regression model's performance using
    model evaluation measures such as R-squared and error functions.
  prefs: []
  type: TYPE_NORMAL
- en: Evaluating regression model performance
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'In this section, we will review the regression evaluation measures for understanding
    the performance level of a regression model. Model evaluation is one of the key
    aspects of any machine learning model building process. It helps us to assess
    how our model will perform when we put it into production. We will use the following
    metrics for model evaluation:'
  prefs: []
  type: TYPE_NORMAL
- en: '**R-squared**'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**MSE**'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**MAE**'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**RMSE**'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: R-squared
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'R-squared (or coefficient of determination) is a statistical model evaluation
    measure that assesses the goodness of a regression model. It helps data analysts
    to explain model performance compared to the base model. Its value lies between
    0 and 1\. A value near 0 represents a poor model while a value near 1 represents
    a perfect fit. Sometimes, R-squared results in a negative value. This means your
    model is worse than the average base model. We can explain R-squared using the
    following formula:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/e171c969-0da0-46c7-ab1b-33ce7bafd90e.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Let''s understand all the components one by one:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Sum of Squares Regression** (**SSR**): This estimates the difference between
    the forecasted value and the mean of the data.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Sum of Squared** **Errors** (**SSE**): This estimates the change between
    the original or genuine value and the forecasted value.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Total Sum of Squares** (**SST**): This is the change between the original
    or genuine value and the mean of the data.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: MSE
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'MSE is an abbreviation of mean squared error. It is explained as the square
    of change between the original and forecasted values and the average between them
    for all the values:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/87b88053-52bb-470b-bc8a-79aea12bcc15.png)'
  prefs: []
  type: TYPE_IMG
- en: Here, ![](img/9e6905e4-62fa-4828-a207-b87404efc49d.png) is the original value
    and ![](img/fe8a8b54-b9f3-4efc-a833-c3d640a21db2.png) is the forecasted value.
  prefs: []
  type: TYPE_NORMAL
- en: MAE
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'MAE is an abbreviation of mean absolute error. It is explained as the absolute
    change between the original and forecasted values and the average between them
    for all the values:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/5459d946-f2a9-4dd7-8e2a-d092deee0b12.png)'
  prefs: []
  type: TYPE_IMG
- en: Here, ![](img/da944b30-ee27-4bef-9cf2-3dc08dac979b.png) is the original value,
    and ![](img/13e98d6f-6465-4fd5-a4c1-190fa165ad54.png) is the forecasted value.
  prefs: []
  type: TYPE_NORMAL
- en: RMSE
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'RMSE is an abbreviation of root mean squared error. It is explained as the
    square root of MSE:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/ab6ed537-f2b1-4d2a-b07d-9804a8d06828.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Let''s evaluate the model performance on a testing dataset. In the previous
    section, we predicted the values for the test set. Now, we will compare the predicted
    values with the actual values of the test set (`y_test`). scikit-learn offers
    the `metrics` class for evaluating the models. For regression model evaluation,
    we have methods for R-squared, MSE, MAE, and RMSE. Each of the methods takes two
    inputs: the actual values of the test set and the predicted values (`y_test` and
    `y_pred`). Let''s assess the performance of the linear regression model:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE12]'
  prefs: []
  type: TYPE_PRE
- en: 'This results in the following output:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE13]'
  prefs: []
  type: TYPE_PRE
- en: In the example, we have evaluated the linear regression model using MAE, MSE,
    RMSE, and R-squared. Here, R-squared is 0.85, which indicates that the model explains
    the 85% variability of the data.
  prefs: []
  type: TYPE_NORMAL
- en: Fitting polynomial regression
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Polynomial regression is a type of regression analysis that is used to adapt
    the nonlinear relationships between dependent and independent variables. In this
    type of regression, variables are modeled as the *n*th polynomial degree. It is
    used to understand the growth rate of various phenomena, such as epidemic outbreaks
    and growth in sales. Let''s understand the equation of polynomial regression:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/36c4aef7-f852-4525-b590-229645ada4ee.png)'
  prefs: []
  type: TYPE_IMG
- en: Here, ![](img/cb087be6-8131-4041-b20a-5e1039fef70b.png) is the independent variable
    and ![](img/280499c8-5605-4576-9ddf-a5735ed52c18.png) is a dependent variable.
    The ![](img/df2c782f-57c3-4404-8788-ef97f52c6ecc.png) intercepts, ![](img/761a1c0b-b2d7-488a-981a-1f69e3c7b7b3.png)...![](img/ab186eaf-109d-42ef-b318-77731682d08c.png),
    are a coefficient of *x* and ![](img/31dddf97-8805-43a1-9041-8ba8eefe5a4c.png)
    (the Greek letter pronounced as epsilon) is an error term that will act as a random
    variable.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let''s see an example to understand the polynomial concept in detail:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE14]'
  prefs: []
  type: TYPE_PRE
- en: 'This results in the following output:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/eae9d6ca-ec61-44ce-b87f-4652b0bff8cd.png)'
  prefs: []
  type: TYPE_IMG
- en: 'In the preceding code, we have displayed a dataset that has a polynomial relationship.
    Let''s see how we can map this relationship in regression analysis:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE15]'
  prefs: []
  type: TYPE_PRE
- en: 'This results in the following output:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/a159cce1-d335-4ef7-8326-bf8697e80e27.png)'
  prefs: []
  type: TYPE_IMG
- en: In the preceding code, we have read the polynomial relationship dataset, converted
    the *X* column into a polynomial *n*th degree column using `PolynomialFeatures()`,
    and then applied linear regression on `X_polynomial` and `label`. The preceding
    output plot shows that the resultant model captures the performance. Now, it's
    time to jump to another type of regression model, which can be used for classification
    purposes.
  prefs: []
  type: TYPE_NORMAL
- en: Regression models for classification
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Classification is the most utilized technique in the area of machine and statistical
    learning. Most machine learning problems are classification problems, such as
    detecting spam emails, analyzing financial risk, churn analysis, and discovering
    potential customers.
  prefs: []
  type: TYPE_NORMAL
- en: 'Classification can be of two types: binary and multi-class classification.
    Binary classification target variables have only two values: either 0 and 1 or
    yes or no. Examples of binary classification are whether a customer will buy an
    item or not, whether the customer will switch or churn to another brand or not,
    spam detection, disease prediction, and whether a loan applicant will default
    or not. Multi-class classification has more than two classes, for example, for
    categories of news articles, the classes could be sports, politics, business,
    and many more.'
  prefs: []
  type: TYPE_NORMAL
- en: Logistic regression is one of the classification methods, although its name
    ends with regression. It is a commonly used binary class classification method.
    It is a basic machine learning algorithm for all kinds of classification problems.
    It finds the association between dependent (or target) variables and sets of independent
    variables (or features). In the next section, we will look at logistic regression
    in detail.
  prefs: []
  type: TYPE_NORMAL
- en: Logistic regression
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Logistic regression is a kind of supervised machine learning algorithm that
    is utilized to forecast a binary outcome and classify observations. Its dependent
    variable is a binary variable with two classes: 0 or 1\. For example, it can be
    used to detect whether a loan applicant will default or not. It is a unique type
    of regression where the dependent or target variable is binary. It computes a
    log of the odds ratio of the target variable, which represents the probability
    of occurrence of an event, for example, the probability of a person suffering
    from diabetes.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Logistic regression is a kind of simple linear regression where the dependent
    or target variable is categorical. It uses the sigmoid function on the prediction
    result of linear regression. We can also use the logistic regression algorithm
    for multiple target classes. For multiple-class problems, it is called multinomial
    logistic regression. Multinomial logistic regression is a modification of logistic
    regression; it uses the softmax function instead of the sigmoid activation function:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/1dd8a555-b048-4adc-8249-330fd32b39a6.png)'
  prefs: []
  type: TYPE_IMG
- en: 'The sigmoid function is also known as a logistic function or an S-shaped curve.
    It maps input values between the ranges 0 and 1, which represents the probability
    of occurrence of an event. If the curve moves toward positive infinity, then the
    outcome becomes 1 and if the curve moves toward negative infinity, then the outcome
    becomes 1\. Let''s see the formula for the sigmoid function and logistic regression
    equation:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/8786165a-b015-4d0d-bfb9-b2e9e7bd4717.png)'
  prefs: []
  type: TYPE_IMG
- en: 'The following formula shows the logistic regression equation:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/681655c1-e4f0-470b-9df2-0bd7f8bece73.png)'
  prefs: []
  type: TYPE_IMG
- en: 'The term in the `log()` function is known as an odds ratio or "odds." The odds
    ratio is the ratio of the probability of the occurrence of an event to the probability
    of not occurrence of an event. In the following graph, you can see how logistic
    regression output behaves:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/55c4ce11-4880-4a18-9cef-47f075533ddc.png)'
  prefs: []
  type: TYPE_IMG
- en: We can see the ratio lands roughly around 0.5 here. Let's explore logistic regression
    a bit more in the upcoming subsections.
  prefs: []
  type: TYPE_NORMAL
- en: Characteristics of the logistic regression model
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'In this subsection, we will focus on the basic characteristics and assumptions
    of logistic regression. Let''s understand the following characteristics:'
  prefs: []
  type: TYPE_NORMAL
- en: The dependent or target variable should be binary in nature.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: There should be no multicollinearity among independent variables.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Coefficients are estimated using maximum likelihood.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Logistic regression follows Bernoulli distribution.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: There is no R-squared for model evaluation. The model was evaluated using concordance,
    KS statistics.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Types of logistic regression algorithms
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'There are various types of logistic regression algorithms available for different
    use cases and scenarios. In this section, we will focus on binary, multinomial,
    and ordinal logistic regression. Let''s see each of them and understand where
    we can utilize them:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Binary logistic regression m****odel**:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: In the binary logistic regression model, the dependent or target column has
    only two values, such as whether a loan will default or not default, an email
    is spam or not spam, or a patient is diabetic or non-diabetic.
  prefs: []
  type: TYPE_NORMAL
- en: '**Multinomial logistic regression model**:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: In a multinomial logistic regression model, a dependent or target column has
    three or more than three values, such as predicting the species of the iris flower
    and predicting the category of news articles, such as politics, business, and
    sports.
  prefs: []
  type: TYPE_NORMAL
- en: '**Ordinal logistic regression**:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: In the ordinal logistic regression model, a dependent variable will have ordinal
    or sequence classes, such as movie and hotel ratings.
  prefs: []
  type: TYPE_NORMAL
- en: Advantages and disadvantages of logistic regression
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The logistic regression model not only provides prediction (0 or 1) but also
    gives the probabilities of outcomes, which helps us to understand the confidence
    of a prediction. It is easy to implement and understand and is interpretable.
  prefs: []
  type: TYPE_NORMAL
- en: A large number of independent variables will increase the amount of variance
    explained, which results in model overfitting. Logistic regression cannot work
    with non-linear relationships. It will also not perform well with highly correlated
    feature variables (or independent variables).
  prefs: []
  type: TYPE_NORMAL
- en: Implementing logistic regression using scikit-learn
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Now that you know all about logistic regression, let''s implement it in Python
    using the `scikit-learn` library. Let''s create a model using naive Bayes classification.
    We will do so using the following steps:'
  prefs: []
  type: TYPE_NORMAL
- en: 'We will first import the dataset and the required libraries using the following
    code:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE16]'
  prefs: []
  type: TYPE_PRE
- en: 'This results in the following output:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/becd7d75-8005-43aa-9a97-1458940b7744.png)'
  prefs: []
  type: TYPE_IMG
- en: In our preceding example, we are reading the Pima Indians Diabetes dataset.
    This dataset does not give the column names, so we have to do so.
  prefs: []
  type: TYPE_NORMAL
- en: 'In the `read_csv()` function, we will pass the header to `None` and names to
    the column list that was created before reading the CSV file:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE17]'
  prefs: []
  type: TYPE_PRE
- en: 'After loading the dataset, we need to divide the dataset into independent (feature
    set) column features and dependent (or label) column targets. After this, the
    dataset will be partitioned into training and testing sets. Now, both the dependent
    and independent columns are divided into train and test sets (`feature_train`,
    `feature_test`, `target_train`, and `target_test`) using `train_test_split()`.
    `train_test_split()` takes dependent and independent DataFrames, `test_size` and
    `random_state`. Here, `test_size` will decide the ratio of the train-test split
    (that is, a `test_size` value of `0.3` means 30% testing set and the remaining
    70% will be the training set), and `random_state` is used as a seed value for
    reproducing the same data split each time. If `random_state` is `None`, then it
    will randomly split the records each time, which will give different performance
    measures:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE18]'
  prefs: []
  type: TYPE_PRE
- en: 'This results in the following output:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE19]'
  prefs: []
  type: TYPE_PRE
- en: Now, we are ready to create a logistic regression model. First, we will import
    the `LogisticRegression` class and create its object or model. This model will
    fit on the training dataset (`X_train` and `y_train`). After training, the model
    is ready to make predictions using the `predict()` method. scikit-learn's `metrics`
    class offers various methods for performance evaluation, such as accuracy. The
    `accuracy_score()` methods will take actual labels (`y_test`) and predicted labels
    (`y_pred`).
  prefs: []
  type: TYPE_NORMAL
- en: Summary
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this chapter, we discovered regression analysis algorithms. This will benefit
    you in gaining an important skill for predictive data analysis. You have gained
    an understanding of concepts such as regression analysis, multicollinearity, dummy
    variables, regression evaluation measures, and logistic regression. The chapter
    started with simple linear and multiple regressions. After simple linear and multiple
    regressions, our main focus was on multicollinearity, model development, and model
    evaluation measures. In later sections, we focused on logistic regression, characteristics,
    types of regression, and its implementation.
  prefs: []
  type: TYPE_NORMAL
- en: The next chapter, [Chapter 10](ed220fe6-db8c-4167-8442-27233d957d09.xhtml),
    *Supervised Learning – Classification Techniques*, will focus on classification,
    its techniques, the train-test split strategy, and performance evaluation measures.
    In later sections, the focus will be on data splitting, the confusion matrix,
    and performance evaluation measures such as accuracy, precision, recall, F1-score,
    ROC, and AUC.
  prefs: []
  type: TYPE_NORMAL
