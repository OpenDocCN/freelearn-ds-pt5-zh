- en: Customer Lifetime Value
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this chapter, we are going to focus on the second use case of predictive
    analytics in marketing, the customer lifetime value that we discussed in the previous
    chapter. In marketing, it is always a challenge to budget for marketing campaigns.
    We do not want to spend too much and result in a negative ROI. However, we also
    do not want to spend too little and have no visible impact or outcome. When determining
    the budget for a marketing strategy, it is essential to know what the expected
    return will be from running a given marketing campaign. Understanding what the
    **customer lifetime value** (**CLV**) is for individual customers can help marketers
    justify their marketing budget, as well as target potential high-value customers.
    In this chapter, we are going to discuss in more detail the concept and the advantage
    of calculating the CLV, as well as how to build a predictive machine learning
    model to predict the expected CLV for individual customers in Python and R.
  prefs: []
  type: TYPE_NORMAL
- en: 'In this chapter, we will cover the following topics:'
  prefs: []
  type: TYPE_NORMAL
- en: CLV
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Evaluation metrics for regression models
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Predicting the 3 month CLV with Python
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Predicting the 3 month CLV with R
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: CLV
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In marketing, the CLV is one of the key metrics to have and monitor. The CLV
    measures customers' total worth to the business over the course of their lifetime
    relationship with the company. This metric is especially important to keep track
    of for acquiring new customers. It is generally more expensive to acquire new
    customers than to keep existing customers, so knowing the lifetime value and the
    costs associated with acquiring new customers is essential in order to build marketing
    strategies with a positive ROI. For example, if the average CLV of your customer
    is $100 and it only costs $10 to acquire a new customer, then your business will
    be generating more revenue as you acquire new customers.
  prefs: []
  type: TYPE_NORMAL
- en: However, if it costs $150 to acquire a new customer and the average CLV of your
    customer is still $100, then you will be losing money for each acquisition. Simply
    put, if your marketing spend for new customer acquisition exceeds the CLV, you
    will be losing money for each acquisition, and it is better to just work with
    the existing customers.
  prefs: []
  type: TYPE_NORMAL
- en: There are multiple ways to calculate CLV. One way is to find the customer's
    average purchase amount, purchase frequency, and lifetime span and do a simple
    calculation to get the CLV. For example, think of a hypothetical case, where a
    customer's average purchase amount is $100 and he or she makes purchases five
    times every month on average. Then this customer's average value per month is
    $500, which is simply multiplying the average purchase amount with the average
    purchase frequency. Now, we need to know this customer's lifetime span. One way
    to estimate a customer's lifetime span is to look at the average monthly churn
    rate, which is the percentage of customers leaving and terminating the relationship
    with your business. You can estimate a customer's lifetime span by dividing one
    by the churn rate. Assuming 5% of the churn rate in our hypothetical case, the
    estimated customer's lifetime span is 20 years. Given the customer's average value
    per month of $500 and lifetime span of 20 years, the CLV of this customer turns
    out to be $120,000\. This final CLV amount is calculated by multiplying $500,
    the average value per month, by 12 months and the lifetime span of 20 years.
  prefs: []
  type: TYPE_NORMAL
- en: Because we do not typically know the lifetime span of customers, we often try
    to estimate CLV over the course of a certain period. It can be done by estimating
    a customer's 12-month CLV, 24-month CLV, or can also be a 3-month CLV. Aside from
    the method we discussed through an example, CLV can also be estimated through
    building predictive models. Using machine learning algorithms and customers' purchase
    history data, we can build machine learning models that predict customers' CLV
    over the course of a certain period. In the programming exercises in this chapter,
    we are going to learn how to build a regression model that predicts customers'
    3-month CLV.
  prefs: []
  type: TYPE_NORMAL
- en: Evaluating regression models
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: We need to use a different set of metrics for evaluating regression models from
    those for classification model evaluations. This is because the prediction output
    of a regression model takes continuous values, meaning it can take any value and
    is not restricted to taking from a predefined set of values. On the other hand,
    as we have seen in [Chapter 8](4f5163a1-c34a-495f-bc5f-e02f9b2a2052.xhtml), *Predicting
    the Likelihood of Marketing Engagement*, the prediction output of a classification
    model can only take a certain number of values. As was the case for the engagement
    prediction, our classification model from the previous chapter could only take
    two values—zero for no engagement and one for engagement. Because of this difference,
    we need to use different metrics to evaluate regression models.
  prefs: []
  type: TYPE_NORMAL
- en: 'In this section, we are going to discuss four commonly used methodologies to
    evaluate regression models—**mean squared error** (**MSE**), **median absolute
    error** (**MAE**), *R²*, and predicted versus actual scatter plot. As the name
    suggests, MSE measures the average of the squared errors, where the errors are
    the differences between the predicted and actual values. The equation for *MSE*
    looks as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/df961a94-c63a-455d-baaa-f02de0eb111a.png)'
  prefs: []
  type: TYPE_IMG
- en: The *Y* values in this equation are the actual values and *Y' *values are the
    predicted values. Because MSE is an average of squared errors, this measure is
    sensitive to and highly affected by outliers.
  prefs: []
  type: TYPE_NORMAL
- en: 'The MAE, on the other hand, is less sensitive to outliers and considered more
    robust, as the median is affected by the outliers or values at the end tails much
    less than the average. The equation, borrowed from this `scikit-learn` documentation
    page, [https://scikit-learn.org/stable/modules/model_evaluation.html#median-absolute-error](https://scikit-learn.org/stable/modules/model_evaluation.html#median-absolute-error),
    looks as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/19aeba3e-bfca-4e51-b991-91e483b583ba.png)'
  prefs: []
  type: TYPE_IMG
- en: The *y* values in this equation represent the actual values and the ![](img/961dcb23-3ac8-4cd7-b07a-e5beeaaebc0d.png) values
    represent the predicted values.
  prefs: []
  type: TYPE_NORMAL
- en: 'Another frequently used measure for regression models is *R²*, also called
    the coefficient of determination. *R²* measures the goodness of fit. In other
    words, it measures how well a regression model is fitted to the data. Simply put,
    *R²* is the percentage of the explained variability of the target variable by
    the regression model. The equation looks as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/d07966c9-3620-4cb9-a62d-eeb514756e3c.png)'
  prefs: []
  type: TYPE_IMG
- en: '*R²* typically ranges between zero and one. The *R²* value of zero means the
    model does not explain or capture the target variable variability at all and is
    not a good fit to the data. On the other hand, the *R²* value of one means that
    the model captures 100% of the target variable variability and is a perfect fit
    to the data. The closer to one the *R²* value is, the better the model fit is.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Lastly, a scatter plot of predicted values against actual values is also used
    to visualize how closely the model fits. An example of this scatter plot looks
    like the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/fb192e2b-eec1-4f51-a8c5-e0123c35a3c7.png)'
  prefs: []
  type: TYPE_IMG
- en: For a good fit, you will see points in this scatter plot that are close to the
    diagonal line. If the model's *R²* is high, the points will be close to the diagonal
    line. On the other hand, if the model's *R²* is low, the points will be dispersed
    away from the diagonal line. In the following programming exercises, we will discuss
    how to compute and visualize these measures in Python and R, and will use these
    measures to evaluate our regression model.
  prefs: []
  type: TYPE_NORMAL
- en: Predicting the 3 month CLV with Python
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this section, we are going to discuss how to build and evaluate regression
    models using machine learning algorithms in Python. By the end of this section,
    we will have built a predictive model using a linear regression algorithm to predict
    the CLV**, **more specifically, the expected 3 month customer value. We will be
    mainly using the `pandas`, `matplotlib`, and `scikit-learn` packages to analyze,
    visualize, and build machine learning models that predict the expected 3 month
    customer value. For those readers who would like to use R instead of Python for
    this exercise, you can skip to the next section.
  prefs: []
  type: TYPE_NORMAL
- en: For this exercise, we will be using one of the publicly available datasets from
    the UCI Machine Learning Repository, which can be found at this link: [http://archive.ics.uci.edu/ml/datasets/online+retail](http://archive.ics.uci.edu/ml/datasets/online+retail).
  prefs: []
  type: TYPE_NORMAL
- en: 'You can follow this link and download the data that is available in XLSX format,
    named `Online Retail.xlsx`. Once you have downloaded this data, you can load it
    into your Jupyter Notebook by running the following command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: 'The DataFrame, `df`, looks as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/a9eb6cfd-3f17-4def-a284-75d9244a0dad.png)'
  prefs: []
  type: TYPE_IMG
- en: As you might have noticed, we have used this dataset a few times in the previous
    chapters. With the knowledge we gained about this dataset from the previous chapters,
    we are going to first prepare our data by cleaning it up.
  prefs: []
  type: TYPE_NORMAL
- en: Data cleanup
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'As you might recall, there are a few things we need to clean up in this dataset. The
    clean-up steps are as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Handling negative quantity**: There are transactions with a negative `Quantity`
    value, which represent canceled orders. We are going to ignore those canceled
    orders for this exercise, so we will need to exclude them from our `pandas` DataFrame.
    The code to exclude these negative values in the `Quantity` column looks as follows:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: We are simply taking all of those rows with a positive `Quantity` value and
    storing them back to the `df` variable.
  prefs: []
  type: TYPE_NORMAL
- en: '**Dropping ****NaN**** records**: We need to drop records with no `CustomerID`.
    Since we are going to build a machine learning model to predict the 3 month customer
    value, we need to group the data by the `CustomerID` column. Without it, we cannot
    properly build models for this project. The code to drop records with no `CustomerID`
    values looks like the following code snippet:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: As you can see from this code, we are using the `notnull` function in the `pandas`
    package. This function returns a list of arrays, where `True` values indicate
    that the value in the given index is not `null` and `False` values indicate that
    the value in the given index is `null`. We store these records with not null values
    in the `CustomerID` column back to the `df` variable.
  prefs: []
  type: TYPE_NORMAL
- en: '**Handling incomplete data**: Another cleanup we need to do is to handle incomplete
    data. If you recall from previous chapters, the transaction data for the last
    month is incomplete. Take a look at the following output:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![](img/a3af534f-d396-4326-99bb-56e0fc12fd39.png)'
  prefs: []
  type: TYPE_IMG
- en: 'As you can see from this output, the dataset has all of the transactions between
    December 1, 2010 and December 9, 2011\. The data for the last month, December
    2011, is not complete. In order to properly build a model for the 3 month customer
    value predictions, we are going to ignore the transactions in the last month.
    Take a look at the following code that shows how to drop those records from our
    DataFrame:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: We are simply taking all of the transactions that occurred before December 01,
    2011 and storing them back to the `df` variable.
  prefs: []
  type: TYPE_NORMAL
- en: '**Total sales value**: Lastly, we need to create a column for the total sales
    value for each transaction. Take a look at the following code:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: We are multiplying the `Quantity` column by the `UnitPrice` column to get the
    total purchase amount for each transaction. Then, we store these values into a
    column named `Sales`. We have now completed all of the clean-up tasks.
  prefs: []
  type: TYPE_NORMAL
- en: 'Now we have cleaned up all of the transaction data, let''s summarize this data
    for each order or `InvoiceNo`. Take a look at the following code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: 'As you can see from this code, we are grouping the `DataFrame` `df` by two
    columns, `CustomerID` and `InvoiceNo`. Then, we are summing up all of the `Sales` values
    for each customer and order, and taking the last transaction time for the given
    order as `InvoiceDate`. This way we now have a `DataFrame`, `orders_df`, as we
    need to know about each order that each customer placed. The data looks like the
    following:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/ff405d41-3509-416f-a52b-97f8687aa1ff.png)'
  prefs: []
  type: TYPE_IMG
- en: Before we dive into building models, let's take a closer look at this customer
    purchase history data.
  prefs: []
  type: TYPE_NORMAL
- en: Data analysis
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'In order to calculate the CLV, we need to know the frequency, recency, and
    total amount of purchases by each customer. We are going to compute basic information
    about each customer''s average and lifetime purchase amount, as well as each customer''s
    duration and frequency of purchases. Take a look at the following code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: We first group by the `CustomerID` column and aggregate the numbers by `Sales`
    and `InvoiceDate` columns. If you look closely at the aggregation functions, we
    are using four customer aggregation functions: `groupby_mean`, `groupby_count`,
    `purchase_duration`, and `avg_frequency`. The first function, `groupby_mean`,
    simply computes the average for each group and the second function, `groupby_count`,
    simply counts the number of records in each group. The `purchase_duration` function
    counts the number of days between the first and last invoice dates in each group
    and the `avg_frequency` function calculates the average number of days between
    orders by dividing `purchase_duration` by the number of orders.
  prefs: []
  type: TYPE_NORMAL
- en: 'The resulting `DataFrame` looks like the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/e08ded75-3b01-4dd6-867a-70ca5df000ab.png)'
  prefs: []
  type: TYPE_IMG
- en: This data gives us an idea of the purchases each customer has made. For example,
    the customer with ID `12346` only made one purchase on January 18, 2011\. However,
    the customer with ID `12347` has made six purchases that range from December 7,
    2010 to October 31, 2011, or over the course of `327` days. The average amount
    this customer spent on each order is `680` and, on average, this customer made
    a purchase every `54.5` days.
  prefs: []
  type: TYPE_NORMAL
- en: Let's take a closer look at the distributions of the number of purchases that
    the repeat customers have made.
  prefs: []
  type: TYPE_NORMAL
- en: 'Take a look at the following code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: 'As you can see from this code, we clean up the column names of the DataFrame, `summary_df`, in
    the first line. Then, we are only taking the customers who have made at least
    two or more purchases, which represents repeat customers. Lastly, we group by
    the `sales_count` column and count how many customers belong to each category.
    The resulting plot looks as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/449becae-6f10-4e97-985c-08c3d53b7023.png)'
  prefs: []
  type: TYPE_IMG
- en: 'As you can see from this plot, the majority of customers have made 10 or less
    purchases historically. Let''s take a look at the average number of days between
    purchases for these repeat customers. Take a look at the following code first:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs: []
  type: TYPE_PRE
- en: 'We are building a histogram with the purchase frequency data using the `hist`
    function in the `pandas` package. The `bins` parameter defines the number of histogram
    bins to build. The result looks as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/7f913c60-4b71-4ffe-aa3f-1c8c10660bbe.png)'
  prefs: []
  type: TYPE_IMG
- en: This plot tells us the overall view of how frequently repeat customers made
    purchases historically. As you can see from this plot, the majority of repeat
    customers made purchases every 20 to 50 days.
  prefs: []
  type: TYPE_NORMAL
- en: Predicting the 3 month CLV
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this section, we are going to build a model that predicts the 3 month customer
    value using the `pandas` and `scikit-learn` packages in Python. We are going to
    first slice the data into chunks of 3 months and take the last 3 months' data
    as the target for predictions and the rest as the features. We will first prepare
    our data for model building and then train a linear regression model for the 3
    month customer value predictions.
  prefs: []
  type: TYPE_NORMAL
- en: Data preparation
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'In order to build a predictive model, we need to prepare our data first, so
    that we can feed the relevant data into the model. Take a look at the following
    code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs: []
  type: TYPE_PRE
- en: 'Since we want to predict the 3 month customer value, we are breaking down the
    data into chunks of 3 months for each customer. As you can see in the `groupby`
    function, we group the previously built DataFrame `orders_df` by `CustomerID`
    and a custom `Grouper`, which groups `InvoiceDate` by every 3 months. Then, for
    each group of 3 month time windows, we sum up all of the sales to get the total
    purchase amount, take the average of purchase amount and the total number of purchases
    for the given period for each customer. This way we have aggregate data that has
    purchase information for each customer for every 3 months. Lastly, we do some
    cleanup for the column names. The data in `data_df` now looks like the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/33c49877-1890-4c97-8648-38c7ad25ab60.png)'
  prefs: []
  type: TYPE_IMG
- en: 'In order to make things simpler, let''s encode the `InvoiceDate` column values
    so that they are easier to read than the current date format. Take a look at the
    following code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE10]'
  prefs: []
  type: TYPE_PRE
- en: 'As you can see from this code, we are encoding date values into `M_1`, `M_2`,
    `M_3`, and so forth, where the smaller number represents more recent dates. For
    example, the date `2011-12-31` is now encoded as `M_1` and the date `2011-09-30` is
    now encoded as `M_2`. The result looks as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/379317cf-1ae3-4426-b577-ebe2c341ac7e.png)'
  prefs: []
  type: TYPE_IMG
- en: 'We are now ready to build a sample set with features and target variables.
    As briefly mentioned before, we are going to use the last 3 months as the target
    variable and the rest as the features, meaning we are going to train a machine
    learning model that predicts the last 3 months'' customer value with the rest
    of the data. In order to train such a model, we need to transform this data into
    tabular data, where the rows represent the individual customers and the columns
    represent each feature. Take a look at the following code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE11]'
  prefs: []
  type: TYPE_PRE
- en: 'As you can see from this code, we use the `pandas` function, `pivot_table`,
    where the index is going to be `CustomerID` and the columns are going to be `sales_sum`,
    `sales_avg`, and `sales_count` for each 3 month period. The DataFrame, `features_df`, that
    we created here looks like the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/de663bc6-6fdc-42c6-896c-c7110483f16c.png)'
  prefs: []
  type: TYPE_IMG
- en: 'You might notice that this data has `NaN` values. We can encode these `NaN`
    values with `0.0` using the following code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE12]'
  prefs: []
  type: TYPE_PRE
- en: 'Now that we have built the features DataFrame, let''s build the target variables.
    Take a look at the following code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE13]'
  prefs: []
  type: TYPE_PRE
- en: 'As you can see from this code, we are taking the last 3 month period, the `M_1`
    group, as the target variable. The target column will be `sales_sum`, as we want
    to predict the next 3 month customer value, which is the total purchase amount
    that a given customer is likely to make in the next 3 months. The target variable
    looks like the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/4340c6c8-7f71-45f5-acdd-c4f56f1823b1.png)'
  prefs: []
  type: TYPE_IMG
- en: 'There is only one thing left to build, which is a sample set for building machine
    learning models, combining features and response data together. Take a look at
    the following code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE14]'
  prefs: []
  type: TYPE_PRE
- en: 'As you can see here, we are simply joining the two `DataFrames` on `CustomerID`,
    using the `merge` function. By having the `how=''left''` flag, we take all records
    in the features data, even if there is no corresponding data in the response data.
    This is a case where the given customer did not make any purchases in the last
    3 months, so we encode them as zero. The final sample set now looks as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/15154c88-06d5-4b5a-a549-380ca1644e47.png)'
  prefs: []
  type: TYPE_IMG
- en: With this data, we can now build a model that predicts the next 3 month customer
    value with historical purchase data.
  prefs: []
  type: TYPE_NORMAL
- en: Linear regression
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Similar to the previous chapter, we are going to split the sample set into
    train and test sets, using the following code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE15]'
  prefs: []
  type: TYPE_PRE
- en: As you can see from this code, we are taking 70% of the sample set for training
    the model and the remaining 30% for testing and evaluating the model performance.
    In this section, we will be using a linear regression model. However, we recommend
    experimenting with other machine learning algorithms, such as random forest and
    **support vector machine** (**SVM**).
  prefs: []
  type: TYPE_NORMAL
- en: More details on how to train these models with the `scikit-learn` package can
    be found at the following links: [https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestRegressor.html](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestRegressor.html)
    and [https://scikit-learn.org/stable/modules/generated/sklearn.svm.SVR.html](https://scikit-learn.org/stable/modules/generated/sklearn.svm.SVR.html).
  prefs: []
  type: TYPE_NORMAL
- en: 'In order to train a linear regression model with our dataset, you can use the
    following code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE16]'
  prefs: []
  type: TYPE_PRE
- en: This is as simple as it gets. You import the `LinearRegression` class of the `scikit-learn`
    package and initiate a `LinearRegression` object. Then, you can train a linear
    regression model using the `fit` function with the `x_train` features and the
    `y_train` targets.
  prefs: []
  type: TYPE_NORMAL
- en: 'Once a linear regression model is trained, there is some useful information
    that you can find in the `LinearRegression` object. First, you can get the intercept
    of the linear regression equation, using the `intercept_` attribute of the `LinearRegression`
    object, like the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE17]'
  prefs: []
  type: TYPE_PRE
- en: 'Also, you can find the fitted linear regression model''s coefficients, using
    the `coef_` attribute like the following code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE18]'
  prefs: []
  type: TYPE_PRE
- en: 'The coefficients of each feature of the fitted regression model look as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/068cb89f-24b8-4507-b823-65dbb533af54.png)'
  prefs: []
  type: TYPE_IMG
- en: As you can see from this coefficient output, you can easily find which features
    have negative correlation with the target and which features have positive correlation
    with the target. For example, the previous 3 month period's average purchase amount,
    `sales_avg_M_2`, has negative impacts on the next 3 month customer value. This
    means that the higher the previous 3 month period's purchase amount is, the lower
    the next 3 month purchase amount will be. On the other hand, the second and third most
    recent 3 month period's average purchase amounts, `sales_avg_M_3` and `sales_avg_M_4`,
    are positively correlated with the next 3 month customer value. In other words,
    the more a customer made purchases 3 months to 9 months ago, the higher value
    he or she will bring in the next 3 months. Looking at the coefficients is one
    way to gain insights on how the expected value will change, given certain features.
  prefs: []
  type: TYPE_NORMAL
- en: Using the 3 month customer value prediction output, you can custom-tailor your
    marketing strategies in different ways. Since you know the expected revenue or
    purchase amount from individual customers for the next 3 months, you can set a
    better informed budget for your marketing campaign. It should be set high enough
    to reach your target customers, but low enough to be below the expected 3 month
    customer value, so that you can have a positive ROI marketing campaign. On the
    other hand, you can also use these 3 month customer value prediction output values to
    specifically target these high-value customers for the next 3 months. This can
    help you to create marketing campaigns with a higher ROI, as those high-value
    customers, predicted by this model, are likely to bring in more revenue than the
    others.
  prefs: []
  type: TYPE_NORMAL
- en: Evaluating regression model performance
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Now that we have a machine learning model that is fitted to predict the 3 month
    customer value, let''s discuss how to evaluate the performance of this model.
    As discussed previously, we are going to use *R²*, MAE, and a scatter plot of
    predicted versus actual to evaluate our model. We need to get the prediction output
    from our model first, as shown in the following code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE19]'
  prefs: []
  type: TYPE_PRE
- en: 'The `scikit-learn` package has implemented the functions to compute the *R²*
    and the MAE in their `metrics` module. You can use these functions by importing
    them into your environment, like the following code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE20]'
  prefs: []
  type: TYPE_PRE
- en: 'As the names suggest, the `r2_score` function computes the *R²* and the `median_absolute_error`
    function computes the MAE. You can compute the *R**²* and MAE numbers, using the
    following code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE21]'
  prefs: []
  type: TYPE_PRE
- en: 'As you can see from here, both functions take two parameters, `y_true` and
    `y_pred`. The `y_true` parameter is for the actual target values and the `y_pred`
    parameter is for the predicted target values. Using these codes, the in-sample
    and out-of-sample values for R² and MAE in our case look like the following output:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/eca7324c-292f-46d9-9ac2-80f1f24565af.png)'
  prefs: []
  type: TYPE_IMG
- en: Due to the randomness in splitting the sample set into train and test sets,
    your might differ from these results. In our case, the in-sample R² was `0.4445`
    and the out-of-sample R² was `0.7947`. On the other hand, the in-sample MAE was
    `178.2854` and the out-of-sample MAE was `178.7393`. Looking at these numbers,
    we do not necessarily see a hint of overfitting or a big gap between the in-sample
    and out-of-sample performances.
  prefs: []
  type: TYPE_NORMAL
- en: 'Lastly, let''s take a look at the scatter plot of predicted versus actual.
    You can use the following code for this scatter plot:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE22]'
  prefs: []
  type: TYPE_PRE
- en: 'The resulting plot looks as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/17145852-4938-4328-ae5a-9fd7ed9a18bb.png)'
  prefs: []
  type: TYPE_IMG
- en: As you can see from this plot, the *x*-values are the actual values and the
    *y*-values are the predicted values. As discussed earlier, the more the points
    that are on the straight line, the better the predictions are. This is because
    points on the straight line suggest that the actual values and the predicted values
    are close to each other. Looking at this plot, the points seem to be positioned
    around the straight line, which suggests that the predictions and the actual values
    are not too far apart from each other.
  prefs: []
  type: TYPE_NORMAL
- en: The full code for this Python exercise can be found at the following repository: [https://github.com/yoonhwang/hands-on-data-science-for-marketing/blob/master/ch.9/python/CustomerLifetimeValue.ipynb](https://github.com/yoonhwang/hands-on-data-science-for-marketing/blob/master/ch.9/python/CustomerLifetimeValue.ipynb).
  prefs: []
  type: TYPE_NORMAL
- en: Predicting the 3 month CLV with R
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this section, we are going to discuss how to build and evaluate regression
    models using machine learning algorithms in R. By the end of this section, we
    will have built a predictive model using a linear regression algorithm to predict
    the CLV, more specifically, the expected 3 month customer value. We will be using
    a handful of R packages, such as `dplyr`, `reshape2`, and `caTools`, to analyze,
    transform, and prepare the data for building machine learning models to predict
    the expected 3 month customer value. For those readers who would like to use Python
    instead of R for this exercise, you can refer to the previous section.
  prefs: []
  type: TYPE_NORMAL
- en: 'For this exercise, we will be using one of the publicly available datasets
    from the UCI Machine Learning Repository, which can be found at this link: [http://archive.ics.uci.edu/ml/datasets/online+retail](http://archive.ics.uci.edu/ml/datasets/online+retail).
    You can follow this link and download the data that is available in XLSX format,
    named `Online Retail.xlsx`. Once you have downloaded this data, you can load it
    into your R environment by running the following command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE23]'
  prefs: []
  type: TYPE_PRE
- en: 'The DataFrame, `df`, looks as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/2d1c74f8-8a70-4f8c-8529-b3997cb85879.png)'
  prefs: []
  type: TYPE_IMG
- en: As you might have noticed, we have used this dataset a few times in the previous
    chapters. With the knowledge we gained about this dataset from the previous chapters,
    we are going to first prepare our data by cleaning up the data.
  prefs: []
  type: TYPE_NORMAL
- en: Data cleanup
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'As you might recall, there are a few things we need to clean up in this dataset.
    The clean-up steps are as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Handling negative quantity**: There are transactions with a negative `Quantity`
    value, which represent canceled orders. We are going to ignore those canceled
    orders for this exercise, so we will need to exclude them from our `DataFrame`.
    The code to exclude these negative values in the `Quantity` column looks as follows:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE24]'
  prefs: []
  type: TYPE_PRE
- en: We are simply taking all of those rows with a positive `Quantity` value and
    storing them back to the variable `df`.
  prefs: []
  type: TYPE_NORMAL
- en: '**Dropping NA r****ecords**: We need to drop records with no value in the `CustomerID`
    column. Since we are going to build a machine learning model to predict the 3
    month customer value, we need to group the data by the `CustomerID` column. Without
    it, we cannot properly build models for this project. The code to drop records
    with null values looks like the following code snippet:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE25]'
  prefs: []
  type: TYPE_PRE
- en: As you can see from this code, we are using the `na.omit` function in R. This
    function returns an object with `null` or `NA` values removed. Then, we store
    the output back to the original DataFrame, `df` variable.
  prefs: []
  type: TYPE_NORMAL
- en: '**Handling incomplete data**: If you recall from previous chapters, the transaction
    data for the last month is incomplete. Take a look at the following output:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![](img/aaa9c600-f132-4fee-90ec-67411a59dd9c.png)'
  prefs: []
  type: TYPE_IMG
- en: 'As you can see from this output, the dataset has all the transactions between
    December 1st, 2010 and December 9, 2011\. The data for the last month, December
    of 2011, is not complete. In order to properly build a model for the 3 month customer
    value predictions, we are going to ignore the transactions in the last month.
    Take a look at the following code on how to drop those records from our DataFrame:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE26]'
  prefs: []
  type: TYPE_PRE
- en: We are simply taking all of the transactions that occurred before December 1,
    2011 and storing them back to the variable, `df`.
  prefs: []
  type: TYPE_NORMAL
- en: '**Total sales value**: Lastly, we need to create a column for the total sales
    value for each transaction. Take a look at the following code:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE27]'
  prefs: []
  type: TYPE_PRE
- en: We are simply multiplying the `Quantity` column by the `UnitPrice` column to
    get the total purchase amount for each transaction. Then, we store these values
    into a column named `Sales`. We have now completed all the cleanup tasks.
  prefs: []
  type: TYPE_NORMAL
- en: 'Now we have cleaned up all the transaction data, let''s summarize this data
    for each order or `InvoiceNo`. Take a look at the following code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE28]'
  prefs: []
  type: TYPE_PRE
- en: 'As you can see from this code, we are grouping `df` by two columns, `CustomerID` and `InvoiceNo`.
    Then, we are summing up all the `Sales` values for each customer and order, and
    taking the last transaction time for the given order as the `InvoiceDate`. This
    way we now have a DataFrame, `ordersDF`, that we need to know about each order
    that each customer placed. The data looks like the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/0232f5d8-47e5-426d-97f4-0d2f72b64178.png)'
  prefs: []
  type: TYPE_IMG
- en: Before we dive into building models, let's take a closer look at this customer
    purchase history data.
  prefs: []
  type: TYPE_NORMAL
- en: Data analysis
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'In order to calculate the CLV, we need to know the frequency, recency, and
    total amount of purchases by each customer. We are going to compute basic information
    about each customer''s average and lifetime purchase amount, as well as each customer''s
    duration and frequency of purchases. Take a look at the following code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE29]'
  prefs: []
  type: TYPE_PRE
- en: We first group by the `CustomerID` column and aggregate the numbers by `Sales` and `InvoiceDate` columns.
    Using the `min`, `max`, `sum`, `mean`, and `n` functions in R, we can compute
    the minimum, maximum, and total purchase amount, as well as the average amount
    and the number of purchases for each customer. We also use the `min` and `max`
    functions to get the first and last order dates for each customer. For `PurchaseDuration`,
    we are taking the number of days between the last and the first order dates. For
    `PurchaseFrequency`, we are dividing the `PurchaseDuration` number by the number
    of orders to get the average number of days between purchases.
  prefs: []
  type: TYPE_NORMAL
- en: 'The resulting DataFrame, `summaryDF`, looks like the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/a3175c13-7c99-4c44-ae47-f08ac0948bf4.png)'
  prefs: []
  type: TYPE_IMG
- en: This data gives us an idea of the purchases each customer has made. For example,
    the customer with ID `12346` only made one purchase on January 18, 2011\. However,
    the customer with ID `12347` has made six purchases that range from December 7,
    2010 to October 31, 2011, or over the course of `327` days. The average amount
    this customer spent on each order is about `681` and, on average, this customer
    made a purchase every `54.5` days.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let''s take a closer look at the distributions of the number of purchases that
    the repeat customers have made. Take a look at the following code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE30]'
  prefs: []
  type: TYPE_PRE
- en: 'We first exclude customers with only one purchase from our analysis in the
    first line of code. Then, we count the number of customers for each `SalesCount`.
    Lastly, we create a bar plot using `ggplot` and `geom_bar` to display this data.
    The result looks as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/dbf9950d-c0b6-4061-9472-fd93bc4cebce.png)'
  prefs: []
  type: TYPE_IMG
- en: 'As you can see from this plot, the majority of customers have made 10 or less
    purchases historically. Let''s take a look at the average number of days between
    purchases for these repeat customers. Take a look at the following code first:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE31]'
  prefs: []
  type: TYPE_PRE
- en: 'We are building a histogram with the purchase frequency data using the `hist` function
    in R. The `breaks` parameter defines the number of histogram bins to build. The
    result looks as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/6031bee7-adc4-4f42-918c-e2d66dbe8c27.png)'
  prefs: []
  type: TYPE_IMG
- en: This plot tells us the overall view of how frequently repeat customers made
    purchases historically. As you can see from this plot, the majority of repeat
    customers made purchases every 20 to 50 days.
  prefs: []
  type: TYPE_NORMAL
- en: Predicting the 3 month CLV
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this section, we are going to build a model that predicts the 3 month customer
    value in R. We are going to first slice the data into chunks of 3 months and take
    the last 3 month data as the target for predictions and the rest as the features.
    We will first prepare our data for model building and then train a linear regression
    model for the 3 month customer value predictions.
  prefs: []
  type: TYPE_NORMAL
- en: Data preparation
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'In order to build a predictive model, we need to prepare our data first, so
    that we can feed in the relevant data into the model. Take a look at the following
    code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE32]'
  prefs: []
  type: TYPE_PRE
- en: 'As you can see from this code, we are using the `lubridate` package that is
    going to help us to handle data with dates more easily. Using the `round_date`
    function in the `lubridate` package, we first round `InvoiceDate` to the nearest
    quarter. Then, we group the data by `CustomerID` and the newly-created column, `Quarter`, to
    get the quarterly sales data for each customer. For each group of 3 month time
    window, we sum up all of the sales to get the total purchase amount and take the
    average of purchase amount, and the total number of purchases for the given period
    for each customer. This way we have aggregate data that has purchase information
    for each customer for every 3 months. The data in `dataDF` now looks like the
    following:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/8fbd0c64-17c6-4532-9e93-045b613adbc8.png)'
  prefs: []
  type: TYPE_IMG
- en: 'In order to make things simpler, let''s encode the `Quarter` column values
    to make them easier to read than the current date format. Take a look at the following
    code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE33]'
  prefs: []
  type: TYPE_PRE
- en: 'As you can see from this code, we are encoding the date values into `Q1`, `Q2`, `Q3`,
    and so forth, where the smaller number represents more recent dates. For example,
    the date `2012-01-01` is now encoded as `Q1` and the date `2011-10-01` is now
    encoded as `Q2`. The result looks as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/6c559f4b-73bd-49e1-82d2-f9c8e9ee2cca.png)'
  prefs: []
  type: TYPE_IMG
- en: 'We are now ready to build a sample set with features and target variables.
    As briefly mentioned before, we are going to use the last 3 months as the target
    variable and the rest as the features, meaning we are going to train a machine
    learning model that predicts the last 3 month customer value with the rest of
    the data. In order to train such a model, we need to transform this data into
    tabular data, where the rows represent the individual customers and the columns
    represent each feature. Take a look at the following code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE34]'
  prefs: []
  type: TYPE_PRE
- en: 'As you can see from this code, we are using the `reshape2` package to pivot
    the data. For example, using the `dcast` function in the `reshape2` package, we
    first transform the `SalesSum` data, where the row index represents each customer
    or `CustomerID`, the columns are each quarter, and the values are the total sales
    or purchase amount for the given customer and quarter. We repeat this process
    three times for `SalesSum`, `SalesAvg`, and `SalesCount` columns and merge the
    data in the end. Using the `merge` function, we can merge these DataFrames by
    the `CustomerID` index. Lastly, we encode the `null` or `NA` values with 0, by
    using the `is.na` function. The result looks like the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/90c833e6-f5c6-499c-bedb-e46a4836123f.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Now that we have built the features `DataFrame`, let''s build the target variables.
    Take a look at the following code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE35]'
  prefs: []
  type: TYPE_PRE
- en: 'As you can see from this code, we are taking the last 3 month period, `Q1` group,
    as the target variable. The target column will be `SalesSum`, as we want to predict
    the next 3 month customer value, which is the total purchase amount that a given
    customer is likely to make in the next 3 months. The result looks like the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/612c5361-629a-43f7-8728-81b3cf31d43c.png)'
  prefs: []
  type: TYPE_IMG
- en: 'There is only one thing left to build, which is a sample set for building machine
    learning models, combining features and response data together. Take a look at
    the following code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE36]'
  prefs: []
  type: TYPE_PRE
- en: 'As you can see here, we are simply joining the two `DataFrames` on `CustomerID` using
    the `merge` function. By having the `all.x=TRUE` flag, we take all records in
    the features data, even if there is no corresponding data in the response data.
    This is a case where the given customer did not make any purchases in the last
    3 months, so we encode them as 0\. The final sample set now looks as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/18c944a9-5933-4b2a-ab76-20467400ca57.png)'
  prefs: []
  type: TYPE_IMG
- en: With this data, we can now build a model that predicts the next 3 month customer
    value with historical purchase data.
  prefs: []
  type: TYPE_NORMAL
- en: Linear regression
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Similar to the previous chapter, we are going to split the sample set into
    train and test sets using the following code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE37]'
  prefs: []
  type: TYPE_PRE
- en: As you can see from this code, we are taking 80% of the sample set for training
    the model and the remaining 20% for testing and evaluating the model performance.
    In this section, we will be using a linear regression model. However, we recommend
    experimenting with other machine learning algorithms, such as **random forest** and **support
    vector machine (SVM)**. You can train a random forest model with the `randomForest`
    package and an SVM model with the `e1071` package. We highly recommend taking
    a look at their documentation on the usage.
  prefs: []
  type: TYPE_NORMAL
- en: 'In order to train a linear regression model with our dataset, you can use the
    following code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE38]'
  prefs: []
  type: TYPE_PRE
- en: This is as simple as it gets. You simply supply a formula, which is `CLV_3_Month
    ~ .` in our case, and the data to train with, which is the `train` variable in
    our case, to the `lm` function. This will instruct your machine to train a linear
    regression model with the given data.
  prefs: []
  type: TYPE_NORMAL
- en: 'Once a linear regression model is trained, there is some useful information
    you can find in the model object. You can use the following command to get detailed
    information about the model:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE39]'
  prefs: []
  type: TYPE_PRE
- en: 'The output looks as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/3553d6a1-54c6-4672-bc4b-27bb187be74a.png)'
  prefs: []
  type: TYPE_IMG
- en: As you can see from this output, you can easily find the coefficients of each
    feature and which features have negative or positive correlation with the target.
    For example, the previous 3 month period's aggregate purchase amount, `SalesSum.Q2`,
    has positive impacts on the next 3 month customer value. This means that the higher
    the previous 3 month period's total purchase amount is, the higher the next 3
    month purchase amount will be. On the other hand, the second and fourth most recent
    3 month period's aggregate purchase amounts, `SalesSum.Q3` and `SalesSum.Q5`,
    are negatively correlated with the next 3 month customer value. In other words,
    the more a customer made purchases two quarters or four quarters ago, the lower
    the value he or she will bring in the next 3 months. Looking at the coefficients
    is one way to gain insights on how the expected value will change, given certain
    features.
  prefs: []
  type: TYPE_NORMAL
- en: Using the 3 month customer value prediction output, you can custom-tailor your
    marketing strategies in different ways. Since you know the expected revenue or
    purchase amount from individual customers for the next 3 months, you can set a
    better informed budget for your marketing campaign. It should be set high enough
    to reach your target customers, but low enough to be below the expected 3 month
    customer value, so that you can have a positive ROI marketing campaign. On the
    other hand, you can also use these 3 month customer value prediction outputs to
    specifically target these high-value customers for the next 3 months. This can
    help you to create marketing campaigns with a higher ROI, as those high-value
    customers, predicted by this model, are likely to bring in more revenue than the
    others.
  prefs: []
  type: TYPE_NORMAL
- en: Evaluating regression model performance
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Now that we have a machine learning model that is trained to predict the 3
    month customer value, let''s discuss how to evaluate the performance of this model.
    As discussed previously, we are going to use R2, MAE, and a scatter plot of predicted
    versus actual to evaluate our model. We first need to get the prediction output
    from our model, like the following code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE40]'
  prefs: []
  type: TYPE_PRE
- en: 'We are going to use the `miscTools` package to compute the in-sample and out-of-sample
    R² values. Take a look at the following code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE41]'
  prefs: []
  type: TYPE_PRE
- en: 'The R² values, in our case, look like the following output:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/446db2ee-cf0e-4c18-bc01-bc97fdbb3225.png)'
  prefs: []
  type: TYPE_IMG
- en: Due to the randomness in splitting the sample set into train and test sets,
    your results might differ from these results. In our case, the in-sample R² was `0.4557` and
    the out-of-sample R² was `0.1235`. The rather big gap between the in-sample and
    out-of-sample R² values suggests that there is some overfitting happening, where
    the model performs significantly better in the train set and worse in the test
    set. In case of overfitting, you can try different combinations of features or
    use more samples for training.
  prefs: []
  type: TYPE_NORMAL
- en: 'Next, let''s take a look at the MAE for in-sample and out-of-sample predictions.
    Take a look at the following code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE42]'
  prefs: []
  type: TYPE_PRE
- en: 'As you can see from this code, we are using the `median` and `abs` functions
    to get the median of absolute errors in the in-sample and out-of-sample predictions.
    The result in our case looks like the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/8956d3d9-c5d5-4ca6-9f0d-964a9eb69a2f.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Lastly, let''s take a look at the scatter plot of predicted versus actual.
    You can use the following code for this scatter plot:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE43]'
  prefs: []
  type: TYPE_PRE
- en: 'The resulting plot looks as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/df0b8b7c-13e9-46b2-a9f0-ed8f14d5c050.png)'
  prefs: []
  type: TYPE_IMG
- en: As you can see from this plot, the *x*-values are the actual values and the
    *y*-values are the predicted values. As discussed earlier, the more the points
    are on the straight line, the better the predictions are. This is because points
    on the straight line suggest that the actual values and the predicted values are
    close to each other. Looking at this plot, the points do not seem to be spread around
    the straight line, which suggest that the predictions are rather poor. This is
    in line with the low out-of-sample *R²* value that we observed previously. Scatter
    plot of predicted versus actual values is a good way to visualize the model performance.
  prefs: []
  type: TYPE_NORMAL
- en: The full code for this R exercise can be found at the following repo: [https://github.com/yoonhwang/hands-on-data-science-for-marketing/blob/master/ch.9/R/CustomerLifetimeValue.R](https://github.com/yoonhwang/hands-on-data-science-for-marketing/blob/master/ch.9/R/CustomerLifetimeValue.R)
  prefs: []
  type: TYPE_NORMAL
- en: Summary
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this chapter, we have learned what CLV is and its importance and usage in
    marketing. Particularly for justifying the cost of customer acquisition, it is
    crucial to have a good understanding of how much value each new customer is going
    to bring to the company. We discussed how CLV calculations can help marketers
    to develop positive ROI marketing strategies. Then, we went through a hypothetical
    example to show how we can calculate the CLV, using average purchase amount, purchase
    frequency, and customer lifetime span. We also mentioned another approach of using
    machine learning and predictive models to estimate the CLV.
  prefs: []
  type: TYPE_NORMAL
- en: During the programming exercises, we have learned how to build regression models
    that predict the CLV over the course of a 3 month period. In Python, we used the `scikit-learn`
    package to build a `LinearRegression` model. In R, we used the built-in `lm` function to
    train a linear regression model with our data. For regression model evaluations,
    we have discussed four commonly used measures, MSE, MAE, R², and predicted versus
    actual scatter plot, and what each of these metrics measures and tells us about
    the performance of regression models. In our programming exercises, we discussed
    how to compute and visualize MAE, R², and predicted versus actual scatter plot
    in Python and R.
  prefs: []
  type: TYPE_NORMAL
- en: In the following chapter, we are going to cover customer segmentation. We will
    discuss how segmenting the customer base can help marketers better understand
    their customers and come up with more efficient marketing strategies.
  prefs: []
  type: TYPE_NORMAL
