- en: Preface
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The volume of data that enterprises acquire every day is increasing exponentially.
    It is now possible to store these vast amounts of information on low cost platforms
    such as Hadoop.
  prefs: []
  type: TYPE_NORMAL
- en: The conundrum these organizations now face is what to do with all this data
    and how to glean key insights from this data. Thus R comes into picture. R is
    a very amazing tool that makes it a snap to run advanced statistical models on
    data, translate the derived models into colorful graphs and visualizations, and
    do a lot more functions related to data science.
  prefs: []
  type: TYPE_NORMAL
- en: One key drawback of R, though, is that it is not very scalable. The core R engine
    can process and work on very limited amount of data. As Hadoop is very popular
    for Big Data processing, corresponding R with Hadoop for scalability is the next
    logical step.
  prefs: []
  type: TYPE_NORMAL
- en: This book is dedicated to R and Hadoop and the intricacies of how data analytics
    operations of R can be made scalable by using a platform as Hadoop.
  prefs: []
  type: TYPE_NORMAL
- en: With this agenda in mind, this book will cater to a wide audience including
    data scientists, statisticians, data architects, and engineers who are looking
    for solutions to process and analyze vast amounts of information using R and Hadoop.
  prefs: []
  type: TYPE_NORMAL
- en: Using R with Hadoop will provide an elastic data analytics platform that will
    scale depending on the size of the dataset to be analyzed. Experienced programmers
    can then write Map/Reduce modules in R and run it using Hadoop's parallel processing
    Map/Reduce mechanism to identify patterns in the dataset.
  prefs: []
  type: TYPE_NORMAL
- en: Introducing R
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: R is an open source software package to perform statistical analysis on data.
    R is a programming language used by data scientist statisticians and others who
    need to make statistical analysis of data and glean key insights from data using
    mechanisms, such as regression, clustering, classification, and text analysis.
    R is registered under **GNU** (**General Public License**). It was developed by
    Ross Ihaka and Robert Gentleman at the University of Auckland, New Zealand, which
    is currently handled by the R Development Core Team. It can be considered as a
    different implementation of S, developed by Johan Chambers at Bell Labs. There
    are some important differences, but a lot of the code written in S can be unaltered
    using the R interpreter engine.
  prefs: []
  type: TYPE_NORMAL
- en: 'R provides a wide variety of statistical, machine learning (linear and nonlinear
    modeling, classic statistical tests, time-series analysis, classification, clustering)
    and graphical techniques, and is highly extensible. R has various built-in as
    well as extended functions for statistical, machine learning, and visualization
    tasks such as:'
  prefs: []
  type: TYPE_NORMAL
- en: Data extraction
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Data cleaning
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Data loading
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Data transformation
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Statistical analysis
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Predictive modeling
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Data visualization
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: It is one of the most popular open source statistical analysis packages available
    on the market today. It is crossplatform, has a very wide community support, and
    a large and ever-growing user community who are adding new packages every day.
    With its growing list of packages, R can now connect with other data stores, such
    as MySQL, SQLite, MongoDB, and Hadoop for data storage activities.
  prefs: []
  type: TYPE_NORMAL
- en: Understanding features of R
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Let''s see different useful features of R:'
  prefs: []
  type: TYPE_NORMAL
- en: Effective programming language
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Relational database support
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Data analytics
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Data visualization
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Extension through the vast library of R packages
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Studying the popularity of R
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'The graph provided from KD suggests that R is the most popular language for
    data analysis and mining:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Studying the popularity of R](img/3282OS_Preface_01.jpg)'
  prefs: []
  type: TYPE_IMG
- en: The following graph provides details about the total number of R packages released
    by R users from 2005 to 2013\. This is how we explore R users. The growth was
    exponential in 2012 and it seems that 2013 is on track to beat that.
  prefs: []
  type: TYPE_NORMAL
- en: 'R allows performing Data analytics by various statistical and machine learning
    operations as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: Regression
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Classification
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Clustering
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Recommendation
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Text mining
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '![Studying the popularity of R](img/3282OS_Preface_02.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Introducing Big Data
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Big Data has to deal with large and complex datasets that can be structured,
    semi-structured, or unstructured and will typically not fit into memory to be
    processed. They have to be processed in place, which means that computation has
    to be done where the data resides for processing. When we talk to developers,
    the people actually building Big Data systems and applications, we get a better
    idea of what they mean about 3Vs. They typically would mention the 3Vs model of
    Big Data, which are velocity, volume, and variety.
  prefs: []
  type: TYPE_NORMAL
- en: Velocity refers to the low latency, real-time speed at which the analytics need
    to be applied. A typical example of this would be to perform analytics on a continuous
    stream of data originating from a social networking site or aggregation of disparate
    sources of data.
  prefs: []
  type: TYPE_NORMAL
- en: Volume refers to the size of the dataset. It may be in KB, MB, GB, TB, or PB
    based on the type of the application that generates or receives the data.
  prefs: []
  type: TYPE_NORMAL
- en: Variety refers to the various types of the data that can exist, for example,
    text, audio, video, and photos.
  prefs: []
  type: TYPE_NORMAL
- en: Big Data usually includes datasets with sizes. It is not possible for such systems
    to process this amount of data within the time frame mandated by the business.
    Big Data volumes are a constantly moving target, as of 2012 ranging from a few
    dozen terabytes to many petabytes of data in a single dataset. Faced with this
    seemingly insurmountable challenge, entirely new platforms are called Big Data
    platforms.
  prefs: []
  type: TYPE_NORMAL
- en: '![Introducing Big Data](img/3282OS_Preface_03.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Getting information about popular organizations that hold Big Data
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Some of the popular organizations that hold Big Data are as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Facebook: It has 40 PB of data and captures 100 TB/day'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Yahoo!: It has 60 PB of data'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Twitter: It captures 8 TB/day'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'EBay: It has 40 PB of data and captures 50 TB/day'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'How much data is considered as Big Data differs from company to company. Though
    true that one company''s Big Data is another''s small, there is something common:
    doesn''t fit in memory, nor disk, has rapid influx of data that needs to be processed
    and would benefit from distributed software stacks. For some companies, 10 TB
    of data would be considered Big Data and for others 1 PB would be Big Data. So
    only you can determine whether the data is really Big Data. It is sufficient to
    say that it would start in the low terabyte range.'
  prefs: []
  type: TYPE_NORMAL
- en: Also, a question well worth asking is, as you are not capturing and retaining
    enough of your data do you think you do not have a Big Data problem now? In some
    scenarios, companies literally discard data, because there wasn't a cost effective
    way to store and process it. With platforms as Hadoop, it is possible to start
    capturing and storing all that data.
  prefs: []
  type: TYPE_NORMAL
- en: Introducing Hadoop
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Apache Hadoop is an open source Java framework for processing and querying vast
    amounts of data on large clusters of commodity hardware. Hadoop is a top level
    Apache project, initiated and led by Yahoo! and Doug Cutting. It relies on an
    active community of contributors from all over the world for its success.
  prefs: []
  type: TYPE_NORMAL
- en: With a significant technology investment by Yahoo!, Apache Hadoop has become
    an enterprise-ready cloud computing technology. It is becoming the industry de
    facto framework for Big Data processing.
  prefs: []
  type: TYPE_NORMAL
- en: Hadoop changes the economics and the dynamics of large-scale computing. Its
    impact can be boiled down to four salient characteristics. Hadoop enables scalable,
    cost-effective, flexible, fault-tolerant solutions.
  prefs: []
  type: TYPE_NORMAL
- en: Exploring Hadoop features
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Apache Hadoop has two main features:'
  prefs: []
  type: TYPE_NORMAL
- en: HDFS (Hadoop Distributed File System)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: MapReduce
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Studying Hadoop components
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Hadoop includes an ecosystem of other products built over the core HDFS and
    MapReduce layer to enable various types of operations on the platform. A few popular
    Hadoop components are as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Mahout**: This is an extensive library of machine learning algorithms.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Pig**: Pig is a high-level language (such as PERL) to analyze large datasets
    with its own language syntax for expressing data analysis programs, coupled with
    infrastructure for evaluating these programs.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Hive**: Hive is a data warehouse system for Hadoop that facilitates easy
    data summarization, ad hoc queries, and the analysis of large datasets stored
    in HDFS. It has its own SQL-like query language called **Hive Query Language**
    (**HQL**), which is used to issue query commands to Hadoop.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**HBase**: **HBase** (**Hadoop Database**) is a distributed, column-oriented
    database. HBase uses HDFS for the underlying storage. It supports both batch style
    computations using MapReduce and atomic queries (random reads).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Sqoop**: Apache Sqoop is a tool designed for efficiently transferring bulk
    data between Hadoop and Structured Relational Databases. **Sqoop** is an abbreviation
    for (**SQ**)L to Had(**oop**).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**ZooKeper**: ZooKeeper is a centralized service to maintain configuration
    information, naming, providing distributed synchronization, and group services,
    which are very useful for a variety of distributed systems.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Ambari**: A web-based tool for provisioning, managing, and monitoring Apache
    Hadoop clusters, which includes support for Hadoop HDFS, Hadoop MapReduce, Hive,
    HCatalog, HBase, ZooKeeper, Oozie, Pig, and Sqoop.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Understanding the reason for using R and Hadoop together
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: I would also say that sometimes the data resides on the HDFS (in various formats).
    Since a lot of data analysts are very productive in R, it is natural to use R
    to compute with the data stored through Hadoop-related tools.
  prefs: []
  type: TYPE_NORMAL
- en: As mentioned earlier, the strengths of R lie in its ability to analyze data
    using a rich library of packages but fall short when it comes to working on very
    large datasets. The strength of Hadoop on the other hand is to store and process
    very large amounts of data in the TB and even PB range. Such vast datasets cannot
    be processed in memory as the RAM of each machine cannot hold such large datasets.
    The options would be to run analysis on limited chunks also known as sampling
    or to correspond the analytical power of R with the storage and processing power
    of Hadoop and you arrive at an ideal solution. Such solutions can also be achieved
    in the cloud using platforms such as Amazon EMR.
  prefs: []
  type: TYPE_NORMAL
- en: What this book covers
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: '[Chapter 1](ch01.html "Chapter 1. Getting Ready to Use R and Hadoop"), *Getting
    Ready to Use R and Hadoop*, gives an introduction as well as the process of installing
    R and Hadoop.'
  prefs: []
  type: TYPE_NORMAL
- en: '[Chapter 2](ch02.html "Chapter 2. Writing Hadoop MapReduce Programs"), *Writing
    Hadoop MapReduce Programs*, covers basics of Hadoop MapReduce and ways to execute
    MapReduce using Hadoop.'
  prefs: []
  type: TYPE_NORMAL
- en: '[Chapter 3](ch03.html "Chapter 3. Integrating R and Hadoop"), *Integrating
    R and Hadoop*, shows deployment and running of sample MapReduce programs for RHadoop
    and RHIPE by various data handling processes.'
  prefs: []
  type: TYPE_NORMAL
- en: '[Chapter 4](ch04.html "Chapter 4. Using Hadoop Streaming with R"), *Using Hadoop
    Streaming with R*, shows how to use Hadoop Streaming with R.'
  prefs: []
  type: TYPE_NORMAL
- en: '[Chapter 5](ch05.html "Chapter 5. Learning Data Analytics with R and Hadoop"),
    *Learning Data Analytics with R and Hadoop*, introduces the Data analytics project
    life cycle by demonstrating with real-world Data analytics problems.'
  prefs: []
  type: TYPE_NORMAL
- en: '[Chapter 6](ch06.html "Chapter 6. Understanding Big Data Analysis with Machine
    Learning"), *Understanding Big Data Analysis with Machine Learning*, covers performing
    Big Data analytics by machine learning techniques with RHadoop.'
  prefs: []
  type: TYPE_NORMAL
- en: '[Chapter 7](ch07.html "Chapter 7. Importing and Exporting Data from Various
    DBs"), *Importing and Exporting Data from Various DBs*, covers how to interface
    with popular relational databases to import and export data operations with R.'
  prefs: []
  type: TYPE_NORMAL
- en: '[Appendix](apa.html "Appendix A. References"), *References*, describes links
    to additional resources regarding the content of all the chapters being present.'
  prefs: []
  type: TYPE_NORMAL
- en: What you need for this book
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: As we are going to perform Big Data analytics with R and Hadoop, you should
    have basic knowledge of R and Hadoop and how to perform the practicals and you
    will need to have R and Hadoop installed and configured. It would be great if
    you already have a larger size data and problem definition that can be solved
    with data-driven technologies, such as R and Hadoop functions.
  prefs: []
  type: TYPE_NORMAL
- en: Who this book is for
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: This book is great for R developers who are looking for a way to perform Big
    Data analytics with Hadoop. They would like all the techniques of integrating
    R and Hadoop, how to write Hadoop MapReduce, and tutorials for developing and
    running Hadoop MapReduce within R. Also this book is aimed at those who know Hadoop
    and want to build some intelligent applications over Big Data with R packages.
    It would be helpful if readers have basic knowledge of R.
  prefs: []
  type: TYPE_NORMAL
- en: Conventions
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this book, you will find a number of styles of text that distinguish between
    different kinds of information. Here are some examples of these styles, and an
    explanation of their meaning.
  prefs: []
  type: TYPE_NORMAL
- en: 'Code words in text, database table names, folder names, filenames, file extensions,
    pathnames, dummy URLs, user input, and Twitter handles are shown as follows: "Preparing
    the `Map()` input."'
  prefs: []
  type: TYPE_NORMAL
- en: 'A block of code is set as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: 'Any command-line input or output is written as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: '**New terms** and **important words** are shown in bold. Words that you see
    on the screen, in menus or dialog boxes for example, appear in the text like this:
    "Open the **Password** tab. ".'
  prefs: []
  type: TYPE_NORMAL
- en: Note
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Warnings or important notes appear in a box like this.
  prefs: []
  type: TYPE_NORMAL
- en: Tip
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Tips and tricks appear like this.
  prefs: []
  type: TYPE_NORMAL
- en: Reader feedback
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Feedback from our readers is always welcome. Let us know what you think about
    this book—what you liked or may have disliked. Reader feedback is important for
    us to develop titles that you really get the most out of.
  prefs: []
  type: TYPE_NORMAL
- en: To send us general feedback, simply send an e-mail to `<[feedback@packtpub.com](mailto:feedback@packtpub.com)>`,
    and mention the book title via the subject of your message.
  prefs: []
  type: TYPE_NORMAL
- en: If there is a topic that you have expertise in and you are interested in either
    writing or contributing to a book, see our author guide on [www.packtpub.com/authors](http://www.packtpub.com/authors).
  prefs: []
  type: TYPE_NORMAL
- en: Customer support
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Now that you are the proud owner of a Packt book, we have a number of things
    to help you to get the most from your purchase.
  prefs: []
  type: TYPE_NORMAL
- en: Downloading the example code
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: You can download the example code files for all Packt books you have purchased
    from your account at [http://www.packtpub.com](http://www.packtpub.com). If you
    purchased this book elsewhere, you can visit [http://www.packtpub.com/support](http://www.packtpub.com/support)
    and register to have the files e-mailed directly to you.
  prefs: []
  type: TYPE_NORMAL
- en: Errata
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Although we have taken every care to ensure the accuracy of our content, mistakes
    do happen. If you find a mistake in one of our books—maybe a mistake in the text
    or the code—we would be grateful if you would report this to us. By doing so,
    you can save other readers from frustration and help us improve subsequent versions
    of this book. If you find any errata, please report them by visiting [http://www.packtpub.com/submit-errata](http://www.packtpub.com/submit-errata),
    selecting your book, clicking on the **errata** **submission** **form** link,
    and entering the details of your errata. Once your errata are verified, your submission
    will be accepted and the errata will be uploaded on our website, or added to any
    list of existing errata, under the Errata section of that title. Any existing
    errata can be viewed by selecting your title from [http://www.packtpub.com/support](http://www.packtpub.com/support).
  prefs: []
  type: TYPE_NORMAL
- en: Piracy
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Piracy of copyright material on the Internet is an ongoing problem across all
    media. At Packt, we take the protection of our copyright and licenses very seriously.
    If you come across any illegal copies of our works, in any form, on the Internet,
    please provide us with the location address or website name immediately so that
    we can pursue a remedy.
  prefs: []
  type: TYPE_NORMAL
- en: Please contact us at `<[copyright@packtpub.com](mailto:copyright@packtpub.com)>`
    with a link to the suspected pirated material.
  prefs: []
  type: TYPE_NORMAL
- en: We appreciate your help in protecting our authors, and our ability to bring
    you valuable content.
  prefs: []
  type: TYPE_NORMAL
- en: Questions
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: You can contact us at `<[questions@packtpub.com](mailto:questions@packtpub.com)>`
    if you are having a problem with any aspect of the book, and we will do our best
    to address it.
  prefs: []
  type: TYPE_NORMAL
