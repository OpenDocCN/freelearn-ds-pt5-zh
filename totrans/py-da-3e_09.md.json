["```py\n# import pandas\nimport pandas as pd\n\n# Read the data using csv\ndata=pd.read_csv('employee.csv')\n```", "```py\n# See initial 5 records\ndata.head()\n```", "```py\n# See last 5 records\ndata.tail()\n```", "```py\n# Print list of columns in the data\nprint(data.columns)\n```", "```py\nIndex(['name', 'age', 'income', 'gender', 'department', 'grade',\n 'performance_score'], dtype='object')\n```", "```py\n# Print the shape of a DataFrame\nprint(data.shape)\n```", "```py\n(9, 7)\n```", "```py\n# Check the information of DataFrame\ndata.info()\n```", "```py\n# Check the descriptive statistics\ndata.describe()\n```", "```py\n# Filter columns\ndata.filter(['name', 'department'])\n```", "```py\n# Filter column \"name\"\ndata['name']\n\n0       Allen Smith\n1           S Kumar\n2       Jack Morgan\n3         Ying Chin\n4     Dheeraj Patel\n5     Satyam Sharma\n6      James Authur\n7        Josh Wills\n8          Leo Duck\nName: name, dtype: object\n```", "```py\n# Filter column \"name\"\ndata[['name']]\n```", "```py\n# Filter two columns: name and department\ndata[['name','department']]\n```", "```py\n# Select rows for the specific index\ndata.filter([0,1,2],axis=0)\n```", "```py\n# Filter data using slicing\ndata[2:5]\n```", "```py\n# Filter data for specific value\ndata[data.department=='Sales']\n```", "```py\n# Select data for multiple values\ndata[data.department.isin(['Sales','Finance'])]\n```", "```py\n# Filter employee who has more than 700 performance score\ndata[(data.performance_score >=700)]\n```", "```py\n# Filter employee who has more than 500 and less than 700 performance score\ndata[(data.performance_score >=500) & (data.performance_score < 700)]\n```", "```py\n# Filter employee who has performance score of less than 500\ndata.query('performance_score<500')\n```", "```py\n# Drop missing value rows using dropna() function\n# Read the data\n\ndata=pd.read_csv('employee.csv')\ndata=data.dropna()\ndata\n```", "```py\n# Read the data\ndata=pd.read_csv('employee.csv')\n\n# Fill all the missing values in the age column with mean of the age column\ndata['age']=data.age.fillna(data.age.mean())\ndata\n```", "```py\n# Fill all the missing values in the income column with a median of the income column\ndata['income']=data.income.fillna(data.income.median())\ndata\n```", "```py\n# Fill all the missing values in the gender column(category column) with the mode of the gender column\ndata['gender']=data['gender'].fillna(data['gender'].mode()[0])\ndata\n```", "```py\n# Dropping the outliers using Standard Deviation\n# Read the data\ndata=pd.read_csv('employee.csv')\n\n# Dropping the outliers using Standard Deviation\nupper_limit= data['performance_score'].mean () + 3 * data['performance_score'].std ()\nlower_limit = data['performance_score'].mean () - 3 * data['performance_score'].std ()\ndata = data[(data['performance_score'] < upper_limit) & (data['performance_score'] > lower_limit)]\ndata\n```", "```py\n# Read the data\ndata=pd.read_csv('employee.csv')\n\n# Drop the outlier observations using Percentiles\nupper_limit = data['performance_score'].quantile(.99)\nlower_limit = data['performance_score'].quantile(.01)\ndata = data[(data['performance_score'] < upper_limit) & (data['performance_score'] > lower_limit)]\ndata\n```", "```py\n# Read the data\ndata=pd.read_csv('employee.csv')\n# Dummy encoding\nencoded_data = pd.get_dummies(data['gender'])\n\n# Join the encoded _data with original dataframe\ndata = data.join(encoded_data)\n\n# Check the top-5 records of the dataframe\ndata.head()\n```", "```py\n# Import one hot encoder\nfrom sklearn.preprocessing import OneHotEncoder\n\n# Initialize the one-hot encoder object\nonehotencoder = OneHotEncoder()\n\n# Fill all the missing values in income column(category column) with mode of age column\ndata['gender']=data['gender'].fillna(data['gender'].mode()[0])\n\n# Fit and transforms the gender column\nonehotencoder.fit_transform(data[['gender']]).toarray()\n```", "```py\narray([[1., 0.],\n       [1., 0.],\n       [0., 1.],\n       [1., 0.],\n       [1., 0.],\n       [1., 0.],\n       [1., 0.],\n       [1., 0.],\n       [0., 1.]])\n```", "```py\n# Import pandas\nimport pandas as pd\n\n# Read the data\ndata=pd.read_csv('employee.csv')\n\n# Import LabelEncoder\nfrom sklearn.preprocessing import LabelEncoder\n\n# Instantiate the Label Encoder Object\nlabel_encoder = LabelEncoder()\n\n# Fit and transform the column\nencoded_data = label_encoder.fit_transform(data['department'])\n\n# Print the encoded\nprint(encoded_data)\n```", "```py\n[2 1 0 0 2 1 2 1 0 2]\n```", "```py\n# Perform inverse encoding\ninverse_encode=label_encoder.inverse_transform([0, 0, 1, 2])\n\n# Print inverse encode\nprint(inverse_encode)\n```", "```py\n['Finance' 'Finance' 'Operations' 'Sales']\n```", "```py\n# Import pandas and OrdinalEncoder\nimport pandas as pd\nfrom sklearn.preprocessing import OrdinalEncoder\n\n# Load the data\ndata=pd.read_csv('employee.csv')\n\n# Initialize OrdinalEncoder with order\norder_encoder=OrdinalEncoder(categories=['G0','G1','G2','G3','G4'])\n\n# fit and transform the grade\ndata['grade_encoded'] = label_encoder.fit_transform(data['grade'])\n\n# Check top-5 records of the dataframe\ndata.head()\n```", "```py\n# Import StandardScaler(or z-score normalization)\nfrom sklearn.preprocessing import StandardScaler\n\n# Initialize the StandardScaler\nscaler = StandardScaler()\n\n# To scale data\nscaler.fit(data['performance_score'].values.reshape(-1,1))\ndata['performance_std_scaler']=scaler.transform(data['performance_score'].values.reshape(-1,1))\ndata.head()\n```", "```py\n# Import MinMaxScaler\nfrom sklearn.preprocessing import MinMaxScaler\n\n# Initialise the MinMaxScaler\nscaler = MinMaxScaler()\n\n# To scale data\nscaler.fit(data['performance_score'].values.reshape(-1,1))\ndata['performance_minmax_scaler']=scaler.transform(data['performance_score'].values.reshape(-1,1))\ndata.head()\n```", "```py\n# Import RobustScaler\nfrom sklearn.preprocessing import RobustScaler\n\n# Initialise the RobustScaler\nscaler = RobustScaler()\n\n# To scale data\nscaler.fit(data['performance_score'].values.reshape(-1,1))\ndata['performance_robust_scaler']=scaler.transform(data['performance_score'].values.reshape(-1,1))\n\n# See initial 5 records\ndata.head()\n```", "```py\n# Read the data\ndata=pd.read_csv('employee.csv')\n\n# Create performance grade function\ndef performance_grade(score):\n    if score>=700:\n        return 'A'\n    elif score<700 and score >= 500:\n        return 'B'\n    else:\n        return 'C'\n\n# Apply performance grade function on whole DataFrame using apply() function.\ndata['performance_grade']=data.performance_score.apply(performance_grade)\n\n# See initial 5 records\ndata.head()\n```", "```py\n# Split the name column in first and last name\ndata['first_name']=data.name.str.split(\" \").map(lambda var: var[0])\ndata['last_name']=data.name.str.split(\" \").map(lambda var: var[1])\n\n# Check top-5 records\ndata.head()\n```"]