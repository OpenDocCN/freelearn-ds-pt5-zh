<html><head></head><body><div id="sbo-rt-content" class="calibre1"><section class="calibre2">

                            <header class="calibre2">
                    <h1 class="header-title">Database Progression to Database Regression</h1>
                </header>
            
            <article class="calibre2">
                
<p class="calibre4">In this chapter, we get started by offering a definition for (data) statistical regression, then move on to discussing regression concepts, and outlining how a developer might use the most common regression techniques for forecasting and prediction within a typical data development project.</p>
<p class="calibre4">In this chapter, we've organized information into the following areas:</p>
<ul class="calibre18">
<li class="calibre19">An introduction to statistical regression</li>
<li class="calibre19">Methods for identification of opportunities for using regression (in data projects)</li>
<li class="calibre19">R and statistical regression</li>
<li class="calibre19">A working example</li>
</ul>


            </article>

            
        </section>
    </div>



  
<div id="sbo-rt-content" class="calibre1"><section class="calibre2">

                            <header class="calibre2">
                    <h1 class="header-title">Introducing statistical regression</h1>
                </header>
            
            <article class="calibre2">
                
<p class="calibre4">As promised, let's get going in this chapter with a section that provides a clear explanation of what statistical regression is.</p>
<p class="calibre4">For starters, statistical regression is also routinely referred to as regression analysis and is a process for estimating the relationships among variables<strong class="calibre7">.</strong> This process encompasses numerous techniques for modeling and analyzing variables, focusing on the relationship between a dependent variable and one (or more) independent variables (or <strong class="calibre7">predictors</strong><strong class="calibre7">).</strong></p>
<p class="calibre4">So specifically, regression analysis is the work done to identify and understand how the (best representative) value of a dependent variable (a variable that <strong class="calibre7">depends</strong> on other factors) changes when any one of the independent variables (a variable that <strong class="calibre7">stands alone</strong> and isn't changed by the other variables) is changed while the other independent variables stay the same.</p>
<p class="calibre4">A simple example might be how the total dollars spent on marketing (an independent variable example) impacts the total sales dollars (a dependent variable example) over a period of time (is it really as simple as more marketing equates to higher sales?), or perhaps there is a correlation between the total marketing dollars spent (independent variable), discounting a products price (another independent variable), and the amount of sales (a dependent variable)?</p>
<div class="packt_infobox">Keep in mind this key point that regression analysis is used to understand which among the independent variables are related to the dependent variable(s), not just the relationship of these variables. Also, the inference of causal relationships (between the independent and dependent variables) is an important objective. However, this can lead to illusions or false relationships, so caution is recommended!</div>
<p class="calibre4">Overall, regression analysis can be thought of as estimating the conditional expectations of the value of the dependent variable, given the independent variables being observed, that is, endeavoring to predict the average value of the dependent variable when the independent variables are set to certain values. I call this the lever affect—meaning when one increases or decreases a value of one component, it directly affects the value at least one other (variable).</p>
<p class="calibre4">An alternate objective of the process of regression analysis is the establishment of location parameters or the quantile of a distribution. In other words, this idea is to determine values that may be a cutoff, dividing a range of a probability distribution values.</p>
<p class="calibre4">You'll find that regression analysis can be a great tool for prediction and forecasting (not just complex machine learning applications). We'll explore some real-world examples later, but for now, let's us look at some techniques for the process.</p>


            </article>

            
        </section>
    </div>



  
<div id="sbo-rt-content" class="calibre1"><section class="calibre2">

                            <header class="calibre2">
                    <h1 class="header-title">Techniques and approaches for regression</h1>
                </header>
            
            <article class="calibre2">
                
<p class="calibre4">You'll find that various techniques for carrying out regression analysis have been developed and accepted.</p>
<p class="calibre4">Some research may show the top techniques as the following:</p>
<ul class="calibre18">
<li class="calibre19">Linear</li>
<li class="calibre19">Logistic</li>
<li class="calibre19">Polynomial</li>
<li class="calibre19">Stepwise</li>
<li class="calibre19">Ridge</li>
<li class="calibre19">Lasso</li>
</ul>
<p class="calibre4">Here are a quick few words on each:</p>
<ul class="calibre18">
<li class="calibre19"><strong class="calibre3">Linear regression</strong>: Linear regression is the most basic type of regression and is commonly used for predictive analysis projects. In fact, when you are working with a single predictor (variable), we call it simple linear regression, and if there are multiple predictor variables, we call it multiple linear regression. Simply put, linear regression uses linear predictor functions whose values are estimated from the data in the model.</li>
<li class="calibre19"><strong class="calibre3">Logistic regression</strong>: Logistic regression is a regression model where the dependent variable is a categorical variable. This means that the variable only has two possible values, for example, pass/fail, win/lose, alive/dead, or healthy/sick. If the dependent variable has more than two possible values, one can use various modified logistic regression techniques, such as multinomial logistic regression, ordinal logistic regression, and so on.</li>
<li class="calibre19"><strong class="calibre3">Polynomial regression</strong>: When we speak of polynomial regression, the focus of this technique is on modeling the relationship between the independent variable and the dependent variable as an n<sup class="calibre31">th</sup> degree polynomial.
<ul class="calibre18">
<li class="calibre19">Polynomial regression is considered to be a special case of multiple linear regressions. The predictors resulting from the polynomial expansion of the baseline predictors are known as <strong class="calibre3">interactive features</strong>.</li>
</ul>
</li>
<li class="calibre19"><strong class="calibre3">Stepwise regression</strong>: Stepwise regression is a technique that uses some kind of automated procedure to continually execute a step of logic, that is, during each step, a variable is considered for addition to or subtraction from the set of independent variables based on some prespecified criterion.</li>
<li class="calibre19"><strong class="calibre3">Ridge regression</strong>: Often predictor variables are identified as being interrelated. When this occurs, the regression coefficient of any one variable depends on which other predictor variables are included in the model and which ones are left out. Ridge regression is a technique where a small bias factor is added to the selected variables in order to improve this situation. Therefore, ridge regression is actually considered a remedial measure to alleviate multicollinearity amongst predictor variables.</li>
<li class="calibre19"><strong class="calibre3">Lasso regression</strong>: <strong class="calibre3">Lasso</strong> (<strong class="calibre3">least absolute shrinkage selector operator</strong>) regression is a technique where both predictor variable selection and regularization are performed in order to improve the prediction accuracy and interpretability of the result it produces.</li>
</ul>


            </article>

            
        </section>
    </div>



  
<div id="sbo-rt-content" class="calibre1"><section class="calibre2">

                            <header class="calibre2">
                    <h1 class="header-title">Choosing your technique</h1>
                </header>
            
            <article class="calibre2">
                
<p class="calibre4">In addition to the aforementioned regression techniques, there are numerous others to consider with, most likely, more to come. With so many options, it's important to choose the technique that is right for your data and your project.</p>
<p class="calibre4"><span class="calibre14">Rather than selecting the right regression approach, it is more about selecting the most effective regression approach.</span></p>
<p class="calibre4"><span class="calibre14">Typically, you use the data to identify the regression approach you'll use. You start by establishing statistics or a profile for your data. With this effort, you need to identify and understand the importance of the different variables, their relationships, coefficient signs</span><strong class="calibre7">,</strong> <span class="calibre14">and their effect.</span></p>
<p class="calibre4"><span class="calibre14">Overall, here's some generally good advice for choosing the right regression approach from your project:</span></p>
<ol class="calibre25">
<li class="calibre27">Copy what others have done and had success with. Do the research. Incorporate the results of other projects into yours. Don't reinvent the wheel. Also, even if an observed approach doesn't quite fit as it was used, perhaps some simple adjustments would make it a good choice.</li>
<li class="calibre27">Keep your approach as simple as possible. Many studies show that simpler models generally produce better predictions. Start simple, and only make the model more complex as needed. The more complex you make your model, the more likely it is that you are tailoring the model to your dataset specifically, and generalizability suffers.</li>
</ol>
<ol start="3" class="calibre25">
<li class="calibre27">Check your work. As you evaluate methods, check the residual plots (more on this in the next section of this chapter) because they can help you avoid inadequate models and adjust your model for better results.</li>
<li class="calibre27">Use your subject matter expertise. No statistical method can understand the underlying process or subject area the way you do. Your knowledge is a crucial part and, most likely, the most reliable way of determining the best regression approach for your project.</li>
</ol>


            </article>

            
        </section>
    </div>



  
<div id="sbo-rt-content" class="calibre1"><section class="calibre2">

                            <header class="calibre2">
                    <h1 class="header-title">Does it fit?</h1>
                </header>
            
            <article class="calibre2">
                
<p class="calibre4">After selecting a model that you feel is appropriate for use with your data (also known as determining that the approach is the best fit), you need to validate your selection, that is, determine its fit.</p>
<p class="calibre4">A well-fitting regression model results in predicted values close to the observed data values.</p>
<p class="calibre4">The mean model (which uses the mean for every predicted value) would generally be used if there were no informative predictor variables. The fit of a proposed regression model should, therefore, be better than the fit of the mean model.</p>
<p class="calibre4">As a data scientist, you will need to scrutinize the coefficients of determination, measure the standard error of estimate, analyze the significance of regression parameters and confidence intervals (will talk more about these later in this chapter).</p>
<div class="packt_tip">Remember that the better the fit of a regression model, most likely the better the precision in, or just better, the results.</div>
<p class="calibre4">It has been proven that simple models produce more accurate results! Keep this always in mind when selecting an approach or technique, and even when the problem might be complex, it is not always obligatory to adopt a complex regression approach.</p>


            </article>

            
        </section>
    </div>



  
<div id="sbo-rt-content" class="calibre1"><section class="calibre2">

                            <header class="calibre2">
                    <h1 class="header-title">Identifying opportunities for statistical regression</h1>
                </header>
            
            <article class="calibre2">
                
<p class="calibre4">Typical statistical analysis efforts which often become official statistical projects, start out with determining an objective and then, ultimately, determining the right approach to meet that objective.</p>
<p class="calibre4">Popular data science opinion declares determining an objective as establishing the purpose of a statistical analysis effort, then splits the purpose into three areas:</p>
<ol class="calibre25">
<li class="calibre27">Summarizing data (also called building a data profile)</li>
<li class="calibre27">Exposing and exploring relationships between variables in the data</li>
<li class="calibre27">Testing the significance of differences (between variables or groups within the data)</li>
</ol>


            </article>

            
        </section>
    </div>



  
<div id="sbo-rt-content" class="calibre1"><section class="calibre2">

                            <header class="calibre2">
                    <h1 class="header-title">Summarizing data</h1>
                </header>
            
            <article class="calibre2">
                
<p class="calibre4">If your statistical objective is to summarize data, you generate descriptive statistics, such as mean, standard deviation, variances, and so on.</p>


            </article>

            
        </section>
    </div>



  
<div id="sbo-rt-content" class="calibre1"><section class="calibre2">

                            <header class="calibre2">
                    <h1 class="header-title">Exploring relationships</h1>
                </header>
            
            <article class="calibre2">
                
<p class="calibre4">If your statistical objective is to look for and learn about relationships in your data, you first examine your data for a form or, in other words, ask the question: does your data revolve around frequencies or measurements? From there, the number of predictor variables will dictate to you what regression (or other) approach you should use in your project.</p>


            </article>

            
        </section>
    </div>



  
<div id="sbo-rt-content" class="calibre1"><section class="calibre2">

                            <header class="calibre2">
                    <h1 class="header-title">Testing significance of differences</h1>
                </header>
            
            <article class="calibre2">
                
<p class="calibre4">If your statistical objective involves testing the differences (between groups) found in the data, then you start out by identifying both the groups as well as the number of those groups. Data analysis involve data with a single group (of interest) leverages (compares values to) a mean, while data with more than one group can use the number of groups to determine which predictive approach one should consider.</p>


            </article>

            
        </section>
    </div>



  
<div id="sbo-rt-content" class="calibre1"><section class="calibre2">

                            <header class="calibre2">
                    <h1 class="header-title">Project profitability</h1>
                </header>
            
            <article class="calibre2">
                
<p class="calibre4">As a real-world example, let's consider a consulting services organization that has data collected describing its project work over time. This organization may be contracted to lead technology and/or business-related projects of all sizes and effort levels. Each project has expenses and revenues. Some projects are profitable, and some are not. The firm is interested in identifying which variables (if any) are candidates for predicting how profitable a project will be, in other words, which variables (in particular) are significant predictors of the dependent variable (in this case profitability)?</p>
<p class="calibre4">Examining the data, we see a good list of both variables and measurements; some of which are listed as follows:</p>
<ul class="calibre18">
<li class="calibre19">Number of consultants assigned to the project <strong class="calibre3">full time</strong> (<strong class="calibre3">FT</strong>)</li>
<li class="calibre19">Number of consultants assigned to the project <strong class="calibre3">part-time</strong> (<strong class="calibre3">PT</strong>)</li>
<li class="calibre19">Number of sub-contractors assigned to the project (FT or PT)</li>
<li class="calibre19">Number of customer resources assigned to the project full time</li>
<li class="calibre19">Number of customer resources assigned to the project part-time</li>
<li class="calibre19">Years of experience with the projects core technology</li>
<li class="calibre19">Total project management hours</li>
<li class="calibre19">Total development hours</li>
<li class="calibre19">Hourly bill rate</li>
<li class="calibre19">Total hours invoiced</li>
<li class="calibre19">Number of technologies used in the project</li>
<li class="calibre19">Project style (Time and materials, not to exceed or staff augment) and so on</li>
</ul>
<p class="calibre4">Generally while speaking, when the data scientist uses regression analysis, he or she is hoping to answer the following three questions:</p>
<ol class="calibre25">
<li class="calibre27">Does a set of predictor variables do a good job in predicting an outcome variable? In our project profitability example, would the number of full-time consultants assigned to a project do a good job of predicting profitability?</li>
<li class="calibre27">Which variables (in particular) are significant predictors of the dependent variable? Again, in our project profitability example, can we identify a significant predictor as the number of full-time consultants assigned to the project or perhaps the total project management hours?</li>
</ol>
<ol start="3" class="calibre25">
<li class="calibre27">What is the regression equation (the estimated relationship or effect of some variables on others) that shows how the set of predictor variables can be used to predict the outcome? In our project profitability example, would the regression equation be this?</li>
</ol>
<div class="packt_figure"><img class="image-border35" src="Images/7b090962-687b-4437-b80c-0fa1298c4b01.png"/></div>
<p class="calibre4">Our project profitability example looks like it could be a reasonable candidate for regression analysis.</p>
<p class="calibre4">In this chapter<strong class="calibre7">'</strong>s next sections<strong class="calibre7">,</strong> we'll attempt to establish a profile for the project data and then use an appropriate regression technique to establish it. Then, examine variable relationships and, hopefully, predict project profitability based upon selected predictor variables.</p>


            </article>

            
        </section>
    </div>



  
<div id="sbo-rt-content" class="calibre1"><section class="calibre2">

                            <header class="calibre2">
                    <h1 class="header-title">R and statistical regression</h1>
                </header>
            
            <article class="calibre2">
                
<p class="calibre4">Before we jump right into our modeling, let's take a moment to validate the use of R as our statistical modeling tool.</p>
<p class="calibre4">R is an open-source statistical environment and a powerful programming language that continues to be one of the most popular choices for statistical modeling. Modeled after S and S-Plus, R has an ever-growing, widespread audience as is well maintained by the R core-development team (an international team of volunteer developers).</p>
<p class="calibre4">R and many related resources can easily be found online along with detailed directions for downloading the software, accompanying packages and other sources of documentation. In addition, there are a ton of specialized routines that have been written for R by people all over the world and made freely available as R packages.</p>
<p class="calibre4">Since R is a programming language, it brings the power of programming to your project, but it does require some expertise with the tool. Thankfully, it offers a <strong class="calibre7">graphical user interface</strong> (<strong class="calibre7">GUI</strong>) to make things easier and allow you to copy and paste from other sources and projects.</p>


            </article>

            
        </section>
    </div>



  
<div id="sbo-rt-content" class="calibre1"><section class="calibre2">

                            <header class="calibre2">
                    <h1 class="header-title">A working example</h1>
                </header>
            
            <article class="calibre2">
                
<p class="calibre4">Let's now get back to our real-world example of project profitability!</p>
<p class="calibre4">We know that our consulting service organizations project results data describes the results of all its project work over time. There are 100 projects (or observations) in our data and consists of two variables hours billed and profit. The first variable is self-explanatory: it's the total number of hours billed to the client for that project. The second is a US dollar amount that equates to the revenues collected from the client after subtracting all expenses (for the project).</p>
<p class="calibre4">We know that each project has both expenses and revenue, and some projects are profitable while others are not. In addition, even projects that are profitable vary greatly in their level of profitability. Again, the firm is interested in identifying which variables (if any) are candidates for predicting how profitable a project will be.</p>
<p class="calibre4">Let's get started with our statistical analysis!</p>


            </article>

            
        </section>
    </div>



  
<div id="sbo-rt-content" class="calibre1"><section class="calibre2">

                            <header class="calibre2">
                    <h1 class="header-title">Establishing the data profile</h1>
                </header>
            
            <article class="calibre2">
                
<p class="calibre4">Before attempting to use our project results data to build a regression model, one usually attempts to analyze the data, identifying the key variables. Most often, you would create various visualizations with your data (we walk through this next in this section) in an effort to understand the cause-and-effect relationships among variables or groups within the data.</p>
<p class="calibre4">In statistics, these tasks are commonly referred to as performing a graphical analysis and correlation study.</p>


            </article>

            
        </section>
    </div>



  
<div id="sbo-rt-content" class="calibre1"><section class="calibre2">

                            <header class="calibre2">
                    <h1 class="header-title">The graphical analysis</h1>
                </header>
            
            <article class="calibre2">
                
<p class="calibre4">In our statistical analysis example, we want to build a simple regression model that we can use to predict project profitability (profit) by establishing a statistically significant linear relationship with hours billed (to a client) (hours billed). Therefore, we can begin our graphical analysis by plotting this data in various ways.</p>
<p class="calibre4">Typically, for each of the independent variables (predictors), the following plots should be drawn to visualize the following behavior:</p>
<ul class="calibre18">
<li class="calibre19"><strong class="calibre3">Scatter plot</strong>: This is drawn to visualize the linear relationship between the predictor and the response.</li>
<li class="calibre19"><strong class="calibre3">Box plot</strong>: This is drawn to spot any outlier observations in the variable. Having outliers in a predictor can drastically affect the predictions as they can easily affect the direction/slope of the line of best fit.</li>
<li class="calibre19"><strong class="calibre3">Density plot</strong>: This is drawn to see the distribution of the predictor variable. Ideally, a close to a normal distribution (a bell-shaped curve), without being skewed to the left or right is preferred.</li>
</ul>
<p class="calibre4">Scatter plots can help visualize any linear relationships between the dependent (response) variable and independent (predictor) variables.</p>
<div class="packt_infobox">Ideally, if you are observing multiple predictor variables, a scatter plot should be drawn for each one of them against the response.</div>
<p class="calibre4">Following are the simple R commands that use the variables <kbd class="calibre22">HoursBilled</kbd> and <kbd class="calibre22">Profit</kbd> from our project results data to create our scatter plot visualization:</p>
<pre class="calibre29"># --- load our project results data 
 
MyData &lt;- read.csv(file="c:/Worker/HoursBilledProfit.csv", header=TRUE, sep=",") 
 
# --- build our scatter plot on the relationship between our 
# --- variables 
 
scatter.smooth(x=MyData$HoursBilled, y=MyData$Profit, main="Hours Billed vs. Profit")  # scatterplot </pre>
<p class="calibre4">The following graph is our generated scatterplot:</p>
<div class="packt_figure"><img class="alignnone18" src="Images/3ae6df40-ace7-4d00-b3e8-411078648653.png"/></div>
<p class="calibre4">The <strong class="calibre7">Hours Billed vs Profit</strong> scatter plot along with the smoothing line shown in the preceding diagram suggests an initially linearly increasing then decreasing relationship between the total hours billed to a project and the profit variables.</p>
<div class="packt_infobox">Note that one of the underlying assumptions in linear regression is that the relationship between the response and predictor variables is linear and additive, so this data initially looks like it fits.</div>
<p class="calibre4">Our next step is to look for any outliers in our data. Data points that land outside the 1.5 * interquartile-range (1.5 * IQR) are considered to be outliers, where IQR is calculated as the distance between the 25th percentile and 75th percentile values for that variable.</p>
<p class="calibre4">In a statistical analysis of data, a boxplot is commonly used for graphically depicting groups of numerical data through their quartiles. These visualizations may also have lines extending vertically from the boxes (some data scientists refer to these lines as whiskers), indicating variability outside the upper and lower quartiles. Boxplots are very good for the identification of outliers.</p>
<p class="calibre4">The following R commands are used to some generate boxplots:</p>
<pre class="calibre29"># --- load our project results data 
 
MyData &lt;- read.csv(file="c:/Worker/HoursBilledProfit.csv", header=TRUE, sep=",") 
 
par(mfrow=c(1, 2))  # divide graph area in 2 columns 
 
# --- box plot for hours billed 
 
boxplot(MyData$HoursBilled, main="Hours Billed", sub=paste("Outlier rows: ", boxplot.stats(MyData$HoursBilled)$out))   
 
# --- box plot for Profit 
 
boxplot(MyData$Profit, main="Profit", sub=paste("Outlier rows: ", boxplot.stats(MyData$Profit)$out))   </pre>
<p class="calibre4">The following are the outlier boxplots for the preceding R commands generated from our project results data:</p>
<div class="packt_figure"><img class="alignnone19" src="Images/8279ac06-1dc7-4895-bfb2-9baadc7b244f.png"/></div>
<p class="calibre4">You can notice the outlier identified in the variable profit (on the right side of the preceding figure). The <strong class="calibre7">Outlier rows: 3648270</strong> corresponds to a data point in our file:</p>
<div class="packt_figure"><img class="alignnone20" src="Images/47c233e9-b008-4d6f-b9db-dad210083490.png"/></div>
<p class="calibre4">Finally, a density plot can be created to see how close our response variables (<kbd class="calibre22">ProjectID</kbd>,<kbd class="calibre22">HoursBilled</kbd>, and <kbd class="calibre22">Profit</kbd>) may be to normality. To do this, we can use the following R commands:</p>
<pre class="calibre29"># --- load our project results data 
 
MyData &lt;- read.csv(file="c:/Worker/HoursBilledProfit.csv", header=TRUE, sep=",") 
library(e1071) 
 
# --- divide graph area in 2 columns 
 
 
par(mfrow=c(1, 2))   
 
# --- density plot for profit 
plot(density(MyData$Profit), main="Density Plot: Profit", ylab="Frequency", sub=paste("Skewness:", round(e1071::skewness(MyData$Profit), 2)))   
polygon(density(MyData$Profit), col="red") 
 
# --- density plot for hours billed 
 
plot(density(MyData$HoursBilled), main="Density Plot: Hours Billed", ylab="Frequency", sub=paste("Skewness:", round(e1071::skewness(MyData$HoursBilled), 2)))   
polygon(density(MyData$HoursBilled), col="red")</pre>
<p class="calibre4">Following are the density plots:</p>
<div class="packt_figure"><img class="alignnone21" src="Images/c2a2e669-27f7-45ee-a3d8-3264d1920d02.png"/></div>
<p class="calibre4">So, do we see a relevant relationship between hoursbilled to a project and how (if at all) profitable the project is?</p>
<p class="calibre4">One way for us to be sure is to establish a correlation between the variables. Correlation suggests the level of linear dependence between two variables that occur in pair, just like what we think we have with hoursbilled and (project) profit.</p>
<p class="calibre4">If the data scientist found that profit increases along with an increase in every project HoursBilled, then there would be a high positive correlation between the two variables, and, therefore, the correlation between them will be closer to 1. Conversely, the opposite is true for an inverse relationship, in which case, the correlation between the variables will be close to -1.</p>
<p class="calibre4">A value closer to 0 suggests a weak relationship between the variables. A low correlation (-0.2 &lt; x &lt; 0.2) probably suggests that much of variation of the response variable (Y) is unexplained by the predictor (X), in which case, we should probably look for better explanatory variables.</p>
<p class="calibre4">The R programming language again provides us with a way to easily accomplish this: the <kbd class="calibre22">cor</kbd> function, which will determine a correlation between our two variables:</p>
<div class="packt_figure"><img class="alignnone22" src="Images/3c0d81b4-2fa6-4396-a345-8be8d5ee00da.png"/></div>
<p class="calibre4">The given preceding output, we may determine that there really isn't any reason to believe that as the number of hours billed on a projected increase, so does the profitability. Given this information, we should look at some other possible predictor variables.</p>
<p class="calibre4">For the sake of time, (we want to get on with our regression model building) rather than starting over, we'll make an educated guess that perhaps the variable Total project management hours is a good predictor of project profitability. Let's try running the same cor function using this variable:</p>
<div class="packt_figure"><img class="alignnone23" src="Images/f62bcd6f-3e4d-4712-9f8a-f7944bca40ae.png"/></div>
<p class="calibre4">As the preceding calculated correlation indicates (generated again by the use of the R function <kbd class="calibre22">cor</kbd>), the variable <kbd class="calibre22">ProjectManagement</kbd> seems to have a higher positive correlation (than hours billed) to project profitability.</p>
<p class="calibre4">Typically, we would take the time to rebuild the visualizations we created earlier in this section using this data (such as the following scatterplot), but again, for the sake of time, we'll move ahead:</p>
<div class="packt_figure"><img class="alignnone24" src="Images/1253d970-0708-49e5-903f-7bcd3449255b.png"/></div>
<p class="calibre4">We can see (from our scatterplot: <strong class="calibre7">Profit Management vs. Profit</strong>) that this time, we have a smooth, linear regression of our data in that as the amount of project management time increases, so does the projects overall profitably!</p>
<p class="calibre4">Let's move on!</p>
<p class="calibre4">So now that we have established (what appears to be) a fine linear relationship with visualizations such as a scatter plot (and other examples in the previous section) and then by computing a positive correlation (using the R function <kbd class="calibre22">cor</kbd>), we can try to construct an actual linear regression model.</p>
<p class="calibre4">Once again, R provides us with a relevant function—<kbd class="calibre22">lm()</kbd>. The <kbd class="calibre22">lm()</kbd> function takes in two main arguments:</p>
<ul class="calibre18">
<li class="calibre19">Formula (an object of class formula)</li>
<li class="calibre19">Data (typically a <kbd class="calibre22">data.frame</kbd>)</li>
</ul>
<p class="calibre4">Following are the R commands we can use to generate an R regression model:</p>
<pre class="calibre29"># --- build linear regression model on all of our 
# --- project results data 
 
alinearMod &lt;- lm(ProjectManagement ~ Profit, data=MyData) 
print(alinearMod) </pre>
<p class="calibre4">Following are the results of building our model:</p>
<div class="packt_figure"><img class="alignnone25" src="Images/e778dae8-1493-43e0-a2ea-24d706665329.png"/></div>
<p class="calibre4">Using the preceding R commands to build a linear model, we have established the relationship between the predictor (Project Management hours) and response (the profitability of the project) in the form of a mathematical formula for Project Management (ProjectManagement) as a function of <kbd class="calibre22">Profit</kbd>.</p>
<p class="calibre4">We can use the coefficients from the preceding output (<kbd class="calibre22">Intercept: 6.180</kbd> and <kbd class="calibre22">Profit: 1.629</kbd>) to create the formula:</p>
<p class="cdpaligncenter"><em class="calibre21">projectmanagement = −6.180+ 1.629 * profit</em></p>
<p class="calibre4">With our linear model and formula, we can predict the profit value of a project if a corresponding Project Management (total hours) is known. Exciting!</p>
<div class="packt_infobox">Although we have established a means for prediction (of project profitability), keep in mind that before using any regression model, you have to ensure that it is statistically significant.</div>


            </article>

            
        </section>
    </div>



  
<div id="sbo-rt-content" class="calibre1"><section class="calibre2">

                            <header class="calibre2">
                    <h1 class="header-title">Predicting with our linear model</h1>
                </header>
            
            <article class="calibre2">
                
<p class="calibre4">We just created a linear regression model using R commands with all of our project results data. In the real-world, one would rather chunk the data using what is called the <strong class="calibre7">80:20 sample rule</strong>. This means that 80% of the data will be used for training the model, while the other 20% can be used for testing and validation.</p>
<p class="calibre4">Let's go through this process now.</p>


            </article>

            
        </section>
    </div>



  
<div id="sbo-rt-content" class="calibre1"><section class="calibre2">

                            <header class="calibre2">
                    <h1 class="header-title">Step 1: Chunking the data</h1>
                </header>
            
            <article class="calibre2">
                
<p class="calibre4">We can read our project results data in, then use the R sample function to create our 2 two chunks of data (as <kbd class="calibre22">trainingData</kbd> and <kbd class="calibre22">testData</kbd>), as shown in the following R commands as follows:</p>
<pre class="calibre29"># --- first load our project results data 
# --- from our CSV file into the object MyData 
 
MyData &lt;- read.csv(file="c:/Worker/ProjectManagementProfit.csv", header=TRUE, sep=",") 
 
# --- next we are setting the ""sample seed"" 
# --- to reproduce results of random sampling 
 
set.seed(100)   
trainingRowIndex &lt;- sample(1:nrow(MyData), 0.8*nrow(MyData))   
 
# --- create our ""chunk"" of  
# --- model training data 
 
trainingData &lt;- MyData [trainingRowIndex,] 
 
# --- create our ""chunk of  
# --- test data   
testData &lt;- MyData [-trainingRowIndex,]</pre>


            </article>

            
        </section>
    </div>



  
<div id="sbo-rt-content" class="calibre1"><section class="calibre2">

                            <header class="calibre2">
                    <h1 class="header-title">Step 2: Creating the model on the training data</h1>
                </header>
            
            <article class="calibre2">
                
<p class="calibre4">Like we did earlier in this chapter, we can use the R function lm to create our regression model with our<kbd class="calibre22">trainingData</kbd> chunk<strong class="calibre7">:</strong></p>
<pre class="calibre29"># --- Build the model on training data  
 
lmMod &lt;- lm(ProjectManagement ~ Profit, data=trainingData)  </pre>


            </article>

            
        </section>
    </div>



  
<div id="sbo-rt-content" class="calibre1"><section class="calibre2">

                            <header class="calibre2">
                    <h1 class="header-title">Step 3: Predicting the projected profit on test data</h1>
                </header>
            
            <article class="calibre2">
                
<p class="calibre4"><span class="calibre14">Then, we use the R function predict to create our project predictions, as shown in the following R commands:</span></p>
<pre class="calibre29"># --- predict project profitability  
 
ProfitPred &lt;- predict(lmMod, testData) 
   </pre>
<p class="calibre4">Following is the output generated by the preceding R commands:</p>
<div class="packt_figure"><img class="alignnone26" src="Images/26a88536-6059-40bb-b49c-5145504273df.png"/></div>


            </article>

            
        </section>
    </div>



  
<div id="sbo-rt-content" class="calibre1"><section class="calibre2">

                            <header class="calibre2">
                    <h1 class="header-title">Step 4: Reviewing the model</h1>
                </header>
            
            <article class="calibre2">
                
<p class="calibre4">Perhaps the final step in our process is to create a summation of the model and review it for statistical significance.</p>
<p class="calibre4">We can use the R function summary:</p>
<pre class="calibre29"># --- generate the summary of the model  
 
summary (lmMod)</pre>
<p class="calibre4">This generates the following output:</p>
<div class="packt_figure"><img class="alignnone27" src="Images/c0587526-64be-4b31-aa63-186f1581b4f3.png"/></div>
<p class="calibre4">From the preceding output generated, we are shown that our model predictor's <kbd class="calibre22">p</kbd> values are visually interpreted as significant, shown by the significance stars at the end of the row (outlined), so we know we have a statistically significant model.</p>


            </article>

            
        </section>
    </div>



  
<div id="sbo-rt-content" class="calibre1"><section class="calibre2">

                            <header class="calibre2">
                    <h1 class="header-title">Step 4: Accuracy and error</h1>
                </header>
            
            <article class="calibre2">
                
<p class="calibre4">A simple correlation between the actual values (the actual project profit totals) and the model's predicted (profit) values can be used to test the accuracy of our project profit predictions.</p>
<p class="calibre4">This is illustrated in the following R commands, as follows where we again utilize the R function <kbd class="calibre22">cor</kbd>:</p>
<div class="packt_figure"><img class="alignnone28" src="Images/b8097495-44fc-43f6-a297-f2a47755a60b.png"/></div>
<p class="calibre4">A high correlation accuracy implies that the actual and predicted values have similar directional movement, that is, when the actual values increase, the predicted also increase, and vice versa; or it is to assume that as the total Project Management hours on a project increase or decrease, the project's profitability increase or decrease in the same manner!</p>


            </article>

            
        </section>
    </div>



  
<div id="sbo-rt-content" class="calibre1"><section class="calibre2">

                            <header class="calibre2">
                    <h1 class="header-title">Summary</h1>
                </header>
            
            <article class="calibre2">
                
<p class="calibre4">In this chapter, we introduced a statistical regression, noted the most common regression approaches, and provided some advice on selecting the correction approach for a particular statistical project. In addition, we mentioned how to identify opportunities for using statistical regression and discussed data summarization, exploring relationships, and testing for significance of the difference.</p>
<p class="calibre4">Finally, we wrapped up with a working example of linear regression modeling for r predicting project profitability.</p>
<p class="calibre4">The next chapter will introduce the developer to the idea of statistical regularization for improving data models in an effort to help comprehend what statistical regularization is and why it is important as well as feel comfortable with various statistical regularization methods.</p>
<p class="calibre4"/>
<p class="calibre4"/>


            </article>

            
        </section>
    </div>



  </body></html>