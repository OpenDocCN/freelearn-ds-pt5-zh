["```py\njupyter notebook\n```", "```py\nimport numpy as np\nfrom sklearn.linear_model import LogisticRegression\n```", "```py\ninput_data = np.array([\n    [0, 0],\n    [0.25, 0.25],\n    [0.5, 0.5],\n   [1, 1],\n])\n\noutput_data = [\n    0,\n    0,\n    1,\n    1\n]\n```", "```py\nlogit_model = LogisticRegression()\nlogit_model.fit(input_data, output_data)\n```", "```py\nlogit_model.coef_    # output: array([[0.43001235, 0.43001235]])\nlogit_model.intercept_    # output: array([-0.18498028])\n```", "```py\npredicted_output = logit_model.predict(input_data)\n```", "```py\nimport matplotlib.pyplot as plt\n\nplt.scatter(\n    x=input_data[:,0], \n    y=input_data[:,1], \n    color=[('red' if x == 1 else 'blue') for x in output_data]\n)\nplt.xlabel('X')\nplt.ylabel('Y')\nplt.title('Actual')\nplt.grid()\nplt.show()\n```", "```py\n%matplotlib inline\n```", "```py\n# Input Data\ndata <- data.frame(\n  \"X\"=c(0, 0.25, 0.5, 1), \n  \"Y\"=c(0, 0.5, 0.5, 1), \n  \"output\"=c(0, 0, 1, 1)\n)\n```", "```py\n# Train logistic regression\nlogit.fit <- glm(\n  output ~ X + Y, \n  data = data, \n  family = binomial\n)\n```", "```py\n# Show Fitted Results\nsummary(logit.fit)\n```", "```py\n# Predict Class Probabilities\nlogit.probs <- predict(\n  logit.fit, \n  newdata=data, \n  type=\"response\"\n)\n\n# Predict Classes\nlogit.pred <- ifelse(logit.probs > 0.5, 1, 0)    \nlogit.pred    # output: 0 0 1 1\n```", "```py\ninstall.packages('ggplot2')\n```", "```py\n# Plotting Library\nlibrary(ggplot2)\n\n# Simple Scatterplot\nggplot(data, aes(x=X, y=Y, color=output)) +\n  geom_point(size=3, shape=19) +\n  ggtitle('Actual') +\n  theme(plot.title = element_text(hjust = 0.5))\n```", "```py\nggplot(data, aes(x=X, y=Y, color=logit.pred)) + \n  geom_point(size=3, shape=19) +\n  ggtitle('Predicted') +\n  theme(plot.title = element_text(hjust = 0.5))\n```"]