["```py\n    import Data.Map (Map)\n    import qualified Data.Map as Map\n    import Data.List (minimumBy, sort, transpose)\n    import Data.Ord (comparing)\n    ```", "```py\n    type Point = [Double] \n    ```", "```py\n    dist :: Point -> Point -> Double\n\n    dist a b = sqrt $ sum $ map (^2) $ zipWith (-) a b\n    ```", "```py\n    assign :: [Point] -> [Point] -> Map Point [Point]\n\n    assign centroids points = \n      Map.fromListWith (++) [(assignPoint p, [p]) | p<- points]\n\n      where assignPoint p = \n        minimumBy (comparing (dist p)) centroids\n    ```", "```py\n    relocate :: Map Point [Point] -> Map Point [Point]\n\n    relocate centroidsMap = \n      Map.foldWithKey insertCenter Map.empty centroidsMap\n      where insertCenter _ ps m = Map.insert (center ps) ps m\n            center [] = [0,0]\n            center ps = map average (transpose ps)\n            average xs = sum xs / fromIntegral (length xs)\n    ```", "```py\n    kmeans :: [Point] -> [Point] -> [Point]\n\n    kmeans centroids points = \n    if converged \n    then centroids \n    else kmeans (Map.keys newCentroidsMap) points\n\n    where converged = \n            all (< 0.00001) $ zipWith dist \n                 (sort centroids) (Map.keys newCentroidsMap)\n\n          newCentroidsMap = \n            relocate (assign centroids points)\n\n          equal a b = dist a b < 0.00001 \n    ```", "```py\n    main = do\n    let points = [ [0,0], [1,0], [0,1], [1,1]\n                 , [7,5], [9,6], [8,7] ]\n    let centroids = kmeans (take 2 points) points\n    print centroids \n    ```", "```py\n    $ runhaskell Main.hs\n\n    [[0.5,0.5],[8.0,6.0]]\n\n    ```", "```py\n    import Data.Map (Map, (!), delete)\n    import qualified Data.Map as Map\n    import Data.Ord (comparing)\n    import Data.List (sort, tails, transpose, minimumBy)\n    ```", "```py\n    type Point = [Double]\n    ```", "```py\n    center :: [Point] -> Point\n\n    center points = map average (transpose points)\n      where average xs = sum xs / fromIntegral (length xs)\n    ```", "```py\n    merge :: Map Point [Point] -> Map Point [Point]\n\n    merge m = \n            Map.insert (center [a,b]) ((m ! a) ++ (m ! b)) newM\n\n    where (a,b) = nearest (Map.keys m)\n\n                newM = Map.delete b (Map.delete a m)\n\n                equal a b = dist a b < 0.00001\n\n                dist a b = sqrt $ sum $ map (^2) $ zipWith (-) a b\n\n                nearest points = \n                      minimumBy (comparing (uncurry dist)) \n                      [(a, b) | (a : rest) <- tails points, b <- rest] \n    ```", "```py\n    run :: Int -> Map Point [Point] -> Map Point [Point]\n\n    run k m = if length (Map.keys m) == k \n              then m \n              else run k (merge m)\n    ```", "```py\n    initialize :: [Point] -> Map Point [Point]\n\n    initialize points = \n      foldl (\\m p -> Map.insert p [p] m) Map.empty points\n    ```", "```py\n    main = do\n          let points = [ [0,0], [1,0], [0,1], [1,1]\n                         , [7,5], [9,6], [8,7]]\n          let centroids = Map.keys $ run 2 (initialize points)\n          print centroids\n    ```", "```py\n    $ runhaskell Main.hs\n\n    [[0.5,0.5],[7.75,5.75]]\n\n    ```", "```py\n$ cabal install hierarchical-clustering\n\n```", "```py\n    import Data.Clustering.Hierarchical\n    ```", "```py\n    data Point = Point [Double] deriving Show\n    ```", "```py\n    dist :: Point -> Point -> Distance\n    dist (Point a) (Point b) = sqrt $ sum $ map (^2) $ \n                               zipWith (-) a b\n    ```", "```py\n    printCluster :: Dendrogram Point -> Double -> IO ()\n\n    printCluster clusters cut = do\n             let es = map elements $ clusters `cutAt` cut\n             mapM_ print es\n    ```", "```py\n    main = do\n            let points = \n    map Point [ [0,0], [1,0], [0,1], [1,1]\n              , [7,5], [9,6], [8,7] ]\n            let clusters = dendrogram SingleLinkage points dist\n            printCluster clusters 2.0\n    ```", "```py\n    [Point [0.0,1.0], Point [1.0,0.0], Point [0.0,0.0], Point [1.0,1.0]] \n    [Point [7.0,5.0]] \n    [Point [9.0,6.0], Point [8.0,7.0]]\n    ```", "```py\n$ cabal install statistics\n\n```", "```py\n    import Statistics.Sample (variance)\n    import Data.Vector.Unboxed (fromList)\n    ```", "```py\n    avgVar points centroids = avg [variance . fromList $\n      map (dist c) ps | (c, ps) <- Map.assocs m]\n      where m = assign centroids points\n               avg xs = (sum xs) / (fromIntegral (length xs)) \n    ```", "```py\n    main = do\n      let points = [ [0,0], [1,0], [0,1]\n                           , [20,0], [21,0], [20,1]\n                           , [40,5], [40,6], [40,8] ]\n    ```", "```py\n          let centroids = [ kmeans (take k points) points | \n                               k <- [1..length points] ]\n          let avgVars = map (avgVar points) centroids\n          print avgVars\n    ```", "```py\n    $ git clone https://github.com/BinRoot/lexeme-clustering\n\n    ```", "```py\n    $ cd lexeme-clustering/\n\n    ```", "```py\n    $ cabal install\n\n    ```", "```py\n    $ cat input.txt\n    mama\n    papa\n    sissy\n    bro\n    mother\n    father\n    grandfather\n    grandmother\n    uncle\n    mommy\n    daddy\n    ma\n    pa\n    mom\n    dad\n    sister\n    brother\n\n    ```", "```py\n    $ dist/build/lexeme-clustering/lexeme-clustering input.txt\n\n    ```", "```py\n    # Clustering\n    bro, brother\n    dad, daddy\n    grandfather, grandmother\n    father, ma, mama, mom, mommy, mother, pa, papa\n    sissy, sister\n    uncle\n\n    ```", "```py\ncabal install chatter\n\n```", "```py\n    import NLP.POS\n    import Data.Text (pack)\n    ```", "```py\n    main = do\n    tagger <- defaultTagger\n    ```", "```py\n    let text = pack \"The best jokes have no punchline.\"\n    print $ tag tagger text\n    ```", "```py\n    [[ (\"The\", Tag \"at\"), \n     (\"best\", Tag \"jjt\"), \n     (\"jokes\", Tag \"nns\"), \n     (\"have\", Tag \"hv\"), \n     (\"no\", Tag \"at\"), \n     (\"punchline\",Tag \"nn\"), \n     (\".\",Tag \".\") ]]\n\n    ```", "```py\n$ cabal install sequor --prefix=`pwd`\n\n```", "```py\n        $ tar –zxvf sequor-0.7.2.tar.gz\n\n        ```", "```py\n    $ cd sequor-0.7.2\n\n    ```", "```py\n    $ cat README.*\n\n    ```", "```py\n    $ cabal install –-prefix=`pwd`\n\n    ```", "```py\n    $ cat input.txt\n    On\n    Tuesday\n    Richard\n    Stallman\n    will\n    visit\n    Charlottesville\n    ,\n    Virginia\n    in\n    the\n    United \n    States\n\n    ```", "```py\n    $ bin/seminer en < input.txt > output.txt\n\n    ```", "```py\n    $ cat output.txt\n    O\n    B-DATE\n    B-PERSON\n    I-PERSON\n    O\n    O\n    B-GPE:CITY\n    O\n    B-GPE:STATE_PROVINCE\n    O\n    O\n    B-GPE:COUNTRY\n    I-GPE:COUNTRY\n\n    ```", "```py\n        $ ./bin/sequor train data/all.features data/train.conll \\\n        model --rate 0.1 --beam 10 --iter 5 --hash \\\n        --heldout data/devel.conll\n\n        ```", "```py\n    $ ./bin/sequor predict model < data/test.conll > \\\n    data/test.labels\n\n    ```", "```py\n    B-NP\n    I-NP\n    B-PP\n    B-NP\n    I-NP\n    O\n    B-VP\n    B-NP\n    B-VP\n    B-NP\n\n    ```", "```py\n$ cabal install csv\n\n```", "```py\n    import Data.List (nub, elemIndices)\n    import qualified Data.Map as M\n    import Data.Map (Map, (!))\n    import Data.List (transpose)\n    import Text.CSV\n    ```", "```py\n    type Class = String\n    type Feature = String\n    type Entropy = Double\n    type DataSet = [([String], Class)]\n    ```", "```py\n    main = do\n      rawCSV <- parseCSVFromFile \"input.csv\"\n      either handleError doWork rawCSV\n\n    handleError = error \"invalid file\"\n    ```", "```py\n    doWork csv = do\n      let removeInvalids = filter (\\x -> length x > 1)\n      let myData = map (\\x -> (init x, last x)) $ removeInvalids csv\n      print $ dtree \"root\" myData\n    ```", "```py\n    samples :: DataSet -> [[String]]\n    samples d = map fst d\n\n    classes :: DataSet -> [Class]\n    classes d = map snd d\n    ```", "```py\n    entropy :: (Eq a) => [a] -> Entropy\n\n    entropy xs = sum $ map (\\x -> prob x * info x) $ nub xs\n      where prob x = (length' (elemIndices x xs)) / (length' xs)\n            info x = negate $ logBase 2 (prob x)\n            length' xs = fromIntegral $ length xs\n    ```", "```py\n    splitAttr :: [(Feature, Class)] -> Map Feature [Class]\n\n    splitAttr fc = foldl (\\m (f,c) -> M.insertWith (++) f [c] m)\n                   M.empty fc\n    ```", "```py\n    splitEntropy :: Map Feature [Class] -> M.Map Feature Entropy\n\n    splitEntropy m = M.map entropy m\n    ```", "```py\n    informationGain :: [Class] -> [(Feature, Class)] -> Double\n\n    informationGain s a = entropy s - newInformation\n      where eMap = splitEntropy $ splitAttr a\n            m = splitAttr a\n            toDouble x = read x :: Double\n            ratio x y = (fromIntegral x) / (fromIntegral y)\n            sumE = M.map (\\x -> (fromIntegral.length) x / (fromIntegral.length) s) m\n            newInformation = M.foldWithKey (\\k a b -> b + a*(eMap!k)) \n              0 sumE\n    ```", "```py\n    highestInformationGain :: DataSet -> Int\n    highestInformationGain d = snd $ maximum $ \n      zip (map ((informationGain . classes) d) attrs) [0..]\n      where attrs = map (attr d) [0..s-1]\n            attr d n = map (\\(xs,x) -> (xs!!n,x)) d\n            s = (length . fst . head) d\n    ```", "```py\n    data DTree = DTree { feature :: String\n                       , children :: [DTree] } \n               | Node String String\n               deriving Show\n    ```", "```py\n    datatrees :: DataSet -> Map String DataSet\n    datatrees d = \n      foldl (\\m (x,n) -> M.insertWith (++) (x!!i) [((x `dropAt` i), fst (cs!!n))] m)\n        M.empty (zip (samples d) [0..])\n      where i = highestInformationGain d\n        dropAt xs i = let (a,b) = splitAt i xs in a ++ drop 1 b\n            cs = zip (classes d) [0..]\n    ```", "```py\n    allEqual :: Eq a => [a] -> Bool\n    allEqual [] = True\n    allEqual [x] = True\n    allEqual (x:xs) = x == (head xs) && allEqual xs\n    ```", "```py\n    dtree :: String -> DataSet -> DTree\n\n    dtree f d \n      | allEqual (classes d) = Node f $ head (classes d)\n      | otherwise = DTree f $ \n                M.foldWithKey (\\k a b -> b ++ [dtree k a] ) [] \n                (datatrees d)\n    ```", "```py\n    DTree { feature = \"root\"\n     , children = [ DTree { feature = \"Sunny\"\n     , children = [ Node \"Normal\" \"Yes\"\n     , Node \"High\" \"No\"\n     ]\n     , DTree { feature = \"Rain\"\n     , children = [ Node \"Weak\" \"Yes\"\n     , Node \"Strong\" \"No\" \n     ] \n     }\n     , Node \"Overcast\" \"Yes\" \n     ] \n     }\n\n    ```", "```py\n$ cabal install KdTree\n$ cabal install CSV\n$ cabal install iproute\n\n```", "```py\n    import Data.Trees.KdTree\n    import Data.IP (IPv4, fromIPv4)\n    import Text.CSV\n    import qualified Data.Map as M\n    import Data.Maybe (fromJust)\n    ```", "```py\n    ipToNum :: String -> Double\n\n    ipToNum str = fromIntegral $ sum $ \n      zipWith (\\a b -> a * 256^b) ns [0..]\n      where ns = reverse $ fromIPv4 (read str :: IPv4)\n    ```", "```py\n    parse :: [Record] -> [(Point3d, String)]\n\n    parse [] = []\n    parse xs = map pair (cleanList xs)\n      where pair [ip, t, c] = \n              (Point3d (ipToNum ip) (read t) 0.0, c)\n            cleanList = filter (\\x -> length x == 3)\n    ```", "```py\n    maxFreq :: [String] -> String\n\n    maxFreq xs = fst $ foldl myCompare (\"\", 0) freqs\n      where freqs = M.toList $ M.fromListWith (+) \n                                             [(c, 1) | c <- xs]\n            myCompare (oldS, oldV) (s,v) = if v > oldV\n                                           then (s, v)\n                                           else (oldS, oldV)\n    ```", "```py\n    test :: KdTree Point3d -> Int -> [(Point3d, String)] \n                           -> Point3d -> String\n\n    test kdtree k pairList p = maxFreq $ map classify neighbors\n      where neighbors = kNearestNeighbors kdtree k p\n            classify x = fromJust (lookup x pairList)\n    ```", "```py\n    main = do\n      rawCSV <- parseCSVFromFile \"input.csv\"\n      either handleError doWork rawCSV\n    ```", "```py\n    handleError = error \"Invalid CSV file\"\n    ```", "```py\n    doWork rawCSV = do\n      let ps = parse rawCSV\n      let kdtree = fromList (map fst ps)\n      let examples = [ [\"71.190.100.100\", \"2000\", \"?\"]\n                     , [\"216.239.33.1\", \"1\", \"?\"] ]\n      let examplePts = map fst $ parse examples\n      print $ map (test kdtree 2 ps) examplePts\n    ```", "```py\n    $ runhaskell Main.hs\n\n    [\"Human\", \"Bot\"]\n\n    ```", "```py\n$ cabal install easyplot\n\n```", "```py\n$ cat input.csv\n\n1,2\n2,3\n3,1\n4,5\n5,3\n6,1\n\n```", "```py\n    import Text.CSV\n    import Graphics.EasyPlot\n    ```", "```py\n    tupes :: [[String]] -> [(Double, Double)]\n\n    tupes records = [ (read x, read y) | [x, y] <- records ]\n    ```", "```py\n    main = do \n      result <- parseCSVFromFile \"input.csv\"\n    ```", "```py\n      case result of\n        Left err -> putStrLn \"Error reading CSV file\"\n        Right csv -> do \n          plot X11 $ Data2D [Title \"Plot\"] [] (tupes csv)\n            return ()\n    ```"]