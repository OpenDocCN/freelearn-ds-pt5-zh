<html><head></head><body>
        <section>

                            <header>
                    <h1 class="header-title">Computing Foundations – Introduction to Python</h1>
                </header>
            
            <article>
                
<p>This chapter will provide an introduction to Python for analytics. It is meant mainly for novice programmers or developers who are not familiar with Python. By the end of the chapter, you will have a basic familiarity with the features of the Python base language, which is integral for healthcare analytics and machine learning. You will also understand how to get started using <kbd>pandas</kbd> and <kbd>scikit-learn</kbd>, two important Python libraries for analytics.</p>
<p>If you would like to follow along using the Jupyter Notebook, we encourage you to refer to the directions in <a href="b15b2b73-d2bb-410f-ab55-5f0f1e91730e.xhtml" target="_blank">Chapter 1</a>, <em>Introduction to Healthcare Analytics</em>, to start a new Jupyter session. The notebook for this chapter is also available online at the book's official code repository.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Variables and types</h1>
                </header>
            
            <article>
                
<p>Basic variable types in Python consist of strings and numeric types. Let's look at both of these types in this section.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Strings</h1>
                </header>
            
            <article>
                
<p>In Python, a <strong>string</strong> is a variable type that stores text characters such as letters, numbers, special characters, and punctuation. In Python, we use single or double quotation marks to indicate that the variable is a string rather than a number:</p>
<pre>var = 'Hello, World!'<br/>print(var)</pre>
<p class="mce-root"/>
<p class="mce-root"/>
<p class="mce-root"/>
<p><span>Strings cannot be used for mathematical operations on numbers. But they can be used for other useful operations, as we see in the following example:</span></p>
<pre>string_1 = '1'<br/>string_2 = '2'<br/>string_sum = string_1 + string_2<br/>print(string_sum)</pre>
<p>The result of the preceding code is to print string <kbd>'12'</kbd>, not <kbd>'3'</kbd>. Instead of adding the two numbers, the <kbd>+</kbd> operator performs concatenation (appending the second string to the end of the first string) in Python when operating on two strings.</p>
<p>Other operators that act on strings include the <kbd>*</kbd> operator (for repeating strings <img class="fm-editor-equation" src="assets/14655201-6690-4b4c-ad90-85b3c37d6601.png" style="width:0.92em;height:1.00em;"/> number of times, for example, <kbd>string_1 * 3</kbd>) and the <kbd>&lt;</kbd> and <kbd>&gt;</kbd> operators (to compare the ASCII values of the strings).</p>
<p>To convert data from a numeric type to a string, we can use the <kbd>str()</kbd> method.</p>
<p>Because strings are sequences (of characters), we can index them and slice them (like we can do with other data containers, as you will see later). A slice is a contiguous section of a string. To index/slice them, we use integers enclosed in square brackets to indicate the character's position:</p>
<pre>test_string = 'Healthcare'<br/>print(test_string[0])</pre>
<p>The output is shown as follows:</p>
<pre>H</pre>
<p>To slice strings, we include the beginning and end positions, separated by a colon, in the square brackets. Note that the end position will include all the characters <em>up to but not including</em> the end position, as we see in the following example:</p>
<pre>print(test_string[0:6])</pre>
<p>The output is as follows:</p>
<pre>Health</pre>
<p>Earlier, we mentioned the <kbd>str()</kbd> method. There are dozens of other methods for strings. A full list of them is available in the online Python documentation at <a href="http://www.python.org">www.python.org</a>. Methods include those for case conversion, finding specific substrings, and stripping whitespace. We'll discuss one more method here<span>–</span>the <kbd>split()</kbd> method. The <kbd>split()</kbd> method acts on a string and takes a <kbd>separator</kbd> argument.</p>
<p class="mce-root"/>
<p>The output is a list of strings; each item in the list is a component of the original string, split by <kbd>separator</kbd>. This is very useful for parsing strings that are delimited by punctuation characters such as <kbd>,</kbd> or <kbd>;</kbd>. We will discuss lists in the next section. Here is an example of the <kbd>split()</kbd> method:</p>
<pre>test_split_string = 'Jones,Bill,49,Atlanta,GA,12345'<br/>output = test_split_string.split(',')<br/>print(output)</pre>
<p>The output is as follows:</p>
<pre>['Jones', 'Bill', '49', 'Atlanta', 'GA', '12345']</pre>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Numeric types</h1>
                </header>
            
            <article>
                
<p>The two numeric types in Python that are most useful for analytics are <strong>integers</strong> and <strong>floating-point</strong> numbers. To convert to these types, you can use the <kbd>int()</kbd> and <kbd>float()</kbd> functions, respectively. The most common operations on numbers are supported with the usual operators: <kbd>+</kbd>, <kbd>-</kbd>, <kbd>*</kbd>, <kbd>/</kbd>, <kbd>&lt;</kbd>, and <kbd>&gt;</kbd>. Modules containing special methods for numeric types that are particularly useful for analytics include <kbd>math</kbd> and <kbd>random</kbd>. More information on numeric types is available in the online Python documentation (see the link in the previous section).</p>
<p>Note that with some Python versions, dividing two integers using the / operator performs <strong>floor division</strong> (with the numbers after the decimal place omitted); for example, <kbd>10/4</kbd> would equal <kbd>2</kbd>, not <kbd>2.5</kbd>. This is a stealthy yet egregious error that can throw off numerical calculations. However, with the version of Python we are using in this book, we don't need to worry about this error.</p>
<p>The <strong>Boolean type</strong> is a special integer type that can be used to represent the <kbd>True</kbd> and <kbd>False</kbd> values. To convert an integer to a Boolean type, you can use the <kbd>bool()</kbd> function. A zero gets converted to <kbd>False</kbd>; any other integer would get converted to <kbd>True</kbd>. Boolean variables behave like 1 (True) and 0 (False), except that they return <kbd>True</kbd> and <kbd>False</kbd>, respectively, when converted to strings.</p>
<p class="mce-root"/>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Data structures and containers</h1>
                </header>
            
            <article>
                
<p>In the last section, we talked about variable types that store single values. Now we will move on to data structures that can hold multiple values. These data structures are lists, tuples, dictionaries, and sets. Lists and tuples are commonly referred to as sequences in Python. In this book, we will use the terms data structures and data containers interchangeably.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Lists</h1>
                </header>
            
            <article>
                
<p>Lists are a widely used data structure that can hold multiple values. Let's look at some features of lists:</p>
<ul>
<li>To make a list, we use square brackets, <kbd>[]</kbd>.<br/>
Example: <kbd>my_list = [1, 2, 3]</kbd><span>.</span></li>
<li>Lists can hold any combination of numeric types, strings, Boolean types, tuples, dictionaries, or even other lists.<br/>
Example: <kbd>my_diverse_list = [51, 'Health', True, [1, 2, 3]]</kbd>.</li>
<li>Lists, like strings, are sequences and support indexing and slicing.<br/>
For example, in the preceding example, <kbd>my_diverse_list[0]</kbd> would equal <kbd>51</kbd>. <kbd>my_diverse_list[0:2]</kbd> would equal <kbd>[51, 'Health']</kbd>. To access the <kbd>3</kbd> of the nested list, we can use <kbd>my_diverse_list[3][2]</kbd>.</li>
<li>Lists are <strong>mutable</strong> (unlike strings and tuples), meaning that we can change individual components using indices.<br/>
For example, if we entered the <kbd>my_diverse_list[2] = False</kbd> command, our new <kbd>my_diverse_list</kbd> would be equal to <kbd>[51, 'Health', False, [1, 2, 3]]</kbd> .</li>
</ul>
<p>Notable advantages of lists for analytics include their vast array of helper methods, such as <kbd>append()</kbd>, <kbd>extend()</kbd>, and <kbd>join()</kbd>, and their interchangeability with the <kbd>pandas</kbd> and <kbd>numpy</kbd> data structures.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Tuples</h1>
                </header>
            
            <article>
                
<p>Tuples are similar to lists. To make a tuple, we use parentheses, <kbd>()</kbd>. Example: <kbd>my_tuple = (1, 2, 3)</kbd>. The main difference between tuples and lists is that tuples are <strong>immutable</strong>, so we cannot change any components of a tuple. If we tried <kbd>my_tuple[0] = 4</kbd>, an error would be thrown. Because their values are immutable, tuples are useful for setting constant variables.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Dictionaries</h1>
                </header>
            
            <article>
                
<p>A <strong>dictionary</strong> is a common data structure in Python. It is used to store unidirectional mappings from keys to values. For example, if we wanted to create a dictionary that stored a list of patient names and their corresponding room numbers, we could use the following code:</p>
<pre>rooms = {<br/>    'Smith': '141-A',<br/>    'Davis': '142',<br/>    'Williams': '144',<br/>    'Johnson': '145-B'<br/>}</pre>
<p>Let's talk about the preceding code snippet in more detail:</p>
<ul>
<li>The names in the <kbd>rooms</kbd> dictionary are referred to as <strong>keys</strong>. The keys in a dictionary must be unique. To access them, we can use the <kbd>keys()</kbd> function, <kbd>rooms.keys()</kbd>.</li>
<li>The room numbers in the <kbd>rooms</kbd> dictionary are referred to as <strong>values</strong>. To access all of the values, we can use the <kbd>values()</kbd> function, <kbd>rooms.values()</kbd>. To access an individual value, we just supply the name of its key in square brackets. For example, <kbd>rooms['Smith']</kbd> will return <kbd>'141-A'</kbd>. For this reason, we say that a dictionary maps keys to their values.</li>
<li>To access a nested list of tuples that contains each key along with its corresponding value, we can use the <kbd>items()</kbd> function, <kbd>rooms.items()</kbd>.</li>
<li>Dictionaries don't have to just be strings; in fact, the values can be any data type/structure. The keys can be particular variables such as integers or strings. While the values are mutable, the keys are immutable.</li>
<li>Dictionaries have no intrinsic order, so indexing and slicing by number is not supported.</li>
</ul>
<p class="mce-root"/>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Sets</h1>
                </header>
            
            <article>
                
<p>Although in Python the set doesn't receive as much attention as its popular cousin the list, sets play an important role in analytics, so we include them here. To make a set, we use the built-in <kbd>set()</kbd> function. There are three things you need to know about sets:</p>
<ul>
<li>They are immutable</li>
<li>They are unordered</li>
<li>The elements of a set are unique</li>
</ul>
<p>Therefore, sets in Python are very similar to their mathematical counterparts if you are familiar with the basic set theory. The set methods also duplicate typical set operations and include <kbd>union()</kbd>, <kbd>intersection()</kbd>, <kbd>add()</kbd>, and <kbd>remove()</kbd>. These functions come in handy when wanting to perform typical set-like operations on data structures, such as lists or tuples, following conversions to sets.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Programming in Python – an illustrative example</h1>
                </header>
            
            <article>
                
<p>In the previous sections, we discussed variable types and data containers. There are many more aspects of Python programming, such as control flow with if/else statements, loops, and comprehensions; functions; and classes and object-oriented programming. Commonly, Python programs are packaged into <strong>modules</strong>, which are self-standing scripts that can be run from the command line to perform computing tasks.</p>
<p>Let's introduce some of these concepts in Python with a "module" of our own (you can use the Jupyter Notebook for this):</p>
<pre>from math import pow<br/><br/><br/>LB_TO_KG = 0.453592<br/>IN_TO_M = 0.0254<br/><br/><br/>class Patient:<br/>    def __init__(self, name, weight_lbs, height_in):<br/>        self.name = name<br/>        self.weight_lbs = weight_lbs<br/>        self.weight_kg = weight_lbs * LB_TO_KG<br/>        self.height_in = height_in<br/>        self.height_m = height_in * IN_TO_M<br/>        <br/>    def calculate_bmi(self):<br/>        return self.weight_kg / pow(self.height_m, 2)<br/>    <br/>    def get_height_m(self):<br/>        return self.height_m<br/>    <br/><br/>if __name__ == '__main__':<br/>    test_patients = [<br/>        Patient('John Smith', 160, 68),<br/>        Patient('Patty Johnson', 180, 73)<br/>    ]<br/>    heights = [patient.get_height_m() for patient in test_patients]<br/>    print(<br/>        "John's height: ", heights[0], '\n',<br/>        "Patty's height: ", heights[1], '\n',<br/>        "John's BMI: ", test_patients[0].calculate_bmi(), '\n',<br/>        "Patty's BMI: ", test_patients[1].calculate_bmi()<br/>    )</pre>
<p>When you run this code, you should see the following output:</p>
<pre>John's height:  1.7271999999999998 
 Patty's height:  1.8541999999999998 
 John's BMI:  24.327647271211504 
 Patty's BMI:  23.74787410486812</pre>
<p>The preceding code is a Python module that prints the height and <strong>body mass indices</strong> (<strong>BMIs</strong>) for two mock patients. Let's take a more detailed look at each element of this code:</p>
<ul>
<li>The first line of the code block is an <strong>import statement</strong>. This allows us to import functions and classes that have been written in other modules that are either distributed with Python, written as open source software, or written by ourselves. A <strong>module</strong> can simply be thought of as a file that contains Python functions, constants, and/or classes. It has a <kbd>.py</kbd> extension. To import a module in its entirety, we can simply use the <kbd>import</kbd> word followed by the module name, for example, <kbd>import math</kbd>. Notice we used the <kbd>from</kbd> keyword as well because we only want to import a specific function, the <kbd>pow()</kbd> function. This also saves us from the inconvenience of having to type <kbd>math.pow()</kbd> every time we want to raise something to a power.</li>
<li>The next two lines contain <strong>constants</strong> that we will use to perform unit conversions. Constants are usually indicated by capital letters.</li>
<li>Next, we define a <kbd>Patient</kbd> class that has a <strong>constructor</strong> and two <strong>methods</strong>. The constructor takes three arguments<span>–</span>the name, height, and weight<span>–</span>and sets three attributes of the specific <kbd>Patient</kbd> instance to equal those three values. It also converts the weight from pounds to kilograms and the height from inches to meters, and stores those values in two extra attributes.</li>
<li>The two methods are coded as <strong>functions</strong>, using the <kbd>def</kbd> keyword. <kbd>calculate_bmi()</kbd> returns the BMI of the patient, while <kbd>get_height()</kbd> simply returns the height in meters.</li>
<li>Next, we have a mini <kbd>if</kbd> statement. All that this <kbd>if</kbd> statement is saying is to run the subsequent code only if it is the main module invoked at the command line. Other <kbd>if</kbd> statements may have multiple <kbd>elif</kbd> clauses and can also include a final <kbd>else</kbd> clause.</li>
<li>Next, we create a list of two patients, John Smith and Patty Johnson, with their heights and weights as listed in the code.</li>
<li>The following line uses a list <strong>comprehension</strong> to create a list of heights of the two patients. Comprehensions are very popular in Python programming and can also be performed with dictionaries.</li>
<li>Finally, our <kbd>print</kbd> statement prints the four numbers as the output (the two heights and the two BMI values).</li>
</ul>
<div class="packt_infobox">Further references for the base Python programming language are given at the end of this chapter. You can also check out the online documentation at <a href="http://www.python.org">www.python.org</a>.</div>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Introduction to pandas</h1>
                </header>
            
            <article>
                
<p><span>Almost all of the features we've discussed so far are features of</span> <em>base</em> <span>Python; that is, no external packages or libraries were required. The truth of the matter is that the majority of the code we write in this book will pertain to one of several</span> <em>external</em> <span>Python packages commonly used for analytics.</span> The <strong>pandas</strong> library (<a href="http://pandas.pydata.org">http://pandas.pydata.org</a>) is an integral part of the later programming chapters. The functions of pandas for machine learning are threefold:</p>
<ul>
<li>Import data from flat files into your Python session</li>
<li>Wrangle, manipulate, format, and cleanse data using the pandas DataFrame and its library of functions</li>
<li>Export data from your Python session to flat files</li>
</ul>
<p class="mce-root"/>
<p>Let's review each of these functions in turn.</p>
<p>Flat files are popular methods of storing healthcare-related data (along with HL7 formats, which are not covered in this book). A <strong>flat file</strong> is a text file representation of data. Using flat files, data can be represented as rows and columns, similar to databases, except that punctuation or whitespace are used as column delimiters, while carriage returns are used as row delimiters. We will see an example flat file in <a href="d029d858-9c6e-4bf0-b793-87cdc4395e86.xhtml" target="_blank">Chapter 7</a>, <em>Making Predictive Models in Healthcare</em>.</p>
<p>pandas allows us to import data into a tabular Python data structure, called a <strong>DataFrame</strong>, from a variety of other Python structures and flat files, including Python dictionaries, pickle objects, <strong>comma-separated values</strong> (<strong>csv</strong>) files, <strong>fixed-width format</strong> (<strong>fwf</strong>) files, Microsoft Excel files, JSON files, HTML files, and even SQL database tables.</p>
<p><span>Once the data is in Python, there are additional functions that you can use to explore and transform the data. Need to perform a mathematical function on a column, such as finding its sum? Need to perform SQL-like operations, such as JOINs or adding columns (see <a href="46c83498-cb6e-45b4-ac39-6875a8d32400.xhtml" target="_blank">Chapter 3</a>, <em>Machine Learning Foundations</em>)? Need to filter rows by a condition? All of the functionality is there in pandas' API</span><span>. We will make good use of some of pandas' functionality i</span>n <a href="023c1d7e-f3f0-42e6-a2be-64bd5ba4ab80.xhtml" target="_blank">Chapter 6</a>, <em>Measuring Healthcare Quality</em> <span>and in</span> <a href="d029d858-9c6e-4bf0-b793-87cdc4395e86.xhtml" target="_blank">Chapter 7</a>, <em>Making Predictive Models in Healthcare</em><span>.</span></p>
<p>Finally, when we are done exploring, cleansing, and wrangling our data, if we can choose to export it out as most of the formats listed. Or we can convert it to a NumPy array and train machine learning models, as we will do later in this book.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">What is a pandas DataFrame?</h1>
                </header>
            
            <article>
                
<p>A <strong>pandas DataFrame</strong> can be thought of as a two-dimensional, matrix-like data structure that consists of rows and columns. A pandas DataFrame is analogous to a dataframe in R or a table in SQL. Advantages over traditional matrices and other Python data structures include the ability to have columns of different types in the same DataFrame, a wide array of predefined functions for easy data manipulation, and one-line interfaces that allow quick conversion to other file formats including databases, flat file formats, and NumPy arrays (for integration with scikit-learn's machine learning functionality). Therefore, <kbd>pandas</kbd> is indeed the glue that holds together many machine learning pipelines, from data importation to algorithm application.</p>
<p class="mce-root"/>
<p>The limitations of pandas include slower performance and lack of built-in parallel processing for pandas functionality. Therefore, if you are working with millions or billions of data points, <strong>Apache Spark</strong> (<a href="https://spark.apache.org/">https://spark.apache.org/</a>) may be a better option, since it has parallel processing built into its language.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Importing data</h1>
                </header>
            
            <article>
                
<p>In this section, we demonstrate how to load data into Python via dictionaries, flat files, and databases.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Importing data into pandas from Python data structures</h1>
                </header>
            
            <article>
                
<p>The first step in working with <kbd>pandas</kbd> DataFrames is to create one using the <kbd>pandas</kbd> constructor function, <kbd>DataFrame()</kbd>. The constructor takes many Python data structures as input. It also takes as input NumPy arrays and pandas <strong>Series</strong>, another type of one-dimensional <kbd>pandas</kbd> data structure that is similar to a list. Here we demonstrate how to convert a dictionary of lists into a DataFrame:</p>
<pre>import pandas as pd<br/>data = {<br/>    'col1': [1, 2, 3],<br/>    'col2': [4, 5, 6],<br/>    'col3': ['x', 'y', 'z']<br/>}<br/><br/>df = pd.DataFrame(data)<br/>print(df)</pre>
<p>The output is as follows:</p>
<pre>   col1  col2 col3
0     1     4    x
1     2     5    y
2     3     6    z</pre>
<p class="mce-root"/>
<p class="mce-root"/>
<p class="mce-root"/>
<p class="mceNonEditable"/>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Importing data into pandas from a flat file</h1>
                </header>
            
            <article>
                
<p>Because healthcare data can often be in flat file format, such as <kbd>.csv</kbd>  or <kbd>.fwf</kbd>, it is important to know of the <kbd>read_csv()</kbd> and <kbd>read_fwf()</kbd> functions that import data into <kbd>pandas</kbd> from these two formats, respectively. Both of the functions take as mandatory arguments the full path of the flat file, along with over a dozen additional optional arguments that specify options including the data types of the columns, the header rows, the columns to include in the DataFrame, and so on (a full listing of the function arguments is available online). It is often easiest to import all the columns as string types and convert the columns to other data types later on. In the following example, a DataFrame called <kbd>data</kbd> is created by using the <kbd>read_csv()</kbd> function to read in a flat <kbd>.csv</kbd> file that contains one header row (<kbd>row #0</kbd>):</p>
<pre>pt_data = pd.read_csv(data_full_path,header=0,dtype='str')</pre>
<p>Because fixed-width files have no explicit character separator, the <kbd>read_fwf()</kbd> function needs an additional argument, <kbd>widths</kbd>, which is a list of integers specifying the column widths for each column. The length of <kbd>widths</kbd> should match the number of columns in the file. As an alternative, the <kbd>colspecs</kbd> argument takes in a list of tuples specifying the starting points and endpoints of each column:</p>
<pre>pt_data = pd.read_fwf(source,widths=data_widths,header=None,dtype='str')</pre>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Importing data into pandas from a database</h1>
                </header>
            
            <article>
                
<p>The <kbd>pandas</kbd> library also has functions to support the import of tables directly from SQL databases. Functions that can accomplish this include <kbd>read_sql_query()</kbd> and <kbd>read_sql_table()</kbd>. Before using these functions, the connection to the database must be established so that it can be passed to the function. In the following example, a table from a SQLite database is read into a DataFrame using the <kbd>read_sql_query()</kbd> function:</p>
<pre class="mce-root">import sqlite3<br/><br/>conn = sqlite3.connect(pt_db_full_path)<br/>table_name = 'TABLE1'<br/>pt_data = pd.read_sql_query('SELECT * from ' + table_name + ';',conn) </pre>
<p class="mce-root"/>
<p class="mce-root"/>
<p class="mce-root"/>
<p class="mceNonEditable"/>
<p>If you wish to connect to a standard database, such as a MySQL database, the code would be similar, except for the connection statement, which would use the corresponding function for a MySQL database.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Common operations on DataFrames</h1>
                </header>
            
            <article>
                
<p>In this section, we'll go over DataFrame operations useful for performing analytics. For descriptions of additional operations, please refer to the official pandas documentation at <a href="https://pandas.pydata.org/">https://pandas.pydata.org/</a>.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Adding columns</h1>
                </header>
            
            <article>
                
<p>Adding columns is a common operation in analytics, whether adding new columns from scratch or transforming existing columns. Let's go over both types of operations here.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Adding blank or user-initialized columns</h1>
                </header>
            
            <article>
                
<p>To add a new column of a DataFrame, you can follow the name of the DataFrame with the name of the new column (enclosed in single quotes and square brackets) and set it equal to whatever value you like. To add a column of empty strings or integers, you can set the column equal to <kbd>""</kbd> or <kbd>numpy.nan</kbd>, respectively (the latter requires importing <kbd>numpy</kbd> beforehand). To add a column of zeros, set the column equal to <kbd>0</kbd>. The following examples illustrate these points:</p>
<pre>df['new_col1'] = ""<br/>df['new_col2'] = 0<br/>print(df)</pre>
<p>The output is as follows:</p>
<pre>   col1  col2 col3 new_col1  new_col2
0     1     4    x                  0
1     2     5    y                  0
2     3     6    z                  0</pre>
<p class="mce-root"/>
<p class="mce-root"/>
<p class="mce-root"/>
<p class="mceNonEditable"/>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Adding new columns by transforming existing columns</h1>
                </header>
            
            <article>
                
<p>In some cases, you might wish to add a new column that is a function of existing columns. In the following example, the new column, titled <kbd>example_new_column_3</kbd>, is added as a sum of the existing columns, <kbd>old_column_1</kbd> and <kbd>old_column_2</kbd>. The <kbd>axis=1</kbd> argument indicates that you wish to take the horizontal sum across the columns instead of the vertical sum of columns:</p>
<pre>df['new_col3'] = df[[<br/>    'col1','col2'<br/>]].sum(axis=1)<br/><br/>print(df)</pre>
<p>The output is as follows:</p>
<pre>   col1  col2 col3 new_col1  new_col2  new_col3
0     1     4    x                  0         5
1     2     5    y                  0         7
2     3     6    z                  0         9</pre>
<p><span>The following second example accomplishes a similar task using the pandas</span> <kbd>apply()</kbd> <span>function.</span> <kbd>apply()</kbd> <span>is a special function because it allows you to apply any function to columns in a DataFrame (including your own custom functions):</span></p>
<pre>old_column_list = ['col1','col2']<br/>df['new_col4'] = df[old_column_list].apply(sum, axis=1)<br/>print(df)</pre>
<p>The output is as follows:</p>
<pre>   col1  col2 col3 new_col1  new_col2  new_col3  new_col4
0     1     4    x                  0         5         5
1     2     5    y                  0         7         7
2     3     6    z                  0         9         9</pre>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Dropping columns</h1>
                </header>
            
            <article>
                
<p>To drop columns, you can use pandas' <kbd>drop()</kbd> function. It takes a single column as well as a list of columns, and in this example, additional optional arguments indicate which is the axis along which to drop and whether or not to drop columns in place:</p>
<pre>df.drop(['col1','col2'], axis=1, inplace=True)<br/>print(df)</pre>
<p class="mce-root"/>
<p class="mce-root"/>
<p class="mce-root"/>
<p class="mceNonEditable"/>
<p>The output is as follows:</p>
<pre>  col3 new_col1  new_col2  new_col3  new_col4
0    x                  0         5         5
1    y                  0         7         7
2    z                  0         9         9</pre>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Applying functions to multiple columns</h1>
                </header>
            
            <article>
                
<p>To apply a function over multiple columns in a DataFrame, the list of columns can be iterated over using a <kbd>for</kbd> loop. In the following example, a predefined list of columns is converted from the string type to the numeric type:</p>
<pre>df['new_col5'] = ['7', '8', '9']<br/>df['new_col6'] = ['10', '11', '12']<br/><br/>for str_col in ['new_col5','new_col6']:<br/>    df[[str_col]] = df[[str_col]].apply(pd.to_numeric)<br/>    <br/>print(df)</pre>
<p>Here is the output:</p>
<pre>  col3 new_col1  new_col2  new_col3  new_col4  new_col5  new_col6
0    x                  0         5         5         7        10
1    y                  0         7         7         8        11
2    z                  0         9         9         9        12</pre>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Combining DataFrames</h1>
                </header>
            
            <article>
                
<p>DataFrames can also be combined with each other, as long as they have the same number of entries along the combining axis. In this example, two DataFrames are concatenated vertically (for example, they contain the same number of columns, and their rows are stacked upon each other). DataFrames can also be concatenated horizontally (if they contain the same number of rows) by specifying the <kbd>axis</kbd> parameter. Note that the column names and row names should correspond to each other across the DataFrames; if they do not, new columns will be formed and NaN values will be inserted for any missing values.</p>
<p>First, we create a new DataFrame name, <kbd>df2</kbd>:</p>
<pre>df2 = pd.DataFrame({<br/>    'col3': ['a', 'b', 'c', 'd'],<br/>    'new_col1': '',<br/>    'new_col2': 0,<br/>    'new_col3': [11, 13, 15, 17],<br/>    'new_col4': [17, 19, 21, 23],<br/>    'new_col5': [7.5, 8.5, 9.5, 10.5],<br/>    'new_col6': [13, 14, 15, 16]<br/>});<br/>print(df2)</pre>
<p>The output is as follows:</p>
<pre>  col3 new_col1  new_col2  new_col3  new_col4  new_col5  new_col6
0    a                  0        11        17       7.5        13
1    b                  0        13        19       8.5        14
2    c                  0        15        21       9.5        15
3    d                  0        17        23      10.5        16</pre>
<p>Next, we perform the concatenation. We set the optional <kbd>ignore_index</kbd> argument equal to <kbd>True</kbd> to avoid duplicate row indices:</p>
<pre>df3 = pd.concat([df, df2] ignore_index = True)<br/>print(df3)</pre>
<p>The output is as follows:</p>
<pre>  col3 new_col1  new_col2  new_col3  new_col4  new_col5  new_col6
0    x                  0         5         5       7.0        10
1    y                  0         7         7       8.0        11
2    z                  0         9         9       9.0        12
3    a                  0        11        17       7.5        13
4    b                  0        13        19       8.5        14
5    c                  0        15        21       9.5        15
6    d                  0        17        23      10.5        16</pre>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Converting DataFrame columns to lists</h1>
                </header>
            
            <article>
                
<p>To extract the contents of a column into a list, you can use the <kbd>tolist()</kbd> function. After being converted to a list, the data can then be iterated over using <kbd>for</kbd> loops and comprehensions:</p>
<pre>my_list = df3['new_col3'].tolist()<br/>print(my_list)</pre>
<p>The output is as follows:</p>
<div class="cell code_cell rendered selected">
<div class="output_wrapper">
<div class="output">
<div class="output_area">
<div class="output_subarea output_text output_stream output_stdout">
<pre>[5, 7, 9, 11, 13, 15, 17]</pre></div>
</div>
</div>
</div>
</div>
<p class="mce-root"/>
<p class="mce-root"/>
<p class="mce-root"/>
<p class="mce-root"/>
<p class="mce-root"/>
<p class="mceNonEditable"/>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Getting and setting DataFrame values</h1>
                </header>
            
            <article>
                
<p>The <kbd>pandas</kbd> library offers two main methods for selectively getting and setting values in DataFrames: <kbd>loc</kbd> and <kbd>iloc</kbd>. The <kbd>loc</kbd> method is mainly for <strong>label-based indexing</strong> (for example, identifying rows/columns using their indices/column names, respectively), while the <kbd>iloc</kbd> method is primarily for <strong>integer-based indexing</strong> (for example, identifying rows/columns using their integer positions in the DataFrame). The specific labels/indices of the rows and columns you wish to access are provided following the name of the DataFrame using square brackets, with row labels/indices preceding column labels/indices and separated from them by a comma. Let's look at some examples.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Getting/setting values using label-based indexing with loc</h1>
                </header>
            
            <article>
                
<p>The <kbd>.loc</kbd> attribute of a DataFrame is used to select values using the labels of the entries. It can be used to retrieve single scalar values from a DataFrame (using singular string labels for both row and column), or multiple values from a DataFrame (using lists of row/column labels). Single and multiple indexing can also be used in combination to get multiple values from a single row or column. The following lines of code illustrate the retrieval of a single scalar value from the <kbd>df</kbd> DataFrame:</p>
<pre>value = df3.loc[0,'new_col5']<br/>print(value)</pre>
<p>The output will be <kbd>7.0</kbd>.</p>
<p>Single/multiple values can also be set using the <kbd>.loc</kbd> attribute and an equals sign:</p>
<pre>df3.loc[[2,3,4],['new_col4','new_col5']] = 1<br/>print(df3)</pre>
<p>The output is as follows:</p>
<pre>  col3 new_col1  new_col2  new_col3  new_col4  new_col5  new_col6
0    x                  0         5         5       7.0        10
1    y                  0         7         7       8.0        11
2    z                  0         9         1       1.0        12
3    a                  0        11         1       1.0        13
4    b                  0        13         1       1.0        14
5    c                  0        15        21       9.5        15
6    d                  0        17        23      10.5        16</pre>
<p class="mce-root"/>
<p class="mce-root"/>
<p class="mce-root"/>
<p class="mceNonEditable"/>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Getting/setting values using integer-based labeling with iloc</h1>
                </header>
            
            <article>
                
<p>The <kbd>.iloc</kbd> attribute works very similarly to the <kbd>.loc</kbd> attribute, except that it uses the integer positions of the rows and columns being accessed, not their labels. In the following example, the value in the 101st row (not the 100th row, since indexing starts at 0) and the 100th column is transferred to <kbd>scalar_value</kbd>:</p>
<pre>value2 = df3.iloc[0,5]<br/>print(value2)</pre>
<p>The output is <kbd>7.0</kbd>.</p>
<p>Note that, similarly to <kbd>.loc</kbd>, lists containing multiple values can be passed to the <kbd>.iloc</kbd> attribute to change multiple entries of a DataFrame at once.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Getting/setting multiple contiguous values using slicing</h1>
                </header>
            
            <article>
                
<p>Sometimes, the multiple values that we wish to get or set are coincidentally in neighboring (contiguous) columns. When this is the case, we can use <strong>slicing</strong> within the square brackets to select multiple values. With slicing, we specify the starting point and endpoint of the data that we wish to access. We can use slicing with both <kbd>.loc</kbd> and <kbd>.iloc</kbd>, although slicing using integers and <kbd>.iloc</kbd> is more common. The following lines of code illustrate slicing to retrieve part of a DataFrame (we can also assign elements using an equals sign). Note that slicing can also be used to access values in lists and tuples (as covered previously in the current chapter):</p>
<pre>partial_df3 = df3.loc[1:3,'new_col2':'new_col4']<br/>print(partial_df3)</pre>
<p>The output is as follows:</p>
<pre>   new_col2  new_col3  new_col4
1         0         7         7
2         0         9         1
3         0        11         1</pre>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Fast getting/setting of scalar values using at and iat</h1>
                </header>
            
            <article>
                
<p>If we are certain that we only wish to get/set single values in a DataFrame, we can use the <kbd>.at</kbd> and <kbd>.iat</kbd> attributes, along with singular labels/integers, respectively. Just remember, the <kbd>i</kbd> in <kbd>.iloc</kbd> and <kbd>.iat</kbd> stands for "integer":</p>
<pre>value3 = df3.iat[3,3]<br/>print(value3)</pre>
<p class="mce-root"/>
<p class="mce-root"/>
<p class="mce-root"/>
<p class="mceNonEditable"/>
<p>The output is <kbd>11</kbd>.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Other operations</h1>
                </header>
            
            <article>
                
<p>Two other common operations are filtering rows using a Boolean condition and sorting rows. Here we will review each of these operations.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Filtering rows using Boolean indexing</h1>
                </header>
            
            <article>
                
<p>So far, we've discussed using labels, integers, and slicing to select values in DataFrames. Sometimes, it is convenient to select certain rows that meet a certain condition in one of their statements. For example, if we wanted to restrict an analysis on people whose age is greater than or equal to 50 years.</p>
<p>pandas DataFrames support <strong>Boolean indexing</strong>, that is, indexing using a vector of Boolean values to indicate which values we wish to include, provided that the length of the Boolean vector is equal to the number of rows in the DataFrame. Because a conditional statement involving a DataFrame column yields exactly that, we can index DataFrames using such conditional statements. In the following example, the <kbd>df</kbd> DataFrame is filtered to include only rows in which the value of the <kbd>age</kbd> column is equal to or exceeds <kbd>50</kbd>:</p>
<pre class="mce-root">df3_filt = df3[df3['new_col3'] &gt; 10]<br/>print(df3_filt)</pre>
<p>The output is as follows:</p>
<pre>  col3 new_col1  new_col2  new_col3  new_col4  new_col5  new_col6
3    a                  0        11         1       1.0        13
4    b                  0        13         1       1.0        14
5    c                  0        15        21       9.5        15
6    d                  0        17        23      10.5        16</pre>
<p>Conditional statements can be chained together using logical operators such as <kbd>|</kbd> or <kbd>&amp;</kbd>.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Sorting rows</h1>
                </header>
            
            <article>
                
<p>If you wish to sort a DataFrame by the value of one of its columns, that can be done using the <kbd>sort_values()</kbd> function; simply specify the column name as the first parameter. <kbd>ascending</kbd> is an optional parameter that lets you specify the sorting direction:</p>
<pre>df3 = df3.sort_values('new_col4', ascending=True)<br/>print(df3)</pre>
<p class="mce-root"/>
<p class="mce-root"/>
<p class="mce-root"/>
<p class="mceNonEditable"/>
<p>The output is as follows:</p>
<pre>  col3 new_col1  new_col2  new_col3  new_col4  new_col5  new_col6
2    z                  0         9         1       1.0        12
3    a                  0        11         1       1.0        13
4    b                  0        13         1       1.0        14
0    x                  0         5         5       7.0        10
1    y                  0         7         7       8.0        11
5    c                  0        15        21       9.5        15
6    d                  0        17        23      10.5        16</pre>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">SQL-like operations</h1>
                </header>
            
            <article>
                
<p>For people who are used to working with heterogeneously typed tables in SQL, switching to similar analyses in Python may seem like a daunting task. Fortunately, there are a number of <kbd>pandas</kbd> functions that can be combined to yield results similar to those yielded by common SQL queries, using operations such as grouping and joining. There is even a subsection in the <kbd>pandas</kbd> documentation (<a href="https://pandas.pydata.org/pandas-docs/stable/comparison_with_sql.html">https://pandas.pydata.org/pandas-docs/stable/comparison_with_sql.html</a>) that describes how to perform SQL-like operations with <kbd>pandas</kbd> DataFrames. We provide two such examples in this section.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Getting aggregate row COUNTs</h1>
                </header>
            
            <article>
                
<p>Sometimes, you may wish to get a count or tally of the occurrences of particular values in a column. For example, you might have a healthcare dataset and you want to know how many times particular payment methods were used during patient visits. In SQL, you could write a query that uses a <kbd>GROUP BY</kbd> clause in conjunction with an aggregate function (in this case, <kbd>COUNT(*)</kbd>) to get a tally of the payment methods:</p>
<pre>SELECT payment, COUNT(*)<br/>FROM data<br/>GROUP BY payment;</pre>
<p>In <kbd>pandas</kbd>, the same result is accomplished by chaining together the <kbd>groupby()</kbd> and <kbd>size()</kbd> functions:</p>
<pre>tallies = df3.groupby('new_col4').size()<br/>print(tallies)</pre>
<p class="mce-root"/>
<p class="mce-root"/>
<p class="mce-root"/>
<p class="mceNonEditable"/>
<p>The output is as follows:</p>
<pre>new_col4
1     3
5     1
7     1
21    1
23    1
dtype: int64</pre>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Joining DataFrames</h1>
                </header>
            
            <article>
                
<p>In <a href="e1b89921-e75b-4b16-a567-8970a173db53.xhtml" target="_blank">Chapter 4</a>, <em>Computing Foundations – Databases</em>, we discussed merging data from two database tables using the <kbd>JOIN</kbd> operation. To use a JOIN operation, you need to specify the names of the two tables, along with the type of JOIN (left, right, outer, or inner) and the columns on which to join:</p>
<pre>SELECT *<br/>FROM left_table OUTER JOIN right_table<br/>ON left_table.index = right_table.index;</pre>
<p>In pandas, you can accomplish table joins using the <kbd>merge()</kbd> or <kbd>join()</kbd> functions. By default, the <kbd>join()</kbd> function joins data on the index of the tables; however, other columns can be used by specifying the <kbd>on</kbd> parameter. If column names are overlapping in the two tables being joined, you will need to specify a <kbd>rsuffix</kbd> or <kbd>lsuffix</kbd> argument that renames the columns so they no longer have identical names:</p>
<pre>df_join_df2 = df.join(df2, how='outer', rsuffix='r')<br/>print(df_join_df2)</pre>
<p>The output is as follows (note the <kbd>NaN</kbd> values in Row 3, a row that was not present in <kbd>df</kbd>):</p>
<pre>  col3 new_col1  new_col2  new_col3  new_col4  new_col5  new_col6 col3r  \
0    x                0.0       5.0       5.0       7.0      10.0     a   
1    y                0.0       7.0       7.0       8.0      11.0     b   
2    z                0.0       9.0       9.0       9.0      12.0     c   
3  NaN      NaN       NaN       NaN       NaN       NaN       NaN     d   

  new_col1r  new_col2r  new_col3r  new_col4r  new_col5r  new_col6r  
0                    0         11         17        7.5         13  
1                    0         13         19        8.5         14  
2                    0         15         21        9.5         15  
3                    0         17         23       10.5         16 </pre>
<p class="mce-root"/>
<p class="mce-root"/>
<p class="mce-root"/>
<p class="mce-root"/>
<p class="mce-root"/>
<p class="mce-root"/>
<p class="mce-root"/>
<p class="mceNonEditable"/>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Introduction to scikit-learn</h1>
                </header>
            
            <article>
                
<p>Entire books have been written on <strong>scikit-learn</strong> (<a href="http://scikit-learn.org/stable/">http://scikit-learn.org/stable/</a>). The scikit-learn library has numerous submodules. Only a few of these submodules will be used in this book (in <a href="d029d858-9c6e-4bf0-b793-87cdc4395e86.xhtml" target="_blank">Chapter 7</a>, <em>Making Predictive Models in Healthcare</em>). These include the <kbd>sklearn.linear_model</kbd> and <kbd>sklearn.ensemble</kbd> submodules, for example. H<span>ere we will give an overview of some of the more commonly used submodules.</span> For convenience, we have grouped the relevant modules into various segments of the data science pipeline discussed in <a href="b15b2b73-d2bb-410f-ab55-5f0f1e91730e.xhtml" target="_blank">Chapter 1</a>, <em>Introduction to Healthcare Analytics</em><strong>.</strong></p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Sample data</h1>
                </header>
            
            <article>
                
<p>scikit-learn includes several sample datasets in the <kbd>sklearn.datasets</kbd> submodule. At least two of these datasets, <kbd>sklearn.datasets.load_breast_cancer</kbd> and <kbd>sklearn.datasets.load_diabetes</kbd>, are healthcare-related. These datasets have been already preprocessed and are small in size, spanning only dozens of features and hundreds of patients. The data we will use in <a href="d029d858-9c6e-4bf0-b793-87cdc4395e86.xhtml" target="_blank">Chapter 7</a>, <em>Making Predictive Models in Healthcare</em> is much bigger and resembles the data you are likely to receive from modern healthcare organizations. These sample sklearn datasets, however, are useful for experimenting with scikit-learn functions.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Data preprocessing</h1>
                </header>
            
            <article>
                
<p>Data preprocessing functionality is present in the <kbd>sklearn.preprocessing</kbd> submodule, among others. Some of the relevant functions of this module are discussed in the following sections.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">One-hot encoding of categorical variables</h1>
                </header>
            
            <article>
                
<p>Almost every dataset has some categorical data contained in it. <strong>Categorical data</strong> is discrete data in which the value can take on a finite number of possible values (usually encoded as a "string"). Because Python's scikit-learn can handle only numeric data, before performing machine learning with scikit-learn, we must find alternative ways of encoding categorical variables.</p>
<p class="mce-root"/>
<p>With <strong>one-hot encoding</strong>, also known as a <strong>1-of-K encoding scheme</strong>, a single categorical variable having <em>k</em> possible values is converted into <em>k</em> different binary variables, each one is positive if and only if the column's value for that observation equaled the value it represents. In <a href="d029d858-9c6e-4bf0-b793-87cdc4395e86.xhtml" target="_blank">Chapter 7</a>, <em>Making Predictive Models in Healthcare</em>, we provide a detailed example of what one-hot encoding is and use a pandas function called <kbd>get_dummies()</kbd> to perform one-hot encoding on a real clinical dataset. scikit-learn also has a class used to perform one-hot encoding, however, it is the <kbd>OneHotEncoder</kbd> class in the <kbd>sklearn.preprocessing</kbd> module.</p>
<p>For instructions on how <kbd>OneHotEncoder</kbd> is used, you can visit the scikit-learn documentation: <a href="http://scikit-learn.org/stable/modules/preprocessing.html#encoding-categorical-features">http://scikit-learn.org/stable/modules/preprocessing.html#encoding-categorical-features</a>.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Scaling and centering</h1>
                </header>
            
            <article>
                
<p>For some machine learning algorithms, it is preferable to transform not only the categorical variables (using one-hot encoding, discussed previously) but also the continuous variables. Recall from <a href="b15b2b73-d2bb-410f-ab55-5f0f1e91730e.xhtml" target="_blank">Chapter 1</a>, <em>Introduction to Healthcare Analytics</em> that a continuous variable is numerical and can take on any rational value (although in many cases they are restricted to integers). A particularly common practice is to <strong>standardize</strong> each continuous variable so that the <em>mean of the variable is zero and the standard deviation is one</em>. For example, take the <kbd>AGE</kbd> variable: it typically ranges from 0 to about 100, with a mean of perhaps 40. Let's pretend that for a particular population, the mean of our <kbd>AGE</kbd> variable is 40 with a standard deviation of 20. If we were to center and rescale our <kbd>AGE</kbd> variable, a person whose age was 40 would be represented as zero in the transformed variable. A person who was 20 years old would be represented as -1, a person who was 60 years old would be represented as 1, a person who was 80 years old would be represented as 2, and a person who was 50 years old would be 0.5. This transformation prevents variables with larger ranges from being overrepresented in the machine learning algorithm.</p>
<p>scikit-learn has many built-in classes and functions for centering and scaling data, including <kbd>sklearn.preprocessing.StandardScaler()</kbd>, <kbd>sklearn.preprocessing.MinMaxScaler()</kbd>, and <kbd>sklearn.preprocessing.RobustScaler()</kbd>. These various tools are specialized for centering and scaling different types of continuous data, such as normally distributed variables, or variables that have many outliers.</p>
<p>For instructions on how the scaling classes are used, you can check out the scikit-learn documentation: <a href="http://scikit-learn.org/stable/modules/preprocessing.html#standardization-or-mean-removal-and-variance-scaling">http://scikit-learn.org/stable/modules/preprocessing.html#standardization-or-mean-removal-and-variance-scaling</a>.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Binarization</h1>
                </header>
            
            <article>
                
<p><strong>Binarization</strong> is yet another type of transformation in which continuous variables are transformed into binary variables. For example, if we had a continuous variable named <kbd>AGE,</kbd> we could binarize the variable around 50 years by thresholding ages 50 and above to have a value of one, and ages with values below 50 to have a value of zero. Binarizing is good to save time and memory when you have many variables; however, in practice, the raw continuous values usually perform better since they are more informative.</p>
<p>While binarization can also be performed in pandas using the code demonstrated earlier, scikit-learn comes with a <kbd>Binarizer</kbd> class that can also be used to binarize features. For instructions on using the <kbd>Binarizer</kbd> class, you can visit <a href="http://scikit-learn.org/stable/modules/preprocessing.html#binarization">http://scikit-learn.org/stable/modules/preprocessing.html#binarization</a>.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Imputation</h1>
                </header>
            
            <article>
                
<p>In <a href="b15b2b73-d2bb-410f-ab55-5f0f1e91730e.xhtml" target="_blank">Chapter 1</a>, <em>Introduction to Healthcare Analytics</em>, we mentioned the importance of handling missing data. <strong>Imputation</strong> is one strategy for dealing with missing values in which missing values are filled in with estimates that are derived based on the data that is present. In healthcare, two common types of imputation are <strong>zero imputation</strong>, in which missing data is taken to be zero (for example, if a particular diagnosis has a value of <kbd>NULL</kbd>, most likely that is because it is not present in the patient chart) and <strong>mean imputation</strong>, in which the missing data is taken to be the mean of the distribution of the present data (for example, if a patient has a missing age, we can impute it as 40). We demonstrated various imputation methods in <a href="e1b89921-e75b-4b16-a567-8970a173db53.xhtml" target="_blank">Chapter 4</a>, <em>Computing Foundations – Databases</em>, and we will write our own custom functions for performing imputation in <a href="d029d858-9c6e-4bf0-b793-87cdc4395e86.xhtml" target="_blank">Chapter 7</a>, <em>Making Predictive Models in Healthcare</em>.</p>
<p>Scikit-learn comes with an <kbd>Imputer</kbd> class for performing different types of imputation. You can see details on how it is used at <a href="http://scikit-learn.org/stable/modules/preprocessing.html#imputation-of-missing-values">http://scikit-learn.org/stable/modules/preprocessing.html#imputation-of-missing-values</a>.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Feature-selection</h1>
                </header>
            
            <article>
                
<p>In machine learning, there is often a misconception that the more data you have, the better off you are. This is usually true with observations (for example, the number of rows in the dataset). However, with features, more isn't always better. In some cases, the performance may be paradoxically better with fewer features, because multiple features with high correlation are biasing the predictions, or because there are more features present than the number of observations.</p>
<p class="mce-root"/>
<p class="mce-root"/>
<p class="mce-root"/>
<p class="mce-root"/>
<p class="mce-root"/>
<p class="mceNonEditable"/>
<p>In other cases, the performance may be the same or infinitesimally worse with, say, half the features, but the smaller number of features may be desirable for a number of reasons, including time considerations, memory availability, or ease of explanation and interpretation to other non-technical stakeholders. In any case, it is almost always a good idea to perform some feature selection on the data. Even if you don't wish to remove any features, performing feature selection and ranking the feature importance can give you great insight into your model and understanding its predictive behavior and performance.</p>
<p>There are a number of classes and functions in the <kbd>sklearn.feature_selection</kbd> module that are built for feature selection, and different sets of classes correspond to different methods of performing feature selection. For example, univariate feature selection involves measuring the statistical dependency between each predictor variable and the target variable, and this can be done using the <kbd>SelectKBest</kbd> or <kbd>SelectPercentile</kbd> classes, among others. The <kbd>VarianceThreshold</kbd> class removes features that have a low variance across observations, for example, those features that are almost always zero. And the <kbd>SelectFromModel</kbd> class prunes features that don't meet a certain strength requirement (in terms of either coefficient or feature importance) after the model has been fit.</p>
<p>For a full list of the feature selection classes in scikit-learn, you can visit <a href="http://scikit-learn.org/stable/modules/feature_selection.html#univariate-feature-selection">http://scikit-learn.org/stable/modules/feature_selection.html#univariate-feature-selection</a>.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Machine learning algorithms</h1>
                </header>
            
            <article>
                
<p>Machine learning algorithms provide a mathematical framework for making predictions for new observations. scikit-learn supports dozens of different ML algorithms that have different strengths and weaknesses. We will discuss some of these algorithms and their corresponding scikit-learn API functionality briefly here. We will use some of these algorithms in <a href="d029d858-9c6e-4bf0-b793-87cdc4395e86.xhtml" target="_blank">Chapter 7</a>, <em>Making Predictive Models in Healthcare</em>.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Generalized linear models</h1>
                </header>
            
            <article>
                
<p>As we discussed in <a href="46c83498-cb6e-45b4-ac39-6875a8d32400.xhtml" target="_blank">Chapter 3</a>, <em>Machine Learning Foundations</em>, a <strong>linear model</strong> can be thought of casually as a weighted combination of features (for example, a weighted sum) to predict a target value. The features are determined by the observations; the weights of each feature are determined by the model. Linear regression predicts a continuous variable, while logistic regression can be thought of as an extended form of linear regression in which the predicted target undergoes a <strong>logit transformation</strong> to be converted to a variable that has a range between zero and one. Such a transformation is useful for performing binary classification tasks such as when there are two possible outcomes.</p>
<p class="mce-root"/>
<p>In scikit-learn, these two algorithms are represented by the <kbd>sklearn.linear_model.LogisticRegression</kbd> and <kbd>sklearn.linear_model.LinearRegression</kbd> classes. We will demonstrate logistic regression in <a href="d029d858-9c6e-4bf0-b793-87cdc4395e86.xhtml" target="_blank">Chapter 7</a>, <em>Making Predictive Models in Healthcare</em>.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Ensemble methods</h1>
                </header>
            
            <article>
                
<p><strong>Ensemble methods</strong> involve making predictions using combinations of different ML models. For example, a <strong>random forest</strong> is a collection of decision tree classifiers that have been decorrelated from each other by choosing and using specific feature sets for each tree. Additionally, <strong>AdaBoost</strong> is an algorithm that fits many weak learners on the data to make effective predictions. These algorithms are supported by the <kbd>sklearn.ensemble</kbd> module.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Additional machine learning algorithms</h1>
                </header>
            
            <article>
                
<p>Some other popular machine learning algorithms include the Naive Bayes algorithm, k-nearest neighbors, neural networks, decision trees, and support vector machines. These are supported in scikit-learn by the <kbd>sklearn.naive_bayes</kbd>, <kbd>sklearn.neighbors</kbd>, <kbd>sklearn.neural_network</kbd>, <kbd>sklearn.tree</kbd>, and <kbd>sklearn.svm</kbd> modules, respectively. In <a href="d029d858-9c6e-4bf0-b793-87cdc4395e86.xhtml" target="_blank">Chapter 7</a>, <em>Making Predictive Models in Healthcare</em>, we will make neural network models on a clinical dataset.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Performance assessment</h1>
                </header>
            
            <article>
                
<p>Lastly, once we make our model using our desired algorithm, it is important to measure its performance. The <kbd>sklearn.metrics</kbd> module is useful for this. As discussed in <a href="46c83498-cb6e-45b4-ac39-6875a8d32400.xhtml" target="_blank">Chapter 3</a>, <em>Machine Learning Foundations</em>, the confusion matrix is particularly important for classification tasks, and it is supported by the <kbd>sklearn.metrics.confusion_matrix()</kbd> function. Determining the receiver operating characteristic (ROC) curve and calculating the <strong>area under the curve</strong> (<strong>AUC</strong>) can be accomplished using the <kbd>sklearn.metrics.roc_curve()</kbd> and <kbd>sklearn.metrics.roc_auc_score()</kbd> functions, respectively. Precision-recall curves are an alternative to the ROC curve that are important for imbalanced datasets, and they are supported by the <kbd>sklearn.metrics.precision_recall_curve()</kbd> function.</p>
<p class="mce-root"/>
<p class="mce-root"/>
<p class="mce-root"/>
<p class="mce-root"/>
<p class="mce-root"/>
<p class="mce-root"/>
<p class="mceNonEditable"/>
<p class="mceNonEditable"/>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Additional analytics libraries</h1>
                </header>
            
            <article>
                
<p>Here we mention three important packages that are frequently used for analytics: NumPy, SciPy, and matplotlib.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">NumPy and SciPy</h1>
                </header>
            
            <article>
                
<p><strong>NumPy</strong> (<a href="http://www.numpy.org/">www.numpy.org</a>) is Python's matrix library. Using <kbd>numpy.array()</kbd> and similar constructs, large matrices can be created and various mathematical operations (including matrix addition and multiplication) can be performed on them. NumPy also has many functions for manipulating the shapes of matrices. Another feature of NumPy is the presence of familiar mathematical functions such as <kbd>sin()</kbd>, <kbd>cos()</kbd>, and <kbd>exp()</kbd>.</p>
<p><strong>SciPy</strong> (<a href="http://www.scipy.org">www.scipy.org</a>) is a toolbox that contains many advanced mathematical modules. Its machine-learning-related subpackages include <kbd>cluster</kbd>, <kbd>stats</kbd>, <kbd>sparse</kbd>, and <kbd>optimize</kbd>. SciPy is an important package that enables scientific computing in Python.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">matplotlib</h1>
                </header>
            
            <article>
                
<p><strong>matplotlib</strong> (<a href="https://matplotlib.org">https://matplotlib.org</a>) is a popular Python 2-D plotting library. According to its website, one "<span>can generate plots, histograms, power spectra, bar charts, error charts, scatterplots, and so on, with just a few lines of code." Its plotting library comes with a myriad of options and features to enable a high degree of customization.</span></p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Summary</h1>
                </header>
            
            <article>
                
<p>In this chapter, we took a whirlwind tour of the base Python language, along with two Python libraries that are important for performing analytics: pandas, and scikit-learn. We have now completed the foundational chapters of this book.</p>
<p>In <a href="023c1d7e-f3f0-42e6-a2be-64bd5ba4ab80.xhtml" target="_blank">Chapter 6</a>, <em>Measuring Healthcare Quality</em>, we will dive into some real-world healthcare provider performance data and analyze it using pandas.</p>


            </article>

            
        </section>
    </body></html>