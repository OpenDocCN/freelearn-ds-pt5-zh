<html><head></head><body>
        <section>

                            <header>
                    <h1 class="header-title">Data-Driven Customer Segmentation</h1>
                </header>
            
            <article>
                
<p>In marketing, we often try to understand the behavior of certain subgroups of the customer base. Especially in targeted marketing, marketers try to segment the customer base in certain ways and focus on each target segment or customer group. This concentration on certain target customer segments results in better performance, as the needs and interests of those customers in the target group align and match better with the business's products, services, or content.</p>
<p>In this chapter, we are going to dive deeper into the concept of customer segmentation. We will discuss what customer segmentation is, the importance and benefits of having a good understanding of different segments of the customer base, and how to utilize customer segment analysis results for different marketing strategies. Aside from a more traditional way of segmenting the customer base, which involves looking at the key statistics of certain attributes of customers and manually cutting the customer base into segments, we can also use machine learning to have machines find the best ways to split the customer base into the desired number of segments. In this chapter, we will learn how we can use the k-means clustering algorithm to build customer segments based on the historical data.</p>
<p>I<span>n this chapte</span><span>r, we will cover the following topics:</span></p>
<ul>
<li>Customer segmentation</li>
<li>Clustering algorithms</li>
<li>Segmenting customers with Python</li>
<li><span>Segmenting customers</span> with R</li>
</ul>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Customer segmentation</h1>
                </header>
            
            <article>
                
<p>Given today's competition within the market, it is critical to understand the different behaviors, types, and interests of customers. Especially in targeted marketing, understanding and categorizing customers is an essential step in forming effective marketing strategies. By segmenting the customer base, marketers can focus on one segment of customers at a time. It also helps marketers to tailor their marketing messages to one specific audience at a time. Customer segmentation is the backbone of successful targeted marketing, with which you can target specific groups of customers with different pricing options, promotions, and product placements that capture the interests of the target audience in the most cost-effective way.</p>
<p>Any business or industry can benefit from a better understanding of different customer segments. For example, television advertisements that are broadcast across all over the USA for an outerwear brand that sells winter clothes, such as parkas, snow boots, and hats, would not be so cost-effective. People residing in areas that never really get cold, such as Florida, Southern California, or Hawaii, would most likely not be interested in purchasing winter clothes. However, people residing in areas with cold winters, such as Alaska, Minnesota, or North Dakota, would most likely want to buy clothes that will keep them warm. So, for this outerwear brand, instead of sending out marketing mails or emails to all of their customers, it would be better to target those segments of customers, based on their geographic information, that live in places where they would need winter clothes more frequently than other customers.</p>
<p>As another example, if you own a rental building near a college, you might want to target your customers based on their age and education. Marketing to customers between 20 and 30 and who are attending surrounding colleges will have higher return than marketing to others. For hotel businesses, you might want to target those couples who have upcoming anniversaries for romantic package deals. Using social media platforms, such as Facebook or Instagram, you can target this segment of customers. </p>
<p>As we briefly discussed with these three cases, understanding your customers and which segment describes them the best can help you develop effective and efficient marketing strategies. When segmenting the customer base into subgroups, you can use certain characteristics and their statistics, as shown in <a href="72e8f4ee-7f95-4acc-928d-d33c9fc31bd6.xhtml" target="_blank">Chapter 7</a>, <em>Exploratory Analysis for Customer Behavior</em>. However, when you are trying to segment your customers with multiple attributes, it becomes exponentially more difficult. In the following sections, we are going to discuss how we can use machine learning for customer segmentation.</p>
<p class="mce-root"/>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Clustering algorithms</h1>
                </header>
            
            <article>
                
<p class="mce-root"><strong>Clustering algorithms</strong> are frequently used in marketing for customer segmentation. This is a method of unsupervised learning that learns the commonalities between groups from data. Unlike supervised learning, where there is a target and a labeled variable that you would like to predict, unsupervised learning learns from data without any target or labeled variable. Among numerous other clustering algorithms, we are going to explore the usage of the k-means clustering algorithm in this chapter.</p>
<p>The k-means clustering algorithm splits the records in the data into a pre-defined number of clusters, where the data points within each cluster are close to each other. In order to group similar records together, the k-means clustering algorithm tries to find the centroids, which are the centers or means of clusters, to minimize the distances between the data points and the centroids within the clusters. The objective equation (from <a href="https://scikit-learn.org/stable/modules/clustering.html#k-means">https://scikit-learn.org/stable/modules/clustering.html#k-means</a>) looks like this:</p>
<p class="CDPAlignCenter CDPAlign"><img src="assets/f2785420-51f0-409c-80cd-28663ce10950.png" style="width:14.33em;height:5.00em;"/></p>
<p>Here <em>n</em> is the number of records in the dataset, <em>x<sub>i</sub></em> is the <em>i</em>th data point, <em>C</em> is the number of clusters, and <em>µ<sub>j</sub></em> is the <em>j</em>th centroid.</p>
<p>One downside or difficulty of using k-means clustering for customer segmentation is the fact that you need to know the number of clusters beforehand. However, quite often, you do not know what is the optimal number of clusters to create. The silhouette coefficient can be used to evaluate and help you make decisions on what the best number of clusters will be for your segmentation problem. Simply put, the silhouette coefficient measures how close the data points are to their clusters compared to other clusters. The equation is shown here:</p>
<p class="CDPAlignCenter CDPAlign"><img src="assets/58a5fb9b-0539-4e54-ad29-baa5fc082d4b.png" style="width:10.67em;height:3.67em;"/></p>
<p>Here <kbd>b</kbd> is the average of the distance between a point and its closest cluster and <kbd>a</kbd> is the average distance among data points within the same cluster. The silhouette coefficient value ranges from -1 to 1, where the closer the values are to 1, the better they are. In the following programming exercises, we will be segmenting the customer base from our dataset, using the k-means clustering algorithm and the silhouette coefficient.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Segmenting customers with Python</h1>
                </header>
            
            <article>
                
<p>In this section, we are going to discuss how to segment the customer base into subgroups using the clustering algorithm in Python. By the end of this section, we will have built a customer segmentation model using the k-means clustering algorithm. We will be mainly using the<span> </span><kbd>pandas</kbd><span>,</span><span> </span><kbd>matplotlib</kbd><span>, and <kbd>scikit-learn</kbd> </span>packages to analyze, visualize, and build machine learning models. <span>For those readers, who would like to use R, instead of Python, for this exercise, you can skip to the next section.</span></p>
<p><span>For this exercise, we will be using one of the publicly available datasets fro</span>m the UCI Machine Learning Repository, which can be fo<span>und at this link: <a href="http://archive.ics.uci.edu/ml/datasets/online+retail">http://archive.ics.uci.edu/ml/datasets/online+retail</a></span><span>. You can follow this link and download the data, which is available in XLSX format, named <kbd>Online Retail.xlsx</kbd>. Once you have downloaded this data, you can load it into your Jupyter Notebook by running the following command:</span></p>
<pre>import pandas as pd<br/><br/>df = pd.read_excel('../data/Online Retail.xlsx', sheet_name='Online Retail')</pre>
<p>The DataFrame,<span> </span><kbd>df</kbd>, looks like this:</p>
<p class="CDPAlignCenter CDPAlign"><img src="assets/f5468769-a05c-42eb-b78b-b31ed60dd46d.png"/></p>
<p><span>As you can notice, we have used this dataset a few times in the previous chapters.</span><span> As you might recall from previous chapters, there are a few things we need to clean up before we proceed.</span></p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Data cleanup</h1>
                </header>
            
            <article>
                
<p>Before we can start building clustering models, there are five tasks we need to do to clean up our data and prepare it for modeling. The clean-up steps are as follows:</p>
<ol>
<li><strong>Dropping canceled orders</strong>: We are going to drop records with negative <kbd>Quantity</kbd>, using the following code:</li>
</ol>
<pre>        df = df.loc[df['Quantity'] &gt; 0]</pre>
<ol start="2">
<li><strong>Dropping records with no <kbd>CustomerID</kbd></strong>: There are <kbd>133,361</kbd> records with no <kbd>CustomerID</kbd> and we are going to drop those records with the following code:</li>
</ol>
<pre>        df = df[pd.notnull(df['CustomerID'])]</pre>
<ol start="3">
<li><strong>Excluding an incomplete month</strong>: As you might recall from previous chapters, the data in the month of December, 2011, is incomplete. You can exclude this data with the following code:</li>
</ol>
<pre>        df = df.loc[df['InvoiceDate'] &lt; '2011-12-01']</pre>
<ol start="4">
<li><strong>Computing total sales from</strong> <strong>the Quantity and UnitPrice columns</strong>: For our analyses, we need the total sales value, so we are going to multiply the two <kbd>Quantity</kbd> and <kbd>UnitPrice</kbd> columns, to get the total sales, as shown in the following code:</li>
</ol>
<pre>          df['Sales'] = df['Quantity'] * df['UnitPrice']</pre>
<ol start="5">
<li><strong>Per-customer data</strong>: In order to analyze customer segments, we need to transform our data, so that each record represents the purchase history of individual customers. Take a look at the following code:</li>
</ol>
<pre>        customer_df = df.groupby('CustomerID').agg({<br/>            'Sales': sum,<br/>            'InvoiceNo': lambda x: x.nunique()<br/>        })<br/><br/>        customer_df.columns = ['TotalSales', 'OrderCount']<br/>        customer_df['AvgOrderValue'] =     <br/>        customer_df['TotalSales']/customer_df['OrderCount']</pre>
<p>As you can see from this code, we are grouping the <kbd>DataFrame</kbd>, <kbd>df</kbd>, by <kbd>CustomerID</kbd> and computing the total sales and the number of orders for each customer. Then, we also calculate the average per-order value, <kbd>AvgOrderValue</kbd>, by dividing the <kbd>TotalSales</kbd> column by the <kbd>OrderCount</kbd> column. The result is shown in the following screenshot:</p>
<p class="CDPAlignCenter CDPAlign"><br/>
<img src="assets/2e9bfddd-62e5-43d9-814c-bcb7fbc4e241.png" style="width:26.08em;height:35.33em;"/></p>
<p>Now, as you can see from this data, the three columns, <kbd>TotalSales</kbd>, <kbd>OrderCount</kbd>, and <kbd>AvgOrderValue</kbd>, have different scales. <kbd>TotalSales</kbd> can take any values from <kbd>0</kbd> to <kbd>26,848</kbd>, while <kbd>OrderCount</kbd> takes values between <kbd>1</kbd> and <kbd>201</kbd>. Clustering algorithms are highly affected by the scales of the data, so we need to normalize this data to be on the same scale. We are going to take two steps to normalize this data. First, we are going to rank the data, so that the values of each column range from <kbd>1</kbd> to <kbd>4298</kbd>, which is the total number of records. Take a look at the following code:</p>
<pre>rank_df = customer_df.rank(method='first')</pre>
<p>The result is shown in the following screenshot:</p>
<p class="CDPAlignCenter CDPAlign"><br/>
<img src="assets/126f7dc1-1f1c-424d-81f5-686b2e44d060.png" style="width:25.33em;height:33.58em;"/></p>
<p>Next, we are going to normalize this data to center around the mean and have a mean of <kbd>0</kbd> and a standard deviation of <kbd>1</kbd>. Take a look at the following code:</p>
<pre>normalized_df = (rank_df - rank_df.mean()) / rank_df.std()</pre>
<p>The result is shown in the following screenshot:</p>
<p class="CDPAlignCenter CDPAlign"><br/>
<img src="assets/1bad843b-fbd9-471d-b4e5-fc43a62e6cd0.png" style="width:22.75em;height:30.75em;"/></p>
<p><br/>
Take a look at the statistics of each of these columns, shown in the following screenshot:</p>
<p class="CDPAlignCenter CDPAlign"><img src="assets/c17e2528-0809-43b9-bf02-5adf9dfeddf4.png" style="width:22.42em;height:16.00em;"/></p>
<p>You can see that the values are centered around at <kbd>0</kbd> and have a standard deviation of <kbd>1</kbd>. We are going to use this data for the following clustering analyses.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">k-means clustering</h1>
                </header>
            
            <article>
                
<p>The <strong>k-means clustering</strong> algorithm is a frequently used algorithm for drawing insights into the formations and separations within data. In marketing, it is often used to build customer segments and understand the behaviors of these different segments. Let's dive into building clustering models in Python.</p>
<p>In order to use the k-means clustering algorithm in the <kbd>scikit-learn</kbd> package, we need to import the <kbd>kmeans</kbd> module, as shown in the following code:</p>
<pre>from sklearn.cluster import KMeans</pre>
<p>Then, you can build and fit a k-means clustering model, using the following code:</p>
<pre>kmeans = KMeans(n_clusters=4).fit(normalized_df[['TotalSales', 'OrderCount', 'AvgOrderValue']])</pre>
<p>As you can see from this code, we are building a clustering model that splits the data into four segments. You can change the desired number of clusters with the <kbd>n_clusters</kbd> parameter. Using the <kbd>fit</kbd> function, you can train a k-means clustering algorithm to learn to split the given data. In this code, we are building four clusters, based on the <kbd>TotalSales</kbd>, <kbd>OrderCount</kbd>, and <kbd>AvgOrderValue</kbd> values. The trained model object, <kbd>kmeans</kbd>, stores the labels and centers of the clusters in the <kbd>labels_</kbd> and <kbd>cluster_centers_</kbd> attributes of the model object. You can retrieve these values as shown in the following code:</p>
<pre>kmeans.labels_<br/>kmeans.cluster_centers_</pre>
<p>Now that we have built our first clustering model, let's visualize this data. First, take a look at the following code:</p>
<pre>four_cluster_df = normalized_df[['TotalSales', 'OrderCount', 'AvgOrderValue']].copy(deep=True)<br/>four_cluster_df['Cluster'] = kmeans.labels_</pre>
<p>We store the cluster label information for each record into a newly created DataFrame, <kbd>four_cluster_df</kbd>. With this <kbd>DataFrame</kbd>, we can visualize the clusters, using the following code:</p>
<pre>plt.scatter(<br/>    four_cluster_df.loc[four_cluster_df['Cluster'] == 0]['OrderCount'], <br/>    four_cluster_df.loc[four_cluster_df['Cluster'] == 0]['TotalSales'],<br/>    c='blue'<br/>)<br/><br/>plt.scatter(<br/>    four_cluster_df.loc[four_cluster_df['Cluster'] == 1]['OrderCount'], <br/>    four_cluster_df.loc[four_cluster_df['Cluster'] == 1]['TotalSales'],<br/>    c='red'<br/>)<br/><br/>plt.scatter(<br/>    four_cluster_df.loc[four_cluster_df['Cluster'] == 2]['OrderCount'], <br/>    four_cluster_df.loc[four_cluster_df['Cluster'] == 2]['TotalSales'],<br/>    c='orange'<br/>)<br/><br/>plt.scatter(<br/>    four_cluster_df.loc[four_cluster_df['Cluster'] == 3]['OrderCount'], <br/>    four_cluster_df.loc[four_cluster_df['Cluster'] == 3]['TotalSales'],<br/>    c='green'<br/>)<br/><br/>plt.title('TotalSales vs. OrderCount Clusters')<br/>plt.xlabel('Order Count')<br/>plt.ylabel('Total Sales')<br/><br/>plt.grid()<br/>plt.show()</pre>
<p>As you can see from this code, we are visualizing the data using scatter plots. The result is shown in the following screenshot:</p>
<p class="CDPAlignCenter CDPAlign"><img src="assets/cf3a60cb-0e8e-416d-bf46-ce464c85d530.png" style="width:27.92em;height:19.17em;"/></p>
<p>Let's take a closer look at this plot. The cluster in blue is the group of low-value customers, who have not purchased our products so much. On the other hand, the cluster in red is the group of high-value customers, who have purchased the greatest amount and who have purchased products frequently. We can also visualize the clusters with different angles, using the rest of the variables. Take a look at the following plots:</p>
<p class="CDPAlignCenter CDPAlign"><img src="assets/0d93eb9d-2344-4996-96e4-05b1163a2fbc.png" style="width:25.58em;height:18.17em;"/> <img src="assets/ff0c9ce9-0012-4d72-8afe-a43c0407c603.png" style="font-size: 1em;width:26.08em;height:17.75em;"/></p>
<p>The first plot shows the clusters visualized based on <kbd>AvgOrderValue</kbd> and <kbd>OrderCount</kbd>. On the other hand, the second plot shows the clusters visualized based on <span><kbd>AvgOrderValue</kbd> </span>and <kbd>TotalSales</kbd>. As you can see from these plots, the cluster in blue has the lowest average per-order value and the lowest number of orders. However, the cluster in red has the highest average per-order value and the greatest number of orders. Visualizing clusters helps you understand the characteristics of different clusters much more easily and clearly.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Selecting the best number of clusters</h1>
                </header>
            
            <article>
                
<p>Often, we do not know what the best number of clusters to use is when building k-means clustering models. As discussed in an earlier section of this chapter, we can use the silhouette coefficient to determine what the best number of clusters is to split the data. In the <kbd>scikit-learn</kbd> package, you can use the <kbd>silhouette_score</kbd> function in the <kbd>sklearn.metrics</kbd> module to calculate the silhouette score and measure the quality of clusters. Take a look at the following code:</p>
<pre>from sklearn.metrics import silhouette_score<br/><br/>for n_cluster in [4,5,6,7,8]:<br/>    kmeans = KMeans(n_clusters=n_cluster).fit(<br/>        normalized_df[['TotalSales', 'OrderCount', 'AvgOrderValue']]<br/>    )<br/>    silhouette_avg = silhouette_score(<br/>        normalized_df[['TotalSales', 'OrderCount', 'AvgOrderValue']], <br/>        kmeans.labels_<br/>    )<br/>    <br/>    print('Silhouette Score for %i Clusters: %0.4f' % (n_cluster, silhouette_avg))</pre>
<p>As you can see from this code, we are experimenting with five different numbers of clusters: <kbd>4</kbd>, <kbd>5</kbd>, <kbd>6</kbd>, <kbd>7</kbd>, and <kbd>8</kbd>. For each amount of clusters, we are going to measure the silhouette score and choose the amount of clusters with the highest score. The output of this code looks like this:</p>
<p class="CDPAlignCenter CDPAlign"><img src="assets/120a5ca4-f783-4157-bd15-5ed4d103c34d.png" style="width:22.42em;height:6.00em;"/></p>
<p>In our case, of the five different numbers of clusters we have experimented with, the best number of clusters <span>with the highest silhouette score</span> was <kbd>4</kbd>. In the following section, we will use <kbd>4</kbd> as the number of clusters to show how we can interpret the results of the clustering analysis.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Interpreting customer segments</h1>
                </header>
            
            <article>
                
<p>In this section, we are going to discuss different ways to draw insights from the results of the previous clustering analysis. Let's first build a k-means clustering model with four clusters. You can use the following code:</p>
<pre>kmeans = KMeans(n_clusters=4).fit(<br/>    normalized_df[['TotalSales', 'OrderCount', 'AvgOrderValue']]<br/>)<br/><br/>four_cluster_df = normalized_df[['TotalSales', 'OrderCount', 'AvgOrderValue']].copy(deep=True)<br/>four_cluster_df['Cluster'] = kmeans.labels_</pre>
<p>As you can see from this code, we are fitting a k-means clustering model with <kbd>4</kbd> clusters, based on three attributes: <kbd>TotalSales</kbd>, <kbd>OrderCount</kbd>, and <kbd>AvgOrderValue</kbd>. Then, we store the cluster label information into a DataFrame, <kbd>four_cluster_df</kbd>. This DataFrame is shown in the following screenshot:</p>
<p class="CDPAlignCenter CDPAlign"><img src="assets/85420d12-e0cf-4985-a6e9-28b16c9bc6ca.png" style="width:26.83em;height:30.92em;"/></p>
<p>The first thing we are going to look at is the centers of each cluster. You can get the cluster centers using the following code:</p>
<pre>kmeans.cluster_centers_</pre>
<p>The output of this code is shown in the following screenshot:</p>
<p class="CDPAlignCenter CDPAlign"><img src="assets/63a9df3e-69eb-49e5-88e4-2a1505d6a11b.png" style="width:29.25em;height:5.42em;"/></p>
<p>Let's take a closer look at this. The fourth cluster has the lowest numbers for all three attributes. This suggests that the fourth cluster contains customers with the smallest amount of sales, smallest number of orders, and lowest average per-order value. This group of customers is one of low-value customers. On the other hand, the third cluster has the highest numbers for all three attributes. The customers in the third cluster have the greatest amount of sales, greatest number of orders, and highest average per-order value. So, these customers in the third cluster purchase expensive items and give the business the highest revenue. You would typically want to focus your marketing efforts on this segment of customers, as it will result in the highest return.</p>
<p>The customers in the second cluster are interesting. They make purchases relatively frequently, as they have a medium-to-high cluster center value for <kbd>OrderCount</kbd>, but their average per-order value is low, as the cluster center for <kbd>AvgOrderValue</kbd> is low. These are the customers who make frequent purchases of low-value items. So, it would be perfect to market items with low per-item prices to this segment of customers. The customers in the first cluster are also interesting. Their contributions to the revenue and number of orders are medium to low, looking at the centers of this cluster. However, their average per-order value is high. These are the customers who buy expensive items infrequently. Thus, it would be perfect to market expensive items to this segment of customers.</p>
<p>As you can see from this example, looking at the centers of clusters helps us understand different types and segments of customers and how to target them differently. Lastly, we can also find out what the best-selling items are for each customer segment. Take a look at the following code:</p>
<pre>high_value_cluster = four_cluster_df.loc[four_cluster_df['Cluster'] == 2]<br/><br/>pd.DataFrame(<br/>    df.loc[<br/>        df['CustomerID'].isin(high_value_cluster.index)<br/>    ].groupby('Description').count()[<br/>        'StockCode'<br/>    ].sort_values(ascending=False).head()<br/>)</pre>
<p>As we have seen before, the third cluster was the group of high-value customers, and we are going to take a look at the top five best-selling items for this group. The output of this code is as follows:</p>
<p class="CDPAlignCenter CDPAlign"><img src="assets/a6ce561c-d6b2-4ae2-a2b3-cabc1c3b3d8d.png" style="width:22.25em;height:12.17em;"/></p>
<p>For this high-value segment, the best-selling item was <kbd>JUMBO BAG RED RETROSPOT</kbd> and the second best-selling item was <kbd>REGENCY CAKESTAND 3 TIER</kbd>. You can utilize this information in marketing strategies, when you target this customer segment. In your marketing campaigns, you can recommend items similar to these best-selling items to this segment of customers, as they are the most interested in these types of items. </p>
<div class="packt_infobox">You can find the full code for this exercise in the following repository: <a href="https://github.com/yoonhwang/hands-on-data-science-for-marketing/blob/master/ch.10/python/CustomerSegmentation.ipynb">https://github.com/yoonhwang/hands-on-data-science-for-marketing/blob/master/ch.10/python/CustomerSegmentation.ipynb</a>.</div>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Segmenting customers with R</h1>
                </header>
            
            <article>
                
<p>In this section, we are going to discuss how to segment the customer base into subgroups using a clustering algorithm in R. By the end of this section, we will have built a customer segmentation model using the k-means clustering algorithm. <span>For those readers who would like to use Python, instead of R, for this exercise, see the previous section.</span></p>
<p class="mce-root"/>
<p>For this exercise, we will be using one of the publicly available datasets from the UCI Machine Learning Repository<span>, which can be found at this link: <a href="http://archive.ics.uci.edu/ml/datasets/online+retail">http://archive.ics.uci.edu/ml/datasets/online+retail</a></span><span>. You can follow this link and download the data, which is available in XLSX format, named <kbd>Online Retail.xlsx</kbd>. Once you have downloaded this data, you can load it into your RStudio by running the following command:</span></p>
<pre>library(readxl)<br/><br/>#### 1. Load Data ####<br/>df &lt;- read_excel(<br/>  path="~/Documents/data-science-for-marketing/ch.10/data/Online Retail.xlsx", <br/>  sheet="Online Retail"<br/>)</pre>
<p>The DataFrame,<span> </span><kbd>df</kbd>, is shown in the following screenshot:</p>
<p class="CDPAlignCenter CDPAlign"><img src="assets/9b038be6-75b9-4d33-881a-81dac9d8e3fd.png" style="width:85.08em;height:33.00em;"/></p>
<p><span>As you may have noticed, we have used this dataset a few times in the previous chapters</span><span>. As you might recall from previous chapters, there are a few things we need to clean up before we proceed.</span></p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Data cleanup</h1>
                </header>
            
            <article>
                
<p><span>Before we can start building clustering models, there are five tasks we need to do to clean up our data and prepare it for modeling. The clean-up steps are as follows:</span></p>
<ol>
<li><strong>Dropping canceled orders</strong>: We are going to drop records with negative <kbd>Quantity</kbd>, using the following code:</li>
</ol>
<pre>        df &lt;- df[which(df$Quantity &gt; 0),]</pre>
<ol start="2">
<li><strong>Dropping records with no<span> </span>CustomerID</strong><span>:</span> There are<span> </span><kbd>133,361</kbd><span> </span>records with no<span> </span><kbd>CustomerID</kbd><span> </span>and we are going to drop those records with the following code:</li>
</ol>
<pre>        df &lt;- na.omit(df)</pre>
<ol start="3">
<li><strong>Excluding an incomplete month</strong>: As you might recall from previous chapters, the data in the month of December, 2011, is incomplete. You can exclude this data with the following code:</li>
</ol>
<pre>        df &lt;- df[which(df$InvoiceDate &lt; '2011-12-01'),]</pre>
<ol start="4">
<li><strong>Computing total sales from<span> the </span>Quantity<span> </span>and<span> </span>UnitPrice<span> </span>columns</strong>: For our analyses, we need the total sales value, so we are going to multiply the <kbd>Quantity</kbd><span> </span>and<span> </span><kbd>UnitPrice</kbd> columns, to get the total sales, as shown in the following code:</li>
</ol>
<pre>        df$Sales &lt;- df$Quantity * df$UnitPrice</pre>
<ol start="5">
<li><strong>Per-customer data</strong>: In order to analyze customer segments, we need to transform our data, so that each record represents the purchase history of individual customers. Take a look at the following code:</li>
</ol>
<pre>        # per customer data<br/>        customerDF &lt;- df %&gt;% <br/>          group_by(CustomerID) %&gt;% <br/>          summarize(TotalSales=sum(Sales),      <br/>        OrderCount=length(unique(InvoiceDate))) %&gt;%<br/>          mutate(AvgOrderValue=TotalSales/OrderCount)</pre>
<p>As you can see from this code, we are grouping the DataFrame,<span> </span><kbd>df</kbd>, by<span> </span><kbd>CustomerID</kbd><span> </span>and computing the total sales and the number of orders for each customer. Then, we also calculate the average per-order value,<span> </span><kbd>AvgOrderValue</kbd>, by dividing the<span> </span><kbd>TotalSales</kbd><span> </span>column by the<span> </span><kbd>OrderCount</kbd><span> </span>column. The result is shown in the following screenshot:</p>
<p class="CDPAlignCenter CDPAlign"><br/>
<img src="assets/c0592e46-d55e-4294-836c-d066aa92a56f.png" style="width:31.83em;height:26.75em;"/></p>
<p>Now, as you can see from this data, the<span> </span><kbd>TotalSales</kbd>,<span> </span><kbd>OrderCount</kbd>, and<span> </span><kbd>AvgOrderValue</kbd> columns, have different scales. <kbd>TotalSales</kbd><span> </span>can take any values from<span> </span><kbd>0</kbd><span> </span>to<span> </span><kbd>26,848</kbd>, while<span> </span><kbd>OrderCount</kbd><span> </span>takes values between<span> </span><kbd>1</kbd><span> </span>and<span> </span><kbd>201</kbd>. Clustering algorithms are highly affected by the scales of the data, so we need to normalize this data to be on the same scale. We are going to take two steps to normalize this data. First, we are going to rank the data, so that the values of each column range from<span> </span><kbd>1</kbd><span> </span>to<span> </span><kbd>4298</kbd>, which is the total number of records. Take a look at the following code:</p>
<pre>rankDF &lt;- customerDF %&gt;%<br/>  mutate(TotalSales=rank(TotalSales), OrderCount=rank(OrderCount, ties.method="first"), AvgOrderValue=rank(AvgOrderValue))</pre>
<p class="mce-root"/>
<p>The result is shown in the following screenshot:</p>
<p class="CDPAlignCenter CDPAlign"><br/>
<img src="assets/b1420338-a64d-4835-8315-fd540e09fc3c.png" style="width:30.50em;height:24.42em;"/></p>
<p>Next, we are going to normalize this data to center around the mean, and have a mean of<span> </span><kbd>0</kbd><span> </span>and a standard deviation of<span> </span><kbd>1</kbd>, using the <kbd>scale</kbd> function in R. Take a look at the following code:</p>
<pre>normalizedDF &lt;- rankDF %&gt;%<br/>  mutate(TotalSales=scale(TotalSales), OrderCount=scale(OrderCount), AvgOrderValue=scale(AvgOrderValue))</pre>
<p>The result is shown in the following screenshot:</p>
<p class="CDPAlignCenter CDPAlign"><br/>
<img src="assets/cc0d9282-7791-4d3d-8532-6e2feafde93f.png" style="width:30.75em;height:26.17em;"/></p>
<p>Take a look at the statistics of each of these columns, as shown in the following screenshot:</p>
<p class="CDPAlignCenter CDPAlign"><br/>
<img src="assets/3565018b-68bc-439f-81a1-793ea6211417.png" style="width:35.08em;height:11.75em;"/></p>
<p>You can see that the values are centered around at <kbd>0</kbd> and have a standard deviation of <kbd>1</kbd>. We are going to use this data for the following clustering analyses.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">k-means clustering</h1>
                </header>
            
            <article>
                
<p>The <strong>k-means clustering</strong><span> </span>algorithm is a frequently used algorithm to draw insights on the formations and separations within the data. In marketing, it is often used to build customer segments and understand the behaviors of these different segments. Let's dive into building clustering models in R.</p>
<p><span>You can build and fit a k-means clustering model using the following code:</span></p>
<pre>cluster &lt;- kmeans(normalizedDF[c("TotalSales", "OrderCount", "AvgOrderValue")], 4)</pre>
<p>As you can see from this code, we are building a clustering model that splits the data into <kbd>4</kbd> segments. The first parameter of the <kbd>kmeans</kbd> function is for the data to be used for k-means clustering and the second parameter is to define the desired number of clusters. In this code, we are building <kbd>4</kbd> clusters, based on the<span> </span><kbd>TotalSales</kbd>,<span> </span><kbd>OrderCount</kbd>, and<span> </span><kbd>AvgOrderValue</kbd> values. The trained k-means clustering model object,<span> </span><kbd>cluster</kbd>, stores the labels and centers of the clusters in the<span> </span><kbd>cluster</kbd><span> </span>and <kbd>centers</kbd> variables of the model object. You can retrieve these values, as shown in the following code:</p>
<pre>cluster$cluster<br/>cluster$centers</pre>
<p>Now that we have built our first clustering model, let's visualize this data. First, we are going to store the cluster labels as a separate column, named <kbd>Cluster</kbd>, in the <kbd>normalizedDF</kbd> variable, as shown in the following code:</p>
<pre># cluster labels<br/>normalizedDF$Cluster &lt;- cluster$cluster</pre>
<p>Then, we can visualize the clusters, using the following code:</p>
<pre>ggplot(normalizedDF, aes(x=AvgOrderValue, y=OrderCount, color=Cluster)) +<br/>  geom_point()</pre>
<p>As you can see from this code, we are visualizing the data using scatterplots. The result in shown in the following screenshot:</p>
<p class="CDPAlignCenter CDPAlign"><img src="assets/8f0fa682-ec51-4a5b-8927-49e536fa1566.png" style="width:34.00em;height:21.92em;"/></p>
<p>Let's take a closer look at this plot. The cluster in the bottom left is the group of low-value customers, who have not purchased our products so much. On the other hand, the cluster in the top right with the darkest color is the group of high-value customers, who have purchased the greatest amount and who have purchased products frequently. We can also visualize the clusters with different angles, using the rest of the variables. Take a look at the following plots:</p>
<p class="CDPAlignCenter CDPAlign"><img src="assets/6be6df8c-46c0-4f9f-a21a-501922c395ce.png" style="width:26.92em;height:17.33em;"/></p>
<p class="CDPAlignCenter CDPAlign"><img src="assets/b59c48f0-4142-4a5a-b1c3-3525d90911d4.png" style="font-size: 1em;width:26.00em;height:16.83em;"/></p>
<p>The first plot shows the clusters visualized based on <kbd>AvgOrderValue</kbd><span> </span>and<span> </span><kbd>OrderCount</kbd>. On the other hand, the second plot the clusters visualized based on <span><kbd>AvgOrderValue</kbd> </span>and<span> </span><kbd>TotalSales</kbd>. As you can see from these plots, the cluster in the bottom left with the second-lightest color has the lowest average per-order value and the lowest number of orders. However, the cluster in the top right with the darkest color has the highest average per-order value and the greatest number of orders. Visualizing clusters helps you understand the characteristics of different clusters much more easily and clearly.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Selecting the best number of clusters</h1>
                </header>
            
            <article>
                
<p>Quite often, we do not know what the best number of clusters to use is when building k-means clustering models. As discussed in an earlier section of this chapter, we can use the<span> </span>silhouette coefficient to determine what the best number of clusters is to split the data. In R, you can use the <kbd>silhouette</kbd> function in the <kbd>cluster</kbd> library to calculate the silhouette score and measure the quality of clusters. Take a look at the following code:</p>
<pre># Selecting the best number of cluster<br/>library(cluster)<br/><br/>for(n_cluster in 4:8){<br/>  cluster &lt;- kmeans(normalizedDF[c("TotalSales", "OrderCount", "AvgOrderValue")], n_cluster)<br/>  <br/>  silhouetteScore &lt;- mean(<br/>    silhouette(<br/>      cluster$cluster, <br/>      dist(normalizedDF[c("TotalSales", "OrderCount", "AvgOrderValue")], method = "euclidean")<br/>    )[,3]<br/>  )<br/>  print(sprintf('Silhouette Score for %i Clusters: %0.4f', n_cluster, silhouetteScore))<br/>}</pre>
<p>As you can see from this code, we are experimenting with five different number of clusters: <kbd>4</kbd>, <kbd>5</kbd>, <kbd>6</kbd>, <kbd>7</kbd>, and <kbd>8</kbd>. For each number of clusters, we are going to measure the silhouette score and choose the number of clusters with the highest score. The output of this code is shown in the following screenshot:</p>
<p class="CDPAlignCenter CDPAlign"><img src="assets/71fd5298-4fb1-4576-846a-81667a4b383f.png" style="width:24.08em;height:6.33em;"/></p>
<p>In our case, of the five different numbers of clusters we have experimented with, the best number of clusters with the highest silhouette score was<span> </span><kbd>4</kbd>. In the following section, we will use<span> </span><kbd>4</kbd><span> </span>for the number of clusters to show how we can interpret the results of clustering analysis.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Interpreting customer segments</h1>
                </header>
            
            <article>
                
<p>In this section, we are going to discuss different ways to draw insights from the results of the previous clustering analysis. Let's first build a k-means clustering model with <kbd>4</kbd> clusters. You can use the following code:</p>
<pre># Interpreting customer segments<br/>cluster &lt;- kmeans(normalizedDF[c("TotalSales", "OrderCount", "AvgOrderValue")], 4)<br/>normalizedDF$Cluster &lt;- cluster$cluster</pre>
<p>As you can see from this code, we are fitting a k-means clustering model with<span> </span><kbd>4</kbd><span> </span>clusters, based on the three attributes: <kbd>TotalSales</kbd>,<span> </span><kbd>OrderCount</kbd>, and<span> </span><kbd>AvgOrderValue</kbd>. Then, we store the cluster label information into a DataFrame,<span> </span><kbd>normalizedDF</kbd>. This<span> </span>DataFrame is shown in the following screenshot:</p>
<p class="CDPAlignCenter CDPAlign"><img src="assets/dcc5181c-f58a-4f37-a201-47af60d942af.png" style="width:33.17em;height:22.83em;"/></p>
<p>The first thing we are going to look at is the centers of each cluster. You can get the cluster centers using the following code:</p>
<pre># cluster centers<br/>cluster$centers</pre>
<p>The output of this code is shown in the following screenshot:</p>
<p class="CDPAlignCenter CDPAlign"><img src="assets/8870c2db-382e-497c-af61-322637e57e57.png" style="width:17.92em;height:7.33em;"/></p>
<p>Let's take a closer look at this. The third<span> </span>cluster has the lowest numbers for all three attributes. This suggests that the third<span> </span>cluster contains customers with the lowest amount of sales, lowest number of orders, and lowest average per-order value. This group of customers is a group of low-value customers. On the other hand, the fourth<span> </span>cluster has the highest numbers for all three attributes. The customers in the fourth<span> </span>cluster have the highest amount of sales, highest number of orders, and highest average per-order value. This suggests that these customers in the fourth<span> </span>cluster purchase expensive items and give the business the highest revenue. You would typically want to focus your marketing efforts on this segment of customers, as it will result in the highest return.</p>
<p>The customers in the first<span> </span>cluster are interesting. They make purchases relatively frequently, as they have a medium to high cluster center value for <kbd>OrderCount</kbd>, but their average per-order value is low, as the cluster center for <kbd>AvgOrderValue</kbd><span> </span>is low. These are the type of customers who make frequent purchases of low-value items. So, it would be perfect to market items with low per-item prices to this segment of customers. The customers in the second<span> </span>cluster are also interesting. Their contributions to the revenue and number of orders are low, looking at the centers of this cluster. However, their average per-order value is high. These are the type of customers who buy expensive items infrequently. Thus, it would be perfect to market expensive items to this segment of customers.</p>
<p>As you can see from this example, looking at the centers of clusters helps us understand different types and segments of customers and how to target them differently. Lastly, we can also find out what the best-selling items are for each customer segment. Take a look at the following code:</p>
<pre># High value cluster<br/>highValueCustomers &lt;- unlist(<br/>  customerDF[which(normalizedDF$Cluster == 4),'CustomerID'][,1], use.names = FALSE<br/>)<br/><br/>df[which(df$CustomerID %in% highValueCustomers),] %&gt;%<br/>  group_by(Description) %&gt;%<br/>  summarise(Count=n()) %&gt;%<br/>  arrange(desc(Count))</pre>
<p>As we have seen before, the fourth<span> </span>cluster was the group of high-value customers and we are going to take a look at the best-selling items for this group. The output of this code is shown in the following screenshot:</p>
<p class="CDPAlignCenter CDPAlign"><img src="assets/cd6cdcfe-9b9e-44af-997a-f5e24b82267b.png" style="width:26.17em;height:18.75em;"/></p>
<p class="mce-root"/>
<p>For this high-value segment, the best-selling item was<span> </span><strong>JUMBO BAG RED RETROSPOT<span> </span></strong>and the second best-selling item was<span> </span><strong>REGENCY CAKESTAND 3 TIER</strong>. You can utilize this information in the marketing strategies, when you target this customer segment. In your marketing campaigns, you can recommend items similar to these best-selling items to this segment of customers, as they are the most interested in these types of items. </p>
<div class="packt_infobox">You can find the full code for this exercise in the following repository:<span> <a href="https://github.com/yoonhwang/hands-on-data-science-for-marketing/blob/master/ch.10/R/CustomerSegmentation.R">https://github.com/yoonhwang/hands-on-data-science-for-marketing/blob/master/ch.10/R/CustomerSegmentation.R</a></span>.</div>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Summary</h1>
                </header>
            
            <article>
                
<p>In this chapter, we have learned more about customer segmentation. We worked through three simple scenarios of how customer segmentation could help different businesses to form better and more cost-effective marketing strategies. We have discussed how having a good understanding of different customer segments, how customers in different segments behave, and what they need and are interested in can help you target your audience better. We have also learned about the k-means clustering algorithm, which is one of the most frequently used clustering algorithms for customer segmentation. In order to evaluate the quality of clusters, we have shown how we can use the silhouette coefficient.</p>
<p>During programming exercises, we have experimented with how we can build a k-means clustering model in Python and R. In Python, we could use the <kbd>KMeans</kbd> module in the <kbd>scikit-learn</kbd> package and in R, we could use the <kbd>kmeans</kbd> function to build clustering models. Using the <kbd>silhouette_score</kbd> function in Python and the <kbd>silhouette</kbd> function in R, we have seen how we could use silhouette coefficients to evaluate the qualities of clusters and have seen how looking at <span>silhouette scores can help us determine the best number of clusters. Lastly, we have discussed how to interpret clustering analysis results, using scatter plots and cluster centroids, and we have seen how to find out the best-selling items for each customer segment.</span></p>
<p>In the next chapter, we are going to discuss customers at risk of churn and how to retain those customers. We will work together to build neural network models in Python and R, using the <kbd>keras</kbd> package, to identify those customers who are likely to churn.</p>


            </article>

            
        </section>
    </body></html>