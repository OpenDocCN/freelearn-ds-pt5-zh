["```py\n    import findspark\n    findspark.init()\n    import pyspark\n    import random\n    ```", "```py\n    from pyspark import SparkContext\n    sc = SparkContext()\n    ```", "```py\n    from pyspark.sql import SQLContext\n    sqlc = SQLContext(sc)\n    ```", "```py\n    df = sqlc.read.format('com.databricks.spark.csv').options(header = 'true', inferschema = 'true').load('/Users/iris.csv')\n    ```", "```py\n    df.show(5)\n    ```", "```py\n    from pyspark.sql.functions import isnan, when, count, col\n    df.select([count(when(isnan(c) | col(c).isNull(),\n                    c)).alias(c) for c in df.columns]).show()\n    ```", "```py\n    df.filter(col('Sepallength').isNull()).count()\n    ```", "```py\n    2\n    ```", "```py\n    from pyspark.sql.functions import isnan, when, count, col\n    ```", "```py\n    df.select([count(when(isnan(i) | col(i).isNull(), i)).alias(i) for i in df.columns]).show()\n    ```", "```py\n    df.describe().show(1)\n    ```", "```py\ndf.where(col('Sepallength').isNull()).show()\n```", "```py\n    df.select('Sepallength').dropna().count()\n    ```", "```py\n    df.dropna().count()\n    ```", "```py\n    y = df.select('Sepallength','Petallength').fillna(1)\n    ```", "```py\n    y.select([count(when(isnan(i) | col(i).isNull(), i)).alias(i) for i in y.columns]).show()\n    ```", "```py\n    z = df.fillna(1)\n    ```", "```py\n    z.select([count(when(isnan(k) | col(k).isNull(), k)).alias(k) for k in z.columns]).show()\n    ```", "```py\n    df.corr('Sepallength', 'Sepalwidth')\n    ```", "```py\n    from pyspark.mllib.stat import Statistics\n    import pandas as pd\n    ```", "```py\n    z = df.fillna(1)\n    ```", "```py\n    a = z.drop('Species')\n    ```", "```py\n    features = a.rdd.map(lambda row: row[0:])\n    correlation_matrix = Statistics.corr(features, method=\"pearson\")\n    ```", "```py\n    correlation_df = pd.DataFrame(correlation_matrix)\n    ```", "```py\n    correlation_df.index, correlation_df.columns = a.columns, a.columns\n    ```", "```py\n    correlation_df\n    ```"]