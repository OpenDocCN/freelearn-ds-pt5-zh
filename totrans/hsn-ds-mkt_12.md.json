["```py\nimport pandas as pd\n\ndf = pd.read_csv('../data/WA_Fn-UseC_-Marketing-Customer-Value-Analysis.csv')\n```", "```py\ndf['Engaged'] = df['Response'].apply(lambda x: 1 if x == 'Yes' else 0)\n```", "```py\ntdf['Engaged'].mean()\n```", "```py\ncolumns_to_encode = [\n    'Sales Channel', 'Vehicle Size', 'Vehicle Class', 'Policy', 'Policy Type', \n    'EmploymentStatus', 'Marital Status', 'Education', 'Coverage'\n]\n```", "```py\ncategorical_features = []\nfor col in columns_to_encode:\n   encoded_df = pd.get_dummies(df[col])\n    encoded_df.columns = [col.replace(' ', '.') + '.' + x for x in encoded_df.columns]\n\n    categorical_features += list(encoded_df.columns)\n\n    df = pd.concat([df, encoded_df], axis=1)\n```", "```py\ndf['Is.Female'] = df['Gender'].apply(lambda x: 1 if x == 'F' else 0)\n\ncategorical_features.append('Is.Female')\n```", "```py\nall_features = continuous_features + categorical_features\nresponse = 'Engaged'\n\nsample_df = df[all_features + [response]]\nsample_df.columns = [x.replace(' ', '.') for x in sample_df.columns]\nall_features = [x.replace(' ', '.') for x in all_features]\n```", "```py\nfrom sklearn.model_selection import train_test_split\n\nx_train, x_test, y_train, y_test = train_test_split(sample_df[all_features], sample_df[response], test_size=0.3)\n```", "```py\nfrom sklearn.ensemble import RandomForestClassifier\n```", "```py\nrf_model = RandomForestClassifier()\n```", "```py\nrf_model = RandomForestClassifier(\n    n_estimators=200,\n    max_depth=5\n)\n\nrf_model.fit(X=x_train, y=y_train)\n```", "```py\nrf_model.estimators_[0].predict(x_test)\n```", "```py\nrf_model.feature_importances_\n```", "```py\nfeature_importance_df = pd.DataFrame(list(zip(rf_model.feature_importances_, all_features)))\nfeature_importance_df.columns = ['feature.importance', 'feature']\n```", "```py\nfrom sklearn.metrics import accuracy_score, precision_score, recall_score\n```", "```py\nin_sample_preds = rf_model.predict(x_train)\nout_sample_preds = rf_model.predict(x_test)\n```", "```py\n# accuracy\naccuracy_score(actual, predictions)\n\n# precision \nprecision_score(actual, predictions)\n\n# recall \nrecall_score(actual, predictions)\n```", "```py\nfrom sklearn.metrics import roc_curve, auc\n```", "```py\nin_sample_preds = rf_model.predict_proba(x_train)[:,1]\nout_sample_preds = rf_model.predict_proba(x_test)[:,1]\n```", "```py\nin_sample_fpr, in_sample_tpr, in_sample_thresholds = roc_curve(y_train, in_sample_preds)\nout_sample_fpr, out_sample_tpr, out_sample_thresholds = roc_curve(y_test, out_sample_preds)\n```", "```py\nin_sample_roc_auc = auc(in_sample_fpr, in_sample_tpr)\nout_sample_roc_auc = auc(out_sample_fpr, out_sample_tpr)\n\nprint('In-Sample AUC: %0.4f' % in_sample_roc_auc)\nprint('Out-Sample AUC: %0.4f' % out_sample_roc_auc)\n```", "```py\nplt.figure(figsize=(10,7))\n\nplt.plot(\n    out_sample_fpr, out_sample_tpr, color='darkorange', label='Out-Sample ROC curve (area = %0.4f)' % in_sample_roc_auc\n)\nplt.plot(\n    in_sample_fpr, in_sample_tpr, color='navy', label='In-Sample ROC curve (area = %0.4f)' % out_sample_roc_auc\n)\nplt.plot([0, 1], [0, 1], color='gray', lw=1, linestyle='--')\nplt.grid()\nplt.xlim([0.0, 1.0])\nplt.ylim([0.0, 1.05])\nplt.xlabel('False Positive Rate')\nplt.ylabel('True Positive Rate')\nplt.title('RandomForest Model ROC Curve')\nplt.legend(loc=\"lower right\")\n\nplt.show()\n```", "```py\n#### 1\\. Load Data ####\ndf <- read.csv(\n  file=\"~/Documents/data-science-for-marketing/ch.8/data/WA_Fn-UseC_-Marketing-Customer-Value-Analysis.csv\", \n  header=TRUE\n)\n```", "```py\n## 2.1\\. Response Variable: Response\ndf$Engaged <- as.integer(df$Response) - 1\n```", "```py\nmean(df$Engaged)\n```", "```py\n## 2.2\\. Categorical Features\n\ncategoricalVars = c(\n  'Sales.Channel', 'Vehicle.Size', 'Vehicle.Class', 'Policy', 'Policy.Type',\n  'EmploymentStatus', 'Marital.Status', 'Education', 'Coverage', 'Gender'\n)\n```", "```py\nencodedDF <- model.matrix(~.-1, df[categoricalVars])\n```", "```py\n## 2.3\\. Continuous Features\ncontinuousFeatures <- c(\n  'Customer.Lifetime.Value', 'Income', 'Monthly.Premium.Auto',\n  'Months.Since.Last.Claim', 'Months.Since.Policy.Inception',\n  'Number.of.Open.Complaints', 'Number.of.Policies', 'Total.Claim.Amount'\n)\n\nencodedDF <- cbind(encodedDF, df[continuousFeatures])\n```", "```py\ninstall.packages('caTools')\n```", "```py\nlibrary(caTools)\n\nsample <- sample.split(df$Customer, SplitRatio = .7)\n\ntrainX <- as.matrix(subset(encodedDF, sample == TRUE))\ntrainY <- as.double(as.matrix(subset(df$Engaged, sample == TRUE)))\n\ntestX <- as.matrix(subset(encodedDF, sample == FALSE))\ntestY <- as.double(as.matrix(subset(df$Engaged, sample == FALSE)))\n```", "```py\ninstall.packages('randomForest')\n```", "```py\nlibrary(randomForest)\n\nrfModel <- randomForest(x=trainX, y=factor(trainY))\n```", "```py\nrfModel <- randomForest(x=trainX, y=factor(trainY), ntree=200, maxnodes=24)\n```", "```py\npredict(rfModel, trainX, predict.all=TRUE)\n```", "```py\n# - Feature Importances\nimportance(rfModel)\n```", "```py\ninSamplePreds <- as.double(predict(rfModel, trainX)) - 1\noutSamplePreds <- as.double(predict(rfModel, testX)) - 1\n```", "```py\n# - Accuracy\naccuracy <- mean(testY == outSamplePreds)\n\n# - Precision\nprecision <- sum(outSamplePreds & testY) / sum(outSamplePreds)\n\n# - Recall\nrecall <- sum(outSamplePreds & testY) / sum(testY)\n```", "```py\ninstall.packages('ROCR')\n```", "```py\nlibrary(ROCR)\n\ninSamplePredProbs <- as.double(predict(rfModel, trainX, type='prob')[,2])\noutSamplePredProbs <- as.double(predict(rfModel, testX, type='prob')[,2])\n\npred <- prediction(outSamplePredProbs, testY)\nperf <- performance(pred, measure = \"tpr\", x.measure = \"fpr\") \nauc <- performance(pred, measure='auc')@y.values[[1]]\n\nplot(\n  perf, \n  main=sprintf('Random Forest Model ROC Curve (AUC: %0.2f)', auc), \n  col='darkorange', \n  lwd=2\n) + grid()\nabline(a = 0, b = 1, col='darkgray', lty=3, lwd=2)\n```"]