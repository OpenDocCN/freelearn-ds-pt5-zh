- en: My Name is Bayes, Naive Bayes
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: '"Prediction is very difficult, especially if it''s about the future"'
  prefs: []
  type: TYPE_NORMAL
- en: -Niels Bohr
  prefs: []
  type: TYPE_NORMAL
- en: '**Machine learning (ML)** in combination with big data is a radical combination
    that has created some great impacts in the field of research in Academia and Industry.
    Moreover, many research areas are also entering into big data since datasets are
    being generated and produced in an unprecedented way from diverse sources and
    technologies, commonly referred as the **Data Deluge**. This imposes great challenges
    on ML, data analytics tools, and algorithms to find the real **VALUE** out of
    big data criteria such as volume, velocity, and variety. However, making predictions
    from these huge dataset has never been easy.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Considering this challenge, in this chapter we will dig deeper into ML and
    find out how to use a simple yet powerful method to build a scalable classification
    model and even more. In a nutshell, the following topics will be covered throughout
    this chapter:'
  prefs: []
  type: TYPE_NORMAL
- en: Multinomial classification
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Bayesian inference
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Naive Bayes
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Decision trees
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Naive Bayes versus decision trees
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Multinomial classification
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In ML, **multinomial** (also known as multiclass) classification is the task
    of classifying data objects or instances into more than two classes, that is,
    having more than two labels or classes. Classifying data objects or instances
    into two classes is called **binary classification**. More technically, in multinomial
    classification, each training instance belongs to one of N different classes subject
    to `N >=2`. The goal is then to construct a model that correctly predicts the
    classes to which the new instances belong. There may be numerous scenarios having
    multiple categories in which the data points belong. However, if a given point
    belongs to multiple categories, this problem decomposes trivially into a set of
    unlinked binary problems, which can be solved naturally using a binary classification
    algorithm.
  prefs: []
  type: TYPE_NORMAL
- en: Readers are suggested not be confused distinguishing the multiclass classification
    with multilabel classification, where multiple labels are to be predicted for
    each instance. For more on Spark-based implementation for the multilabel classification,
    interested readers should refer to [https://spark.apache.org/docs/latest/mllib-evaluation-metrics.html#multilabel-classification](https://spark.apache.org/docs/latest/mllib-evaluation-metrics.html#multilabel-classification).
  prefs: []
  type: TYPE_NORMAL
- en: 'Multiclass classification techniques can be divided into several categories
    as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: Transformation to binary
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Extension from binary
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Hierarchical classification
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Transformation to binary
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Using the transformation to binary technique, a multiclass classification problem
    can be transformed into an equivalent strategy for multiple binary classification
    problems. In other words, this technique can be referred to as a *problem transformation
    techniques*. A detailed discussion from the theoretical and practical perspectives
    is out of the scope of this chapter. Therefore, here we will discuss only one
    example of the problem transformation technique called **One-Vs-The-Rest** (**OVTR**)
    algorithm as the representative of this category.
  prefs: []
  type: TYPE_NORMAL
- en: Classification using One-Vs-The-Rest approach
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this subsection, we will describe an example of performing multiclass classification
    using the OVTR algorithm by converting the problem into equivalent multiple binary
    classification problems. The OVTR strategy breaks down the problem and trains
    each binary classifier per class. In other words, the OVTR classifier strategy
    consists of fitting one binary classifier per class. It then treats all the samples
    of the current class as positive samples, and consequently other samples of other
    classifiers are treated as negatives samples.
  prefs: []
  type: TYPE_NORMAL
- en: This is a modular machine learning technique no doubt. However, on the downside,
    this strategy requires a base classifier from the multiclass family. The reason
    is that the classifier must produce a real value also called *confidence scores*
    instead of a prediction of the actual labels. The second disadvantage of this
    strategy is that if the dataset (aka training set) contains discrete class labels,
    these eventually lead to vague prediction results. In that case, multiple classes
    can be predicted for a single sample. To make the preceding discussion clearer,
    now let's see an example as follows.
  prefs: []
  type: TYPE_NORMAL
- en: 'Suppose that we have a set of 50 observations divided into three classes. Thus,
    we will use the same logic as before for selecting the negative examples too.
    For the training phase, let''s have the following setting:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Classifier 1** has 30 positive examples and 20 negative examples'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Classifier 2** has 36 positive examples and 14 negative examples'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Classifier 3** has 14 positive examples and 24 negative examples'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: On the other hand, for the testing phase, suppose I have a new instance that
    need to be classified into one of the previous classes. Each of the three classifiers,
    of course, produces a probability with respect to the estimation This is an estimation
    of how low an instance belongs to the negative or positive examples in the classifier?
    In this case, we should always compare the probabilities of positive class in
    one versus the rest. Now that for *N* classes, we will have *N* probability estimates
    of the positive class for one test sample. Compare them, and whichever probability
    is the maximum of *N* probabilities belongs to that particular class. Spark provides
    multiclass to binary reduction with the OVTR algorithm, where the **Logistic Regression**
    algorithm is used as the base classifier.
  prefs: []
  type: TYPE_NORMAL
- en: Now let's see another example of a real dataset to demonstrate how Spark classifies
    all the features using OVTR algorithm. The OVTR classifier eventually predicts
    handwritten characters from the **Optical Character Reader** (**OCR**) dataset.
    However, before diving into the demonstration, let's explore the OCR dataset first
    to get the exploratory nature of the data. It is to be noted that when OCR software
    first processes a document, it divides the paper or any object into a matrix such
    that each cell in the grid contains a single glyph (also known different graphical
    shapes), which is just an elaborate way of referring to a letter, symbol, or number
    or any contextual information from the paper or the object.
  prefs: []
  type: TYPE_NORMAL
- en: To demonstrate the OCR pipeline, let's assume that the document contains only
    alpha characters in English that match glyphs to one of the 26 capital letters,
    that is, *A* to *Z*. We will use the OCR letter dataset from the *UCI Machine
    Learning Data Repository*. The dataset was denoted by W*. Frey* and *D. J. Slate.*
    While exploring the dataset, you should observe 20,000 examples of 26 English
    capital letters. Letter written in capital letters are available as printed using
    20 different, randomly reshaped and distorted black and white fonts as glyphs
    of different shapes. In short, predicting all the characters from 26 alphabets
    turns the problem itself into a multiclass classification problem with 26 classes.
    Consequently, a binary classifier will not be able to serve our purpose.
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/00362.gif)**Figure 1**: Some of the printed glyphs (Source: Letter
    recognition using Holland-style adaptive classifiers, ML, V. 6, p. 161-182, by
    W. Frey and D.J. Slate [1991])'
  prefs: []
  type: TYPE_IMG
- en: 'The preceding figure shows the images that I explained earlier.*The dataset*
    provides an example of some of the printed glyphs distorted in this way; therefore,
    the letters are computationally challenging for a computer to identify. Yet, these
    glyphs are easily recognized by a human being. The following figure shows the
    statistical attributes of the top 20 rows:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/00020.jpeg)**Figure 2:** The snapshot of the dataset shown as the data
    frame'
  prefs: []
  type: TYPE_NORMAL
- en: Exploration and preparation of the OCR dataset
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: According to the dataset description, glyphs are scanned using an OCR reader
    on to the computer then they are automatically converted into pixels. Consequently,
    all the 16 statistical attributes (in **figure 2**) are recorded to the computer
    too. The the concentration of black pixels across various areas of the box provide
    a way to differentiate 26 letters using OCR or a machine learning algorithm to
    be trained.
  prefs: []
  type: TYPE_NORMAL
- en: Recall that **support vector machines** (**SVM**), Logistic Regression, Naive
    Bayesian-based classifier, or any other classifier algorithms (along with their
    associated learners) require all the features to be numeric. LIBSVM allows you
    to use a sparse training dataset in an unconventional format. While transforming
    the normal training dataset to the LIBSVM format. Only the nonzero values that
    are also included in the dataset are stored in a sparse array/matrix form. The
    index specifies the column of the instance data (feature index). However, any
    missing data is taken as holding zero value too. The index serves as a way to
    distinguish between the features/parameters. For example, for three features,
    indices 1, 2, and 3 would correspond to the *x*, *y*, and *z* coordinates, respectively.
    The correspondence between the same index values of different data instances is
    merely mathematical when constructing the hyperplane; these serve as coordinates.
    If you skip any index in between, it should be assigned a default value of zero.
  prefs: []
  type: TYPE_NORMAL
- en: 'In most practical cases, we might need to normalize the data against all the
    features points. In short, we need to convert the current tab-separated OCR data
    into LIBSVM format to make the training step easier. Thus, I''m assuming you have
    downloaded the data and converted into LIBSVM format using their own script. The
    resulting dataset that is transformed into LIBSVM format consisting of labels
    and features is shown in the following figure:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/00223.gif)**Figure 3:** A snapshot of 20 rows of the OCR dataset in
    LIBSVM format'
  prefs: []
  type: TYPE_NORMAL
- en: 'Interested readers can refer to the following research article for gaining
    in-depth knowledge: *Chih-Chung Chang* and *Chih-Jen Lin*, *LIBSVM: a library
    for support vector machines*, *ACM Transactions on Intelligent Systems and Technology*,
    2:27:1--27:27, 2011\. You can also refer to a public script provided on my GitHub
    repository at [https://github.com/rezacsedu/RandomForestSpark/](https://github.com/rezacsedu/RandomForestSpark/)
    that directly converts the OCR data in CSV into LIBSVM format. I read the data
    about all the letters and assigned a unique numeric value to each. All you need
    is to show the input and output file path and run the script.'
  prefs: []
  type: TYPE_NORMAL
- en: Now let's dive into the example. The example that I will be demonstrating has
    11 steps including data parsing, Spark session creation, model building, and model
    evaluation.
  prefs: []
  type: TYPE_NORMAL
- en: '**Step 1\. Creating Spark session** - Create a Spark session by specifying
    master URL, Spark SQL warehouse, and application name as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: '**Step 2\. Loading, parsing, and creating the data frame** - Load the data
    file from the HDFS or local disk and create a data frame, and finally show the
    data frame structure as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: '**Step 3\. Generating training and test set to train the model** - Let''s generate
    the training and test set by splitting 70% for training and 30% for the test:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: '**Step 4\. Instantiate the base classifier** - Here the base classifier acts
    as the multiclass classifier. For this case, it is the Logistic Regression algorithm
    that can be instantiated by specifying parameters such as the number of max iterations,
    tolerance, regression parameter, and Elastic Net parameters.'
  prefs: []
  type: TYPE_NORMAL
- en: Note that Logistic Regression is an appropriate regression analysis to conduct
    when the dependent variable is dichotomous (binary). Like all regression analyses,
    Logistic Regression is a predictive analysis. Logistic regression is used to describe
    data and to explain the relationship between one dependent binary variable and
    one or more nominal, ordinal, interval, or ratio level independent variables.
  prefs: []
  type: TYPE_NORMAL
- en: For a a Spark-based implementation of the Logistic Regression algorithm, interested
    readers can refer to [https://spark.apache.org/docs/latest/mllib-linear-methods.html#logistic-regression](https://spark.apache.org/docs/latest/mllib-linear-methods.html#logistic-regression).
  prefs: []
  type: TYPE_NORMAL
- en: 'In brief, the following parameters are used to training a Logistic Regression
    classifier:'
  prefs: []
  type: TYPE_NORMAL
- en: '`MaxIter`: This specifies the number of maximum iterations. In general, more
    is better.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`Tol`: This is the tolerance for the stopping criteria. In general, less is
    better, which helps the model to be trained more intensively. The default value
    is 1E-4.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`FirIntercept`: This signifies if you want to intercept the decision function
    while generating the probabilistic interpretation.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`Standardization`: This signifies a Boolean value depending upon if would like
    to standardize the training or not.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`AggregationDepth`: More is better.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`RegParam`: This signifies the regression params. Less is better for most cases.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`ElasticNetParam`: This signifies more advanced regression params. Less is
    better for most cases.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Nevertheless, you can specify the fitting intercept as a `Boolean` value as
    true or false depending upon your problem type and dataset properties:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: '**Step 5\. Instantiate the OVTR classifier** - Now instantiate an OVTR classifier
    to convert the multiclass classification problem into multiple binary classifications
    as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: Here `classifier` is the Logistic Regression estimator. Now it's time to train
    the model.
  prefs: []
  type: TYPE_NORMAL
- en: '**Step 6\. Train the multiclass model** - Let''s train the model using the
    training set as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: '**Step 7\. Score the model on the test set** - We can score the model on test
    data using the transformer (that is, `ovrModel`) as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: '**Step 8\. Evaluate the model** - In this step, we will predict the labels
    for the characters in the first column. But before that we need instantiate an
    `evaluator` to compute the classification performance metrics such as accuracy,
    precision, recall, and `f1` measure as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: '**Step 9\. Compute performance metrics** - Compute the classification accuracy,
    precision, recall, `f1` measure, and error on test data as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs: []
  type: TYPE_PRE
- en: '**Step 10.** Print the performance metrics:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs: []
  type: TYPE_PRE
- en: 'You should observe the value as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE10]'
  prefs: []
  type: TYPE_PRE
- en: '**Step 11.** Stop the Spark session:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE11]'
  prefs: []
  type: TYPE_PRE
- en: This way, we can convert a multinomial classification problem into multiple
    binary classifications problem without sacrificing the problem types. However,
    from step 10, we can observe that the classification accuracy is not good at all.
    It might be because of several reasons such as the nature of the dataset we used
    to train the model. Also even more importantly, we did not tune the hyperparameters
    while training the Logistic Regression model. Moreover, while performing the transformation,
    the OVTR had to sacrifice some accuracy.
  prefs: []
  type: TYPE_NORMAL
- en: Hierarchical classification
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In a hierarchical classification task, the classification problem can be resolved
    by dividing the output space into a tree. In that tree, parent nodes are divided
    into multiple child nodes. The process persists until each child node depicts
    a single class. Several methods have been proposed based on the hierarchical classification
    technique. Computer vision is an example of such areas where recognizing pictures
    or written text are something that use hierarchical processing does. An extensive
    discussion on this classifier is out of the scope of this chapter.
  prefs: []
  type: TYPE_NORMAL
- en: Extension from binary
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: This is a technique for extending existing binary classifiers to solve multiclass
    classification problems. To address multiclass classification problems, several
    algorithms have been proposed and developed based on neural networks, DTs, Random
    forest, k-nearest neighbors, Naive Bayes, and SVM. In the following sections,
    we will discuss the Naive Bayes and the DT algorithm as two representatives of
    this category.
  prefs: []
  type: TYPE_NORMAL
- en: Now, before starting to solve multiclass classification problems using Naive
    Bayes algorithms, let's have a brief overview of Bayesian inference in the next
    section.
  prefs: []
  type: TYPE_NORMAL
- en: Bayesian inference
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this section, we will briefly discuss **Bayesian inference** (**BI**) and
    its underlying theory. Readers will be familiar with this concept from the theoretical
    and computational viewpoints.
  prefs: []
  type: TYPE_NORMAL
- en: An overview of Bayesian inference
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Bayesian inference is a statistical method based on Bayes theorem. It is used
    to update the probability of a hypothesis (as a strong statistical proof) so that
    statistical models can repeatedly update towards more accurate learning. In other
    words, all types of uncertainty are revealed in terms of statistical probability
    in the Bayesian inference approach. This is an important technique in theoretical
    as well as mathematical statistics. We will discuss the Bayes theorem broadly
    in a later section.
  prefs: []
  type: TYPE_NORMAL
- en: Furthermore, Bayesian updating is predominantly foremost in the incremental
    learning and dynamic analysis of the sequence of the dataset. For example time
    series analysis, genome sequencing in biomedical data analytics, science, engineering,
    philosophy, and law are some example where Bayesian inference is used widely.
    From the philosophical perspective and decision theory, Bayesian inference is
    strongly correlated to predictive probability. This theory, however, is more formally
    known as the **Bayesian probability**.
  prefs: []
  type: TYPE_NORMAL
- en: What is inference?
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Inference or model evaluation is the process of updating probabilities of the
    denouement derived from the model at the end. As a result, all the probabilistic
    evidence is eventually known against the observation at hand so that observations
    can be updated while using the Bayesian model for classification analysis. Later
    on, this information is fetched to the Bayesian model by instantiating the consistency
    against all the observations in the dataset. The rules that are fetched to the
    model are referred to as prior probabilities where a probability is assessed before
    making reference to certain relevant observations, especially subjectively or
    on the assumption that all possible outcomes be given the same probability. Then
    beliefs are computed when all the evidence is known as posterior probabilities.
    These posterior probabilities reflect the levels of hypothesis computed based
    on updated evidence.
  prefs: []
  type: TYPE_NORMAL
- en: The Bayes theorem is used to compute the posterior probabilities that signify
    a consequence of two antecedents. Based on these antecedents, a prior probability
    and a likelihood function are derived from a statistical model for the new data
    for model adaptability. We will further discuss the Bayes theorem in a later section.
  prefs: []
  type: TYPE_NORMAL
- en: How does it work?
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Here we discuss a general setup for a statistical inference problem. At the
    first place, from the data, we estimate the desired quantity and there might be
    unknown quantities too that we would like to estimate. It could be simply a response
    variable or predicted variable, a class, a label, or simply a number. If you are
    familiar with the *frequentist* approach, you might know that in this approach
    the unknown quantity say `θ` is assumed to be a fixed (nonrandom) quantity that
    is to be estimated by the observed data.
  prefs: []
  type: TYPE_NORMAL
- en: However, in the Bayesian framework, an unknown quantity say `θ` is treated as
    a random variable. More specifically, it is assumed that we have an initial guess
    about the distribution of `θ`, which is commonly referred to as the **prior distribution**.
    Now, after observing some data, the distribution of `θ` is updated. This step
    is usually performed using Bayes' rule (for more details, refer to the next section).
    This is why this approach is called the Bayesian approach. However, in short,
    from the prior distribution, we can compute predictive distributions for future
    observations.
  prefs: []
  type: TYPE_NORMAL
- en: This unpretentious process can be justified as the appropriate methodology to
    uncertain inference with the help of numerous arguments. However, the consistency
    is maintained with the clear principles of the rationality of these arguments.
    In spite of this strong mathematical evidence, many machine learning practitioners
    are uncomfortable with, and a bit reluctant of, using the Bayesian approach. The
    reason behind this is that often they view the selection of a posterior probability
    or prior as being arbitrary and subjective; however, in reality, this is subjective
    but not arbitrary.
  prefs: []
  type: TYPE_NORMAL
- en: Inappropriately, many Bayesians don't really think in true Bayesian terms. One
    can, therefore, find many pseudo-Bayesian procedures in the literature, in which
    models and priors are used that cannot be taken seriously as expressions of prior
    belief. There may also be computational difficulties with the Bayesian approach.
    Many of these can be addressed using **Markov chain Monte Carlo** methods, which
    are another main focus of my research. The details of this approach will be clearer
    as you go through this chapter.
  prefs: []
  type: TYPE_NORMAL
- en: Naive Bayes
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In ML, **Naive Bayes** (**NB**) is an example of the probabilistic classifier
    based on the well-known Bayes' theorem with strong independence assumptions between
    the features. We will discuss Naive Bayes in detail in this section.
  prefs: []
  type: TYPE_NORMAL
- en: An overview of Bayes' theorem
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In probability theory, **Bayes' theorem** describes the probability of an event
    based on a prior knowledge of conditions that is related to that certain event.
    This is a theorem of probability originally stated by the Reverend Thomas Bayes.
    In other words, it can be seen as a way of understanding how the probability theory
    is true and affected by a new piece of information. For example, if cancer is
    related to age, the information about *age* can be used to assess the probability
    that a person might have cancer more accurately*.*
  prefs: []
  type: TYPE_NORMAL
- en: 'Bayes'' theorem is stated mathematically as the following equation:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/00241.gif)'
  prefs: []
  type: TYPE_IMG
- en: 'In the preceding equation, *A* and *B* are events with *P (B) ≠ 0,* and the
    other terms can be described as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '*P*(*A*) and *P*(*B*) are the probabilities of observing *A* and *B* without
    regard to each other (that is, independence)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*P*(*A* | *B*) is the conditional probability of observing event *A* given
    that *B* is true'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*P*(*B*| *A*) is the conditional probability of observing event *B* given that
    *A* is true'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'As you probably know, a well-known Harvard study shows that only 10% of happy
    people are rich. However, you might think that this statistic is very compelling
    but you might be somewhat interested in knowing the percentage of rich people
    are also really happy*.* Bayes'' theorem helps you out on how to calculate this
    reserving statistic using two additional clues:'
  prefs: []
  type: TYPE_NORMAL
- en: The percentage of people overall who are happy, that is, *P(A).*
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: The percentage of people overall who are rich, that is *P(B).*
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'The key idea behind Bayes'' theorem is reversing the statistic considering
    the overall rates**.** Suppose that the following pieces of information are available
    as a prior:'
  prefs: []
  type: TYPE_NORMAL
- en: 40% of people are happy and *=> P(A).*
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 5% of people are rich *=> P(B).*
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Now let''s consider that the Harvard study is correct, that is, *P(B|A) = 10%*.
    Now the fraction of rich people who are happy, that is, *P(A | B),* can be calculated
    as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '*P(A|B) = {P(A)* P(B| A)}/ P(B) = (40%*10%)/5% = 80%*'
  prefs: []
  type: TYPE_NORMAL
- en: 'Consequently, a majority of the people are also happy! Nice. To make it clearer,
    now let''s assume the population of the whole world is 1,000 for simplicity. Then,
    according to our calculation, there are two facts that exist:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Fact 1: This tells us 400 people are happy, and the Harvard study tells us
    that 40 of these happy people are also rich.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Fact 2: There are 50 rich people altogether, and so the fraction who are happy
    is 40/50 = 80%.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: This proves the Bayes theorem and its effectiveness. However, more comprehensive
    examples can be found at [https://onlinecourses.science.psu.edu/stat414/node/43](https://onlinecourses.science.psu.edu/stat414/node/43).
  prefs: []
  type: TYPE_NORMAL
- en: My name is Bayes, Naive Bayes
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: I'm Bayes, Naive Bayes (NB). I'm a successful classifier based upon the principle
    of **maximum a posteriori** (**MAP**). As a classifier, I am highly scalable,
    requiring a number of parameters linear in the number of variables (features/predictors)
    in a learning problem. I have several properties, for example, I am computationally
    faster, if you can hire me to classify something I'm simple to implement, and
    I can work well with high-dimensional datasets. Moreover, I can handle missing
    values in your dataset. Nevertheless, I'm adaptable since the model can be modified
    with new training data without rebuilding the model.
  prefs: []
  type: TYPE_NORMAL
- en: In Bayesian statistics, a MAP estimate is an estimate of an unknown quantity
    that equals the mode of the posterior distribution. The MAP estimate can be used
    to obtain a point estimate of an unobserved quantity on the basis of empirical
    data.
  prefs: []
  type: TYPE_NORMAL
- en: 'Sounds something similar to James Bond movies? Well, you/we can think a classifer
    as agent 007, right? Just kidding. I believe I am not as the parameters of the
    Naive Bayes classifier such as priori and conditional probabilities are learned
    or rather determined using a deterministic set of steps: this involves two very
    trivial operations that can be blindingly fast on modern computers, that is, counting
    and dividing. There is no *iteration*. There is no *epoch*. There is *no optimization
    of a cost equation* (which can be complex, of cubic order on an average or at
    least of square order complexity). There is no *error back-propagation*. There
    is no operation(s) involving *solving a matrix equation*. These make Naive Bayes
    and its overall training faster.'
  prefs: []
  type: TYPE_NORMAL
- en: 'However, before hiring this agent, you/we can discover his pros and cons so
    that we can use this agent like a trump card by utilizing it''s best only. Well,
    here''s table summarizing the pros and cons of this agent:'
  prefs: []
  type: TYPE_NORMAL
- en: '| **Agent** | **Pros** | **Cons** | **Better at** |'
  prefs: []
  type: TYPE_TB
- en: '| **Naive Bayes (NB)** | - Computationally fast- Simple to implement- Works
    well with high dimensions- Can handle missing values- Requires a small amount
    of data to train the model - It is scalable- Is adaptable since the model can
    be modified with new training data without rebuilding the model | - Relies on
    independence assumptions and so performs badly if the assumption does not meet-
    Relatively low accuracy- If you have no occurrences of a class label and a certain
    attribute value together then the frequency-based probability estimate will be
    zero | - When data has lots of missing values- When dependencies of features from
    each other are similar between features- Spam filtering and classification- Classifying
    a news article about technology, politics, sports, and so on.- Text mining |'
  prefs: []
  type: TYPE_TB
- en: '**Table 1:** Pros and the cons of the Naive Bayes algorithm'
  prefs: []
  type: TYPE_NORMAL
- en: Building a scalable classifier with NB
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this section, we will see a step-by-step example using **Naive Bayes** (**NB**)
    algorithm. As already stated, NB is highly scalable, requiring a number of parameters
    linear in the number of variables (features/predictors) in a learning problem.
    This scalability has enabled the Spark community to make predictive analytics
    on large-scale datasets using this algorithm. The current implementation of NB
    in Spark MLlib supports both the multinomial NB and Bernoulli NB.
  prefs: []
  type: TYPE_NORMAL
- en: Bernoulli NB is useful if the feature vectors are binary. One application would
    be text classification with a bag of words (BOW) approach. On the other hand,
    multinomial NB is typically used for discrete counts. For example, if we have
    a text classification problem, we can take the idea of Bernoulli trials one step
    further and instead of BOW in a document we can use the frequency count in a document.
  prefs: []
  type: TYPE_NORMAL
- en: 'In this section, we will see how to predict the digits from the **Pen-Based
    Recognition of Handwritten Digits** dataset by incorporating Spark machine learning
    APIs including Spark MLlib, Spark ML, and Spark SQL:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Step 1\. Data collection, preprocessing, and exploration** - The Pen-based
    recognition of handwritten digits dataset was downloaded from the UCI Machine
    Learning Repository at [https://www.csie.ntu.edu.tw/~cjlin/libsvmtools/datasets/multiclass/pendigits.](https://www.csie.ntu.edu.tw/~cjlin/libsvmtools/datasets/multiclass/pendigits)
    This dataset was generated after collecting around 250 digit samples each from
    44 writers, correlated to the location of the pen at fixed time intervals of 100
    milliseconds. Each digit was then written inside a 500 x 500 pixel box. Finally,
    those images were scaled to an integer value between 0 and 100 to create consistent
    scaling between each observation. A well-known spatial resampling technique was
    used to obtain 3 and 8 regularly spaced points on an arc trajectory. A sample
    image along with the lines from point to point can be visualized by plotting the
    3 or 8 sampled points based on their (x, y) coordinates; it looks like what is
    shown in the following table:'
  prefs: []
  type: TYPE_NORMAL
- en: '| Set | ''0'' | ''1'' | ''2'' | ''3'' | ''4'' | ''5'' | ''6'' | ''7'' | ''8''
    | ''9'' | Total |'
  prefs: []
  type: TYPE_TB
- en: '| Training | 780 | 779 | 780 | 719 | 780 | 720 | 720 | 778 | 718 | 719 | 7493
    |'
  prefs: []
  type: TYPE_TB
- en: '| Test | 363 | 364 | 364 | 336 | 364 | 335 | 336 | 364 | 335 | 336 | 3497 |'
  prefs: []
  type: TYPE_TB
- en: 'Table 2: Number of digits used for the training and the test set'
  prefs: []
  type: TYPE_NORMAL
- en: As shown in the preceding table, the training set consists of samples written
    by 30 writers and the testing set consists of samples written by 14 writers.
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/00130.jpeg)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 4: Example of digit 3 and 8 respectively'
  prefs: []
  type: TYPE_NORMAL
- en: 'More on this dataset can be found at [http://archive.ics.uci.edu/ml/machine-learning-databases/pendigits/pendigits-orig.names](http://archive.ics.uci.edu/ml/machine-learning-databases/pendigits/pendigits-orig.names).
    A digital representation of a sample snapshot of the dataset is shown in the following
    figure:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/00149.gif)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 5: A snap of the 20 rows of the hand-written digit dataset'
  prefs: []
  type: TYPE_NORMAL
- en: Now to predict the dependent variable (that is, label) using the independent
    variables (that is, features), we need to train a multiclass classifier since,
    as shown previously, the dataset now has nine classes, that is, nine handwritten
    digits. For the prediction, we will use the Naive Bayes classifier and evaluate
    the model's performance.
  prefs: []
  type: TYPE_NORMAL
- en: '**Step 2.** Load the required library and packages:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE12]'
  prefs: []
  type: TYPE_PRE
- en: '**Step 3.** Create an active Spark session:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE13]'
  prefs: []
  type: TYPE_PRE
- en: Note that here the master URL has been set as `local[*]`, which means all the
    cores of your machine will be used for processing the Spark job. You should set
    SQL warehouse accordingly and other configuration parameter based on the requirements.
  prefs: []
  type: TYPE_NORMAL
- en: '**Step 4\. Create the DataFrame** - Load the data stored in LIBSVM format as
    a DataFrame:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE14]'
  prefs: []
  type: TYPE_PRE
- en: For digits classification, the input feature vectors are usually sparse, and
    sparse vectors should be supplied as input to take advantage of sparsity. Since
    the training data is only used once, and moreover the size of the dataset is relatively
    smaller (that is, few MBs), we can cache it if you use the DataFrame more than
    once.
  prefs: []
  type: TYPE_NORMAL
- en: '**Step 5\. Prepare the training and test set** - Split the data into training
    and test sets (25% held out for testing):'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE15]'
  prefs: []
  type: TYPE_PRE
- en: '**Step 6\. Train the Naive Bayes model** - Train a Naive Bayes model using
    the training set as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE16]'
  prefs: []
  type: TYPE_PRE
- en: '**Step 7\. Calculate the prediction on the test set** - Calculate the prediction
    using the model transformer and finally show the prediction against each label
    as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE17]'
  prefs: []
  type: TYPE_PRE
- en: '![](img/00189.jpeg)**Figure 6:** Prediction against each label (that is, each
    digit)'
  prefs: []
  type: TYPE_IMG
- en: As you can see in the preceding figure, some labels were predicted accurately
    and some of them were wrongly. Again we need to know the weighted accuracy, precision,
    recall and f1 measures without evaluating the model naively.
  prefs: []
  type: TYPE_NORMAL
- en: '**Step 8\. Evaluate the model** - Select the prediction and the true label
    to compute test error and classification performance metrics such as accuracy,
    precision, recall, and f1 measure as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE18]'
  prefs: []
  type: TYPE_PRE
- en: '**Step 9\. Compute the performance metrics** - Compute the classification accuracy,
    precision, recall, f1 measure, and error on test data as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE19]'
  prefs: []
  type: TYPE_PRE
- en: '**Step 10.** Print the performance metrics:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE20]'
  prefs: []
  type: TYPE_PRE
- en: 'You should observe values as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE21]'
  prefs: []
  type: TYPE_PRE
- en: The performance is not that bad. However, you can still increase the classification
    accuracy by performing hyperparameter tuning. There are further opportunities
    to improve the prediction accuracy by selecting appropriate algorithms (that is,
    classifier or regressor) through cross-validation and train split, which will
    be discussed in the following section.
  prefs: []
  type: TYPE_NORMAL
- en: Tune me up!
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: You already know my pros and cons, I have a con that is, my classification accuracy
    is relatively low. However, if you tune me up, I can perform much better. Well,
    should we trust Naive Bayes? If so, shouldn't we look at how to increase the prediction
    performance of this guy? Let's say using the WebSpam dataset. At first, we should
    observe the performance of the NB model, and after that we will see how to increase
    the performance using the cross-validation technique.
  prefs: []
  type: TYPE_NORMAL
- en: 'The WebSpam dataset that downloaded from [http://www.csie.ntu.edu.tw/~cjlin/libsvmtools/datasets/binary/webspam_wc_normalized_trigram.svm.bz2](http://www.csie.ntu.edu.tw/~cjlin/libsvmtools/datasets/binary/webspam_wc_normalized_trigram.svm.bz2)
    contains features and corresponding labels, that is, spam or ham. Therefore, this
    is a supervised machine learning problem, and the task here is to predict whether
    a given message is spam or ham (that is, not spam). The original dataset size
    is 23.5 GB, where the classes are labeled as +1 or -1 (that is, a binary classification
    problem). Later on, we replaced -1 with 0.0 and +1 with 1.0 since Naive Bayes
    does not permit using signed integers. The modified dataset is shown in the following
    figure:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/00054.gif)**Figure 7:** A snapshot of the 20 rows of the WebSpam dataset'
  prefs: []
  type: TYPE_NORMAL
- en: 'At first, we need to import necessary packages as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE22]'
  prefs: []
  type: TYPE_PRE
- en: 'Now create the Spark Session as the entry point to the code as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE23]'
  prefs: []
  type: TYPE_PRE
- en: 'Let''s load the WebSpam dataset and prepare the training set to train the Naive
    Bayes model as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE24]'
  prefs: []
  type: TYPE_PRE
- en: 'In the preceding code, setting the seed is required for reproducibility. Now
    let''s make the prediction on the validation set as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE25]'
  prefs: []
  type: TYPE_PRE
- en: 'Now let''s obtain `evaluator` and compute the classification performance metrics
    like accuracy, precision, recall, and `f1` measure as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE26]'
  prefs: []
  type: TYPE_PRE
- en: 'Now let''s compute and print the performance metrics:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE27]'
  prefs: []
  type: TYPE_PRE
- en: 'You should receive the following output:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE28]'
  prefs: []
  type: TYPE_PRE
- en: 'Although the accuracy is at a satisfactory level, we can further improve it
    by applying the cross-validation technique. The technique goes as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: Create a pipeline by chaining an NB estimator as the only stage of the pipeline
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Now prepare the param grid for tuning
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Perform the 10-fold cross-validation
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Now fit the model using the training set
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Compute the prediction on the validation set
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The first step in model tuning techniques such as cross-validation is pipeline
    creation. A pipeline can be created by chaining a transformer, an estimator, and
    related parameters.
  prefs: []
  type: TYPE_NORMAL
- en: '**Step 1\. Pipeline creation** - Let''s create a Naive Bayes estimator (`nb`
    is an estimator in the following case) and create a pipeline by chaining the estimator
    as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE29]'
  prefs: []
  type: TYPE_PRE
- en: A pipeline can be considered as the data workflow system for training and prediction
    using the model. ML pipelines provide a uniform set of high-level APIs built on
    top of [DataFrames](https://spark.apache.org/docs/latest/sql-programming-guide.html)
    that help users create and tune practical machine learning pipelines. DataFrame,
    transformer, estimator, pipeline, and parameter are the five most important components
    in Pipeline creation. For more on Pipeline, interested readers should refer to
    [https://spark.apache.org/docs/latest/ml-pipeline.html](https://spark.apache.org/docs/latest/ml-pipeline.html)
  prefs: []
  type: TYPE_NORMAL
- en: In the earlier case, the only stage in our pipeline is an estimator that is
    an algorithm for fitting on a DataFrame to produce a transformer to make sure
    the training is carried out successfully.
  prefs: []
  type: TYPE_NORMAL
- en: '**Step 2\. Creating grid parameters** - Let''s use `ParamGridBuilder` to construct
    a grid of parameters to search over:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE30]'
  prefs: []
  type: TYPE_PRE
- en: '**Step 3\. Performing 10-fold cross-validation** - We now treat the pipeline
    as an estimator, wrapping it in a cross-validator instance. This will allow us
    to jointly choose parameters for all Pipeline stages. A `CrossValidator` requires
    an estimator, a set of estimator `ParamMaps`, and an evaluator. Note that the
    evaluator here is a `BinaryClassificationEvaluator`, and its default metric is
    `areaUnderROC`. However, if you use the evaluator as `MultiClassClassificationEvaluator`,
    you will be able to use the other performance metrics as well:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE31]'
  prefs: []
  type: TYPE_PRE
- en: '**Step 4.** Fit the cross-validation model with the training set as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE32]'
  prefs: []
  type: TYPE_PRE
- en: '**Step 5.** Compute performance as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE33]'
  prefs: []
  type: TYPE_PRE
- en: '**Step 6.** Obtain the evaluator, compute the performance metrics, and display
    the results. Now let''s obtain `evaluator` and compute the classification performance
    metrics such as accuracy, precision, recall, and f1 measure. Here `MultiClassClassificationEvaluator`
    will be used for accuracy, precision, recall, and f1 measure:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE34]'
  prefs: []
  type: TYPE_PRE
- en: 'Now compute the classification accuracy, precision, recall, f1 measure, and
    error on test data as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE35]'
  prefs: []
  type: TYPE_PRE
- en: 'Now let''s print the performance metrics:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE36]'
  prefs: []
  type: TYPE_PRE
- en: 'You should now receive the results as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE37]'
  prefs: []
  type: TYPE_PRE
- en: Now this is much better compared to the previous one, right? Please note that
    you might receive a slightly different result due to the random split of the dataset
    and your platform.
  prefs: []
  type: TYPE_NORMAL
- en: The decision trees
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this section, we will discuss the DT algorithm in detail. A comparative analysis
    of Naive Bayes and DT will be discussed too. DTs are commonly considered as a
    supervised learning technique used for solving classification and regression tasks.
    A DT is simply a decision support tool that uses a tree-like graph (or a model
    of decisions) and their possible consequences, including chance event outcomes,
    resource costs, and utility. More technically, each branch in a DT represents
    a possible decision, occurrence, or reaction in terms of statistical probability.
  prefs: []
  type: TYPE_NORMAL
- en: Compared to Naive Bayes, DT is a far more robust classification technique. The
    reason is that at first DT splits the features into training and test set. Then
    it produces a good generalization to infer the predicted labels or classes. Most
    interestingly, DT algorithm can handle both binary and multiclass classification
    problems.
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/00081.jpeg)**Figure 8:** A sample decision tree on the admission test
    dataset using the Rattle package of R'
  prefs: []
  type: TYPE_NORMAL
- en: For instance, in the preceding example figure, DTs learn from the admission
    data to approximate a sine curve with a set of `if...else` decision rules. The
    dataset contains the record of each student who applied for admission, say to
    an American university. Each record contains the graduate record exam score, CGPA
    score, and the rank of the column. Now we will have to predict who is competent
    based on these three features (variables). DTs can be used to solve this kind
    of problem after training the DT model and pruning unwanted branches of the tree.
    In general, a deeper tree signifies more complex decision rules and a better fitted
    model. Therefore, the deeper the tree, the more complex the decision rules and
    the more fitted the model.
  prefs: []
  type: TYPE_NORMAL
- en: If you would like to draw the preceding figure, just run my R script, execute
    it on RStudio, and feed the admission dataset. The script and the dataset can
    be found in my GitHub repository at [https://github.com/rezacsedu/AdmissionUsingDecisionTree](https://github.com/rezacsedu/AdmissionUsingDecisionTree).
  prefs: []
  type: TYPE_NORMAL
- en: Advantages and disadvantages of using DTs
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Before hiring me, you can discover my pros and cons and when I work best from
    Table 3 so that you don't have any late regrets!
  prefs: []
  type: TYPE_NORMAL
- en: '| **Agent** | **Pros** | **Cons** | **Better at** |'
  prefs: []
  type: TYPE_TB
- en: '| **Decision trees (DTs)** | -Simple to implement, train, and interpret-Trees
    can be visualized-Requires little data preparation-Less model building and prediction
    time-Can handle both numeric and categorical data-Possible of validating the model
    using the statistical tests-Robust against noise and missing values-High accuracy
    | -Interpretation is hard with large and complex trees-Duplication may occur within
    the same subtree-Possible issues with diagonal decision boundaries-DT learners
    can create overcomplex trees that do not generalize data well-Sometimes DTs can
    be unstable because of small variants in the data-Learning the DTs itself an NP-complete
    problem (aka. nondeterministic polynomial time -complete problem)-DTs learners
    create biased trees if some classes dominate | -Targeting highly accurate classification-Medical
    diagnosis and prognosis-Credit risk analytics |'
  prefs: []
  type: TYPE_TB
- en: '**Table 3:** Pros and cons of the decision tree'
  prefs: []
  type: TYPE_NORMAL
- en: Decision tree versus Naive Bayes
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: As stated in the preceding table, DTs are very easy to understand and debug
    because of their flexibility for training datasets. They will work with both classification
    as well as regression problems.
  prefs: []
  type: TYPE_NORMAL
- en: If you are trying to predict values out of categorical or continuous values,
    DTs will handle both problems. Consequently, if you just have tabular data, feed
    it to the DT and it will build the model toward classifying your data without
    any additional requirement for upfront or manual interventions. In summary, DTs
    are very simple to implement, train, and interpret. With very little data preparation,
    DTs can build the model with much less prediction time. As said earlier, they
    can handle both numeric and categorical data and are very robust against noise
    and missing values. They are very easy to validate the model using statistical
    tests. More interestingly, the constructed trees can be visualized. Overall, they
    provide very high accuracy.
  prefs: []
  type: TYPE_NORMAL
- en: However, on the downside, DTs sometimes tend to the overfitting problem for
    the training data. This means that you generally have to prune the tree and find
    an optimal one for better classification or regression accuracy. Moreover, duplication
    may occur within the same subtree. Sometimes it also creates issues with diagonal
    decision boundaries towards overfitting and underfitting. Furthermore, DT learners
    can create over-complex trees that do not generalize the data well this makes
    overall interpretation hard. DTs can be unstable because of small variants in
    the data, and as a result learning DT is itself an NP-complete problem. Finally,
    DT learners create biased trees if some classes dominate over others.
  prefs: []
  type: TYPE_NORMAL
- en: Readers are suggested to refer to *Tables 1* and *3* to get a comparative summary
    between Naive Bayes and DTs.
  prefs: []
  type: TYPE_NORMAL
- en: 'On the other hand, there is a saying while using Naive Bayes: *NB requires
    you build a classification by hand*. There''s no way to feed a bunch of tabular
    data to it, and it picks the best features for the classification. In this case,
    however, choosing the right features and features that matter is up to the user,
    that is, you. On the other hand, DTs will pick the best features from tabular
    data. Given this fact, you probably need to combine Naive Bayes with other statistical
    techniques to help toward best feature extraction and classify them later on.
    Alternatively, use DTs to get better accuracy in terms of precision, recall, and
    f1 measure. Another positive thing about Naive Bayes is that it will answer as
    a continuous classifier. However, the downside is that they are harder to debug
    and understand. Naive Bayes does quite well when the training data doesn''t have
    good features with low amounts of data.'
  prefs: []
  type: TYPE_NORMAL
- en: In summary, if you are trying to choose the better classifier from these two
    often times it is best to test each one to solve a problem. My recommendation
    would be to build a DT as well as a Naive Bayes classifier using the training
    data you have and then compare the performance using available performance metrics
    and then decide which one best solves your problem subject to the dataset nature.
  prefs: []
  type: TYPE_NORMAL
- en: Building a scalable classifier with DT algorithm
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'As you have already seen, using the OVTR classifier we observed the following
    values of the performance metrics on the OCR dataset:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE38]'
  prefs: []
  type: TYPE_PRE
- en: This signifies that the accuracy of the model on that dataset is very low. In
    this section, we will see how we could improve the performance using the DT classifier.
    An example with Spark 2.1.0 will be shown using the same OCR dataset. The example
    will have several steps including data loading, parsing, model training, and,
    finally, model evaluation.
  prefs: []
  type: TYPE_NORMAL
- en: 'Since we will be using the same dataset, to avoid redundancy, we will escape
    the dataset exploration step and will enter into the example:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Step 1.** Load the required library and packages as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE39]'
  prefs: []
  type: TYPE_PRE
- en: '**Step 2.** Create an active Spark session as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE40]'
  prefs: []
  type: TYPE_PRE
- en: Note that here the master URL has been set as `local[*]`, which means all the
    cores of your machine will be used for processing the Spark job. You should set
    SQL warehouse accordingly and other configuration parameter based on requirements.
  prefs: []
  type: TYPE_NORMAL
- en: '**Step 3\. Create the DataFrame** - Load the data stored in LIBSVM format as
    a DataFrame as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE41]'
  prefs: []
  type: TYPE_PRE
- en: For the classification of digits, the input feature vectors are usually sparse,
    and sparse vectors should be supplied as input to take advantage of the sparsity.
    Since the training data is only used once, and moreover the size of the dataset
    is relatively small (that is, a few MBs), we can cache it if you use the DataFrame
    more than once.
  prefs: []
  type: TYPE_NORMAL
- en: '**Step 4\. Label indexing** - Index the labels, adding metadata to the label
    column. Then let''s fit on the whole dataset to include all labels in the index:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE42]'
  prefs: []
  type: TYPE_PRE
- en: '**Step 5\. Identifying categorical features** - The following code segment
    automatically identifies categorical features and indexes them:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE43]'
  prefs: []
  type: TYPE_PRE
- en: For this case, if the number of features is more than four distinct values,
    they will be treated as continuous.
  prefs: []
  type: TYPE_NORMAL
- en: '**Step 6\. Prepare the training and test sets** - Split the data into training
    and test sets (25% held out for testing):'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE44]'
  prefs: []
  type: TYPE_PRE
- en: '**Step 7.** Train the DT model as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE45]'
  prefs: []
  type: TYPE_PRE
- en: '**Step 8.** Convert the indexed labels back to original labels as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE46]'
  prefs: []
  type: TYPE_PRE
- en: '**Step 9\. Create a DT pipeline** - Let''s create a DT pipeline by changing
    the indexers, label converter and tree together:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE47]'
  prefs: []
  type: TYPE_PRE
- en: '**Step 10\. Running the indexers** - Train the model using the transformer
    and run the indexers:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE48]'
  prefs: []
  type: TYPE_PRE
- en: '**Step 11\. Calculate the prediction on the test set** - Calculate the prediction
    using the model transformer and finally show the prediction against each label
    as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE49]'
  prefs: []
  type: TYPE_PRE
- en: '![](img/00344.jpeg)**Figure 9:** Prediction against each label (that is, each
    letter)'
  prefs: []
  type: TYPE_IMG
- en: As you can see from the preceding figure, some labels were predicted accurately
    and some of them were predicted wrongly. However, we know the weighted accuracy,
    precision, recall, and f1 measures, but we need to evaluate the model first.
  prefs: []
  type: TYPE_NORMAL
- en: '**Step 12\. Evaluate the model** - Select the prediction and the true label
    to compute test error and classification performance metrics such as accuracy,
    precision, recall, and f1 measure as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE50]'
  prefs: []
  type: TYPE_PRE
- en: '**Step 13\. Compute the performance metrics** - Compute the classification
    accuracy, precision, recall, f1 measure, and error on test data as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE51]'
  prefs: []
  type: TYPE_PRE
- en: '**Step 14.** Print the performance metrics:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE52]'
  prefs: []
  type: TYPE_PRE
- en: 'You should observe values as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE53]'
  prefs: []
  type: TYPE_PRE
- en: Now the performance is excellent, right? However, you can still increase the
    classification accuracy by performing hyperparameter tuning. There are further
    opportunities to improve the prediction accuracy by selecting appropriate algorithms
    (that is, classifier or regressor) through cross-validation and train split.
  prefs: []
  type: TYPE_NORMAL
- en: '**Step 15.** Print the DT nodes:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE54]'
  prefs: []
  type: TYPE_PRE
- en: 'Finally, we will print a few nodes in the DT, as shown in the following figure:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/00199.gif)**Figure 10:** A few decision tree nodes that were generated
    during the model building'
  prefs: []
  type: TYPE_NORMAL
- en: Summary
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this chapter, we discussed some advanced algorithms in ML and found out how
    to use a simple yet powerful method of Bayesian inference to build another kind
    of classification model, multinomial classification algorithms. Moreover, the
    Naive Bayes algorithm was discussed broadly from the theoretical and technical
    perspectives. At the last pace, a comparative analysis between the DT and Naive
    Bayes algorithms was discussed and a few guidelines were provided.
  prefs: []
  type: TYPE_NORMAL
- en: In the next chapter*,* we will dig even deeper into ML and find out how we can
    take advantage of ML to cluster records belonging to a dataset of unsupervised
    observations.
  prefs: []
  type: TYPE_NORMAL
