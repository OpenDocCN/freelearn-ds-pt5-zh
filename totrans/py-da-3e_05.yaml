- en: Linear Algebra
  prefs: []
  type: TYPE_NORMAL
- en: Both linear algebra and statistics are the foundation for any kind of data analysis
    activity. Statistics help us to get an initial descriptive understanding and make
    inferences from data. In the previous chapter, we have understood descriptive
    and inferential statistical measures for data analysis. On the other side, linear
    algebra is one of the fundamental mathematical subjects that is the core foundation
    for any data professional. Linear algebra is useful for working with vectors and
    matrices. Most of the data is available in the form of either a vector or a matrix.
    In-depth knowledge of linear algebra helps data analysts and data scientists understand
    the workflow of machine learning and deep learning algorithms, giving them the
    flexibility to design and modify the algorithms as per your business needs. For
    example, if you want to work with **principal component analysis** (**PCA**) you
    must know the basics of Eigenvalues and Eigenvectors, or if you want to develop
    a recommender system you must know **singular value decomposition** (**SVD**).
    A solid background in mathematics and statistics will facilitate a smoother transition
    into the world of data analytics.
  prefs: []
  type: TYPE_NORMAL
- en: This chapter mainly focuses on the core concepts of linear algebra, such as
    polynomials, determinant, matrix inverse; solving linear equations; eigenvalues
    and eigenvectors; SVD; random numbers; binomial and normal distributions; normality
    tests; and masked arrays. We can also perform these operations in Python using
    the NumPy and SciPy packages. NumPy and SciPy both offer the `linalg` package
    for linear algebra operations.
  prefs: []
  type: TYPE_NORMAL
- en: 'In this chapter, we will cover the following topics:'
  prefs: []
  type: TYPE_NORMAL
- en: Fitting to polynomials with NumPy
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Determinant
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Finding the rank of a matrix
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Matrix inverse using NumPy
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Solving linear equations using NumPy
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Decomposing a matrix using SVD
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Eigenvectors and Eigenvalues using NumPy
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Generating random numbers
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Binomial distribution
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Normal distribution
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Testing normality of data using SciPy
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Creating a masked array using the `numpy.ma` subpackage
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Technical requirements
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'For this chapter, the following technical information is available:'
  prefs: []
  type: TYPE_NORMAL
- en: 'You can find the code and the dataset at the following GitHub link: [https://github.com/PacktPublishing/Python-Data-Analysis-Third-Edition/tree/master/Chapter04](https://github.com/PacktPublishing/Python-Data-Analysis-Third-Edition/tree/master/Chapter04).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: All the code blocks are available in `ch4.ipynb`.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: In this chapter, we will use the NumPy, SciPy, Matplotlib, and Seaborn Python
    libraries.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Fitting to polynomials with NumPy
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Polynomials are mathematical expressions with non-negative strategies. Examples
    of polynomial functions are linear, quadratic, cubic, and quartic functions. NumPy
    offers the `polyfit()` function to generate polynomials using least squares. This
    function takes *x*-coordinate, *y-*coordinate, and degree as parameters, and returns
    a list of polynomial coefficients.
  prefs: []
  type: TYPE_NORMAL
- en: NumPy also offers `polyval()` to evaluate the polynomial at given values. This
    function takes coefficients of polynomials and arrays of points and returns resultant
    values of polynomials. Another function is `linspace()`, which generates a sequence
    of equally separated values. It takes the start, stop, and the number of values
    between the start-stop range and returns equally separated values in the closed
    interval.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let''s see an example to generate and evaluate polynomials using NumPy, as
    follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: 'This results in the following output:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/c79900f3-28a4-4245-a644-e23c87980cf7.png)'
  prefs: []
  type: TYPE_IMG
- en: The graph shown in the preceding screenshot will change in each iteration using
    the program written previously. The reason for this fluctuation is the random
    value generation of vectors.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let''s jump on to the next topic: *Determinant*. We will perform most of the
    linear algebra operations using the `numpy.linalg` subpackage. NumPy offers the
    `linalg` subpackage for linear algebra. We can use linear algebra for matrix operations
    such as inverse, rank, eigenvalues, eigenvectors, solving linear equations, and
    performing linear regression.'
  prefs: []
  type: TYPE_NORMAL
- en: Determinant
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'The determinant is the most essential concept of linear algebra. It is a scalar
    value that is calculated from a square matrix. The determinant is a fundamental
    operation that helps us in the inverse matrix and in solving linear equations.
    Determinants are only calculated for square matrices. A square matrix has an equal
    number of rows and columns. The `numpy.linalg` subpackage provides the `det()`
    function for calculating the determinant of a given input matrix. Let''s compute
    the determinant in the following code block:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: 'This results in the following output:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: In the preceding code block, we have calculated the determinant of a given matrix
    using the `np.linalg.det()` method. Let's understand one more concept of linear
    algebra, which is rank, and compute it using the `numpy.linalg` subpackage.
  prefs: []
  type: TYPE_NORMAL
- en: Finding the rank of a matrix
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Rank is a very important concept when it comes to solving linear equations.
    The rank of a matrix represents the amount of information that is kept in the
    matrix. A lower rank means less information, and a higher rank means a high amount
    of information. Rank can be defined as the number of independent rows or columns
    of a matrix. The `numpy.linalg` subpackage provides the `matrix_rank()` function.
    The `matrix_rank()` function takes the matrix as input and returns the computed
    rank of the matrix. Let''s see an example of the `matrix_rank()` function in the
    following code block:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: 'This results in the following output:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: 'In the preceding code block, the `matrix_rank()` function of `numpy.linalg`
    is used to generate the rank of the matrix. Let''s see another important concept
    of linear algebra: matrix inverse.'
  prefs: []
  type: TYPE_NORMAL
- en: Matrix inverse using NumPy
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'A matrix is a rectangular sequence of numbers, expressions, and symbols organized
    in rows and columns. The multiplication of a square matrix and its inverse is
    equal to the identity matrix I. We can write it using the following equation:'
  prefs: []
  type: TYPE_NORMAL
- en: AA^(-1)= I
  prefs: []
  type: TYPE_NORMAL
- en: 'The `numpy.linalg` subpackage provides a function for an inverse operation:
    the `inv()` function. Let''s invert a matrix using the `numpy.linalg` subpackage.
    First, we create a matrix using the `mat()` function and then find the inverse
    of the matrix using the `inv()` function, as illustrated in the following code
    block:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: 'This results in the following output:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: In the preceding code block, we have computed the inverse of a matrix using
    the `inv()` function of the `numpy.linalg` subpackage.
  prefs: []
  type: TYPE_NORMAL
- en: If the given input matrix is not a square matrix and a singular matrix, it will
    raise a `LinAlgError` error. If you want, you can test the `inv()` function manually.
    I will leave this as an activity for you.
  prefs: []
  type: TYPE_NORMAL
- en: Solving linear equations using NumPy
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Matrix operations can transform one vector into another vector. These operations
    will help us to find the solution for linear equations. NumPy provides the `solve()`
    function to solve linear equations in the form of Ax=B. Here, A is the n*n matrix,
    B is a one-dimensional array and x is the unknown one-dimensional vector. We will
    also use the `dot()` function to compute the dot product of two floating-point
    number arrays.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let''s solve an example of linear equations, as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Create matrix A and array B for a given equation, like this:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: x1+x2 = 200
  prefs: []
  type: TYPE_NORMAL
- en: 3x1+2x2 = 450
  prefs: []
  type: TYPE_NORMAL
- en: This is illustrated in the following code block
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: 'This results in the following output:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs: []
  type: TYPE_PRE
- en: In the preceding code block, we have created a 2*2 matrix and a vector.
  prefs: []
  type: TYPE_NORMAL
- en: 'Solve a linear equation using the `solve()` function, like this:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs: []
  type: TYPE_PRE
- en: 'This results in the following output:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE10]'
  prefs: []
  type: TYPE_PRE
- en: In the preceding code block, we have solved a linear equation using the `solve()`
    function of the `numpy.linalg` subpackage.
  prefs: []
  type: TYPE_NORMAL
- en: 'Check the solution using the `dot()` function, like this:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE11]'
  prefs: []
  type: TYPE_PRE
- en: 'This results in the following output:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE12]'
  prefs: []
  type: TYPE_PRE
- en: In the preceding code block, we have assessed the solution using the `dot()`
    function. You can see the dot product of A and the solution is equivalent to B.
    Till now, we have seen the determinant, rank, inverse, and how to solve linear
    equations. Let's jump to SVD for matrix decomposition.
  prefs: []
  type: TYPE_NORMAL
- en: Decomposing a matrix using SVD
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Matrix decomposition is the process of splitting a matrix into parts. It is
    also known as matrix factorization. There are lots of matrix decomposition methods
    available such as **lower-upper** (**LU**) decomposition, **QR** decomposition
    (where **Q** is orthogonal and **R** is upper-triangular), Cholesky decomposition,
    and SVD.
  prefs: []
  type: TYPE_NORMAL
- en: 'Eigenanalysis decomposes a matrix into vectors and values. SVD decomposes a
    matrix into the following parts: singular vectors and singular values. SVD is
    widely used in signal processing, computer vision, **natural language processing**
    (**NLP**), and machine learning—for example, topic modeling and recommender systems
    where SVD is widely accepted and implemented in real-life business solutions.
    Have a look at the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/5532eee3-3544-47cb-a869-9f70db9ea0c0.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Here, *A* is a *m* x *n* left singular matrix, Σ is a *n x n* diagonal matrix,
    *V* is a *m x n* right singular matrix, and *V^T* is the transpose of the V. The
    `numpy.linalg` subpackage offers the `svd()` function to decompose a matrix. Let''s
    see an example of SVD, as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE13]'
  prefs: []
  type: TYPE_PRE
- en: 'This results in the following output:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE14]'
  prefs: []
  type: TYPE_PRE
- en: 'In the preceding code block, we have decomposed the given matrix into three
    parts: `Left Singular Matrix`, `Diagonal Matrix`, and `Right Singular Matrix`
    using the `svd()` function of the `scipy.linalg` subpackage.'
  prefs: []
  type: TYPE_NORMAL
- en: Eigenvectors and Eigenvalues using NumPy
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Eigenvectors and Eigenvalues are the tools required to understand linear mapping
    and transformation. Eigenvalues are solutions to the equation Ax = λx. Here, A
    is the square matrix, x is the eigenvector, and λ is eigenvalues. The `numpy.linalg`
    subpackage provides two functions, `eig()` and `eigvals()`. The `eig()` function
    returns a tuple of eigenvalues and eigenvectors, and `eigvals()` returns the eigenvalues.
  prefs: []
  type: TYPE_NORMAL
- en: Eigenvectors and eigenvalues are the core fundamentals of linear algebra. Eigenvectors
    and eigenvalues are used in SVD, spectral clustering, and PCA.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let''s compute the eigenvectors and eigenvalues of a matrix, as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Create the matrix using the NumPy `mat()` function, like this:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[PRE15]'
  prefs: []
  type: TYPE_PRE
- en: 'This results in the following output:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE16]'
  prefs: []
  type: TYPE_PRE
- en: 'Compute eigenvectors and eigenvalues using the `eig()` function, like this:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[PRE17]'
  prefs: []
  type: TYPE_PRE
- en: 'This results in the following output:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE18]'
  prefs: []
  type: TYPE_PRE
- en: In the preceding two blocks, we have created a 2*2 matrix and computed eigenvectors
    and eigenvalues using the `eig()` function of the `numpy.linalg` subpackage.
  prefs: []
  type: TYPE_NORMAL
- en: 'Compute eigenvalues using the `eigvals()` function, like this:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[PRE19]'
  prefs: []
  type: TYPE_PRE
- en: 'This results in the following output:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE20]'
  prefs: []
  type: TYPE_PRE
- en: In the preceding code snippet, we have computed the eigenvalues using the `eigvals()`
    function of the `numpy.linalg` subpackage. After performing eigendecomposition,
    we will see how to generate random numbers and a matrix.
  prefs: []
  type: TYPE_NORMAL
- en: Generating random numbers
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Random numbers offer a variety of applications such as Monte Carlo simulation,
    cryptography, initializing passwords, and stochastic processes. It is not easy
    to generate real random numbers, so in reality, most applications use pseudo-random
    numbers. Pseudo numbers are adequate for most purposes except for some rare cases.
    Random numbers can be generated from discrete and continuous data. The `numpy.random()`
    function will generate a random number matrix for the given input size of the
    matrix.
  prefs: []
  type: TYPE_NORMAL
- en: The core random number generator is based on the Mersenne Twister algorithm
    (refer to [https://en.wikipedia.org/wiki/Mersenne_twister](https://en.wikipedia.org/wiki/Mersenne_twister)).
  prefs: []
  type: TYPE_NORMAL
- en: 'Let''s see one example of generating random numbers, as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE21]'
  prefs: []
  type: TYPE_PRE
- en: 'This results in the following output:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE22]'
  prefs: []
  type: TYPE_PRE
- en: In the preceding example, we have generated a 3*3 random matrix using the `numpy.random.random()`
    function. Let's try other distributions for random number generation, such as
    binomial and normal distributions.
  prefs: []
  type: TYPE_NORMAL
- en: Binomial distribution
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Binomial distribution models the number of repeated trials with the same probability
    on each trial. Here, each trial is independent and has two possible outcomes—success
    and failure—that can occur on each client. The following formula represents the
    binomial distribution:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/c0985d39-d707-444f-babe-484dfac674b4.png)'
  prefs: []
  type: TYPE_IMG
- en: Here, p and q are the probabilities of success and failure, n is the number
    of trials, and X is the number of the desired output.
  prefs: []
  type: TYPE_NORMAL
- en: The `numpy.random` subpackage provides a `binomial()` function that generates
    samples based on the binomial distribution for certain parameters, number of trials,
    and the probability of success.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let''s consider a 17th-century gambling house where you can bet on eight tossing
    pieces and nine coins being flipped. If you get five or more heads then you win,
    otherwise you will lose. Let''s write code for this simulation for 1,000 coins
    using the `binomial()` function, as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE23]'
  prefs: []
  type: TYPE_PRE
- en: 'This results in the following output:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/af8abb7c-edbe-42cc-a935-f7d0276d38f8.png)'
  prefs: []
  type: TYPE_IMG
- en: In the preceding code block, we first created the `cash_balance` array of size
    500 with zero values and updated the first value with 500\. Then, we generated
    values between 0 to 9 using the `binomial()` function. After this, we updated
    the `cash_balance` array based on the results of coin tosses and plotted the cash
    balance using the Matplotlib library.
  prefs: []
  type: TYPE_NORMAL
- en: 'In each execution, the code will generate different results or random walks.
    If you want to make walking constant, you need to use the seed value in the `binomial()`
    function. Let''s try another form of distribution for the random number generator:
    normal distribution.'
  prefs: []
  type: TYPE_NORMAL
- en: Normal distribution
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Normal distributions occur frequently in real-life scenarios. A normal distribution
    is also known as a bell curve because of its characteristic shape. The probability
    density function models continuous distribution. The `numpy.random` subpackage
    offers lots of continuous distributions such as beta, gamma, logistic, exponential,
    multivariate normal, and normal distribution. The `normal()` functions find samples
    from Gaussian or normal distribution.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let''s write code for visualizing the normal distribution using the `normal()`
    function, as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE24]'
  prefs: []
  type: TYPE_PRE
- en: 'This results in the following output:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/c4c38ec6-d2a7-47d0-9857-7884ae05e388.png)'
  prefs: []
  type: TYPE_IMG
- en: Here, we have generated random values using the `normal()` function of the `numpy.
    random` subpackage and displayed the values using a histogram and line plot or
    bell curve or theoretical **probability density function** (**PDF**) with mean
    0 and standard deviation of 1.
  prefs: []
  type: TYPE_NORMAL
- en: Testing normality of data using SciPy
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: A normal distribution is commonly used at a wide scale in scientific and statistical
    operations. As per the central limit theorem, as sample size increases, the sample
    distribution approaches a normal distribution. The normal distribution is well
    known and easy to use. In most cases, it is recommended to confirm the normality
    of data, especially in parametric methods, assuming that the data is Gaussian-distributed.
    There are lots of normality tests that exist in the literature such as the Shapiro-Wilk
    test, the Anderson-Darling test, and the D'Agostino-Pearson test. The `scipy.stats`
    package offers most of the tests for normality.
  prefs: []
  type: TYPE_NORMAL
- en: 'In this section, we will learn how to apply normality tests on data. We are
    using three samples of small-, medium-, and large-sized random data. Let''s generate
    the data samples for all three samples using the `normal()` function, as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE25]'
  prefs: []
  type: TYPE_PRE
- en: 'We will now explore various techniques to check the normality of the data:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Using a histogram:** A histogram is the easiest and fastest method to check
    the normality of the data. It divides the data into bins and counts the observation
    into each bin. Finally, it visualizes the data. Here, we are using `distplot()`
    from the `seaborn` library to plot the histogram and kernel density estimation.
    Let''s see an example of a histogram for a small sample, as follows:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE26]'
  prefs: []
  type: TYPE_PRE
- en: 'This results in the following output:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/f7cbbbb4-a651-4fbb-afd5-bebb596896ff.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Let''s see an example of the histogram for a medium sample, as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE27]'
  prefs: []
  type: TYPE_PRE
- en: 'This results in the following output:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/f5bb3279-1416-498e-b22b-d684cf26d93a.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Let''s see an example of the histogram for a large sample, as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE28]'
  prefs: []
  type: TYPE_PRE
- en: 'This results in the following output:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/15552b2c-e16e-4535-b5a6-6000bb746f14.png)'
  prefs: []
  type: TYPE_IMG
- en: In the preceding three plots, we can observe that as the sample size increases,
    the curve becomes a normal curve. Histograms can be a good tool to test the normality
    of data.
  prefs: []
  type: TYPE_NORMAL
- en: '**Shapiro-Wilk test:** This test is used to assess the normality of data. In
    Python, the `shapiro()` function of the `scipy.stats` subpackage can be used to
    assess normality. The `shapiro()` function will return tuples of two values: test
    statistics and p-value. Let''s see the following example:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE29]'
  prefs: []
  type: TYPE_PRE
- en: 'This results in the following output:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE30]'
  prefs: []
  type: TYPE_PRE
- en: In the preceding code block, you can see that the small and large datasets have
    p-values greater than 0.05, so as the null hypothesis has failed to reject it,
    this means that the sample looks like a Gaussian or normal distribution; while
    for the medium dataset, the p-value is less than 0.05, so the null hypothesis
    has rejected it, which means the sample does not look like a Gaussian or normal
    distribution.
  prefs: []
  type: TYPE_NORMAL
- en: Similarly, we can try the Anderson-Darling test and the D'Agostino-Pearson test
    for normality using the `anderson()` and `normaltest()` functions of the `scipy.stats`
    subpackage. I will leave this for you as an activity. In visualization, we can
    also try the box plot and **quantile-quantile** (**QQ**) plot techniques to assess
    the normality of data. We will learn the box plot technique in the upcoming chapter,
    [Chapter 5](ec078274-ada3-407c-8c0e-61f5c7b57cd4.xhtml), *Data Visualization*.
    Let's move on to the concept of a masked array.
  prefs: []
  type: TYPE_NORMAL
- en: Creating a masked array using the numpy.ma subpackage
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In most situations, real-life data is noisy and messy. It contains lots of gaps
    or missing characters in the data. Masked arrays are helpful in such cases and
    handle the issue. Masked arrays may contain invalid and missing values. The `numpy.ma`
    subpackage offers all the masked array-required functionality. In this section
    of the chapter, we will use the face image as the original image source and perform
    log mask operations.
  prefs: []
  type: TYPE_NORMAL
- en: 'Have a look at the following code block:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE31]'
  prefs: []
  type: TYPE_PRE
- en: 'This results in the following output:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/b52132fc-7279-48e3-a3bc-afea3ef3dd43.png)'
  prefs: []
  type: TYPE_IMG
- en: In the preceding code block, we first loaded the face image from the `scipy.misc`
    subpackage and created a random mask using the `randint()` function. Then, we
    applied the random mask on the face image. After this, we applied the log operation
    on the original face image and masked face image. Finally, we displayed all the
    images in 2*2 subplots. You can also try a range of mask operations on the image
    from the `numpy.ma` subpackage. Here, we are only focusing on the log operation
    of the masked array. That is all about basic linear algebra concepts. It's time
    to move on to data visualization concepts, in the next chapter.
  prefs: []
  type: TYPE_NORMAL
- en: Summary
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Finally, we can conclude that mathematical subjects such as linear algebra are
    the backbone for all machine learning algorithms. Throughout the chapter, we have
    focused on essential linear algebra concepts to improve you as a data professional.
    In this chapter, you learned a lot about linear algebra concepts using the NumPy
    and SciPy subpackages. Our main focus was on polynomials, determinant, matrix
    inverse; solving linear equations; eigenvalues and eigenvectors; SVD; random numbers;
    binomial and normal distributions; normality tests; and masked arrays.
  prefs: []
  type: TYPE_NORMAL
- en: The next chapter, [Chapter 5](ec078274-ada3-407c-8c0e-61f5c7b57cd4.xhtml), *Data
    Visualization*, is about the important topic of visualizing data with Python.
    Visualization is something we often do when we start analyzing data. It helps
    to display relations between variables in the data. By visualizing the data, we
    can also get an idea about its statistical properties.
  prefs: []
  type: TYPE_NORMAL
