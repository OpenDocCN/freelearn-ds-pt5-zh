- en: Chapter 4. Speaking the Lingua Franca – Data Conversions
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 第四章：说通用语——数据转换
- en: Last summer, I took a cheese-making class at a local cooking school. One of
    the first things we made was ricotta cheese. I was thrilled to learn that ricotta
    can be made in about an hour using just milk and buttermilk, and that buttermilk
    itself can be made from milk and lemon juice. In a kitchen, ingredients are constantly
    transformed into other ingredients, which will in turn be transformed into delicious
    meals. In our data science kitchen, we will routinely perform conversions from
    one data format to another. We might need to do this in order to perform various
    analyses, when we want to merge datasets together, or if we need to store a dataset
    in a new way.
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 去年夏天，我在当地的烹饪学校参加了一门奶酪制作课程。我们做的第一件事就是制作里科塔奶酪。我兴奋地得知，里科塔奶酪可以在大约一个小时内，只用牛奶和酪乳就能做成，而且酪乳本身可以通过牛奶和柠檬汁制作。在厨房中，食材不断地转化为其他食材，进而变成美味的菜肴。在我们的数据科学厨房中，我们也将定期进行数据格式之间的转换。我们可能需要这样做来执行各种分析，当我们想要合并数据集，或者如果我们需要以新的方式存储数据集时。
- en: '**A lingua franca** is a language that is adopted as a common standard in a
    conversation between speakers of different languages. In converting data, there
    are several data formats that can serve as a common standard. We covered some
    of these in [Chapter 2](part0020.xhtml#aid-J2B82 "Chapter 2. Fundamentals – Formats,
    Types, and Encodings"), *Fundamentals – Formats, Types, and Encodings*. JSON and
    CSV are two of the most common. In this chapter, we will spend some time learning:'
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: '**通用语** 是一种在不同语言使用者之间进行交流时被采纳为共同标准的语言。在数据转换中，有几种数据格式可以作为共同标准。我们在[第二章](part0020.xhtml#aid-J2B82
    "第二章：基础 – 格式、类型和编码")，*基础 – 格式、类型和编码*中讨论过其中的一些。JSON 和 CSV 是最常见的两种格式。在本章中，我们将花一些时间学习：'
- en: How to perform some quick conversions into JSON and CSV from software tools
    and languages (Excel, Google Spreadsheets, and phpMyAdmin).
  id: totrans-3
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如何从软件工具和语言（Excel、Google Spreadsheets 和 phpMyAdmin）中快速转换为 JSON 和 CSV 格式。
- en: How to write Python and PHP programs to generate different text formats and
    convert between them.
  id: totrans-4
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如何编写 Python 和 PHP 程序生成不同的文本格式并在它们之间进行转换。
- en: How to implement data conversions in order to accomplish a real`-`world task.
    In this project, we will download a friend network from Facebook using the netvizz
    software, and we will clean the data and convert it into the JSON format needed
    to build a visualization of your social network in D3\. Then, we will clean the
    data in a different way, converting it into the Pajek format needed by the social
    network package called **networkx**.
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如何实现数据转换以完成一个实际的`-`世界任务。在这个项目中，我们将使用 netvizz 软件从 Facebook 下载朋友网络数据，然后清理数据并将其转换为构建社交网络可视化所需的
    JSON 格式。接着，我们将以不同的方式清理数据，并将其转换为 **networkx** 社交网络包所需的 Pajek 格式。
- en: Quick tool-based conversions
  id: totrans-6
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 快速的工具基础转换
- en: One of the quickest and easiest ways to convert a small to medium amount of
    data is just to ask whatever software tool you are using to do it for you. Sometimes,
    the application you are using will already have the option to convert the data
    into the format you want. Just as with the tips and tricks in [Chapter 3](part0024.xhtml#aid-MSDG2
    "Chapter 3. Workhorses of Clean Data – Spreadsheets and Text Editors"), *Workhorses
    of Clean Data – Spreadsheets and Text Editors*, we want to take advantage of these
    hidden features in our tools, if at all possible. If you have too much data for
    an application-based conversion, or if the particular conversion you want is not
    available, we will cover programmatic solutions in the upcoming sections, *Converting
    with PHP* and *Converting with Python*.
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 转换少量到中等量数据的最快、最简单方法之一就是直接让你使用的任何软件工具为你执行转换。有时，你使用的应用程序已经具备将数据转换为你需要的格式的选项。就像在[第三章](part0024.xhtml#aid-MSDG2
    "第三章：清洁数据的得力工具 – 电子表格和文本编辑器")，*清洁数据的得力工具 – 电子表格和文本编辑器*中提到的技巧一样，我们希望尽可能地利用工具中的这些隐藏功能。如果你要处理的数据量太大，无法通过应用程序转换，或者你需要的特定转换功能不可用，我们将在接下来的部分中介绍编程解决方案，即*使用
    PHP 转换*和*使用 Python 转换*。
- en: Spreadsheet to CSV
  id: totrans-8
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 电子表格转 CSV
- en: 'Saving a spreadsheet as a delimited file is quite straightforward. Both Excel
    and Google spreadsheets have **File** menu options for **Save As**; in this option,
    select **CSV (MS DOS)**. Additionally, Google Spreadsheets has the options to
    save as an Excel file and save as a tab-delimited file. There are a few limitations
    with saving something as CSV:'
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 将电子表格保存为分隔符文件非常简单。Excel 和 Google 电子表格的 **文件** 菜单中都有 **另存为** 选项；在该选项中，选择 **CSV
    (MS DOS)**。此外，Google 电子表格还提供将文件保存为 Excel 文件和制表符分隔文件的选项。将文件保存为 CSV 也有一些限制：
- en: In both Excel and Google Spreadsheets, when you use the **Save As** feature,
    only the current sheet will be saved. This is because, by nature, a CSV file describes
    only one set of data; therefore, it cannot have multiple sheets in it. If you
    have a multiple-sheet spreadsheet, you will need to save each sheet as a separate
    CSV file.
  id: totrans-10
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在 Excel 和 Google 电子表格中，当你使用 **另存为** 功能时，只会保存当前工作表。这是因为 CSV 文件本身仅描述一组数据，因此它不能包含多个工作表。如果你有一个多工作表的电子表格，你需要将每个工作表保存为单独的
    CSV 文件。
- en: In both these tools, there are relatively few options for how to customize the
    CSV file, for example, Excel saves the data with commas as the separator (which
    makes sense as it is a CSV file) and gives no options to enclose data values in
    quotation marks or for different line terminators.
  id: totrans-11
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在这两个工具中，定制 CSV 文件的选项相对较少，例如，Excel 保存数据时使用逗号作为分隔符（因为它是一个 CSV 文件，这样做很合理），并且没有选项将数据值用引号括起来或设置不同的行结束符。
- en: Spreadsheet to JSON
  id: totrans-12
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 电子表格转 JSON
- en: JSON is a little trickier to contend with than CSV. Excel does not have an easy
    JSON converter, though there are several converter tools online that purport to
    convert CSV files for you into JSON.
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 与 CSV 相比，JSON 要稍微难处理一些。虽然 Excel 没有简单的 JSON 转换器，但有一些在线转换工具声称能够将 CSV 文件转换为 JSON。
- en: Google Spreadsheets, however, has a JSON converter available via a URL. There
    are a few downsides to this method, the first of which is that you have to publish
    your document to the Web (at least temporarily) in order to access the JSON version
    of it. You will also have to customize the URL with some very long numbers that
    identify your spreadsheet. It also produces a lot of information in the JSON dump—probably
    more than you will want or need. Nonetheless, here are some step-by-step instructions
    to convert a Google Spreadsheet into its JSON representation.
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，Google 电子表格提供了一个通过 URL 访问的 JSON 转换器。使用这种方法有一些缺点，首先是你必须将文档发布到 Web 上（至少是暂时的），才能访问它的
    JSON 版本。你还需要用一些非常长的数字来定制 URL，这些数字用来标识你的电子表格。它还会在 JSON 输出中生成大量信息——可能比你需要的还要多。尽管如此，以下是将
    Google 电子表格转换为 JSON 表示的逐步说明。
- en: Step one – publish Google spreadsheet to the Web
  id: totrans-15
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 第一步 – 将 Google 电子表格发布到 Web 上
- en: After your Google spreadsheet is created and saved, select **Publish to the
    Web** from the **File** menu. Click through the subsequent dialogue boxes (I took
    all the default selections for mine). At this point, you will be ready to access
    the JSON for this file via a URL.
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 在你的 Google 电子表格创建并保存后，从 **文件** 菜单中选择 **发布到 Web**。点击接下来的对话框（我选择了所有默认选项）。此时，你就可以通过
    URL 访问该文件的 JSON 版本。
- en: Step two – create the correct URL
  id: totrans-17
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 第二步 – 创建正确的 URL
- en: 'The URL pattern to create JSON from a published Google spreadsheet looks like
    this:'
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 从发布的 Google 电子表格中创建 JSON 的 URL 模式如下：
- en: '[http://spreadsheets.google.com/feeds/list/key/sheet/public/basic?alt=json](http://spreadsheets.google.com/feeds/list/key/sheet/public/basic?alt=json)'
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: '[http://spreadsheets.google.com/feeds/list/key/sheet/public/basic?alt=json](http://spreadsheets.google.com/feeds/list/key/sheet/public/basic?alt=json)'
- en: 'There are three parts of this URL that you will need to alter to match your
    specific spreadsheet file:'
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 这个 URL 中有三个部分需要修改，以匹配你的特定电子表格文件：
- en: '**list**: (optional) You can change `list` to, say, cells if you would prefer
    to see each cell listed separately with its reference (A1, A2, and so on) in the
    JSON file. If you want each row as an entity, leave `list` in the URL.'
  id: totrans-21
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**list**: （可选）你可以将 `list` 更改为比如 `cells`，如果你希望在 JSON 文件中查看每个单元格的参考（如 A1, A2
    等），而每个单元格单独列出。如果你希望每一行作为一个实体，保持 `list` 在 URL 中即可。'
- en: '**key**: Change `key` in this URL to match the long, unique number that Google
    internally uses to represent your file. In the URL of your spreadsheet, as you
    are looking at it in the browser, this key is shown as a long identifier between
    two slashes, just after the **/spreadsheets/d** portion of the URL, shown as follows:![Step
    two – create the correct URL](img/image00268.jpeg)'
  id: totrans-22
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**密钥**：将此URL中的`key`更改为与Google内部用于表示您的文件的长且唯一的编号匹配。在电子表格的URL中，您在浏览器中查看时，密钥显示为两个斜杠之间的长标识符，位于**/spreadsheets/d**部分之后，如下所示：![第二步
    - 创建正确的URL](img/image00268.jpeg)'
- en: '**sheet**: Change the word sheet in the sample URL to `od6` to indicate that
    you are interested in converting the first sheet.'
  id: totrans-23
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**表格**：将示例网址中的“sheet”更改为`od6`，以表示您希望转换第一个工作表。'
- en: Note
  id: totrans-24
  prefs:
  - PREF_IND
  - PREF_H3
  type: TYPE_NORMAL
  zh: 注意
- en: 'What does `od6` mean? Google uses a code to represent each of the sheets. However,
    the codes are not strictly in numeric order. There is a lengthy discussion about
    the numbering scheme on the question on this Stack Overflow post and its answers:
    [http://stackoverflow.com/questions/11290337/](http://stackoverflow.com/questions/11290337/)'
  id: totrans-25
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '`od6`是什么意思？Google使用代码来表示每个工作表。然而，这些代码并非严格按数字顺序排列。在Stack Overflow上的一个问题及其回答中有关于编号方案的详细讨论：[http://stackoverflow.com/questions/11290337/](http://stackoverflow.com/questions/11290337/)'
- en: 'To test this procedure, we can create a Google spreadsheet for the universities
    and the counts that we generated from the exercise at the end of the example project
    in [Chapter 3](part0024.xhtml#aid-MSDG2 "Chapter 3. Workhorses of Clean Data –
    Spreadsheets and Text Editors"), *Workhorses of Clean Data – Spreadsheets and
    Text Editors*. The first three rows of this spreadsheet look like this:'
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 为了测试这个过程，我们可以创建一个Google电子表格，包含我们从示例项目[第3章](part0024.xhtml#aid-MSDG2 "第3章 数据清理的工作马——电子表格和文本编辑器")最后的练习中生成的大学名称和计数数据，*数据清理的工作马——电子表格和文本编辑器*。这个电子表格的前三行如下所示：
- en: '| Yale University | 26 |'
  id: totrans-27
  prefs: []
  type: TYPE_TB
  zh: '| 耶鲁大学 | 26 |'
- en: '| Princeton University | 25 |'
  id: totrans-28
  prefs: []
  type: TYPE_TB
  zh: '| 普林斯顿大学 | 25 |'
- en: '| Cornell University | 24 |'
  id: totrans-29
  prefs: []
  type: TYPE_TB
  zh: '| 康奈尔大学 | 24 |'
- en: 'My URL to access this file via JSON looks like this:'
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 我用来通过JSON访问此文件的URL如下所示：
- en: '[http://spreadsheets.google.com/feeds/list/1mWIAk_5KNoQHr4vFgPHdm7GX8Vh22WjgAUYYHUyXSNM/od6/public/basic?alt=json](http://spreadsheets.google.com/feeds/list/1mWIAk_5KNoQHr4vFgPHdm7GX8Vh22WjgAUYYHUyXSNM/od6/public/basic?alt=json)'
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: '[http://spreadsheets.google.com/feeds/list/1mWIAk_5KNoQHr4vFgPHdm7GX8Vh22WjgAUYYHUyXSNM/od6/public/basic?alt=json](http://spreadsheets.google.com/feeds/list/1mWIAk_5KNoQHr4vFgPHdm7GX8Vh22WjgAUYYHUyXSNM/od6/public/basic?alt=json)'
- en: 'Pasting this URL into the browser yields a JSON representation of the data.
    It has 231 entries in it, each of which looks like the following snippet. I have
    formatted this entry with added line breaks for easier reading:'
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 将这个URL粘贴到浏览器中会返回数据的JSON表示。它包含231个条目，每个条目如下所示。我已经为更易阅读对该条目进行了格式化，添加了换行符：
- en: '[PRE0]'
  id: totrans-33
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: 'Even with my reformatting, this JSON is not very pretty, and many of these
    name-value pairs will be uninteresting to us. Nonetheless, we have successfully
    generated a functional JSON. If we are using a program to consume this JSON, we
    will ignore all the extraneous information about the spreadsheet itself and just
    go after the title and content entities and the `$t` values (`Yale University`
    and `_cokwr: 26`, in this case). These values are highlighted in the JSON shown
    in the preceding example. If you are wondering whether there is a way to go from
    a spreadsheet to CSV to JSON, the answer is yes. We will cover how to do exactly
    that in the *Converting with PHP* and *Converting with Python* sections later
    in this chapter.'
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: '即使我进行了重新格式化，这个JSON看起来也不太美观，而且其中许多名称-值对对我们来说并不有趣。尽管如此，我们已经成功生成了一个可用的JSON。如果我们使用程序来处理这个JSON，我们会忽略关于电子表格本身的所有冗余信息，只关注标题和内容实体以及`$t`值（在此案例中是`Yale
    University`和`_cokwr: 26`）。这些值在前面示例中的JSON中已被突出显示。如果你在想是否有办法从电子表格到CSV再到JSON，答案是肯定的。我们将在本章后面的*使用PHP转换*和*使用Python转换*部分详细介绍如何做到这一点。'
- en: SQL to CSV or JSON using phpMyAdmin
  id: totrans-35
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 使用phpMyAdmin将SQL导出为CSV或JSON
- en: In this section, we'll discuss two options for writing JSON and CSV directly
    from a database, MySQL in our case, without using any programming.
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，我们将讨论两种直接从数据库（我们这里使用的是MySQL）写入JSON和CSV的选项，而无需使用任何编程。
- en: 'First, phpMyAdmin is a very common web-based frontend for MySQL databases.
    If you are using a modern version of this tool, you will be able to export an
    entire table or the results of a query as a CSV or JSON file. Using the same enron
    database we first visited in [Chapter 1](part0014.xhtml#aid-DB7S1 "Chapter 1. Why
    Do You Need Clean Data?"), *Why Do You Need Clean Data?*, consider the following
    screenshot of the **Export** tab, with **JSON** selected as the target format
    for the entire **employeelist** table (CSV is also available in this select box):'
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，phpMyAdmin 是一个非常常见的基于 Web 的 MySQL 数据库前端。如果你使用的是该工具的现代版本，你将能够将整个表格或查询结果导出为
    CSV 或 JSON 文件。使用我们在[第一章](part0014.xhtml#aid-DB7S1 "第一章。为什么你需要干净的数据？")中首次访问的相同
    enron 数据库，*为什么你需要干净的数据？*，请看以下的 **导出** 标签截图，其中 **JSON** 被选为整个 **employeelist**
    表的目标格式（此选择框中也可以选择 CSV）：
- en: '![SQL to CSV or JSON using phpMyAdmin](img/image00269.jpeg)'
  id: totrans-38
  prefs: []
  type: TYPE_IMG
  zh: '![使用 phpMyAdmin 将 SQL 转换为 CSV 或 JSON](img/image00269.jpeg)'
- en: PhpMyAdmin JSON export for entire tables
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: PhpMyAdmin 导出整个表格的 JSON
- en: 'The process to export the results of a query is very similar, except that instead
    of using the **Export** tab on the top of the screen, run the SQL query and then
    use the **Export** option under **Query results operations** at the bottom of
    the page, shown as follows:'
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 导出查询结果的过程非常类似，唯一的不同是，在页面顶部使用 **导出** 标签，而是运行 SQL 查询后，使用页面底部 **查询结果操作** 下的 **导出**
    选项，如下所示：
- en: '![SQL to CSV or JSON using phpMyAdmin](img/image00270.jpeg)'
  id: totrans-41
  prefs: []
  type: TYPE_IMG
  zh: '![使用 phpMyAdmin 将 SQL 转换为 CSV 或 JSON](img/image00270.jpeg)'
- en: PhpMyAdmin can export the results of a query as well
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: PhpMyAdmin 也可以导出查询结果
- en: 'Here is a simple query we can run on the `employeelist` table to test this
    process:'
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 这里有一个简单的查询，我们可以在 `employeelist` 表上运行来测试这个过程：
- en: '[PRE1]'
  id: totrans-44
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: 'When we export the results as JSON, phpMyAdmin shows us 151 values formatted
    like this:'
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 当我们将结果导出为 JSON 时，phpMyAdmin 会显示我们 151 个按以下格式整理的值：
- en: '[PRE2]'
  id: totrans-46
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: The phpMyAdmin tool is a good one, and it is effective for converting moderate
    amounts of data stored in MySQL, especially as the results of a query. If you
    are using a different RDBMS, your SQL interface will likely have a few formatting
    options of its own that you should explore.
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: phpMyAdmin 工具是一个不错的工具，对于将中等量的数据从 MySQL 转换出来非常有效，尤其是作为查询结果。如果你使用的是不同的关系数据库管理系统（RDBMS），你的
    SQL 界面可能也有一些你应该探索的格式化选项。
- en: 'Another strategy is to bypass phpMyAdmin entirely and just use your MySQL command
    line to write out a CSV file that is formatted the way you want:'
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 另一种策略是完全绕过 phpMyAdmin，直接使用 MySQL 命令行来写出你想要格式化的 CSV 文件：
- en: '[PRE3]'
  id: totrans-49
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: This will write a comma-delimited file with the name specified (`employees.csv`).
    It will be written into the current directory.
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 这将写入一个以逗号分隔的文件，文件名为指定的 (`employees.csv`)。它将被写入当前目录。
- en: What about JSON? There is no very clean way to output JSON with this strategy,
    so you should either use the phpMyAdmin solution shown previously, or use a more
    robust solution written in PHP or Python. These programmatic solutions are covered
    in further sections, so keep reading.
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 那么 JSON 呢？使用这种策略没有非常简洁的方式来输出 JSON，因此你应该使用之前展示的 phpMyAdmin 解决方案，或者使用 PHP 或 Python
    编写的更强大的解决方案。这些编程解决方案将在后面的章节中详细介绍，因此请继续阅读。
- en: Converting with PHP
  id: totrans-52
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用 PHP 转换
- en: In our [Chapter 2](part0020.xhtml#aid-J2B82 "Chapter 2. Fundamentals – Formats,
    Types, and Encodings"), *Fundamentals – Formats, Types, and Encodings*, in a discussion
    on JSON numeric formatting, we briefly showed how to use PHP to connect to a database,
    run a query, build a PHP array from the results, and then print the JSON results
    to the screen. Here, we will first extend this example to write a file rather
    than print to the screen and also to write a CSV file. Next, we will show how
    to use PHP to read in JSON files and convert to CSV files, and vice versa.
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们的[第二章](part0020.xhtml#aid-J2B82 "第二章。基础知识 – 格式、类型和编码")中，*基础知识 – 格式、类型和编码*，我们在讨论
    JSON 数值格式化时，简要展示了如何使用 PHP 连接到数据库、运行查询、从结果中构建 PHP 数组，然后将 JSON 结果打印到屏幕上。在这里，我们将首先扩展这个示例，将结果写入文件而不是打印到屏幕，并且还会写入
    CSV 文件。接下来，我们将展示如何使用 PHP 读取 JSON 文件并转换为 CSV 文件，反之亦然。
- en: SQL to JSON using PHP
  id: totrans-54
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 使用 PHP 将 SQL 转换为 JSON
- en: 'In this section, we will write a PHP script to connect to the `enron` database,
    run a SQL query, and export is as a JSON-formatted file. Why write a PHP script
    for this instead of using phpMyAdmin? Well, this strategy will be useful in cases
    where we need to perform additional processing on the data before exporting it
    or where we suspect that we have more data than what a web-based application (such
    as phpMyAdmin) can run:'
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，我们将编写一个 PHP 脚本，连接到 `enron` 数据库，运行 SQL 查询，并将其导出为 JSON 格式的文件。为什么要写 PHP 脚本而不是使用
    phpMyAdmin 呢？这个方法在我们需要在导出数据之前对其进行额外处理，或者怀疑数据量大于基于 Web 的应用（如 phpMyAdmin）能够处理的情况下会很有用：
- en: '[PRE4]'
  id: totrans-56
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: This code writes a JSON-formatted output file to the location you specify in
    the `file_put_contents()` line.
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 这段代码将 JSON 格式的输出文件写入你在 `file_put_contents()` 行中指定的位置。
- en: SQL to CSV using PHP
  id: totrans-58
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 使用 PHP 将 SQL 转换为 CSV
- en: 'The following code snippet shows how to use the PHP file output stream to create
    a CSV-formatted file of the results of a SQL query. Save this code as a `.php`
    file in the script-capable directory on your web server, and then request the
    file in the browser. It will automatically download a CSV file with the correct
    values in it:'
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 以下代码片段展示了如何使用 PHP 文件输出流创建一个包含 SQL 查询结果的 CSV 格式文件。将此代码保存为 `.php` 文件到你网站服务器的脚本目录中，然后在浏览器中请求该文件。它将自动下载一个包含正确值的
    CSV 文件：
- en: '[PRE5]'
  id: totrans-60
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: 'The results are formatted as follows (these are the first three lines only):'
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 结果的格式如下（仅展示前三行）：
- en: '[PRE6]'
  id: totrans-62
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: 'If you are wondering whether Phillip''s e-mail is really supposed to have two
    dots in it, we can run a quick query to find out how many of Enron''s e-mails
    are formatted like that:'
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你在想是否 Phillip 的电子邮件真的是应该有两个点，我们可以运行一个快速查询来查找有多少 Enron 的电子邮件是这样格式的：
- en: '[PRE7]'
  id: totrans-64
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: It turns out that 24 of the e-mail addresses have double dots like that.
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 结果显示有 24 个电子邮件地址含有双点。
- en: JSON to CSV using PHP
  id: totrans-66
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 使用 PHP 将 JSON 转换为 CSV
- en: 'Here, we will use PHP to read in a JSON file and convert it to CSV and output
    a file:'
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，我们将使用 PHP 读取 JSON 文件并将其转换为 CSV，并输出一个文件：
- en: '[PRE8]'
  id: totrans-68
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: This code will create a CSV with each line in it, just like the previous example.
    We should be aware that the `file_get_contents()` function reads the file into
    the memory as a string, so you may find that for extremely large files, you will
    need to use a combination of the `fread()`, `fgets()`, and `fclose()`PHP functions
    instead.
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 这段代码将创建一个包含每行数据的 CSV 文件，类似于前面的示例。我们应该注意，`file_get_contents()` 函数将文件读取到内存中作为字符串，因此对于极大的文件，你可能需要使用
    `fread()`、`fgets()` 和 `fclose()` 等 PHP 函数的组合来处理。
- en: CSV to JSON using PHP
  id: totrans-70
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 使用 PHP 将 CSV 转换为 JSON
- en: 'Another common task is to read in a CSV file and write it out as a JSON file.
    Most of the time, we have a CSV in which the first row is a header row. The header
    row lists the column name for each column in the file, and we would like each
    item in the header row to become the keys for the JSON-formatted version of the
    file:'
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 另一个常见任务是读取 CSV 文件并将其写入为 JSON 文件。通常情况下，我们有一个 CSV 文件，其中第一行是表头行。表头行列出了文件中每一列的列名，我们希望将表头行中的每一项作为
    JSON 格式文件的键：
- en: '[PRE9]'
  id: totrans-72
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: 'The result of this code on the `enronEmail.csv` file created earlier, with
    a header row, is as follows:'
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: 这段代码对之前创建的 `enronEmail.csv` 文件（包含一个表头行）的结果如下：
- en: '[PRE10]'
  id: totrans-74
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: For this example, of the 151 results in the actual CSV file, only the first
    three rows are shown.
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个示例中，实际 CSV 文件中的 151 条结果中，只显示了前三行。
- en: Converting with Python
  id: totrans-76
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用 Python 转换
- en: In this section, we describe a variety of ways to manipulate CSV into JSON,
    and vice versa, using Python. In these examples, we will explore different ways
    to accomplish this goal, both using specially installed libraries and using more
    plain-vanilla Python code.
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，我们描述了多种使用 Python 操作 CSV 转换为 JSON，以及反向操作的方法。在这些示例中，我们将探索实现这一目标的不同方式，既包括使用特别安装的库，也包括使用更基础的
    Python 代码。
- en: CSV to JSON using Python
  id: totrans-78
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 使用 Python 将 CSV 转换为 JSON
- en: 'We have found several ways to convert CSV files to JSON using Python. The first
    of these uses the built-in `csv` and `json` libraries. Suppose we have a CSV file
    that has rows like this (only the first three rows shown):'
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: 我们已经找到几种使用 Python 将 CSV 文件转换为 JSON 的方法。其中一种方法使用了内置的 `csv` 和 `json` 库。假设我们有一个
    CSV 文件，其中的行如下（仅展示前三行）：
- en: '[PRE11]'
  id: totrans-80
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: 'We can write a Python program to read these rows and convert them to JSON:'
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以编写一个 Python 程序来读取这些行并将其转换为 JSON：
- en: '[PRE12]'
  id: totrans-82
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: 'The resulting JSON will look like this (only the first two rows are shown):'
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: 结果的 JSON 将如下所示（仅展示前两行）：
- en: '[PRE13]'
  id: totrans-84
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: One nice thing about using this method is that it does not require any special
    installations of libraries or any command-line access, apart from getting and
    putting the files you are reading (CSV) and writing (JSON).
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: 使用这种方法的一个优点是，它不需要任何特殊的库安装或命令行访问，除了获取和放置你正在读取（CSV）和写入（JSON）文件之外。
- en: CSV to JSON using csvkit
  id: totrans-86
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 使用 csvkit 将 CSV 转换为 JSON
- en: 'The second method of changing CSV into JSON relies on a very interesting Python
    toolkit called **csvkit**. To install csvkit using Canopy, simply launch the Canopy
    terminal window (you can find it inside Canopy by navigating to **Tools** | **Canopy
    Terminal**) and then run the `pip install csvkit` command. All the dependencies
    for using csvkit will be installed for you. At this point, you have the option
    of accessing csvkit via a Python program as a library using `import csvkit` or
    via the command line, as we will do in the following snippet:'
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: 改变 CSV 为 JSON 的第二种方法依赖于一个非常有趣的 Python 工具包 **csvkit**。要通过 Canopy 安装 csvkit，只需启动
    Canopy 终端窗口（你可以在 Canopy 中通过导航至 **工具** | **Canopy 终端** 找到它），然后运行 `pip install csvkit`
    命令。所有使用 csvkit 所需的依赖将自动为你安装。此时，你可以选择通过 Python 程序作为库使用 `import csvkit` 来访问 csvkit，或通过命令行访问，正如我们将在接下来的代码段中所做的那样：
- en: '[PRE14]'
  id: totrans-88
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: This command takes a `enronEmail.csv` CSV file and transforms it to a JSON `enronEmail.csvkit.json`
    file quickly and painlessly.
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: 该命令将 `enronEmail.csv` 文件转换为 JSON 格式的 `enronEmail.csvkit.json` 文件，过程快速而简便。
- en: 'There are several other extremely useful command-line programs that come with
    the csvkit package, including `csvcut`, which can extract an arbitrary list of
    columns from a CSV file, and `csvformat`, which can perform delimiter exchanges
    on CSV files or alter line endings or similar cleaning procedures. The `csvcut`
    program is particularly helpful if you want to extract just a few columns for
    processing. For any of these command-line tools, you can redirect its output to
    a new file. The following command line takes a file called `bigFile.csv`, cuts
    out the first and third column, and saves the result as a new CSV file:'
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: csvkit 包含多个其他非常有用的命令行程序，其中包括 `csvcut`，它可以从 CSV 文件中提取任意列列表，以及 `csvformat`，它可以执行
    CSV 文件的分隔符交换，或修改行结束符等清理操作。如果你只想提取少数几列进行处理，`csvcut` 程序特别有用。对于这些命令行工具中的任何一个，你都可以将其输出重定向到一个新文件。以下命令行处理一个名为
    `bigFile.csv` 的文件，剪切出第一列和第三列，并将结果保存为一个新的 CSV 文件：
- en: '[PRE15]'
  id: totrans-91
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: Tip
  id: totrans-92
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 提示
- en: Additional information about csvkit, including full documentation, downloads,
    and examples, is available at [http://csvkit.rtfd.org/](http://csvkit.rtfd.org/).
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: 关于 csvkit 的更多信息，包括完整的文档、下载和示例，见 [http://csvkit.rtfd.org/](http://csvkit.rtfd.org/)。
- en: Python JSON to CSV
  id: totrans-94
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: Python JSON 转 CSV
- en: 'It is quite straightforward to use Python to read in a JSON file and convert
    it to CSV for processing:'
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: 使用 Python 读取 JSON 文件并将其转换为 CSV 进行处理是非常简单的：
- en: '[PRE16]'
  id: totrans-96
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: This program takes a JSON file called `enronEmailPy.json` and exports a CSV-formatted
    version of this file using the keys for the JSON as the header row new file, called
    `enronEmailPy.csv`.
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: 该程序接收一个名为 `enronEmailPy.json` 的 JSON 文件，并使用 JSON 的键作为头行，将该文件导出为 CSV 格式的新文件，名为
    `enronEmailPy.csv`。
- en: The example project
  id: totrans-98
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 示例项目
- en: In this chapter, we have focused on converting data from one format to another,
    which is a common data cleaning task that will need to be done time and again
    before the rest of the data analysis project can be completed. We focused on some
    very common text formats (CSV and JSON) and common locations for data (files and
    SQL databases). Now, we are ready to extend our basic knowledge of data conversions
    with a sample project that will ask us to make conversions between some less standardized—
    but still text-based—data formats.
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们重点介绍了将数据从一种格式转换为另一种格式，这是一个常见的数据清理任务，在数据分析项目的其余部分完成之前需要多次执行。我们聚焦于一些非常常见的文本格式（CSV
    和 JSON）和常见的数据存储位置（文件和 SQL 数据库）。现在，我们准备通过一个示例项目扩展我们对数据转换的基本知识，该项目将要求我们在一些不那么标准化但仍然是文本格式的数据格式之间进行转换。
- en: 'In this project, we want to investigate our Facebook social network. We will:'
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个项目中，我们将研究我们的 Facebook 社交网络。我们将：
- en: Download our Facebook social network (friends and relationships between them)
    using netvizz into a text-based file format called **Graph Description Format**
    (**GDF**).
  id: totrans-101
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用 netvizz 下载我们的 Facebook 社交网络（朋友及其之间的关系），并保存为一种名为 **图描述格式**（**GDF**）的文本格式。
- en: Build a graphical representation of a Facebook social network showing the people
    in our network as nodes and their friendships as connecting lines (called *edges*)
    between these nodes. To do this, we will use the D3 JavaScript graphing library.
    This library expects a JSON representation of the data in the network.
  id: totrans-102
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Calculate some metrics about the social network, such as the size of the network
    (known as the *degree* of the network) and the shortest path between two people
    our network. To do this, we will use the `networkx` package in Python. This package
    expects data in a text-based format, called the **Pajek** format.
  id: totrans-103
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: The primary goal of this project will be to show how to reconcile all these
    different expected formats (GDF, Pajek, and JSON) and perform conversions from
    one format to another. Our secondary goal will be to actually provide enough sample
    code and guidance to perform a small analysis of our social network.
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
- en: Step one – download Facebook data as GDF
  id: totrans-105
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'For this step, you will need to be logged into your Facebook account. Use Facebook''s
    search box to find the netvizz app, or use this URL to directly link to the netvizz
    app: [https://apps.facebook.com/netvizz/](https://apps.facebook.com/netvizz/).'
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
- en: 'Once on the netvizz page, click on **personal network**. The page that follows
    explains that clicking on the **start** button will provide a downloadable file
    with two items in it: a GDF format file that lists all your friends and the connections
    between them and a tab-delimited **Tab Separated Values** (**TSV**) stats file.
    We are primarily interested in the GDF file for this project. Click on the **start**
    button, and on the subsequent page, right-click on the GDF file to save it to
    your local disk, as shown in the following screenshot:'
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
- en: '![Step one – download Facebook data as GDF](img/image00271.jpeg)'
  id: totrans-108
  prefs: []
  type: TYPE_IMG
- en: The netvizz Facebook app allows us to download our social network as a GDF file
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
- en: It may be helpful to also give the file a shorter name at this point. (I called
    my file `personal.gdf` and saved it in a directory created just for this project.)
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
- en: Step two – look at the GDF file format in a text editor
  id: totrans-111
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Open the file in your text editor (I am using Text Wrangler for this), and
    note a few things about the format of this file:'
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
- en: 'The file is divided into two parts: nodes and edges.'
  id: totrans-113
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: The nodes are found in the first part of the file, preceded by the word `nodedef`.
    The list of nodes is a list of all my friends and some basic facts about them
    (their gender and their internal Facebook identification number). The nodes are
    listed in the order of the date when the person joined Facebook.
  id: totrans-114
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: The second part of the file shows the edges or connections between my friends.
    Sometimes, these are also called links. This section of the file is preceded by
    the word `edgedef`. The edges describe which of my friends are linked to which
    other friends.
  id: totrans-115
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Here is an excerpt of what a nodes section looks like:'
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE17]'
  id: totrans-117
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: 'Here is an excerpt of what an edges section looks like. It shows that `Bugs`
    (`1234`) and `Daffy` (`2345`) are friends, and `Bugs` is also friends with `Minnie`
    (`3456`):'
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
  zh: 以下是边部分的摘录。它显示了 `Bugs`（`1234`）和 `Daffy`（`2345`）是朋友，而 `Bugs` 也与 `Minnie`（`3456`）是朋友：
- en: '[PRE18]'
  id: totrans-119
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: Step three – convert the GDF file into JSON
  id: totrans-120
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 第三步 - 将 GDF 文件转换为 JSON
- en: The task we want to perform is to build a representation of this data as a social
    network in D3\. First, we need to look at the dozens of available examples of
    D3 to build a social network, such as those available in the D3 galleries of examples,
    [https://github.com/mbostock/d3/wiki/Gallery](https://github.com/mbostock/d3/wiki/Gallery)
    and [http://christopheviau.com/d3list/](http://christopheviau.com/d3list/).
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
  zh: 我们要执行的任务是使用 D3 构建该数据的社交网络表示。首先，我们需要查看 D3 中用于构建社交网络的几十个现有示例，例如 D3 示例库中的示例：[https://github.com/mbostock/d3/wiki/Gallery](https://github.com/mbostock/d3/wiki/Gallery)
    和 [http://christopheviau.com/d3list/](http://christopheviau.com/d3list/)。
- en: 'These examples of social network diagrams rely on JSON files. Each JSON file
    shows nodes and the edges between them. Here is an example of what one of these
    JSON files should look like:'
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
  zh: 这些社交网络图的示例依赖于 JSON 文件。每个 JSON 文件展示了节点以及它们之间的边。以下是这些 JSON 文件的一个示例：
- en: '[PRE19]'
  id: totrans-123
  prefs: []
  type: TYPE_PRE
  zh: '[PRE19]'
- en: 'The most important thing about this JSON code is to note that it has the same
    two main chunks as the GDF file did: nodes and edges. The nodes are simply the
    person''s name. The edges are a list of number pairs representing friendship relations.
    Instead of using the Facebook identification number, though, these pairs use an
    index for each item in the nodes list, starting with `0`.'
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
  zh: 这段 JSON 代码最重要的一点是，它具有与 GDF 文件相同的两个主要部分：节点和边。节点仅仅是人的名字。边是一个数字对列表，表示友谊关系。不过，这些对并没有使用
    Facebook 的标识号，而是使用了节点列表中每个项的索引，从 `0` 开始。
- en: We do not have a JSON file at this point. We only have a GDF file. How will
    we build this JSON file? When we look closely at the GDF file, we can see that
    it looks a lot like two CSV files stacked on top of one another. From earlier
    in this chapter, we know we have several different strategies to convert from
    CSV to JSON.
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
  zh: 此时我们还没有 JSON 文件，只有一个 GDF 文件。那么我们如何构建这个 JSON 文件呢？当我们仔细查看 GDF 文件时，会发现它看起来像是两个
    CSV 文件叠在一起。正如本章早些时候提到的，我们有几种不同的策略可以将 CSV 转换为 JSON。
- en: Therefore, we decide to convert GDF to CSV and then CSV to JSON.
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，我们决定将 GDF 转换为 CSV，再将 CSV 转换为 JSON。
- en: Note
  id: totrans-127
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 注意
- en: Wait; what if that JSON example doesn't look like the JSON files I found online
    to perform a social network diagram in D3?
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
  zh: 等等，如果那个 JSON 示例看起来和我在网上找到的用于在 D3 中绘制社交网络图的 JSON 文件不一样怎么办？
- en: 'Some of the examples of D3 social network visualizations that you may find
    online will show many additional values for each node or link, for example, they
    may include extra attributes that can be used to signify a difference in size,
    a hover feature, or a color change, as shown in this sample: [http://bl.ocks.org/christophermanning/1625629](http://bl.ocks.org/christophermanning/1625629).
    This visualization shows relationships between paid political lobbyists in Chicago.
    In this example, the code takes into account information in the JSON file to determine
    the size of the circles for the nodes and the text that is displayed when you
    hover over the nodes. It makes a really nice diagram, but it is complicated. As
    our primary goal is to learn how to clean the data, we will work with a pared
    down, simple example here that does not have many of these extras. Do not worry,
    though; our example will still build a nifty D3 diagram!'
  id: totrans-129
  prefs: []
  type: TYPE_NORMAL
  zh: 你在网上找到的 D3 社交网络可视化示例可能会展示每个节点或连接的许多附加值，例如，它们可能包括额外的属性，用于表示大小差异、悬停功能或颜色变化，如这个示例所示：[http://bl.ocks.org/christophermanning/1625629](http://bl.ocks.org/christophermanning/1625629)。该可视化展示了芝加哥的付费政治游说者之间的关系。在这个示例中，代码会根据
    JSON 文件中的信息来决定节点的圆圈大小以及当你将鼠标悬停在节点上时显示的文本。它制作了一个非常漂亮的图表，但它比较复杂。由于我们的主要目标是学习如何清理数据，我们将在这里处理一个简化的示例，不包含许多这些额外功能。不过不用担心，我们的示例仍然会构建出一个漂亮的
    D3 图表！
- en: 'To convert the GDF file to JSON in the format we want, we can follow these
    steps:'
  id: totrans-130
  prefs: []
  type: TYPE_NORMAL
  zh: 要将 GDF 文件转换为我们需要的 JSON 格式，可以按照以下步骤进行：
- en: Use a text editor to split the `personal.gdf` file into two files, `nodes.gdf`
    and `links.gdf.`
  id: totrans-131
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用文本编辑器将 `personal.gdf` 文件拆分为两个文件，`nodes.gdf` 和 `links.gdf`。
- en: 'Alter the header row in each file to match the column names we eventually want
    in the JSON file:'
  id: totrans-132
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 修改每个文件中的标题行，以匹配最终希望在 JSON 文件中出现的列名：
- en: '[PRE20]'
  id: totrans-133
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE20]'
- en: 'Use the `csvcut` utility (part of csvkit discussed previously) to extract the
    first and second columns from the `nodes.gdf` file and redirect the output to
    a new file called `nodesCut.gdf`:'
  id: totrans-134
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE21]'
  id: totrans-135
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE21]'
- en: 'Now, we need to give each edge pair an indexed value rather than their full
    Facebook ID value. The index just identifies this node by its position in the
    node list. We need to perform this transformation so that the data will easily
    feed into the D3 force network code examples that we have, with as little refactoring
    as possible. We need to convert this:'
  id: totrans-136
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE22]'
  id: totrans-137
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE22]'
- en: 'into this:'
  id: totrans-138
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE23]'
  id: totrans-139
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE23]'
- en: 'Here is a small Python script that will create these index values automatically:'
  id: totrans-140
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE24]'
  id: totrans-141
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE24]'
- en: 'Now, go back to the `nodesCut.csv` file and remove the `id` column:'
  id: totrans-142
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE25]'
  id: totrans-143
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE25]'
- en: 'Construct a small Python script that takes each of these files and writes them
    out to a complete JSON file, ready for D3 processing:'
  id: totrans-144
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE26]'
  id: totrans-145
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE26]'
- en: Step four – build a D3 diagram
  id: totrans-146
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'This section shows how to feed our JSON file of nodes and links into a boilerplate
    example of building a force-directed graph in D3\. This code example came from
    the D3 website and builds a simple graph using the JSON file provided. Each node
    is shown as a circle, and when you hover your mouse over the node, the person''s
    name shows up as a tooltip:'
  id: totrans-147
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE27]'
  id: totrans-148
  prefs: []
  type: TYPE_PRE
  zh: '[PRE27]'
- en: The following screenshot shows an example of this social network. One of the
    nodes has been hovered over, showing the tooltip (name) of that node.
  id: totrans-149
  prefs: []
  type: TYPE_NORMAL
- en: '![Step four – build a D3 diagram](img/image00272.jpeg)'
  id: totrans-150
  prefs: []
  type: TYPE_IMG
- en: Social network built with D3
  id: totrans-151
  prefs: []
  type: TYPE_NORMAL
- en: Step five – convert data to the Pajek file format
  id: totrans-152
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: So far, we have converted a GDF file to CSV, and then to JSON, and built a D3
    diagram of it. In the next two steps, we will continue to pursue our goal of getting
    the data in such a format that we can calculate some social network metrics on
    it.
  id: totrans-153
  prefs: []
  type: TYPE_NORMAL
- en: For this step, we will take the original GDF file and tweak it to become a valid
    `Pajek` file, which is the format that is needed by the social network tool called
    networkx.
  id: totrans-154
  prefs: []
  type: TYPE_NORMAL
- en: Note
  id: totrans-155
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: The word *pajek* means *spider* in Slovenian. A social network can be thought
    of as a web made up of nodes and the links between them.
  id: totrans-156
  prefs: []
  type: TYPE_NORMAL
- en: 'The format of our Facebook GDF file converted to a Pajek file looks like this:'
  id: totrans-157
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE28]'
  id: totrans-158
  prefs: []
  type: TYPE_PRE
  zh: '[PRE28]'
- en: 'Here are a few important things to notice right away about this Pajek file
    format:'
  id: totrans-159
  prefs: []
  type: TYPE_NORMAL
- en: It is space-delimited, not comma-delimited.
  id: totrans-160
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Just like in the GDF file, there are two main sections of data, and these are
    labeled, starting with an asterisk `*`. The two sections are the vertices (another
    word for nodes) and the edges.
  id: totrans-161
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: There is a count of how many total vertices (nodes) there are in the file, and
    this count goes next to the word vertices on the top line.
  id: totrans-162
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Each person's name has spaces removed and replaced with underscores.
  id: totrans-163
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The other columns are optional in the node section.
  id: totrans-164
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'To convert our GDF file into Pajek format, let''s use the text editor, as these
    changes are fairly straightforward and our file is not very large. We will perform
    the data cleaning tasks as follows:'
  id: totrans-165
  prefs: []
  type: TYPE_NORMAL
- en: Save a copy of your GDF file as a new file and call it something like `fbPajek.net`
    (the `.net` extension is commonly used for Pajek network files).
  id: totrans-166
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Replace the top line in your file. Currently, it looks like this:'
  id: totrans-167
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE29]'
  id: totrans-168
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE29]'
- en: 'You will need to change it to something like this:'
  id: totrans-169
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE30]'
  id: totrans-170
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE30]'
- en: Make sure the number of vertices matches the number you have in your actual
    file. This is the count of nodes. There should be one per line in your GDF file.
  id: totrans-171
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Replace the edges line in your file. Currently, it looks like this:'
  id: totrans-172
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE31]'
  id: totrans-173
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE31]'
- en: 'You will need to change it to look like this:'
  id: totrans-174
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE32]'
  id: totrans-175
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE32]'
- en: 'Starting at line 2, replace every instance of a space with an underscore. This
    works because the only spaces in this file are in the names. Take a look at this:'
  id: totrans-176
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE33]'
  id: totrans-177
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE33]'
- en: 'This action will turn the preceding into this:'
  id: totrans-178
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE34]'
  id: totrans-179
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE34]'
- en: 'Now, use find and replace to replace all the instances of a comma with a space.
    The result for the nodes section will be:'
  id: totrans-180
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE35]'
  id: totrans-181
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE35]'
- en: 'The result for the edges section will be:'
  id: totrans-182
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE36]'
  id: totrans-183
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE36]'
- en: 'One last thing; use the find feature of the text editor to locate any of your
    Facebook friends who have an apostrophe in their name. Replace this apostrophe
    with nothing. Thus, `Cap''n_Crunch` becomes:'
  id: totrans-184
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE37]'
  id: totrans-185
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE37]'
- en: This is now a fully cleaned, Pajek-formatted file.
  id: totrans-186
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Step six – calculate simple network metrics
  id: totrans-187
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: At this point, we are ready to run some simple social network metrics using
    a Python package like networkx. Even though **Social Network Analysis** (**SNA**)
    is beyond the scope of this book, we can still perform a few calculations quite
    easily without delving too deeply into the mysteries of SNA.
  id: totrans-188
  prefs: []
  type: TYPE_NORMAL
- en: First, we should make sure that we have the `networkx` package installed. I
    am using Canopy for my Python editor, so I will use the Package Manager to search
    for networkx and install it.
  id: totrans-189
  prefs: []
  type: TYPE_NORMAL
- en: 'Then, once networkx is installed, we can write some quick Python code to read
    our Pajek file and output a few interesting facts about the structure of my Facebook
    network:'
  id: totrans-190
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE38]'
  id: totrans-191
  prefs: []
  type: TYPE_PRE
  zh: '[PRE38]'
- en: 'The result for my network looks like the following output. The top ten nodes
    are listed, along with a count of how many of my other nodes each of these links
    to:'
  id: totrans-192
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE39]'
  id: totrans-193
  prefs: []
  type: TYPE_PRE
  zh: '[PRE39]'
- en: This shows that `Bambi` is connected to `134` of my other friends, but `Prince_Charming`
    is only connected to `42` of my other friends.
  id: totrans-194
  prefs: []
  type: TYPE_NORMAL
- en: Tip
  id: totrans-195
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: If you get any Python errors about missing quotations, double-check your Pajek
    format file to ensure that all node labels are free of spaces and other special
    characters. In the cleaning procedure explained in the preceding example, we removed
    spaces and the quotation character, but your friends may have more exotic characters
    in their names!
  id: totrans-196
  prefs: []
  type: TYPE_NORMAL
- en: Of course, there are many more interesting things you can do with networkx and
    D3 visualizations, but this sample project was designed to give us a sense of
    how critical data-cleaning processes are to the successful outcome of any larger
    analysis effort.
  id: totrans-197
  prefs: []
  type: TYPE_NORMAL
- en: Summary
  id: totrans-198
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this chapter, we learned many different ways to convert data from one format
    to another. Some of these techniques are simple, such as just saving a file in
    the format you want or looking for a menu option to output the correct format.
    At other times, we will need to write our own programmatic solution.
  id: totrans-199
  prefs: []
  type: TYPE_NORMAL
- en: Many projects, such as the sample project we implemented in this chapter, will
    require several different cleaning steps, and we will have to carefully plan out
    our cleaning steps and write down what we did. Both networkx and D3 are really
    nifty tools, but they do require data to be in a certain format before we are
    ready to use them. Likewise, Facebook data is easily available through netvizz,
    but it too has its own data format. Finding easy ways to convert from one file
    format to the other is a critical skill in data science.
  id: totrans-200
  prefs: []
  type: TYPE_NORMAL
- en: In this chapter, we performed a lot of conversions between structured and semistructured
    data. But what about cleaning messy data, such as unstructured text?
  id: totrans-201
  prefs: []
  type: TYPE_NORMAL
- en: In [Chapter 5](part0033.xhtml#aid-VF2I1 "Chapter 5. Collecting and Cleaning
    Data from the Web"), *Collecting and Cleaning Data from the Web*, we will continue
    to fill up our data science cleaning toolbox by learning some of the ways in which
    we can clean pages that we find on the Web.
  id: totrans-202
  prefs: []
  type: TYPE_NORMAL
