- en: 'Chapter 8. Analytics Study: Prediction - Financial Time Series Analysis and
    Forecasting'
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: '"When making important decisions, it''s ok to trust your instincts but always
    verify with data"'
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: – *David Taieb*
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
- en: The study of time series is a very important field of data science with multiple
    applications in industry, including the weather, medicine, sales, and, of course,
    finance. It is a broad and complex subject and covering it in detail would be
    outside the scope of this book, but we'll try to touch upon a few of the important
    concepts in this chapter, staying sufficiently high level as not to require any
    particular specific knowledge from the reader. We also show how Python is particularly
    well adapted to time series analysis from data manipulation with libraries like
    pandas ([https://pandas.pydata.org](https://pandas.pydata.org)) for data analysis
    and NumPy ([http://www.numpy.org](http://www.numpy.org)) for scientific computation,
    to visualization with Matplotlib ([https://matplotlib.org](https://matplotlib.org))
    and Bokeh ([https://bokeh.pydata.org](https://bokeh.pydata.org)).
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
- en: This chapter starts with an introduction to the NumPy library and its most important
    APIs that will be put to good use when building descriptive analytics to analyze
    time series representing stock historical financial data. Using Python libraries
    such as `statsmodels` ([https://www.statsmodels.org/stable/index.html](https://www.statsmodels.org/stable/index.html)),
    we'll show how to do statistical exploration and find properties like stationarity,
    **autocorrelation function** (**ACF**), and **partial autocorrelation function**
    (**PACF**). which will be useful to find trends in the data and creating forecasting
    models. We'll then operationalize these analytics by building a PixieApp that
    summarizes all the important statistics and visualizations about stock historical
    financial data.
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
- en: In the second part, we'll attempt to build a time series forecasting model that
    predicts future trends of a stock. We'll use an autoregressive model with Integrated
    Moving Average called **ARIMA** where we use previous values in the time series
    to predict the next value. ARIMA is one of the most popular models currently used,
    although new models based on recurrent neural networks are starting to gain in
    popularity.
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
- en: As usual, we'll conclude the chapter by incorporating the building of an ARIMA
    time series forecasting model in the `StockExplorer` PixieApp.
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
- en: Getting started with NumPy
  id: totrans-7
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The NumPy library is one of the main reasons why Python has gained so much traction
    in the data scientist community. It is a foundational library upon which a lot
    of the most popular libraries, such as pandas ([https://pandas.pydata.org](https://pandas.pydata.org)),
    Matplotlib ([https://matplotlib.org](https://matplotlib.org)), SciPy ([https://www.scipy.org](https://www.scipy.org)),
    and scikit-learn ([http://scikit-learn.org](http://scikit-learn.org)) are built.
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
- en: 'The key capabilities provided by NumPy are:'
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
- en: A very powerful multidimensional NumPy array called ndarray with very high-performance
    mathematical operations (at least compared to regular Python lists and arrays)
  id: totrans-10
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Universal functions also called `ufunc` for short, for providing very efficient
    and easy-to-use element by element operations on one or more ndarray
  id: totrans-11
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Powerful ndarray slicing and selection capabilities
  id: totrans-12
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Broadcasting functions that make it possible to apply arithmetic operations
    on ndarray of different shapes provided that some rules are respected
  id: totrans-13
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Before we start exploring the NumPy APIs, there is one API that is absolutely
    essential to know: `lookfor()`. With this method, you can find a function using
    a query string, which is very useful considering the hundreds of powerful APIs
    provided by NumPy.'
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
- en: 'For example, I can look for a function that computes the average mean of an
    array:'
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  id: totrans-16
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: 'The results are as follows:'
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  id: totrans-18
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: 'Within seconds, I can find a few candidate functions without having to leave
    my Notebook to consult the documentation. In the preceding case, I can spot a
    few functions that are interesting— `np.average` and `np.mean`—for which I still
    need to know their arguments. Again, instead of looking up the documentation which
    takes time and breaks the flow of what I was doing, I use a little-known capability
    of Jupyter Notebooks that provides me with the signature and docstring of the
    function inline. To invoke the inline help of a function, simply position the
    cursor at the end of the function and use the *Shift* + *Tab* combination. Calling
    *Shift* + *Tab* a second time will expand the pop-up window to show more of the
    text as shown in the following screenshot:'
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
- en: Note
  id: totrans-20
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '**Note**: *Shift* + *Tab* only applies to a function.'
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
- en: '![Getting started with NumPy](img/B09699_08_01.jpg)'
  id: totrans-22
  prefs: []
  type: TYPE_IMG
- en: Inline help in Jupyter Notebook.
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
- en: Using this method, I can rapidly iterate over the candidate functions until
    I find the one that fits my needs.
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
- en: 'It is important to note that `np.lookfor()` is not limited to querying the
    NumPy module; you could search in other modules as well. For example, the following
    code searches for `acf` (autocorrelation function) related methods in the `statsmodels`
    package:'
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  id: totrans-26
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: Note
  id: totrans-27
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'You can find the code file here:'
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
- en: '[https://github.com/DTAIEB/Thoughtful-Data-Science/blob/master/chapter%208/sampleCode1.py](https://github.com/DTAIEB/Thoughtful-Data-Science/blob/master/chapter%208/sampleCode1.py)'
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
- en: 'This produces the following results:'
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  id: totrans-31
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: Creating a NumPy array
  id: totrans-32
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'There are many ways to create a NumPy array. Here are the methods most commonly
    used:'
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
- en: From a Python list or tuple using `np.array()`, for example, `np.array([1, 2,
    3, 4])`.
  id: totrans-34
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'From one of the NumPy factory functions:'
  id: totrans-35
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`np.random`: A module that provides a very rich set of functions for randomly
    generating values. This module is composed of the following categories:'
  id: totrans-36
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Simple random data: `rand`, `randn`, `randint`, and so on'
  id: totrans-37
  prefs:
  - PREF_IND
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Permutations: `shuffle`, `permutation`'
  id: totrans-38
  prefs:
  - PREF_IND
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Distributions: `geometric`, `logistic`, and so on'
  id: totrans-39
  prefs:
  - PREF_IND
  - PREF_IND
  type: TYPE_NORMAL
- en: Note
  id: totrans-40
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_H3
  type: TYPE_NORMAL
- en: 'You can find more information on the `np.random` module here:'
  id: totrans-41
  prefs:
  - PREF_IND
  - PREF_IND
  type: TYPE_NORMAL
- en: '[https://docs.scipy.org/doc/numpy-1.14.0/reference/routines.random.html](https://docs.scipy.org/doc/numpy-1.14.0/reference/routines.random.html)'
  id: totrans-42
  prefs:
  - PREF_IND
  - PREF_IND
  type: TYPE_NORMAL
- en: '`np.arange`: Return an ndarray with evenly spaced values within a given interval.'
  id: totrans-43
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Signature: `numpy.arange([start, ]stop, [step, ]dtype=None)`'
  id: totrans-44
  prefs:
  - PREF_IND
  - PREF_IND
  type: TYPE_NORMAL
- en: 'For example: `np.arange(1, 100, 10)`'
  id: totrans-45
  prefs:
  - PREF_IND
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Results: `array([ 1, 11, 21, 31, 41, 51, 61, 71, 81, 91])`'
  id: totrans-46
  prefs:
  - PREF_IND
  - PREF_IND
  type: TYPE_NORMAL
- en: '`np.linspace`: Similar to `np.arange`, it returns an ndarray with evenly spaced
    values within a given interval, the difference being that with `linspace` you
    specify the number of samples you want instead of the number of steps.'
  id: totrans-47
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: 'For example: `np.linspace(1,100,8, dtype=int)`'
  id: totrans-48
  prefs:
  - PREF_IND
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Results: `array([ 1, 15, 29, 43, 57, 71, 85, 100])`'
  id: totrans-49
  prefs:
  - PREF_IND
  - PREF_IND
  type: TYPE_NORMAL
- en: '`np.full`, `np.full_like`, `np.ones`, `np.ones_like`, `np.zeros`, `np.zeros_like`:
    Create an ndarray initialized with a constant value.'
  id: totrans-50
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: 'For example: `np.ones( (2,2), dtype=int)`'
  id: totrans-51
  prefs:
  - PREF_IND
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Results: `array([[1, 1], [1, 1]])`'
  id: totrans-52
  prefs:
  - PREF_IND
  - PREF_IND
  type: TYPE_NORMAL
- en: '`np.eye`, `np.identity`, `np.diag`: Creates an ndarray with constant values
    in the diagonal:'
  id: totrans-53
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: 'For example: `np.eye(3,3)`'
  id: totrans-54
  prefs:
  - PREF_IND
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Results: `array([[1, 0, 0],[0, 1, 0],[0, 0, 1]])`'
  id: totrans-55
  prefs:
  - PREF_IND
  - PREF_IND
  type: TYPE_NORMAL
- en: Note
  id: totrans-56
  prefs:
  - PREF_IND
  - PREF_H3
  type: TYPE_NORMAL
- en: '**Note**: When the `dtype` argument is not provided, NumPy tries to infer it
    from the input argument. However, it may happen that the type returned is not
    the correct one; for example, float is returned when it should be an integer.
    In this case, you should use the `dtype` argument to force the type. For example:'
  id: totrans-57
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE4]'
  id: totrans-58
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE4]'
- en: Why NumPy arrays are so much faster than their Python lists and arrays counterpart?
  id: totrans-59
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: As mentioned before, operations on NumPy arrays run much faster than their Python
    counterpart. This is because Python is a dynamic language that doesn't know, a
    priori, the type it's dealing with and therefore has to constantly query the metadata
    associated with it to dispatch it to the right method. On the other hand, NumPy
    is highly optimized to deal with large multidimensional arrays of data by, among
    other things, delegating the execution of the CPU-intensive routine to external
    highly optimized C libraries that have been precompiled.
  id: totrans-60
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'To be able to do that, NumPy places two important constraints on ndarrays:'
  id: totrans-61
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '**ndarrays are immutable**: Therefore, if you want to change the shape or the
    size of an ndarray or if you want to add/delete elements, you always must create
    a new one. For example, the following code creates an ndarray using the `arange()`
    function which returns a one-dimensional array with evenly spaced values, and
    then reshapes it to fit a 4 by 5 matrix:'
  id: totrans-62
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[PRE5]'
  id: totrans-63
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE5]'
- en: Note
  id: totrans-64
  prefs:
  - PREF_IND
  - PREF_H3
  type: TYPE_NORMAL
- en: 'You can find the code file here:'
  id: totrans-65
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[https://github.com/DTAIEB/Thoughtful-Data-Science/blob/master/chapter%208/sampleCode2.py](https://github.com/DTAIEB/Thoughtful-Data-Science/blob/master/chapter%208/sampleCode2.py)'
  id: totrans-66
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'The results are as follows:'
  id: totrans-67
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE6]'
  id: totrans-68
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE6]'
- en: '**Elements in an ndarray must be of the same type**: ndarray carries the element
    type in the `dtype` member. When creating a new ndarray using the `nd.array()`
    function, NumPy will automatically infer a type that is suitable for all elements.'
  id: totrans-69
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'For example: `np.array([1,2,3]).dtype` will be `dtype(''int64'')`.'
  id: totrans-70
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '`np.array([1,2,''3'']).dtype` will be `dtype(''<U21'')` where `<` means little endian
    (see [https://en.wikipedia.org/wiki/Endianness](https://en.wikipedia.org/wiki/Endianness))
    and `U21` means a 21-character Unicode string.'
  id: totrans-71
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Note
  id: totrans-72
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '**Note**: You can find detailed information about all the supported data types
    here:'
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
- en: '[https://docs.scipy.org/doc/numpy/reference/arrays.dtypes.html](https://docs.scipy.org/doc/numpy/reference/arrays.dtypes.html)'
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
- en: Operations on ndarray
  id: totrans-75
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Most often, we have the need to summarize data over an ndarray. Fortunately,
    NumPy provides a very rich set of functions (also called **reduction functions**)
    that provide out-of-the-box summarization over an ndarray or an axis of the ndarray.
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
- en: 'For reference, a NumPy axis corresponds to a dimension of the array. For example,
    a two-dimensional ndarray has two axes: one running across rows, which is referred
    to as axis 0 and one running across columns which is called axis 1.'
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
- en: 'The following diagram illustrates the axes in a two-dimensional array:'
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
- en: '![Operations on ndarray](img/B09699_08_02.jpg)'
  id: totrans-79
  prefs: []
  type: TYPE_IMG
- en: Axes in a two-dimensional array
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
- en: 'Most of the reduction functions we''ll discuss next take an axis as an argument.
    They fall into the following categories:'
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
- en: '**Mathematical functions**:'
  id: totrans-82
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Trigonometric: `np.sin`, `np.cos`, and so on'
  id: totrans-83
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Hyperbolic: `np.sinh`, `np.cosh`, and so on'
  id: totrans-84
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Rounding: `np.around`, `np.floor`, and so on'
  id: totrans-85
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Sums, products, differences: `np.sum`, `np.prod`, `np.cumsum`, and so on'
  id: totrans-86
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Exponents and logarithms: `np.exp`, `np.log`, and so on'
  id: totrans-87
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Arithmetic: `np.add`, `np.multiply`, and so on'
  id: totrans-88
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Miscellaneous: `np.sqrt`, `np.absolute`, and so on'
  id: totrans-89
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: Note
  id: totrans-90
  prefs:
  - PREF_IND
  - PREF_H3
  type: TYPE_NORMAL
- en: '**Note**: All these unary functions (functions that take only one argument)
    work directly at the ndarray level. For example, we can use `np.square` to square
    all the values in an array at once:'
  id: totrans-91
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Code: `np.square(np.arange(10))`'
  id: totrans-92
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Results: `array([ 0, 1, 4, 9, 16, 25, 36, 49, 64, 81])`'
  id: totrans-93
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'You can find more information on NumPy mathematical functions here:'
  id: totrans-94
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[https://docs.scipy.org/doc/numpy/reference/routines.math.html](https://docs.scipy.org/doc/numpy/reference/routines.math.html)'
  id: totrans-95
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '**Statistical functions**:'
  id: totrans-96
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Order statistics: `np.amin`, `np.amax`, `np.percentile`, and so on'
  id: totrans-97
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Averages and variances: `np.median`, `np.var`, `np.std`, and so on'
  id: totrans-98
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Correlating: `np.corrcoef`, `np.correlate`, `np.cov`, and so on'
  id: totrans-99
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Histograms: `np.histogram`, `np.bincount`, and so on'
  id: totrans-100
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: Note
  id: totrans-101
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '**Note**: pandas provides very tight integration with NumPy and lets you apply
    these NumPy operations on pandas DataFrames. We''ll use this capability quite
    a bit when analyzing time series in the rest of this chapter.'
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
- en: 'The following code example creates a pandas DataFrame and computes the square
    on all the columns:'
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
- en: '![Operations on ndarray](img/B09699_08_03.jpg)'
  id: totrans-104
  prefs: []
  type: TYPE_IMG
- en: Applying NumPy operations to pandas DataFrames
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
- en: Selections on NumPy arrays
  id: totrans-106
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'NumPy arrays support similar slicing operations as Python arrays and lists.
    So, using an ndarray created with the `np.arrange()` method, we can do the following:'
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE7]'
  id: totrans-108
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: Note
  id: totrans-109
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'You can find the code file here:'
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
- en: '[https://github.com/DTAIEB/Thoughtful-Data-Science/blob/master/chapter%208/sampleCode3.py](https://github.com/DTAIEB/Thoughtful-Data-Science/blob/master/chapter%208/sampleCode3.py)'
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
- en: 'Which produces the following results:'
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE8]'
  id: totrans-113
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: Selections using slices also work with NumPy arrays that have multiple dimensions.
    We can use slices for every dimension in the array. This is not the case for Python
    arrays and lists which only allow indexing using integers of slices.
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
- en: Note
  id: totrans-115
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '**Note**: For reference a slice in Python has the following syntax:'
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE9]'
  id: totrans-117
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: 'As an example, let''s create a NumPy array with the shape `(3,4)`, that is,
    3 rows * 4 columns:'
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE10]'
  id: totrans-119
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: 'Returns:'
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE11]'
  id: totrans-121
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: 'Suppose that I want to select only the middle of the matrix, that is, [5, 6].
    I can simply apply slices on rows and columns, for example, `[1:2]` to select
    the second row and `[1:3]` to select the second and third values in the second
    row:'
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE12]'
  id: totrans-123
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: 'Returns:'
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE13]'
  id: totrans-125
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: Another interesting NumPy feature is that we can also use predicates to index
    an ndarray with Boolean values.
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
- en: 'For example:'
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE14]'
  id: totrans-128
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: 'Returns:'
  id: totrans-129
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE15]'
  id: totrans-130
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: We can then use the Boolean ndarray to select subsets of data with a simple
    and elegant syntax.
  id: totrans-131
  prefs: []
  type: TYPE_NORMAL
- en: 'For example:'
  id: totrans-132
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE16]'
  id: totrans-133
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: 'Returns:'
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE17]'
  id: totrans-135
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: Note
  id: totrans-136
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'This is only a small preview of all the selection capabilities of NumPy. For more
    information on NumPy selection, you can visit:'
  id: totrans-137
  prefs: []
  type: TYPE_NORMAL
- en: '[https://docs.scipy.org/doc/numpy-1.13.0/reference/arrays.indexing.html](https://docs.scipy.org/doc/numpy-1.13.0/reference/arrays.indexing.html)'
  id: totrans-138
  prefs: []
  type: TYPE_NORMAL
- en: Broadcasting
  id: totrans-139
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Broadcasting is a very convenient feature of NumPy. It lets you perform arithmetic
    operations on ndarrays having different shapes. The term **broadcasting** comes
    from the fact that the smaller array is automatically duplicated to fit the bigger
    array so that they have compatible shapes. There are however a set of rules that
    govern how broadcasting works.
  id: totrans-140
  prefs: []
  type: TYPE_NORMAL
- en: Note
  id: totrans-141
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'You can find more information on broadcasting here:'
  id: totrans-142
  prefs: []
  type: TYPE_NORMAL
- en: '[https://docs.scipy.org/doc/numpy/user/basics.broadcasting.html](https://docs.scipy.org/doc/numpy/user/basics.broadcasting.html)'
  id: totrans-143
  prefs: []
  type: TYPE_NORMAL
- en: The simplest form of NumPy broadcasting is **scalar broadcasting**, which lets
    you perform element-wise arithmetic operations between an ndarray and a scalar
    (that is, a number).
  id: totrans-144
  prefs: []
  type: TYPE_NORMAL
- en: 'For example:'
  id: totrans-145
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE18]'
  id: totrans-146
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: 'Returns:'
  id: totrans-147
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE19]'
  id: totrans-148
  prefs: []
  type: TYPE_PRE
  zh: '[PRE19]'
- en: Note
  id: totrans-149
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '**Note**: In the following discussion, we assume that we want to operate on
    two ndarrays which do not have the same dimensions.'
  id: totrans-150
  prefs: []
  type: TYPE_NORMAL
- en: 'Broadcasting with smaller arrays needs to follow only one rule: one of the
    arrays must have at least one of its dimensions equal to 1\. The idea is to duplicate
    the smaller array along the dimensions that don''t match until they do.'
  id: totrans-151
  prefs: []
  type: TYPE_NORMAL
- en: 'The following diagram, taken from the [http://www.scipy-lectures.org/](http://www.scipy-lectures.org/)
    website, illustrates very nicely the different cases for adding two arrays:'
  id: totrans-152
  prefs: []
  type: TYPE_NORMAL
- en: '![Broadcasting](img/B09699_08_04.jpg)'
  id: totrans-153
  prefs: []
  type: TYPE_IMG
- en: Broadcasting flow explained
  id: totrans-154
  prefs: []
  type: TYPE_NORMAL
- en: 'Source: [http://www.scipy-lectures.org/_images/numpy_broadcasting.png](http://www.scipy-lectures.org/_images/numpy_broadcasting.png)'
  id: totrans-155
  prefs: []
  type: TYPE_NORMAL
- en: 'The three use cases demonstrated in the preceding diagram are:'
  id: totrans-156
  prefs: []
  type: TYPE_NORMAL
- en: '**The array''s dimensions match**: Perform the sum element-wise as usual.'
  id: totrans-157
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**The smaller array has only 1 row**: Duplicate the rows until the dimensions
    fit the first array. The same algorithm would be used if the smaller array had only
    1 column.'
  id: totrans-158
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**The first array has only 1 column and the second array only 1 row**:'
  id: totrans-159
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Duplicate the columns in the first array until we have the same number of columns
    as the second array
  id: totrans-160
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: Duplicate the rows in the second array until we have the same number of rows
    as the first array
  id: totrans-161
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: 'The following code sample shows NumPy broadcasting in action:'
  id: totrans-162
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE20]'
  id: totrans-163
  prefs: []
  type: TYPE_PRE
  zh: '[PRE20]'
- en: 'Results:'
  id: totrans-164
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE21]'
  id: totrans-165
  prefs: []
  type: TYPE_PRE
  zh: '[PRE21]'
- en: In this section, we provided a basic introduction to NumPy, at least enough
    to get us started and follow the code samples that we'll cover in the rest of
    this chapter. In the next section, we will start the discussion on time series
    with statistical data exploration to find patterns that will help us to identify
    underlying structures in the data.
  id: totrans-166
  prefs: []
  type: TYPE_NORMAL
- en: Statistical exploration of time series
  id: totrans-167
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: For the sample application, we'll use stock historical financial data provided
    by the Quandl data platform financial APIs ([https://www.quandl.com/tools/api](https://www.quandl.com/tools/api))
    and the `quandl` Python library ([https://www.quandl.com/tools/python](https://www.quandl.com/tools/python)).
  id: totrans-168
  prefs: []
  type: TYPE_NORMAL
- en: 'To get started, we need to install the `quandl` library by running the following
    command in its own cell:'
  id: totrans-169
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE22]'
  id: totrans-170
  prefs: []
  type: TYPE_PRE
  zh: '[PRE22]'
- en: Note
  id: totrans-171
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '**Note**: As always, don''t forget to restart the kernel after the installation
    is complete.'
  id: totrans-172
  prefs: []
  type: TYPE_NORMAL
- en: 'Access to the Quandl data is free but limited to 50 calls a day, but you can
    bypass this limit by creating a free account and get an API key:'
  id: totrans-173
  prefs: []
  type: TYPE_NORMAL
- en: Go to [https://www.quandl.com](https://www.quandl.com) and create a new account
    by clicking on the **SIGN UP** button on the top right.
  id: totrans-174
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Fill up the form in three steps of the sign-up wizard. (I chose **Personal**,
    but depending on your situation, you may want to choose **Business** or **Academic**.)
  id: totrans-175
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: At the end of the process, you should receive an email confirmation with a link
    to activate the account.
  id: totrans-176
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Once the account is activated, log in to the Quandl platform website and click on
    **Account Settings** in the top right-hand menu, and then go to the **API KEY**
    tab.
  id: totrans-177
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Copy the API key provided in this page. This value will be used to programmatically
    set the key in the `quandl` Python library as shown in the following code:'
  id: totrans-178
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE23]'
  id: totrans-179
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE23]'
- en: 'The `quandl` library is mainly composed of two APIs:'
  id: totrans-180
  prefs: []
  type: TYPE_NORMAL
- en: '`quandl.get(dataset, **kwargs)`: This returns a pandas DataFrame or a NumPy
    array for the requested dataset(s). The `dataset` argument can be either a string
    (single dataset) or a list of strings (multi dataset). Each dataset follows the
    syntax `database_code/dataset_code` when `database_code` is a data publisher and
    `dataset_code` related to the resource. (See next how to get a full list of all
    the `database_code` and `dataset_code`).'
  id: totrans-181
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`quandl.get(dataset, **kwargs)`：这将返回一个pandas DataFrame或一个NumPy数组，表示请求的数据集。`dataset`参数可以是一个字符串（单一数据集）或一个字符串列表（多个数据集）。每个数据集遵循`database_code/dataset_code`的语法，其中`database_code`是数据发布者，`dataset_code`与资源相关。（接下来我们将介绍如何获取所有`database_code`和`dataset_code`的完整列表）。'
- en: 'The keyword arguments enable you to refine the query. You can find the full
    list of supported arguments in the `quandl` code on GitHub: [https://github.com/quandl/quandl-python/blob/master/quandl/get.py](https://github.com/quandl/quandl-python/blob/master/quandl/get.py).'
  id: totrans-182
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 关键字参数使你能够精细化查询。你可以在GitHub上的`quandl`代码中找到支持的所有参数的完整列表：[https://github.com/quandl/quandl-python/blob/master/quandl/get.py](https://github.com/quandl/quandl-python/blob/master/quandl/get.py)。
- en: 'One interesting keyword argument called `returns` controls the data structure
    returned by the method and can take the following two values:'
  id: totrans-183
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 一个有趣的关键字参数`returns`控制方法返回的数据结构，它可以取以下两个值：
- en: '`pandas`: Returns a pandas DataFrame'
  id: totrans-184
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`pandas`：返回一个pandas DataFrame'
- en: '`numpy`: Returns a NumPy array'
  id: totrans-185
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`numpy`：返回一个NumPy数组'
- en: '`quandl.get_table(datatable_code, **kwargs)`: Returns a non-time series dataset
    (called `datatable`) about a resource. We will not be using this method in this
    chapter, but you can find out more about it by looking at the code: [https://github.com/quandl/quandl-python/blob/master/quandl/get_table.py](https://github.com/quandl/quandl-python/blob/master/quandl/get_table.py).'
  id: totrans-186
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`quandl.get_table(datatable_code, **kwargs)`：返回一个非时间序列数据集（称为`datatable`），用于描述某个资源。在本章中我们不会使用这个方法，但你可以通过查看代码了解更多：[https://github.com/quandl/quandl-python/blob/master/quandl/get_table.py](https://github.com/quandl/quandl-python/blob/master/quandl/get_table.py)。'
- en: 'To get the list of `database_code`, we use the Quandl REST API: `https://www.quandl.com/api/v3/databases?api_key=YOUR_API_KEY&page=n`
    which uses pagination.'
  id: totrans-187
  prefs: []
  type: TYPE_NORMAL
  zh: 为了获取`database_code`的列表，我们使用Quandl REST API：`https://www.quandl.com/api/v3/databases?api_key=YOUR_API_KEY&page=n`，它使用了分页功能。
- en: Note
  id: totrans-188
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 注意
- en: '**Note**: In the preceding URL, replace the `YOUR_API_KEY` value with your
    actual API key.'
  id: totrans-189
  prefs: []
  type: TYPE_NORMAL
  zh: '**注意**：在前面的URL中，将`YOUR_API_KEY`值替换为你实际的API密钥。'
- en: 'The returned payload is in the following JSON format:'
  id: totrans-190
  prefs: []
  type: TYPE_NORMAL
  zh: 返回的payload是以下JSON格式：
- en: '[PRE24]'
  id: totrans-191
  prefs: []
  type: TYPE_PRE
  zh: '[PRE24]'
- en: Note
  id: totrans-192
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 注意
- en: 'You can find the code file here:'
  id: totrans-193
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以在这里找到代码文件：
- en: '[https://github.com/DTAIEB/Thoughtful-Data-Science/blob/master/chapter%208/sampleCode4.json](https://github.com/DTAIEB/Thoughtful-Data-Science/blob/master/chapter%208/sampleCode4.json)'
  id: totrans-194
  prefs: []
  type: TYPE_NORMAL
  zh: '[https://github.com/DTAIEB/Thoughtful-Data-Science/blob/master/chapter%208/sampleCode4.json](https://github.com/DTAIEB/Thoughtful-Data-Science/blob/master/chapter%208/sampleCode4.json)'
- en: 'We use a `while` loop to load all the available pages relying on the `payload[''meta''][''next_page'']`
    value to know when to stop. At each iteration, we append the list of `database_code`
    information into an array called `databases` as shown in the following code:'
  id: totrans-195
  prefs: []
  type: TYPE_NORMAL
  zh: 我们使用`while`循环加载所有可用的页面，依赖于`payload['meta']['next_page']`值来判断何时停止。在每次迭代中，我们将`database_code`信息的列表追加到一个名为`databases`的数组中，如下所示：
- en: '[PRE25]'
  id: totrans-196
  prefs: []
  type: TYPE_PRE
  zh: '[PRE25]'
- en: Note
  id: totrans-197
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 注意
- en: 'You can find the code file here:'
  id: totrans-198
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以在这里找到代码文件：
- en: '[https://github.com/DTAIEB/Thoughtful-Data-Science/blob/master/chapter%208/sampleCode5.py](https://github.com/DTAIEB/Thoughtful-Data-Science/blob/master/chapter%208/sampleCode5.py)'
  id: totrans-199
  prefs: []
  type: TYPE_NORMAL
  zh: '[https://github.com/DTAIEB/Thoughtful-Data-Science/blob/master/chapter%208/sampleCode5.py](https://github.com/DTAIEB/Thoughtful-Data-Science/blob/master/chapter%208/sampleCode5.py)'
- en: 'The `databases` variable now contains an array of JSON objects containing the
    metadata about each `database_code`. We use the PixieDust `display()` API to look at
    the data in a nice searchable table:'
  id: totrans-200
  prefs: []
  type: TYPE_NORMAL
  zh: '`databases`变量现在包含一个包含每个`database_code`元数据的JSON对象数组。我们使用PixieDust的`display()`
    API以漂亮的可搜索表格形式查看数据：'
- en: '[PRE26]'
  id: totrans-201
  prefs: []
  type: TYPE_PRE
  zh: '[PRE26]'
- en: 'In the following screenshot of the PixieDust table, we use the **Filter** button
    described in [Chapter 2](ch02.xhtml "Chapter 2. Python and Jupyter Notebooks to
    Power your Data Analysis"), *Python and Jupyter Notebooks to Power your Data Analysis*,
    to access the statistics about the count of datasets available in each database,
    for example, min, max and mean:'
  id: totrans-202
  prefs: []
  type: TYPE_NORMAL
  zh: 在下面的PixieDust表格截图中，我们使用[第2章](ch02.xhtml "第2章：用Python和Jupyter Notebook驱动数据分析")中描述的**筛选**按钮，*用Python和Jupyter
    Notebook驱动数据分析*，来查看每个数据库中可用数据集的统计信息，例如最小值、最大值和均值：
- en: '![Statistical exploration of time series](img/B09699_08_05.jpg)'
  id: totrans-203
  prefs: []
  type: TYPE_IMG
  zh: '![时间序列的统计探索](img/B09699_08_05.jpg)'
- en: List of Quandl database codes
  id: totrans-204
  prefs: []
  type: TYPE_NORMAL
  zh: Quandl数据库代码列表
- en: 'After searching for a database that contains stock information from the **New York Stock
    Exchange** (**NYSE**), I found the `XNYS` database as shown here:'
  id: totrans-205
  prefs: []
  type: TYPE_NORMAL
- en: Note
  id: totrans-206
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '**Note**: Make sure to increase the number of the value displayed to `300` in the
    chart options dialog, so all the results are shown in the table.'
  id: totrans-207
  prefs: []
  type: TYPE_NORMAL
- en: '![Statistical exploration of time series](img/B09699_08_06.jpg)'
  id: totrans-208
  prefs: []
  type: TYPE_IMG
- en: Looking for a database with stock data from NYSE
  id: totrans-209
  prefs: []
  type: TYPE_NORMAL
- en: Unfortunately, the `XNYS` database is not public and requires a paid subscription.
    I ended up using the `WIKI` database code, which for some reason was not part
    of the list returned by the preceding API request, but which I found in some code
    examples.
  id: totrans-210
  prefs: []
  type: TYPE_NORMAL
- en: 'I then used the `https://www.quandl.com/api/v3/databases/{database_code}/codes`
    REST API to get the list of datasets. Fortunately, this API returns a CSV compressed
    in a ZIP file, which the PixieDust `sampleData()` method can handle easily, as
    shown in the following code:'
  id: totrans-211
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE27]'
  id: totrans-212
  prefs: []
  type: TYPE_PRE
  zh: '[PRE27]'
- en: Note
  id: totrans-213
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'You can find the code file here:'
  id: totrans-214
  prefs: []
  type: TYPE_NORMAL
- en: '[https://github.com/DTAIEB/Thoughtful-Data-Science/blob/master/chapter%208/sampleCode6.py](https://github.com/DTAIEB/Thoughtful-Data-Science/blob/master/chapter%208/sampleCode6.py)'
  id: totrans-215
  prefs: []
  type: TYPE_NORMAL
- en: 'In the PixieDust table interface, we click on the **Options** dialog to increase
    the number of values displayed to `4000` so that we can fit the entire dataset
    (which is 3,198) and use the search bar to look for particular stocks as shown
    in the following screenshot:'
  id: totrans-216
  prefs: []
  type: TYPE_NORMAL
- en: Note
  id: totrans-217
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '**Note**: The search bar only searches for the rows that are displayed in the
    browser, which can be a smaller set when the dataset is too large. Since in this
    case, the dataset is too large, it would be impractical to increase the number
    of rows to display; it is recommended to use the **Filter** instead which guarantees
    to query the entire dataset.'
  id: totrans-218
  prefs: []
  type: TYPE_NORMAL
- en: The CSV file returned by the `quandl` API doesn't have a header, but `PixieDust.sampleData()`
    expects one to be there. This is currently a limitation that will be addressed
    in the future.
  id: totrans-219
  prefs: []
  type: TYPE_NORMAL
- en: '![Statistical exploration of time series](img/B09699_08_07.jpg)'
  id: totrans-220
  prefs: []
  type: TYPE_IMG
- en: List of datasets for the WIKI database
  id: totrans-221
  prefs: []
  type: TYPE_NORMAL
- en: 'For the rest of this section, we load the Microsoft stock (ticker symbol MSFT)
    historical time series data for the last several years and start exploring its
    statistical properties. In the following code, we use `quandl.get()` with the
    `WIKI/MSFT` dataset. We add a column called `daily_spread` that computes the daily
    gain/loss by calling the pandas `diff()` method, which returns the difference
    between the current and previous adjusted close price. Note that the returned
    pandas DataFrame uses the dates as an index, but PixieDust does not support plotting
    time series by the index at this time. Therefore, in the following code, we call
    `reset_index()` to convert the `DateTime` index into a new column called `Date`
    that contains the dates information:'
  id: totrans-222
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE28]'
  id: totrans-223
  prefs: []
  type: TYPE_PRE
  zh: '[PRE28]'
- en: Note
  id: totrans-224
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'You can find the code file here:'
  id: totrans-225
  prefs: []
  type: TYPE_NORMAL
- en: '[https://github.com/DTAIEB/Thoughtful-Data-Science/blob/master/chapter%208/sampleCode7.py](https://github.com/DTAIEB/Thoughtful-Data-Science/blob/master/chapter%208/sampleCode7.py)'
  id: totrans-226
  prefs: []
  type: TYPE_NORMAL
- en: For our first data exploration, we use `display()` to create a line chart of
    the stock adjusted closing price over time using the Bokeh renderer.
  id: totrans-227
  prefs: []
  type: TYPE_NORMAL
- en: 'The following screenshot shows the **Options** configuration and the resulting
    line chart:'
  id: totrans-228
  prefs: []
  type: TYPE_NORMAL
- en: '![Statistical exploration of time series](img/B09699_08_08.jpg)'
  id: totrans-229
  prefs: []
  type: TYPE_IMG
- en: MSFT Price over time, adjusted for dividend distribution, stock split, and other
    corporate actions
  id: totrans-230
  prefs: []
  type: TYPE_NORMAL
- en: 'We can also generate a chart that shows the daily spread for each day of the
    period, as shown in the following screenshot:'
  id: totrans-231
  prefs: []
  type: TYPE_NORMAL
- en: '![Statistical exploration of time series](img/B09699_08_09.jpg)'
  id: totrans-232
  prefs: []
  type: TYPE_IMG
- en: Daily Spread for the MSFT stock
  id: totrans-233
  prefs: []
  type: TYPE_NORMAL
- en: Hypothetical investment
  id: totrans-234
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: As an exercise, let's try to create a chart that shows how a hypothetical investment
    of $10,000 in the selected stock (MSFT) would fare over time. To do this, we must
    compute a DataFrame that contains the total investment value for each day of the
    period, factoring in the daily spread that we calculated in the previous paragraph
    and use the PixieDust `display()` API to visualize the data.
  id: totrans-235
  prefs: []
  type: TYPE_NORMAL
- en: We use pandas ability to select rows using a predicate based on dates to first
    filter the DataFrame to select only the data points in the period we are interested
    in. We then calculate the number of shares bought by dividing the initial investment
    of $10,000 by the closing price on the first day of the period and add the initial
    investment value. All this computation is made very easy, thanks to the efficient
    series computation of pandas and the underlying NumPy foundational library. We use
    the `np.cumsum()` method ([https://docs.scipy.org/doc/numpy-1.14.0/reference/generated/numpy.cumsum.html](https://docs.scipy.org/doc/numpy-1.14.0/reference/generated/numpy.cumsum.html))
    to compute the cumulative sum of all the daily gains adding the initial investment
    value of $10,000.
  id: totrans-236
  prefs: []
  type: TYPE_NORMAL
- en: Finally, we make the chart easier to read by using the `resample()` method that
    converts the frequency from daily to monthly computing the new values using the average
    for the month.
  id: totrans-237
  prefs: []
  type: TYPE_NORMAL
- en: 'The following code computes the growth DataFrame using a period starting in May 2016:'
  id: totrans-238
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE29]'
  id: totrans-239
  prefs: []
  type: TYPE_PRE
  zh: '[PRE29]'
- en: Note
  id: totrans-240
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'You can find the code file here:'
  id: totrans-241
  prefs: []
  type: TYPE_NORMAL
- en: '[https://github.com/DTAIEB/Thoughtful-Data-Science/blob/master/chapter%208/sampleCode8.py](https://github.com/DTAIEB/Thoughtful-Data-Science/blob/master/chapter%208/sampleCode8.py)'
  id: totrans-242
  prefs: []
  type: TYPE_NORMAL
- en: 'The following screenshot shows the graph generated by the `display()` API including
    the configuration options:'
  id: totrans-243
  prefs: []
  type: TYPE_NORMAL
- en: '![Hypothetical investment](img/B09699_08_10.jpg)'
  id: totrans-244
  prefs: []
  type: TYPE_IMG
- en: Hypothetical portfolio growth
  id: totrans-245
  prefs: []
  type: TYPE_NORMAL
- en: Autocorrelation function (ACF) and partial autocorrelation function (PACF)
  id: totrans-246
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Before trying to generate predictive models, it is essential to understand whether
    the time series has identifiable patterns, such as seasonality or trends. One
    popular technique is to look at how data points correlate with previous data points
    according to a specified time lag. The intuition is that the autocorrelation would
    reveal internal structures, such as for example, identifying periods when high
    correlation (positive or negative) occurs. You can experiment with different lag
    values (that is, for each data point, how many previous points are you taking
    into account) to find the right periodicity.
  id: totrans-247
  prefs: []
  type: TYPE_NORMAL
- en: Computing the ACF usually requires calculating the Pearson R correlation coefficient
    for the set of data points ([https://en.wikipedia.org/wiki/Pearson_correlation_coefficient](https://en.wikipedia.org/wiki/Pearson_correlation_coefficient))
    which is not a trivial thing to do. The good news is that the `statsmodels` Python
    library has a `tsa` package (**tsa** stands for **time series analysis**) that
    provides helper methods for computing the ACF, that are tightly integrated with
    pandas Series.
  id: totrans-248
  prefs: []
  type: TYPE_NORMAL
- en: Note
  id: totrans-249
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '**Note**: If not already done, we install the `statsmodels` package using the following
    command, restarting the kernel after completion:'
  id: totrans-250
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE30]'
  id: totrans-251
  prefs: []
  type: TYPE_PRE
  zh: '[PRE30]'
- en: 'The following code uses `plot_acf()` from the `tsa.api.graphics` package to
    compute and visualize the ACF for the adjusted close price of the MSFT stock time series:'
  id: totrans-252
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE31]'
  id: totrans-253
  prefs: []
  type: TYPE_PRE
  zh: '[PRE31]'
- en: 'The following is the result:'
  id: totrans-254
  prefs: []
  type: TYPE_NORMAL
- en: '![Autocorrelation function (ACF) and partial autocorrelation function (PACF)](img/B09699_08_11.jpg)'
  id: totrans-255
  prefs: []
  type: TYPE_IMG
- en: ACF for MSFT with lags = 100
  id: totrans-256
  prefs: []
  type: TYPE_NORMAL
- en: The preceding chart shows the autocorrelation of the data at a number of previous
    data points (lag) given by the *x* abscissa. So, at lag `0`, you always have an
    autocorrelation of `1.0` (you always correlate perfectly with yourself), lag `1`
    shows the autocorrelation with the previous data point, lag `2` shows the autocorrelation
    with the data point that is two steps behind. We can clearly see that the autocorrelation
    decreases as the lags increase. In the preceding chart, we used only 100 lags,
    and we see that the autocorrelation still remains statistically significant at
    around 0.9, which tells us that data separated by long periods of time is not
    correlated. This suggests that the data has a trend, which is quite obvious when
    glancing at the overall price chart.
  id: totrans-257
  prefs: []
  type: TYPE_NORMAL
- en: 'To confirm this hypothesis, we plot the ACF chart with a bigger `lags` argument,
    say `1000` (which is not unreasonable given the fact that our series has more
    than 10,000 data points), as shown in the following screenshot:'
  id: totrans-258
  prefs: []
  type: TYPE_NORMAL
- en: '![Autocorrelation function (ACF) and partial autocorrelation function (PACF)](img/B09699_08_12.jpg)'
  id: totrans-259
  prefs: []
  type: TYPE_IMG
- en: ACF for MSFT with lags = 1000
  id: totrans-260
  prefs: []
  type: TYPE_NORMAL
- en: We now clearly see that the autocorrelation falls below the significance level
    at around `600` lags.
  id: totrans-261
  prefs: []
  type: TYPE_NORMAL
- en: 'To better illustrate how the ACF works, let''s generate a time series that
    is periodic, without a trend and see what we can learn. For example, we can use
    `np.cos()` on a series of evenly spaced points generated with `np.linspace()`:'
  id: totrans-262
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE32]'
  id: totrans-263
  prefs: []
  type: TYPE_PRE
  zh: '[PRE32]'
- en: Note
  id: totrans-264
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'You can find the code file here:'
  id: totrans-265
  prefs: []
  type: TYPE_NORMAL
- en: '[https://github.com/DTAIEB/Thoughtful-Data-Science/blob/master/chapter%208/sampleCode9.py](https://github.com/DTAIEB/Thoughtful-Data-Science/blob/master/chapter%208/sampleCode9.py)'
  id: totrans-266
  prefs: []
  type: TYPE_NORMAL
- en: 'The results are as follows:'
  id: totrans-267
  prefs: []
  type: TYPE_NORMAL
- en: '![Autocorrelation function (ACF) and partial autocorrelation function (PACF)](img/B09699_08_13.jpg)'
  id: totrans-268
  prefs: []
  type: TYPE_IMG
- en: ACF for a periodic series with no trends
  id: totrans-269
  prefs: []
  type: TYPE_NORMAL
- en: In the preceding chart, we can see that the autocorrelation spikes again at
    regular intervals (every 5 lags or so), clearly showing periodicity (also called
    seasonality when dealing with real-world data).
  id: totrans-270
  prefs: []
  type: TYPE_NORMAL
- en: 'Using ACF to detect structure in your time series can sometimes lead to problems,
    especially when you have strong periodicity. In this case, you''ll always see
    a spike in autocorrelation at a multiple of the period, no matter how far back
    you try to autocorrelate your data and this could lead to the wrong interpretation.
    To work around this problem, we use the PACF which uses a shorter lag and unlike
    ACF, doesn''t reuse correlations previously found in shorter time periods. The
    math for ACF and PACF is rather complex, but the reader only needs to understand
    the intuition behind it and happily use libraries such as `statsmodels` to do
    the heavy lifting computation. One resource I used to get more information on
    ACF and PACF can be found here: [https://www.mathworks.com/help/econ/autocorrelation-and-partial-autocorrelation.html](https://www.mathworks.com/help/econ/autocorrelation-and-partial-autocorrelation.html).'
  id: totrans-271
  prefs: []
  type: TYPE_NORMAL
- en: 'Back to our MSFT stock time series, the following code shows how to plot its
    PACF using the `smt.graphics` package:'
  id: totrans-272
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE33]'
  id: totrans-273
  prefs: []
  type: TYPE_PRE
  zh: '[PRE33]'
- en: Note
  id: totrans-274
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'You can find the code file here:'
  id: totrans-275
  prefs: []
  type: TYPE_NORMAL
- en: '[https://github.com/DTAIEB/Thoughtful-Data-Science/blob/master/chapter%208/sampleCode10.py](https://github.com/DTAIEB/Thoughtful-Data-Science/blob/master/chapter%208/sampleCode10.py)'
  id: totrans-276
  prefs: []
  type: TYPE_NORMAL
- en: 'The results are shown in the following screenshot:'
  id: totrans-277
  prefs: []
  type: TYPE_NORMAL
- en: '![Autocorrelation function (ACF) and partial autocorrelation function (PACF)](img/B09699_08_14.jpg)'
  id: totrans-278
  prefs: []
  type: TYPE_IMG
- en: Partial autocorrelation for the MSFT stock time series
  id: totrans-279
  prefs: []
  type: TYPE_NORMAL
- en: We'll get back to ACF and PACF later on in this chapter when we discuss time
    series forecasting with the ARIMA model.
  id: totrans-280
  prefs: []
  type: TYPE_NORMAL
- en: In this section, we've discussed multiple ways to explore the data. It is of
    course by no means exhaustive, but we get the idea of how tools such as Jupyter,
    pandas, NumPy, and PixieDust make it easier to experiment and fail fast if necessary.
    In the next section, we will build a PixieApp that brings all these charts together.
  id: totrans-281
  prefs: []
  type: TYPE_NORMAL
- en: Putting it all together with the StockExplorer PixieApp
  id: totrans-282
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'For the first version of our `StockExplorer` PixieApp, we want to operationalize
    the data exploration of a stock data time series selected by the user. Similar
    to the other PixieApps we''ve built, the first screen has a simple layout with
    an input box where the user can enter a list of stock tickers separated by commas,
    and an **Explore** button to start data exploration. The main screen is composed
    of a vertical navigator bar with a menu for each type of data exploration. To
    make the PixieApp code more modular and easier to maintain and extend, we implement
    each data exploration screen in its own child PixieApp which is triggered by the
    vertical navigation bar. Also, each child PixieApp inherits from a base class
    called `BaseSubApp` that provides common functionalities useful to all the subclasses.
    The following diagram shows the overall UI layout as well as a class diagram for
    all the child PixieApps:'
  id: totrans-283
  prefs: []
  type: TYPE_NORMAL
- en: '![Putting it all together with the StockExplorer PixieApp](img/B09699_08_15.jpg)'
  id: totrans-284
  prefs: []
  type: TYPE_IMG
- en: UI layout of the StockExplorer PixieApp
  id: totrans-285
  prefs: []
  type: TYPE_NORMAL
- en: Let's first look at the implementation for the welcome screen. It is implemented
    in the default route for the `StockExplorer` PixieApp class. The following code
    shows a partial implementation of the `StockExplorer` class to include the default
    route only.
  id: totrans-286
  prefs: []
  type: TYPE_NORMAL
- en: Note
  id: totrans-287
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '**Note**: Do not try to run this code yet, until the full implementation is provided.'
  id: totrans-288
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE34]'
  id: totrans-289
  prefs: []
  type: TYPE_PRE
  zh: '[PRE34]'
- en: Note
  id: totrans-290
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'You can find the code file here:'
  id: totrans-291
  prefs: []
  type: TYPE_NORMAL
- en: '[https://github.com/DTAIEB/Thoughtful-Data-Science/blob/master/chapter%208/sampleCode11.py](https://github.com/DTAIEB/Thoughtful-Data-Science/blob/master/chapter%208/sampleCode11.py)'
  id: totrans-292
  prefs: []
  type: TYPE_NORMAL
- en: 'The preceding code is very similar to the other sample PixieApps we''ve seen
    so far. The **Explore** button contains the following two PixieApp attributes:'
  id: totrans-293
  prefs: []
  type: TYPE_NORMAL
- en: 'A `pd_script` child element, which calls a Python snippet to set the stock
    tickers. We also use the `$val` directive to retrieve the user-entered value for
    the stock tickers:'
  id: totrans-294
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[PRE35]'
  id: totrans-295
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE35]'
- en: 'The `pd_options` attribute, which points to the `explore` route:'
  id: totrans-296
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[PRE36]'
  id: totrans-297
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE36]'
- en: The `select_tickers` helper method stores the list of tickers in a dictionary
    member variable and selects the first one as the active ticker. For performance
    reasons, we only load the data when needed, that is, when setting the active ticker
    for the first time or when the user clicks on a particular ticker in the UI.
  id: totrans-298
  prefs: []
  type: TYPE_NORMAL
- en: Note
  id: totrans-299
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '**Note**: As in previous chapters, the `[[StockExplorer]]` notation indicates
    that the code that follows is part of the `StockExplorer` class.'
  id: totrans-300
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE37]'
  id: totrans-301
  prefs: []
  type: TYPE_PRE
  zh: '[PRE37]'
- en: Note
  id: totrans-302
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'You can find the code file here:'
  id: totrans-303
  prefs: []
  type: TYPE_NORMAL
- en: '[https://github.com/DTAIEB/Thoughtful-Data-Science/blob/master/chapter%208/sampleCode12.py](https://github.com/DTAIEB/Thoughtful-Data-Science/blob/master/chapter%208/sampleCode12.py)'
  id: totrans-304
  prefs: []
  type: TYPE_NORMAL
- en: 'The lazy loading of the stock data for a particular ticker symbol into a pandas
    DataFrame is done in `set_active_ticker()`. We first check whether the DataFrame
    has already been loaded by looking if the `df` key is present and, if not, we call the
    `quandl` API with the `dataset_code`: `''WIKI/{ticker}''`. We also add a column
    that computes the daily spread of the stock that will be displayed in the basic
    exploration screen. Finally, we need to call `reset_index()` ([https://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.reset_index.html](https://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.reset_index.html))
    on the DataFrame to convert the index which is a `DateTimeIndex` into its own column
    called `Date`. The reason is that the PixieDust `display()` doesn''t yet support visualization
    of DataFrame with a `DateTimeIndex`.'
  id: totrans-305
  prefs: []
  type: TYPE_NORMAL
- en: In the `explore` route, we return an HTML fragment that builds the layout for
    the whole screen. As shown in the preceding mock-up, we use the `btn-group-vertical`
    and `btn-group-toggle` bootstrap classes to create the vertical navigation bar.
    The list of menus and associated child PixieApp are defined in the `tabs` Python
    variable, and we use Jinja2 `{%for loop%}` to build the content. We also add a
    placeholder `<div>` element with `id ="analytic_screen{{prefix}}"` that will be
    the recipient of the child PixieApp screen.
  id: totrans-306
  prefs: []
  type: TYPE_NORMAL
- en: 'The `explore` route implementation is shown here:'
  id: totrans-307
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE38]'
  id: totrans-308
  prefs: []
  type: TYPE_PRE
  zh: '[PRE38]'
- en: Note
  id: totrans-309
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'You can find the code file here:'
  id: totrans-310
  prefs: []
  type: TYPE_NORMAL
- en: '[https://github.com/DTAIEB/Thoughtful-Data-Science/blob/master/chapter%208/sampleCode13.py](https://github.com/DTAIEB/Thoughtful-Data-Science/blob/master/chapter%208/sampleCode13.py)'
  id: totrans-311
  prefs: []
  type: TYPE_NORMAL
- en: In the preceding code, notice that we use the `@templateArgs` decorator because
    we want to use the `tabs` variable, which is created locally to the method implementation,
    in the Jinja2 template.
  id: totrans-312
  prefs: []
  type: TYPE_NORMAL
- en: Each menu in the vertical navigation bar points to the same `analytic_screen{{prefix}}`
    target and invokes the `show_analytic` route with the selected child PixieApp
    class name referenced by `{{subapp}}`.
  id: totrans-313
  prefs: []
  type: TYPE_NORMAL
- en: In turn, the `show_anatytic` route simply returns an HTML fragment with a `<div>` element
    that has a `pd_app` attribute referencing the child PixieApp class name. We also
    use the `pd_render_onload` attribute to ask PixieApp to render the content of the
    `<div>` element as soon as it is loaded in the browser DOM.
  id: totrans-314
  prefs: []
  type: TYPE_NORMAL
- en: 'The following code is for the `show_analytic` route:'
  id: totrans-315
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE39]'
  id: totrans-316
  prefs: []
  type: TYPE_PRE
  zh: '[PRE39]'
- en: Note
  id: totrans-317
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'You can find the code file here:'
  id: totrans-318
  prefs: []
  type: TYPE_NORMAL
- en: '[https://github.com/DTAIEB/Thoughtful-Data-Science/blob/master/chapter%208/sampleCode14.py](https://github.com/DTAIEB/Thoughtful-Data-Science/blob/master/chapter%208/sampleCode14.py)'
  id: totrans-319
  prefs: []
  type: TYPE_NORMAL
- en: BaseSubApp – base class for all the child PixieApps
  id: totrans-320
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Let''s now look at the implementation for each of the child PixieApps and how
    the base class `BaseSubApp` is used to provide common functionalities. For each
    child PixieApp we want the user to be able to select a stock ticker through a
    tabbed interface as shown in the following screenshot:'
  id: totrans-321
  prefs: []
  type: TYPE_NORMAL
- en: '![BaseSubApp – base class for all the child PixieApps](img/B09699_08_16.jpg)'
  id: totrans-322
  prefs: []
  type: TYPE_IMG
- en: Tab widget for MSFT, IBM, AMZN tickers
  id: totrans-323
  prefs: []
  type: TYPE_NORMAL
- en: 'Instead of repeating the HTML fragment for every child PixieApp, we use a technique
    that I particularly like which consists of creating a Python decorator called
    `add_ticker_selection_markup` that dynamically changes how the function behaves
    (for more information on Python decorators, see [https://wiki.python.org/moin/PythonDecorators](https://wiki.python.org/moin/PythonDecorators)).
    This decorator is created in the `BaseSubApp` class and will automatically prepend
    the tab selection widget HTML markup for the route, as shown in the following
    code:'
  id: totrans-324
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE40]'
  id: totrans-325
  prefs: []
  type: TYPE_PRE
  zh: '[PRE40]'
- en: Note
  id: totrans-326
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'You can find the code file here:'
  id: totrans-327
  prefs: []
  type: TYPE_NORMAL
- en: '[https://github.com/DTAIEB/Thoughtful-Data-Science/blob/master/chapter%208/sampleCode15.py](https://github.com/DTAIEB/Thoughtful-Data-Science/blob/master/chapter%208/sampleCode15.py)'
  id: totrans-328
  prefs: []
  type: TYPE_NORMAL
- en: 'At first glance, the preceding code may appear very hard to read as the `add_ticker_selection_markup`
    decorator method contains two levels of anonymous nested methods. Let''s try to
    explain the purpose for each of them including the main `add_ticker_selection_markup`
    decorator method:'
  id: totrans-329
  prefs: []
  type: TYPE_NORMAL
- en: '`add_ticker_selection_markup`: This is the main decorator method that takes
    one argument called `refresh_ids` which will be used in the generated markup.
    This method returns an anonymous function called `deco` that takes a function
    argument.'
  id: totrans-330
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`deco`: This is the wrapper method that takes one argument called `fn` which
    is a pointer to the original function to which the decorator is applied. This
    method returns an anonymous function called `wrap` which will be called in lieu
    of the original function when it is called in the user code.'
  id: totrans-331
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`wrap`: This is the final wrapper method that takes three arguments:'
  id: totrans-332
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`self`: Pointer to the host class for the function'
  id: totrans-333
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '`*args`: Any variable arguments that the original method defines (could be
    empty)'
  id: totrans-334
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '`**kwargs`: Any keyword arguments that the original method defines (could be
    empty)'
  id: totrans-335
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: The `wrap` method can access the variables that are outside its scope through
    the Python closure mechanism. In this case, it uses the `refresh_ids` to generate
    the tab widget markup, and then calls the `fn` function with the `self`, `args`,
    and `kwargs` arguments.
  id: totrans-336
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Note
  id: totrans-337
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '**Note**: Do not worry if the preceding explanation is still confusing, even
    after reading it multiple times. You can just use the decorator for now, and it
    won''t affect your ability to understand the rest of the chapter.'
  id: totrans-338
  prefs: []
  type: TYPE_NORMAL
- en: StockExploreSubApp – first child PixieApp
  id: totrans-339
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: We can now implement the first child PixieApp called `StockExploreSubApp`. In
    the main screen, we create two `<div>` elements that each have a `pd_options`
    attribute that calls the `show_chart` route with `Adj. Close` and `daily_spread`
    as values. In turn, the `show_chart` route returns a `<div>` element with a `pd_entity`
    attribute pointing to the `parent_pixieapp.get_active_df()` method with a `<pd_options>`
    element that contains a JSON payload for displaying a Bokeh line chart with `Date`
    as the *x* abscissa and whatever value is passed as an argument as the column
    for the *y* ordinate. We also decorate the route with the `BaseSubApp.add_ticker_selection_markup`
    decorator using the ID of the preceding two `<div>` elements as the `refresh_ids`
    argument.
  id: totrans-340
  prefs: []
  type: TYPE_NORMAL
- en: 'The following code shows the implementation for the `StockExplorerSubApp` child PixieApp:'
  id: totrans-341
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE41]'
  id: totrans-342
  prefs: []
  type: TYPE_PRE
  zh: '[PRE41]'
- en: Note
  id: totrans-343
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'You can find the code file here:'
  id: totrans-344
  prefs: []
  type: TYPE_NORMAL
- en: '[https://github.com/DTAIEB/Thoughtful-Data-Science/blob/master/chapter%208/sampleCode16.py](https://github.com/DTAIEB/Thoughtful-Data-Science/blob/master/chapter%208/sampleCode16.py)'
  id: totrans-345
  prefs: []
  type: TYPE_NORMAL
- en: 'In the preceding `show_chart` route, the `pd_entity` uses the `get_active_df()`
    method from the `parent_pixieapp` which is defined in the `StockExplorer` main
    class as follows:'
  id: totrans-346
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE42]'
  id: totrans-347
  prefs: []
  type: TYPE_PRE
  zh: '[PRE42]'
- en: Note
  id: totrans-348
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'You can find the code file here:'
  id: totrans-349
  prefs: []
  type: TYPE_NORMAL
- en: '[https://github.com/DTAIEB/Thoughtful-Data-Science/blob/master/chapter%208/sampleCode17.py](https://github.com/DTAIEB/Thoughtful-Data-Science/blob/master/chapter%208/sampleCode17.py)'
  id: totrans-350
  prefs: []
  type: TYPE_NORMAL
- en: 'As a reminder, the `StockExploreSubApp` is associated with the menu through
    a tuple in the `tabs` array variable declared in the `Explore` route of the `StockExplorer`
    route:'
  id: totrans-351
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE43]'
  id: totrans-352
  prefs: []
  type: TYPE_PRE
  zh: '[PRE43]'
- en: Note
  id: totrans-353
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'You can find the code file here:'
  id: totrans-354
  prefs: []
  type: TYPE_NORMAL
- en: '[https://github.com/DTAIEB/Thoughtful-Data-Science/blob/master/chapter%208/sampleCode18.py](https://github.com/DTAIEB/Thoughtful-Data-Science/blob/master/chapter%208/sampleCode18.py)'
  id: totrans-355
  prefs: []
  type: TYPE_NORMAL
- en: 'The following screenshot shows the `StockExploreSubApp`:'
  id: totrans-356
  prefs: []
  type: TYPE_NORMAL
- en: '![StockExploreSubApp – first child PixieApp](img/B09699_08_17.jpg)'
  id: totrans-357
  prefs: []
  type: TYPE_IMG
- en: StockExploreSubApp main screen
  id: totrans-358
  prefs: []
  type: TYPE_NORMAL
- en: MovingAverageSubApp – second child PixieApp
  id: totrans-359
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The second child PixieApp is `MovingAverageSubApp` which displays a line chart
    of the moving average for the selected stock ticker with a lag that is configurable
    through a slider control. Similar to the ticker selection tab, the lag slider
    will be needed in another child PixieApp. We could use the same decorator technique
    we use for the ticker selection tab control, but here we want to be able to position
    the lag slider anywhere on the page. So instead, we'll use a `pd_widget` control
    called `lag_slider` that we define in the `BaseSubApp` class and return an HTML
    fragment for the slider control. It also adds a `<script>` element that uses the
    jQuery `slider` method available in the jQuery UI module (see [https://api.jqueryui.com/slider](https://api.jqueryui.com/slider)
    for more information). We also add a `change` handler function that is called when
    the user has selected a new value. In this handler, we call the `pixiedust.sendEvent`
    function to publish an event of the `lagSlider` type and a payload containing
    the new value for the lag. It is the responsibility of the caller to add a `<pd_event_handler>`
    element to listen to that event and process the payload.
  id: totrans-360
  prefs: []
  type: TYPE_NORMAL
- en: 'The following code shows the implementation of the `lag_slider` `pd_widget`:'
  id: totrans-361
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE44]'
  id: totrans-362
  prefs: []
  type: TYPE_PRE
  zh: '[PRE44]'
- en: Note
  id: totrans-363
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'You can find the code file here:'
  id: totrans-364
  prefs: []
  type: TYPE_NORMAL
- en: '[https://github.com/DTAIEB/Thoughtful-Data-Science/blob/master/chapter%208/sampleCode19.py](https://github.com/DTAIEB/Thoughtful-Data-Science/blob/master/chapter%208/sampleCode19.py)'
  id: totrans-365
  prefs: []
  type: TYPE_NORMAL
- en: In the `MovingAverageSubApp` we use the `add_ticker_selection_markup` decorator
    with `chart{{prefix}}` as an argument in the default route to add the ticker selection
    tab and add a `<div>` element with `pd_widget` named `lag_slider`, including a
    `<pd_event_handler>` to set the `self.lag` variable and refresh the `chart` div.
    The `chart` div uses a `pd_entity` attribute with the `get_moving_average_df()`
    method that calls the `rolling` method ([https://pandas.pydata.org/pandas-docs/stable/generated/pandas.Series.rolling.html](https://pandas.pydata.org/pandas-docs/stable/generated/pandas.Series.rolling.html))
    on the pandas Series returned from the selected pandas DataFrame and calls the
    `mean()` method on it. Because the PixieDust `display()` does not yet support
    pandas Series, we build a pandas DataFrame using the series index as a column
    called `x` and return it in the `get_moving_average_df()` method.
  id: totrans-366
  prefs: []
  type: TYPE_NORMAL
- en: The following code shows the implementation of the `MovingAverageSubApp` child
    PixieApp
  id: totrans-367
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE45]'
  id: totrans-368
  prefs: []
  type: TYPE_PRE
  zh: '[PRE45]'
- en: Note
  id: totrans-369
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'You can find the code file here:'
  id: totrans-370
  prefs: []
  type: TYPE_NORMAL
- en: '[https://github.com/DTAIEB/Thoughtful-Data-Science/blob/master/chapter%208/sampleCode20.py](https://github.com/DTAIEB/Thoughtful-Data-Science/blob/master/chapter%208/sampleCode20.py)'
  id: totrans-371
  prefs: []
  type: TYPE_NORMAL
- en: 'The following screenshot shows the chart displayed by the `MovingAverageSubApp`:'
  id: totrans-372
  prefs: []
  type: TYPE_NORMAL
- en: '![MovingAverageSubApp – second child PixieApp](img/B09699_08_18.jpg)'
  id: totrans-373
  prefs: []
  type: TYPE_IMG
- en: MovingAverageSubApp screenshot
  id: totrans-374
  prefs: []
  type: TYPE_NORMAL
- en: AutoCorrelationSubApp – third child PixieApp
  id: totrans-375
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: For the third child, PixieApp called `AutoCorrelationSubApp`; we display the
    ACF and PACF of the selected stock DataFrame, which are computed using the `statsmodels`
    package.
  id: totrans-376
  prefs: []
  type: TYPE_NORMAL
- en: 'The following code shows the implementation of the `AutoCorrelationSubApp`
    which also uses the `add_ticker_selection_markup` decorator and the `pd_widget`
    named `lag_slider`:'
  id: totrans-377
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE46]'
  id: totrans-378
  prefs: []
  type: TYPE_PRE
  zh: '[PRE46]'
- en: Note
  id: totrans-379
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'You can find the code file here:'
  id: totrans-380
  prefs: []
  type: TYPE_NORMAL
- en: '[https://github.com/DTAIEB/Thoughtful-Data-Science/blob/master/chapter%208/sampleCode21.py](https://github.com/DTAIEB/Thoughtful-Data-Science/blob/master/chapter%208/sampleCode21.py)'
  id: totrans-381
  prefs: []
  type: TYPE_NORMAL
- en: 'In the preceding code, we define two routes: `show_acf` and `show_pacf` which
    respectively call the `plot_acf` and `plot_pacf` methods of the `smt.graphics`
    package. We also use the `@captureOutput` decorator to signal the PixieApp framework
    to capture the output generated by `plot_acf` and `plot_pacf`.'
  id: totrans-382
  prefs: []
  type: TYPE_NORMAL
- en: 'The following screenshot shows the charts displayed by `AutoCorrelationSubApp`:'
  id: totrans-383
  prefs: []
  type: TYPE_NORMAL
- en: '![AutoCorrelationSubApp – third child PixieApp](img/B09699_08_19.jpg)'
  id: totrans-384
  prefs: []
  type: TYPE_IMG
- en: AutoCorrelationSubApp screenshot
  id: totrans-385
  prefs: []
  type: TYPE_NORMAL
- en: 'In this section, we showed how to put together a sample PixieApp that does
    basic data exploration on a time series and display various statistical charts.
    The complete Notebook can be found here: [https://github.com/DTAIEB/Thoughtful-Data-Science/blob/master/chapter%208/StockExplorer%20-%20Part%201.ipynb](https://github.com/DTAIEB/Thoughtful-Data-Science/blob/master/chapter%208/StockExplorer%20-%20Part%201.ipynb).'
  id: totrans-386
  prefs: []
  type: TYPE_NORMAL
- en: In the next section, we try to build a time series forecast model using a very
    popular model called **Autoregressive Integrated Moving Average** (**ARIMA**).
  id: totrans-387
  prefs: []
  type: TYPE_NORMAL
- en: Time series forecasting using the ARIMA model
  id: totrans-388
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'ARIMA is one of the most popular time series forecasting models and as its
    name indicates is made up of three terms:'
  id: totrans-389
  prefs: []
  type: TYPE_NORMAL
- en: '**AR**: Stands for **autoregression**, which is nothing more than applying
    a linear regression algorithm using one observation and its own lagged observations
    as training data.'
  id: totrans-390
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'The AR model uses the following formula:'
  id: totrans-391
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '![Time series forecasting using the ARIMA model](img/B09699_08_31.jpg)'
  id: totrans-392
  prefs:
  - PREF_IND
  type: TYPE_IMG
- en: Where ![Time series forecasting using the ARIMA model](img/B09699_08_32.jpg)
    are the weights of the models learned from the previous observations and ![Time
    series forecasting using the ARIMA model](img/B09699_08_33.jpg) is the residual
    error for observation *t*.
  id: totrans-393
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: We also call *p* the order of the autoregression model, which is defined as the number
    of lag observations included in the preceding formula.
  id: totrans-394
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'For example:'
  id: totrans-395
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '*AR(2)* is defined as:'
  id: totrans-396
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '![Time series forecasting using the ARIMA model](img/B09699_08_34.jpg)'
  id: totrans-397
  prefs:
  - PREF_IND
  type: TYPE_IMG
- en: '*AR(1)* is defined as:'
  id: totrans-398
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '![Time series forecasting using the ARIMA model](img/B09699_08_35.jpg)'
  id: totrans-399
  prefs:
  - PREF_IND
  type: TYPE_IMG
- en: '**I**: Stands for **integrated**. For the ARIMA model to work, it is assumed
    that the time series is stationary or can be made stationary. A series is said
    to be stationary ([https://en.wikipedia.org/wiki/Stationary_process](https://en.wikipedia.org/wiki/Stationary_process))
    if its mean and variance doesn''t change over time.'
  id: totrans-400
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Note
  id: totrans-401
  prefs:
  - PREF_IND
  - PREF_H3
  type: TYPE_NORMAL
- en: '**Note**: There is also the notion of strict stationarity which requires that
    the joint probability distribution of a subset of observations doesn''t change
    when shifted in time.'
  id: totrans-402
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Using mathematical notation, strict stationarity translates to:'
  id: totrans-403
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '![Time series forecasting using the ARIMA model](img/B09699_08_36.jpg) and
    ![Time series forecasting using the ARIMA model](img/B09699_08_37.jpg) are the
    same for any *t*, *m*, and *k,* with *F* being the joint probability distribution.'
  id: totrans-404
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: In practice, this condition is too strong, and the preceding weaker definition
    provided is preferred.
  id: totrans-405
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'We can make a time series stationary through a transformation that uses differencing
    of the log between an observation and the one before that, as shown in the following
    equation:'
  id: totrans-406
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '![Time series forecasting using the ARIMA model](img/B09699_08_38.jpg)'
  id: totrans-407
  prefs:
  - PREF_IND
  type: TYPE_IMG
- en: It is possible that multiple log differencing transformations are needed before
    the time series is actually made stationary. We call *d* the number of times we transform
    the series using log differencing.
  id: totrans-408
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'For example:'
  id: totrans-409
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '*I(0)* is defined as no log differencing needed (the model is then called ARMA).'
  id: totrans-410
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '*I(1)* is defined as 1 log differencing needed.'
  id: totrans-411
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '*I(2)* is defined as 2 log differencing needed.'
  id: totrans-412
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Note
  id: totrans-413
  prefs:
  - PREF_IND
  - PREF_H3
  type: TYPE_NORMAL
- en: '**Note**: It is important to remember to do the reverse transformation for
    as many integrations that were made, after predicting a value.'
  id: totrans-414
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '**MA**: Stands for **moving average**. The MA model uses the residual error
    from the mean of the current observation and the weighted residual errors of the
    lagged observations. We can define the model using the following formula:![Time
    series forecasting using the ARIMA model](img/B09699_08_39.jpg)'
  id: totrans-415
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Where
  id: totrans-416
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '![Time series forecasting using the ARIMA model](img/B09699_08_40.jpg)'
  id: totrans-417
  prefs:
  - PREF_IND
  type: TYPE_IMG
- en: is the mean of the time series, ![Time series forecasting using the ARIMA model](img/B09699_08_33.jpg)
    are the residual errors in the series and ![Time series forecasting using the ARIMA model](img/B09699_08_41.jpg)
    are the weights for the lagged residual errors.
  id: totrans-418
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: We call *q* the size of the moving average window.
  id: totrans-419
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'For example:'
  id: totrans-420
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '*MA(0)* is defined as no moving average needed (the model is then called AR).'
  id: totrans-421
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '*MA(1)* is defined as using a moving average window of 1\. The formula becomes:'
  id: totrans-422
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '![Time series forecasting using the ARIMA model](img/B09699_08_42.jpg)'
  id: totrans-423
  prefs:
  - PREF_IND
  type: TYPE_IMG
- en: As per the preceding definition, we use the notation *ARIMA(p,d,q)* to define
    an ARIMA model with an autoregression model of order *p*, an integration/differencing
    of order *d*, and a moving average window of size *q*.
  id: totrans-424
  prefs: []
  type: TYPE_NORMAL
- en: 'Implementing all the code to build an ARIMA model can be very time-consuming.
    Fortunately, the `statsmodels` library implements an `ARIMA` class in the `statsmodels.tsa.arima_model`
    package that provides all the computation needed to train a model with the `fit()`
    method and predict values with the `predict()` method. It also takes care of the
    log differencing to make the time series stationary. The trick is to find the
    parameters *p*, *d*, and *q* for building the optimal ARIMA model. For this, we
    use the ACF and PACF chart as follows:'
  id: totrans-425
  prefs: []
  type: TYPE_NORMAL
- en: The *p* value corresponds to the number of lags (on the *x* abscissa) where
    the ACF chart crosses the statistical significance threshold for the first time.
  id: totrans-426
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Similarly, the *q* value corresponds to the number of lags (on the *x* abscissa)
    where the PACF chart crosses the statistical significance threshold for the first
    time.
  id: totrans-427
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Build an ARIMA model for the MSFT stock time series
  id: totrans-428
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'As a reminder, the price chart for the MSFT stock time series looks like this:'
  id: totrans-429
  prefs: []
  type: TYPE_NORMAL
- en: '![Build an ARIMA model for the MSFT stock time series](img/B09699_08_20.jpg)'
  id: totrans-430
  prefs: []
  type: TYPE_IMG
- en: MSFT stock series chart
  id: totrans-431
  prefs: []
  type: TYPE_NORMAL
- en: Before we start building our model, let's first withhold the last 14 days of
    the data for testing and use the rest for training.
  id: totrans-432
  prefs: []
  type: TYPE_NORMAL
- en: 'The following code defines two new variables: `train_set` and `test_set`:'
  id: totrans-433
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE47]'
  id: totrans-434
  prefs: []
  type: TYPE_PRE
  zh: '[PRE47]'
- en: Note
  id: totrans-435
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '**Note**: If you''re still not familiar with the preceding slicing notation,
    please refer to the section on NumPy at the beginning of this chapter'
  id: totrans-436
  prefs: []
  type: TYPE_NORMAL
- en: From the preceding chart, we can clearly observe a growth trend starting in
    2012 but no clear seasonality. Therefore, we can safely assume that there is no
    stationarity. Let's first try to apply a log differencing transformation once
    and plot the corresponding ACF and PACF chart.
  id: totrans-437
  prefs: []
  type: TYPE_NORMAL
- en: 'In the following code, we build the `logmsft` pandas Series by using `np.log()`
    on the `Adj. Close` column and then build the `logmsft_diff` pandas DataFrame
    using the difference between `logmsft` and the lag of 1 (using the `shift()` method).
    As was done before, we also call `reset_index()` to convert the `Date` index into
    a column so that the PixieDust `display()` can process it:'
  id: totrans-438
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE48]'
  id: totrans-439
  prefs: []
  type: TYPE_PRE
  zh: '[PRE48]'
- en: Note
  id: totrans-440
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'You can find the code file here:'
  id: totrans-441
  prefs: []
  type: TYPE_NORMAL
- en: '[https://github.com/DTAIEB/Thoughtful-Data-Science/blob/master/chapter%208/sampleCode22.py](https://github.com/DTAIEB/Thoughtful-Data-Science/blob/master/chapter%208/sampleCode22.py)'
  id: totrans-442
  prefs: []
  type: TYPE_NORMAL
- en: 'The results are shown in the following screenshot:'
  id: totrans-443
  prefs: []
  type: TYPE_NORMAL
- en: '![Build an ARIMA model for the MSFT stock time series](img/B09699_08_21.jpg)'
  id: totrans-444
  prefs: []
  type: TYPE_IMG
- en: MSFT stock series after log differencing applied
  id: totrans-445
  prefs: []
  type: TYPE_NORMAL
- en: From looking at the preceding graph, we can reasonably think that we've succeeded
    at making the time series stationary with 0 as the mean. We can also use a more
    rigorous way to test for stationarity by using the Dickey-Fuller test ([https://en.wikipedia.org/wiki/Dickey%E2%80%93Fuller_test](https://en.wikipedia.org/wiki/Dickey%E2%80%93Fuller_test))
    which tests the null hypothesis that a unit root is present in an *AR(1)* model.
  id: totrans-446
  prefs: []
  type: TYPE_NORMAL
- en: Note
  id: totrans-447
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '**Note**: In statistics, statistical hypothesis testing consists of challenging
    whether a proposed hypothesis is true, by taking a sample and deciding whether
    the claim remains true. We look at the p-value ([https://en.wikipedia.org/wiki/P-value](https://en.wikipedia.org/wiki/P-value))
    which helps determine the significance of the results. More details on statistical
    hypothesis testing can be found here:'
  id: totrans-448
  prefs: []
  type: TYPE_NORMAL
- en: '[https://en.wikipedia.org/wiki/Statistical_hypothesis_testing](https://en.wikipedia.org/wiki/Statistical_hypothesis_testing)'
  id: totrans-449
  prefs: []
  type: TYPE_NORMAL
- en: 'The following code uses the `adfuller` method from the `statsmodels.tsa.stattools`
    package:'
  id: totrans-450
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE49]'
  id: totrans-451
  prefs: []
  type: TYPE_PRE
  zh: '[PRE49]'
- en: Note
  id: totrans-452
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'You can find the code file here:'
  id: totrans-453
  prefs: []
  type: TYPE_NORMAL
- en: '[https://github.com/DTAIEB/Thoughtful-Data-Science/blob/master/chapter%208/sampleCode23.py](https://github.com/DTAIEB/Thoughtful-Data-Science/blob/master/chapter%208/sampleCode23.py)We
    use the `pprint` package which is very useful for *pretty-printing* any Python
    data structures. More info on `pprint` can be found here:'
  id: totrans-454
  prefs: []
  type: TYPE_NORMAL
- en: '[https://docs.python.org/3/library/pprint.html](https://docs.python.org/3/library/pprint.html)'
  id: totrans-455
  prefs: []
  type: TYPE_NORMAL
- en: 'The results (explained in detail at: [http://www.statsmodels.org/devel/generated/statsmodels.tsa.stattools.adfuller.html](http://www.statsmodels.org/devel/generated/statsmodels.tsa.stattools.adfuller.html))
    are shown here:'
  id: totrans-456
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE50]'
  id: totrans-457
  prefs: []
  type: TYPE_PRE
  zh: '[PRE50]'
- en: Note
  id: totrans-458
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'You can find the code file here:'
  id: totrans-459
  prefs: []
  type: TYPE_NORMAL
- en: '[https://github.com/DTAIEB/Thoughtful-Data-Science/blob/master/chapter%208/sampleCode24.json](https://github.com/DTAIEB/Thoughtful-Data-Science/blob/master/chapter%208/sampleCode24.json)'
  id: totrans-460
  prefs: []
  type: TYPE_NORMAL
- en: The p-value is below the significance level; therefore, we can reject the null
    hypothesis that a unit root is present in the *AR(1)* model, which gives us confidence
    that the time series is stationary.
  id: totrans-461
  prefs: []
  type: TYPE_NORMAL
- en: 'We then plot the ACF and PACF chart which will give us the *p* and *q* parameters
    of the ARIMA model:'
  id: totrans-462
  prefs: []
  type: TYPE_NORMAL
- en: 'The following code builds the ACF chart:'
  id: totrans-463
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE51]'
  id: totrans-464
  prefs: []
  type: TYPE_PRE
  zh: '[PRE51]'
- en: Note
  id: totrans-465
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'You can find the code file here:'
  id: totrans-466
  prefs: []
  type: TYPE_NORMAL
- en: '[https://github.com/DTAIEB/Thoughtful-Data-Science/blob/master/chapter%208/sampleCode25.py](https://github.com/DTAIEB/Thoughtful-Data-Science/blob/master/chapter%208/sampleCode25.py)'
  id: totrans-467
  prefs: []
  type: TYPE_NORMAL
- en: 'The results are shown in the following screenshot:'
  id: totrans-468
  prefs: []
  type: TYPE_NORMAL
- en: '![Build an ARIMA model for the MSFT stock time series](img/B09699_08_22.jpg)'
  id: totrans-469
  prefs: []
  type: TYPE_IMG
- en: ACF for the log difference MSFT DataFrame
  id: totrans-470
  prefs: []
  type: TYPE_NORMAL
- en: From the preceding ACF graph, we can see that the correlation crosses the statistical
    significance threshold for the first time at a lag of 1\. Therefore, we'll use
    *p = 1* as the AR order of our ARIMA model.
  id: totrans-471
  prefs: []
  type: TYPE_NORMAL
- en: 'We do the same for the PACF:'
  id: totrans-472
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE52]'
  id: totrans-473
  prefs: []
  type: TYPE_PRE
  zh: '[PRE52]'
- en: Note
  id: totrans-474
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'You can find the code file here:'
  id: totrans-475
  prefs: []
  type: TYPE_NORMAL
- en: '[https://github.com/DTAIEB/Thoughtful-Data-Science/blob/master/chapter%208/sampleCode26.py](https://github.com/DTAIEB/Thoughtful-Data-Science/blob/master/chapter%208/sampleCode26.py)'
  id: totrans-476
  prefs: []
  type: TYPE_NORMAL
- en: 'The results are shown in the following screenshot:'
  id: totrans-477
  prefs: []
  type: TYPE_NORMAL
- en: '![Build an ARIMA model for the MSFT stock time series](img/B09699_08_23.jpg)'
  id: totrans-478
  prefs: []
  type: TYPE_IMG
- en: PACF for the log difference MSFT DataFrame
  id: totrans-479
  prefs: []
  type: TYPE_NORMAL
- en: From the preceding PACF graph, we can also see that the correlation crosses
    the statistical significance threshold for the first time at a lag of 1\. Therefore,
    we'll use *q = 1* as the MA order of our ARIMA model.
  id: totrans-480
  prefs: []
  type: TYPE_NORMAL
- en: We also had to apply the log differencing transformation only once. Therefore
    we'll use *d = 1* for the integrated part of the ARIMA model.
  id: totrans-481
  prefs: []
  type: TYPE_NORMAL
- en: Note
  id: totrans-482
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '**Note**: When calling the `ARIMA` class, if you use *d = 0*, then you may
    have to do the log differencing manually and, in this case, you''ll need to revert
    the transformation yourself on the predicted values. If not, the `statsmodels`
    package will take care of reverting the transformation before returning the predicted
    value.'
  id: totrans-483
  prefs: []
  type: TYPE_NORMAL
- en: 'The following code trains an ARIMA model on the `train_set` time series using
    *p = 1*, *d = 1*, and *q=1* as values to the order tuple argument of the `ARIMA`
    constructor. We then call the `fit()` method to proceed with the training and
    obtain a model:'
  id: totrans-484
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE53]'
  id: totrans-485
  prefs: []
  type: TYPE_PRE
  zh: '[PRE53]'
- en: Note
  id: totrans-486
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'You can find the code file here:'
  id: totrans-487
  prefs: []
  type: TYPE_NORMAL
- en: '[https://github.com/DTAIEB/Thoughtful-Data-Science/blob/master/chapter%208/sampleCode27.py](https://github.com/DTAIEB/Thoughtful-Data-Science/blob/master/chapter%208/sampleCode27.py)'
  id: totrans-488
  prefs: []
  type: TYPE_NORMAL
- en: '**Note**: We use the `warnings` package to avoid getting the mutiple deprecation
    warnings that may happen if you are using older versions of NumPy and pandas.'
  id: totrans-489
  prefs: []
  type: TYPE_NORMAL
- en: In the preceding code, we use `train_set['Adj. Close']` as an argument to the
    `ARIMA` constructor. Since we are using a Series for the data, we also need to
    pass the `train_set['Date']` series for the `dates` argument. Note that if we
    passed a pandas DataFrame instead with a `DateIndex` index, then we wouldn't have
    to use the `dates` argument. The final argument to the `ARIMA` constructor is
    the `order` argument which is a tuple of three values indicating the *p*, *d*,
    and *q* order, as discussed at the beginning of this section.
  id: totrans-490
  prefs: []
  type: TYPE_NORMAL
- en: We then call the `fit()` method that returns the actual ARIMA model that we'll
    use to predict values. For information purposes, we print statistics about the
    residual errors of the model using `arima_model.resid.describe()`.
  id: totrans-491
  prefs: []
  type: TYPE_NORMAL
- en: 'The results are shown here:'
  id: totrans-492
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE54]'
  id: totrans-493
  prefs: []
  type: TYPE_PRE
  zh: '[PRE54]'
- en: The mean residual error is ![Build an ARIMA model for the MSFT stock time series](img/B09699_08_43.jpg)
    which is very close to zero and therefore shows that the model may be overfitting
    the training data.
  id: totrans-494
  prefs: []
  type: TYPE_NORMAL
- en: Now that we have a model let's try to diagnose it. We define a method called
    `plot_predict` that takes a model, a series of dates and a number indicating how
    far back we want to look. We then call the ARIMA `plot_predict()` method to create
    a chart with both the predicted and observed values.
  id: totrans-495
  prefs: []
  type: TYPE_NORMAL
- en: 'The following code shows the implementation for the `plot_predict()` method,
    including calling it twice with `100` and `10`:'
  id: totrans-496
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE55]'
  id: totrans-497
  prefs: []
  type: TYPE_PRE
  zh: '[PRE55]'
- en: Note
  id: totrans-498
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'You can find the code file here:'
  id: totrans-499
  prefs: []
  type: TYPE_NORMAL
- en: '[https://github.com/DTAIEB/Thoughtful-Data-Science/blob/master/chapter%208/sampleCode28.py](https://github.com/DTAIEB/Thoughtful-Data-Science/blob/master/chapter%208/sampleCode28.py)'
  id: totrans-500
  prefs: []
  type: TYPE_NORMAL
- en: 'The results are shown here:'
  id: totrans-501
  prefs: []
  type: TYPE_NORMAL
- en: '![Build an ARIMA model for the MSFT stock time series](img/B09699_08_24.jpg)'
  id: totrans-502
  prefs: []
  type: TYPE_IMG
- en: Observations versus Forecast chart
  id: totrans-503
  prefs: []
  type: TYPE_NORMAL
- en: The preceding charts show how close the predictions are to the actual observations
    from the training set. We now use the test set that was withheld before to further
    diagnose the model. For this part, we use the `forecast()` method which predicts
    the next data point. For each value of the `test_set`, we build a new ARIMA model
    from an array of observations called history that contains the training data augmented
    with each predicted value.
  id: totrans-504
  prefs: []
  type: TYPE_NORMAL
- en: 'The following code shows the implementation for the `compute_test_set_predictions()`
    method that takes a `train_set` and a `test_set` as arguments and returns a pandas
    DataFrame with a `forecast` column containing all the predicted values and a `test`
    column containing the corresponding actual observed values:'
  id: totrans-505
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE56]'
  id: totrans-506
  prefs: []
  type: TYPE_PRE
  zh: '[PRE56]'
- en: Note
  id: totrans-507
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'You can find the code file here:'
  id: totrans-508
  prefs: []
  type: TYPE_NORMAL
- en: '[https://github.com/DTAIEB/Thoughtful-Data-Science/blob/master/chapter%208/sampleCode29.py](https://github.com/DTAIEB/Thoughtful-Data-Science/blob/master/chapter%208/sampleCode29.py)'
  id: totrans-509
  prefs: []
  type: TYPE_NORMAL
- en: 'The following screenshot shows the result chart:'
  id: totrans-510
  prefs: []
  type: TYPE_NORMAL
- en: '![Build an ARIMA model for the MSFT stock time series](img/B09699_08_25.jpg)'
  id: totrans-511
  prefs: []
  type: TYPE_IMG
- en: Chart of predicted versus acutal values
  id: totrans-512
  prefs: []
  type: TYPE_NORMAL
- en: 'We can measure the error using the popular `mean_squared_error` method ([https://en.wikipedia.org/wiki/Mean_squared_error](https://en.wikipedia.org/wiki/Mean_squared_error))
    of the scikit-learn package ([http://scikit-learn.org](http://scikit-learn.org))
    which is defined as follows:'
  id: totrans-513
  prefs: []
  type: TYPE_NORMAL
- en: '![Build an ARIMA model for the MSFT stock time series](img/B09699_08_44.jpg)'
  id: totrans-514
  prefs: []
  type: TYPE_IMG
- en: Where ![Build an ARIMA model for the MSFT stock time series](img/B09699_08_45.jpg)
    is the actual value and ![Build an ARIMA model for the MSFT stock time series](img/B09699_08_46.jpg)is
    the predicted value.
  id: totrans-515
  prefs: []
  type: TYPE_NORMAL
- en: 'The following code defines a `compute_mean_squared_error` method that takes a test
    and a forecast series and returns the value of the mean squared error:'
  id: totrans-516
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE57]'
  id: totrans-517
  prefs: []
  type: TYPE_PRE
  zh: '[PRE57]'
- en: Note
  id: totrans-518
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'You can find the code file here:'
  id: totrans-519
  prefs: []
  type: TYPE_NORMAL
- en: '[https://github.com/DTAIEB/Thoughtful-Data-Science/blob/master/chapter%208/sampleCode30.py](https://github.com/DTAIEB/Thoughtful-Data-Science/blob/master/chapter%208/sampleCode30.py)'
  id: totrans-520
  prefs: []
  type: TYPE_NORMAL
- en: 'The result is shown here:'
  id: totrans-521
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE58]'
  id: totrans-522
  prefs: []
  type: TYPE_PRE
  zh: '[PRE58]'
- en: StockExplorer PixieApp Part 2 – add time series forecasting using the ARIMA
    model
  id: totrans-523
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: In this section, we improve the `StockExplorer` PixieApp by adding a menu that
    provides time series forecasting for the selected stock ticker using an ARIMA
    model. We create a new class called `ForecastArimaSubApp` and update the `tabs`
    variable in the main `StockExplorer` class.
  id: totrans-524
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE59]'
  id: totrans-525
  prefs: []
  type: TYPE_PRE
  zh: '[PRE59]'
- en: Note
  id: totrans-526
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'You can find the code file here:'
  id: totrans-527
  prefs: []
  type: TYPE_NORMAL
- en: '[https://github.com/DTAIEB/Thoughtful-Data-Science/blob/master/chapter%208/sampleCode31.py](https://github.com/DTAIEB/Thoughtful-Data-Science/blob/master/chapter%208/sampleCode31.py)'
  id: totrans-528
  prefs: []
  type: TYPE_NORMAL
- en: The `ForecastArimaSubApp` child PixieApp is composed of two screens. The first
    screen displays the time series chart as well as the ACF and the PACF charts.
    The goal of this screen is to provide the user with the necessary data exploration
    to figure out what are the values for the *p*, *d*, and *q* order of the ARIMA
    model, as explained in the previous section. By looking at the time series chart,
    we can figure out whether the time series is stationary (which, as a reminder,
    is a requirement for building the ARIMA model). If not, the user can click on
    the **Add differencing** button to try to make the DataFrame stationery by using
    a log differencing transformation. The three charts are then updated using the
    transformed DataFrame.
  id: totrans-529
  prefs: []
  type: TYPE_NORMAL
- en: 'The following code shows the default route for the `ForecastArimaSubApp` child
    PixieApp:'
  id: totrans-530
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE60]'
  id: totrans-531
  prefs: []
  type: TYPE_PRE
  zh: '[PRE60]'
- en: Note
  id: totrans-532
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'You can find the code file here:'
  id: totrans-533
  prefs: []
  type: TYPE_NORMAL
- en: '[https://github.com/DTAIEB/Thoughtful-Data-Science/blob/master/chapter%208/sampleCode32.py](https://github.com/DTAIEB/Thoughtful-Data-Science/blob/master/chapter%208/sampleCode32.py)'
  id: totrans-534
  prefs: []
  type: TYPE_NORMAL
- en: 'The preceding code follows a pattern that we should now be familiar with:'
  id: totrans-535
  prefs: []
  type: TYPE_NORMAL
- en: Define a `setup` method that is guaranteed to be called when the PixieApp starts.
    In this method, we make a copy of the selected DataFrame obtained from the parent
    PixieApp. We also maintain a variable called `self.differencing` that tracks whether
    the user clicked on the **Add differencing** button.
  id: totrans-536
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'We create a default route that shows the first screen that is composed of the
    following components:'
  id: totrans-537
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'A header with two buttons: `Add differencing` for making the time series stationary
    and `Continue to forecast` to display the second screen which we''ll discuss later.
    The `Add differencing` button toggles to `Remove differencing` when the differencing
    has been applied.'
  id: totrans-538
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: A `<div>` element that invokes the `show_chart` route to display the time series
    chart.
  id: totrans-539
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: A `<div>` element that invokes the `show_acf` route to display the ACF chart.
  id: totrans-540
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: A `<div>` element that invokes the `show_pacf` route to display the PACF chart.
  id: totrans-541
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: 'We use an empty array `[]` as an argument to the `@BaseSubApp.add_ticker_selection_markup`
    decorator to make sure that the entire screen is refreshed when the user selects
    another stock ticker, and to restart from the first screen. We also need to reset
    the internal variables. To achieve this, we made a change to the `add_ticker_selection_markup`
    to define a new method in `BaseSubApp` called `set_active_ticker` that is a wrapper
    method to the `set_active_ticker` from the parent PixieApp. The idea is to let
    subclasses override this method and inject extra code if needed. We also change
    the `pd_script` attribute for the tab element to invoke this method when the user selects
    a new ticker symbol as shown in the following code:'
  id: totrans-542
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[PRE61]'
  id: totrans-543
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE61]'
- en: Note
  id: totrans-544
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'You can find the code file here:'
  id: totrans-545
  prefs: []
  type: TYPE_NORMAL
- en: '[https://github.com/DTAIEB/Thoughtful-Data-Science/blob/master/chapter%208/sampleCode33.py](https://github.com/DTAIEB/Thoughtful-Data-Science/blob/master/chapter%208/sampleCode33.py)'
  id: totrans-546
  prefs: []
  type: TYPE_NORMAL
- en: 'In the `ForecastArimaSubApp` child PixieApp, we then override the `set_active_tracker`
    method, first calling the super and then calling the `self.setup()` to reinitialize
    the internal variables:'
  id: totrans-547
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE62]'
  id: totrans-548
  prefs: []
  type: TYPE_PRE
  zh: '[PRE62]'
- en: Note
  id: totrans-549
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'You can find the code file here:'
  id: totrans-550
  prefs: []
  type: TYPE_NORMAL
- en: '[https://github.com/DTAIEB/Thoughtful-Data-Science/blob/master/chapter%208/sampleCode34.py](https://github.com/DTAIEB/Thoughtful-Data-Science/blob/master/chapter%208/sampleCode34.py)'
  id: totrans-551
  prefs: []
  type: TYPE_NORMAL
- en: 'The route implementation for the first forecast screen is pretty straightforward.
    The `Add differencing` / `Remove differencing` button has a `pd_script` attribute
    that calls the `self.toggle_differencing()` method and the `pd_refresh` attribute
    to update the entire page. It also defines the three `<div>` elements that respectively
    call the `show_chart`, `show_acf`, and `show_pacf` routes as shown in the following
    code:'
  id: totrans-552
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE63]'
  id: totrans-553
  prefs: []
  type: TYPE_PRE
  zh: '[PRE63]'
- en: Note
  id: totrans-554
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'You can find the code file here:'
  id: totrans-555
  prefs: []
  type: TYPE_NORMAL
- en: '[https://github.com/DTAIEB/Thoughtful-Data-Science/blob/master/chapter%208/sampleCode35.py](https://github.com/DTAIEB/Thoughtful-Data-Science/blob/master/chapter%208/sampleCode35.py)'
  id: totrans-556
  prefs: []
  type: TYPE_NORMAL
- en: 'The `toggle_differencing()` method tracks the current differencing state with
    the `self.differencing` variable and either makes a copy of the active DataFrame
    from the `parent_pixieapp` or applies a log differencing transformation to the
    `self.entity_dataframe` variable as shown in the following code:'
  id: totrans-557
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE64]'
  id: totrans-558
  prefs: []
  type: TYPE_PRE
  zh: '[PRE64]'
- en: Note
  id: totrans-559
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'You can find the code file here:'
  id: totrans-560
  prefs: []
  type: TYPE_NORMAL
- en: '[https://github.com/DTAIEB/Thoughtful-Data-Science/blob/master/chapter%208/sampleCode36.py](https://github.com/DTAIEB/Thoughtful-Data-Science/blob/master/chapter%208/sampleCode36.py)'
  id: totrans-561
  prefs: []
  type: TYPE_NORMAL
- en: 'The `show_acf` and `show_pacf` routes are pretty straightforward. They respectively
    call the `smt.graphics.plot_acf` and `smt.graphics.plot_pacf` methods. They also
    use the `@captureOutput` decorator to pass through the chart image to the target widget:'
  id: totrans-562
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE65]'
  id: totrans-563
  prefs: []
  type: TYPE_PRE
  zh: '[PRE65]'
- en: Note
  id: totrans-564
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'You can find the code file here:'
  id: totrans-565
  prefs: []
  type: TYPE_NORMAL
- en: '[https://github.com/DTAIEB/Thoughtful-Data-Science/blob/master/chapter%208/sampleCode37.py](https://github.com/DTAIEB/Thoughtful-Data-Science/blob/master/chapter%208/sampleCode37.py)'
  id: totrans-566
  prefs: []
  type: TYPE_NORMAL
- en: 'The following screenshot shows the data exploration page of the forecast child PixieApp
    without the differencing:'
  id: totrans-567
  prefs: []
  type: TYPE_NORMAL
- en: '![StockExplorer PixieApp Part 2 – add time series forecasting using the ARIMA
    model](img/B09699_08_26.jpg)'
  id: totrans-568
  prefs: []
  type: TYPE_IMG
- en: First forecast screen without applying differencing
  id: totrans-569
  prefs: []
  type: TYPE_NORMAL
- en: 'As expected, the charts are consistent with a time series that is not stationary.
    When the user clicks on the **Add differencing** button, the following screen
    is shown:'
  id: totrans-570
  prefs: []
  type: TYPE_NORMAL
- en: '![StockExplorer PixieApp Part 2 – add time series forecasting using the ARIMA
    model](img/B09699_08_27.jpg)'
  id: totrans-571
  prefs: []
  type: TYPE_IMG
- en: First forecast screen with differencing applied
  id: totrans-572
  prefs: []
  type: TYPE_NORMAL
- en: The next step is to implement the `do_forecast` route that is invoked by the
    **Continue to Forecast** button. This route is responsible for building the ARIMA
    model; it starts by showing a configuration page with three input texts that let
    the user enter the *p*, *d*, and *q* orders, which have been inferred by looking
    at the charts in the data exploration screen. We add a `Go` button to proceed
    with the model building using the `build_arima_model` route which we'll discuss
    later in this section. The header also has a `Diagnose Model` button that invokes
    another page responsible for evaluating the accuracy of the model.
  id: totrans-573
  prefs: []
  type: TYPE_NORMAL
- en: 'The implementation of the `do_forecast` route is shown here. Note that we use
    the `add_ticker_selection_markup` with an empty array to refresh the entire page when
    the user selects another stock ticker:'
  id: totrans-574
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE66]'
  id: totrans-575
  prefs: []
  type: TYPE_PRE
  zh: '[PRE66]'
- en: Note
  id: totrans-576
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'You can find the code file here:'
  id: totrans-577
  prefs: []
  type: TYPE_NORMAL
- en: '[https://github.com/DTAIEB/Thoughtful-Data-Science/blob/master/chapter%208/sampleCode38.py](https://github.com/DTAIEB/Thoughtful-Data-Science/blob/master/chapter%208/sampleCode38.py)'
  id: totrans-578
  prefs: []
  type: TYPE_NORMAL
- en: 'The following screenshot shows the configuration page of the **Build ARIMA
    model** page:'
  id: totrans-579
  prefs: []
  type: TYPE_NORMAL
- en: '![StockExplorer PixieApp Part 2 – add time series forecasting using the ARIMA
    model](img/B09699_08_28.jpg)'
  id: totrans-580
  prefs: []
  type: TYPE_IMG
- en: Configuration page of the Build Arima model page
  id: totrans-581
  prefs: []
  type: TYPE_NORMAL
- en: 'The **Go** button has a `pd_options` attribute that invokes a route with three
    states: `p_order`, `d_order`, and `q_order` with values taken from the three input
    boxes associated with each attribute.'
  id: totrans-582
  prefs: []
  type: TYPE_NORMAL
- en: The route for building the ARIMA model is shown in the following code. It starts
    by splitting the active DataFrame into a training and test set, withholding 14 observations
    for the test set. It then builds the model and computes the residual errors. Once
    the model is successfully built, we return an HTML markup that contains a chart
    showing the predicted values for the training set versus the actual values in
    the training set. This is done by calling the `plot_predict` route. Finally, we
    also show statistics about the residual errors for the model by creating a `<div>`
    element with a `pd_entity` attribute pointing to the residuals variable with a
    `<pd_options>` child element that configures a table view of all the statistics
  id: totrans-583
  prefs: []
  type: TYPE_NORMAL
- en: The chart showing the predictions versus the actual training set is using the
    `plot_predict` route which calls the `plot_predict` method we created earlier
    in the Notebook. We also use the `@captureOutput` decorator to dispatch the chart
    image to the correct widget.
  id: totrans-584
  prefs: []
  type: TYPE_NORMAL
- en: 'The implementation of the `plot_predict` route is shown here:'
  id: totrans-585
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE67]'
  id: totrans-586
  prefs: []
  type: TYPE_PRE
  zh: '[PRE67]'
- en: Note
  id: totrans-587
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'You can find the code file here:'
  id: totrans-588
  prefs: []
  type: TYPE_NORMAL
- en: '[https://github.com/DTAIEB/Thoughtful-Data-Science/blob/master/chapter%208/sampleCode39.py](https://github.com/DTAIEB/Thoughtful-Data-Science/blob/master/chapter%208/sampleCode39.py)'
  id: totrans-589
  prefs: []
  type: TYPE_NORMAL
- en: 'The `build_arima_model` route implementation is shown here:'
  id: totrans-590
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE68]'
  id: totrans-591
  prefs: []
  type: TYPE_PRE
  zh: '[PRE68]'
- en: Note
  id: totrans-592
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'You can find the code file here:'
  id: totrans-593
  prefs: []
  type: TYPE_NORMAL
- en: '[https://github.com/DTAIEB/Thoughtful-Data-Science/blob/master/chapter%208/sampleCode40.py](https://github.com/DTAIEB/Thoughtful-Data-Science/blob/master/chapter%208/sampleCode40.py)'
  id: totrans-594
  prefs: []
  type: TYPE_NORMAL
- en: 'The following screenshot shows the result for the **Build Arima model** page:'
  id: totrans-595
  prefs: []
  type: TYPE_NORMAL
- en: '![StockExplorer PixieApp Part 2 – add time series forecasting using the ARIMA
    model](img/B09699_08_29.jpg)'
  id: totrans-596
  prefs: []
  type: TYPE_IMG
- en: Model building page
  id: totrans-597
  prefs: []
  type: TYPE_NORMAL
- en: The final screen of the forecast child app is the *diagnose model* screen invoked
    by the `do_diagnose` route. In this screen, we simply display a line chart for
    the DataFrame returned by the `compute_test_set_predictions` method we created
    earlier in the Notebook with the `train_set` and `test_set` variables. The `<div>`
    element for this chart is using a `pd_entity` attribute that calls an intermediary
    class method called `compute_test_set_predictions`. It also has a `<pd_options>`
    child element with the `display()` options for showing the line chart.
  id: totrans-598
  prefs: []
  type: TYPE_NORMAL
- en: 'The following code shows the implementation of the `do_diagnose_screen` route:'
  id: totrans-599
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE69]'
  id: totrans-600
  prefs: []
  type: TYPE_PRE
  zh: '[PRE69]'
- en: Note
  id: totrans-601
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'You can find the code file here:'
  id: totrans-602
  prefs: []
  type: TYPE_NORMAL
- en: '[https://github.com/DTAIEB/Thoughtful-Data-Science/blob/master/chapter%208/sampleCode41.py](https://github.com/DTAIEB/Thoughtful-Data-Science/blob/master/chapter%208/sampleCode41.py)'
  id: totrans-603
  prefs: []
  type: TYPE_NORMAL
- en: 'The following screenshot shows the results of the diagnose page:'
  id: totrans-604
  prefs: []
  type: TYPE_NORMAL
- en: '![StockExplorer PixieApp Part 2 – add time series forecasting using the ARIMA
    model](img/B09699_08_30.jpg)'
  id: totrans-605
  prefs: []
  type: TYPE_IMG
- en: Model diagnose screen
  id: totrans-606
  prefs: []
  type: TYPE_NORMAL
- en: In this section, we have shown how to improve the `StockExplorer` sample PixieApp to
    include forecasting capabilities using the ARIMA model. Incidentally, we've demonstrated
    how to use the PixieApp programming model to create a three-step wizard that first
    performs some data exploration, then configures the parameters of the model and
    builds it and finally diagnoses the model against the test set.
  id: totrans-607
  prefs: []
  type: TYPE_NORMAL
- en: Note
  id: totrans-608
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'The complete implementation of the notebook can be found here:'
  id: totrans-609
  prefs: []
  type: TYPE_NORMAL
- en: '[https://github.com/DTAIEB/Thoughtful-Data-Science/blob/master/chapter%208/StockExplorer%20-%20Part%202.ipynb](https://github.com/DTAIEB/Thoughtful-Data-Science/blob/master/chapter%208/StockExplorer%20-%20Part%202.ipynb)'
  id: totrans-610
  prefs: []
  type: TYPE_NORMAL
- en: Summary
  id: totrans-611
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this chapter, we touched upon the topic of time series analysis and forecasting.
    Of course, we've only scratched the surface, and there is certainly much more
    to explore. It is also a very important field for the industry, especially in
    the finance world, with very active research. For example, we see more and more
    data scientists trying to build time series forecasting models based on recurrent
    neural network ([https://en.wikipedia.org/wiki/Recurrent_neural_network](https://en.wikipedia.org/wiki/Recurrent_neural_network))
    algorithms, with great success. We've also demonstrated how Jupyter Notebooks
    combined with PixieDust and the ecosystem of libraries, such as `pandas`, `numpy`,
    and `statsmodels,` help accelerate the development of analytics as well as its
    operationalization into applications that are consumable by the line of business
    user.
  id: totrans-612
  prefs: []
  type: TYPE_NORMAL
- en: 'In the next chapter, we will look at another important data science use case:
    graphs. We''ll build a sample application related to flight travel and discuss
    how and when we should apply graph algorithms to solve data problems.'
  id: totrans-613
  prefs: []
  type: TYPE_NORMAL
