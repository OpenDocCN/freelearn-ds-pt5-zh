- en: Database Development and Assessment
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this chapter, we will cover the practice of data (database) assessment. We
    will provide an understanding of what statistical assessment is, and why it is
    important to the data scientist, as well as providing instructive examples using
    R to perform various statistical assessment methods.
  prefs: []
  type: TYPE_NORMAL
- en: As we have been endeavoring to do throughout this book, we will draw similarities
    between certain data developer and data scientist concepts, looking at the differences
    between data or database development and data (database) assessment, as well as
    offer a comparison between the practice of data assessment and data (quality)
    assurance.
  prefs: []
  type: TYPE_NORMAL
- en: 'We''ve organized information in this chapter into the following areas:'
  prefs: []
  type: TYPE_NORMAL
- en: Comparison of assessment and statistical assessments
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Development versus assessment
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Is data assessment an assurance of data quality?
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Applying the idea of statistical assessment to your data using R
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Let's get started!
  prefs: []
  type: TYPE_NORMAL
- en: Assessment and statistical assessment
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Merriam-Webster defines assessment as:'
  prefs: []
  type: TYPE_NORMAL
- en: The action or an instance of making a judgment about something.
  prefs: []
  type: TYPE_NORMAL
- en: 'The following image shows flow for assessing statistical data:'
  prefs: []
  type: TYPE_NORMAL
- en: '**![](img/c78bdd2b-3cc2-4748-9fab-e4edddcd725b.png)**'
  prefs: []
  type: TYPE_NORMAL
- en: We need to keep a few pointers in mind for statistical assessment. They are
    listed as follows.
  prefs: []
  type: TYPE_NORMAL
- en: Objectives
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: With that in mind, to be able to make a reasonable assessment--that is, make
    a judgment--on something (anything really), one must first have to set objective(s).
    Assessment objectives help the data scientist determine how to assess data, a
    database, or a statistical data model. Without clear objectives, you'll waste
    valuable time, and potentially, put confidence in a model that doesn't meet a
    business requirement or may even lead to incorrect assumptions (predictions).
  prefs: []
  type: TYPE_NORMAL
- en: Baselines
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Next, (based on your set objectives) standards, minimum acceptable performance,
    or a baseline to establish an opinion on what is being assessed need to be established.
    In other words, how well does what you are assessing compare to what you agree
    is acceptable?
  prefs: []
  type: TYPE_NORMAL
- en: Although we won't spend any significant time here on the process of database
    assessment (rather focus on statistical data or statistical data model assessment),
    we will mention the use of specific measures of performance (performance measures
    or metrics).
  prefs: []
  type: TYPE_NORMAL
- en: Data scientists will frequently use very specific (performance) metrics when
    evaluating the predictive accuracy of a statistical model. These metrics depend
    on the class or type of the problem being assessed and require one to use slightly
    different ways of assessing (the model's) performance. This approach also survives
    as a rule to assess standard, non-statistical data and databases. For example,
    there are specific performance metrics used to assess an **online transaction
    processing** (**OLTP**) data model and those will be quite different from those
    used to assess an **enterprise data warehouse** (**EDW**) model.
  prefs: []
  type: TYPE_NORMAL
- en: Looking a little deeper, when evaluating, performance testing, or assessing
    a (non-statistical) database, one would focus on the identification of various
    benchmarks (that is, benchmarking), capacity determination and planning, executing
    soaking or soak tests, peak-rest intervals (to name a few examples) as part of
    the effort.
  prefs: []
  type: TYPE_NORMAL
- en: Planning for assessment
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Just as the type of non-statistical database (OLTP, EDW, and so on) would determine
    what tests would be used to perform an assessment, so would the type of statistical
    model (for example, regression, classification, binary classification, and so
    on) dictate the appropriate assessment techniques or methods (more on this later
    in this chapter) a data scientist would use to assess a statistical model.
  prefs: []
  type: TYPE_NORMAL
- en: Once you have set the objectives for an assessment and established a baseline,
    an execution plan is developed. The plan typically outlines the entire process
    to be performed. The plan will list the tests to be performed along with the test
    objectives, baselines to be compared to, and even expected outcomes.
  prefs: []
  type: TYPE_NORMAL
- en: Evaluation
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In statistics, the term **performance** is usually interchangeably with the
    idea of a model's accuracy. When speaking about a non-statistical database or
    model, performance is perhaps all about speed—how long it takes for a query to
    return values, how long it takes to commit a transaction, and so on—and accuracy,
    and usually revolves around the idea of quality assurance, not an ability to predict
    values!
  prefs: []
  type: TYPE_NORMAL
- en: When assessing statistical models, a data scientist will look at a model's error
    rate, the number of misclassifications (that were made by a model), the ratio
    of the number of correctly predicted compared to the total number of predicted
    instances (by the model), and more. Again, all of this is dependent on the statistical
    model type and the objectives.
  prefs: []
  type: TYPE_NORMAL
- en: Finally, once completed, the results of both a database and statistical data
    model assessment typically will be visualized in various ways for easier evaluation,
    using commonly accepted methods (again, how one exposes or visualizes process
    results will depend on the objectives of the one preparing the visualizations
    or the objectives of the model). It should be understood that it is not uncommon
    for various portions of an assessment process (or even the entire assessment process)
    to be repeated once the results of the assessment have been evaluated. This may
    be to further clarify something identified in the presented results or for revalidation
    of certain results. In some situations, new project objectives, baselines, and
    even a new plan may be developed and executed.
  prefs: []
  type: TYPE_NORMAL
- en: 'To summarize, the process of performing a database or (statistical) data model
    assessment is, in a broad sense, similar to that both require the following:'
  prefs: []
  type: TYPE_NORMAL
- en: Set objectives (of the database or data model)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Establish baselines (to compare performances too)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Determine (the) plan (to carry out the assessment)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Evaluate the results
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Development versus assessment
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Although an assessment process does produce output, which ultimately is perhaps
    just a decision (that is, does the data, database, or statistical data model under
    observation meet the acceptable limits of performance, based on the objectives?),
    development implies building.
  prefs: []
  type: TYPE_NORMAL
- en: Development can also mean improving by expanding, enlarging, or refining. This
    means that (or at least it implies that) whatever one is developing may never
    be completely done. In fact, development and assessment do go hand in hand.
  prefs: []
  type: TYPE_NORMAL
- en: 'An industry-proven practice recommendation to develop anything is as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: Build (or develop)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Test
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Assess
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Repeat
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'When developing a relational data model, one might utilize a `create` SQL statement,
    something like the following code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: 'Dissecting the preceding code, we can see that the outcome is that a table
    object `test` is generated. Perhaps, keeping the same in mind, assessing a (relational)
    database or data model might use some form of the following code example:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: Statements like the preceding ones execute performance tools that return relevant
    statistics that can be visualized and analyzed.
  prefs: []
  type: TYPE_NORMAL
- en: 'A comparable (although simplistic) statistical development (or create) example
    might look like the following R code (taken from [Chapter 7](46966f7a-6d7f-4e47-b230-e71ef7d5ad01.xhtml),
    *Regularization for Database Improvement*):'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: 'Also from [Chapter 7](46966f7a-6d7f-4e47-b230-e71ef7d5ad01.xhtml), *Regularization
    for Database Improvement*, we used the R function summary to start performing
    some assessment of the performance of the generated linear regression model:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/3bef23e9-cbf9-4318-a0c3-c662ca52409d.png)'
  prefs: []
  type: TYPE_IMG
- en: As mentioned earlier, depending on the **class** of a statistical problem, the
    data scientist will use different approaches or methods to assess (a model's)
    performance (including the R function summary).
  prefs: []
  type: TYPE_NORMAL
- en: Planning
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In the previous section of this chapter, we compared and drew similarities between
    assessment and statistical assessment and also noted that as part of any assessment
    project (or at least one that you want to be successful), you need to create a
    plan.
  prefs: []
  type: TYPE_NORMAL
- en: Moving on to this section where we are relating development and assessment,
    we again see that the first step in the process of developing is perhaps to create
    a plan.
  prefs: []
  type: TYPE_NORMAL
- en: The author believes that the act of creating a plan is a basic requirement for
    any endeavor in life, even getting up in the morning!
  prefs: []
  type: TYPE_NORMAL
- en: The plan that one creates when having database development in mind can be used
    as both a guidebook when implementing (in this case, a database or statistical
    data model) as well as a functional specification (for the database) after implementing
    it.
  prefs: []
  type: TYPE_NORMAL
- en: What about the task of assessing a database (or in statistics, a data model)?
    Well, the same applies. The first step is to develop a detailed assessment plan,
    again that can be used to guide the entire assessment process, then become a functional
    specification reference after the assessment is completed.
  prefs: []
  type: TYPE_NORMAL
- en: Planning always pays for itself. A good development or assessment plan can become
    a detailed project plan, an acceptance testing plan, documentation for deployment,
    and, as already mentioned, a functional specification reference.
  prefs: []
  type: TYPE_NORMAL
- en: Database design is part of the process of data or database development. Designing
    a database can be a complex task. Part of the design process is for a data modeler
    (or very experienced data developer) to study the data, its source(s), the requirements,
    and so on, then produce a detailed data model. This data model will contain all
    of the needed logical as well as physical design choices as well as the physical
    storage parameters needed to generate a design in a **data definition language**
    (**DDL**), which can then be used to actually create the database.
  prefs: []
  type: TYPE_NORMAL
- en: A comprehensive database development plan would include the database design
    phase (modeling through creation) as well as call-outs to multiple testing and
    evaluation steps along the way.
  prefs: []
  type: TYPE_NORMAL
- en: Statistical modeling (actually considered to be a form of mathematical modeling)
    involves embodying or pulling together a set of assumptions concerning or about
    the generation of some sample data and similar data from a (hopefully) much bigger
    population (of data).
  prefs: []
  type: TYPE_NORMAL
- en: A plan for the generation of a statistical model would (similar to a plan to
    generate a database model) include the examination of (sample) data, its source(s),
    all requirements, and so on. Again, as with the previously mentioned plan, the
    statistical modeling plan would include mentioning of each assessment and evaluation
    that the data scientist plans to use on the statistical model.
  prefs: []
  type: TYPE_NORMAL
- en: Typically, a statistical model assessment plan would also include references
    to the visualizations that the data scientist plans to make the point or summarize
    the results following each assessment test.
  prefs: []
  type: TYPE_NORMAL
- en: 'Statistical modeling has been described as studying a system or process to
    predict its future behavior, as said by Madhuri Kulkarni:'
  prefs: []
  type: TYPE_NORMAL
- en: With the availability of observed data of a system, models can help infer various
    alternatives for the system.
  prefs: []
  type: TYPE_NORMAL
- en: Of all the generic tools that can be used for statistical modeling (and to understand
    and manipulate data), R seems to be the most powerful and the most popular.
  prefs: []
  type: TYPE_NORMAL
- en: From a non-statistical modeling perspective, data modeling defines and analyzes
    the requirements to support the business process (within the space of certain
    information systems in the organization). Here, tools such as Erwin Data Modeler
    and MySQL Workbench seem to constitute the tools most often successfully used.
  prefs: []
  type: TYPE_NORMAL
- en: Finally, although development and assessment are separate efforts, they are
    intimately related and, statistical or non-statistical, one does not exist without
    the existence of the other.
  prefs: []
  type: TYPE_NORMAL
- en: Data assessment and data quality assurance
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: To be methodical with our discussions here, let's look at how data assessment
    compares or stacks up to data quality (assurance).
  prefs: []
  type: TYPE_NORMAL
- en: Data quality assurance, or often referred to as **tidying the data** by data
    scientists, is the process of addressing (perhaps perceived) issues or concerns
    that had been identified within data. These issues affect the use, quality, and
    outcome (performance) of a database or data model—data quality, of course, being
    relative to the proposed purpose of use (of the data, database, or data model).
  prefs: []
  type: TYPE_NORMAL
- en: Categorizing quality
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Typically, issues with data quality may be categorized into one of the following
    areas:'
  prefs: []
  type: TYPE_NORMAL
- en: Accuracy
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Completeness
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Update Status
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Relevance
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Consistency (across sources)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Reliability
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Appropriateness
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Accessibility
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: You'll find plenty of data quality categorizing overlap between statistical
    and non-statistical data. Sometimes, a data quality issue may appear to apply
    strictly to a particular genre—stat versus non-stat—but after further investigation
    or at least more experience with the data or in the field, you may find the quality
    is quality.
  prefs: []
  type: TYPE_NORMAL
- en: The quality of data can affect outcomes and data's quality can be affected by
    the way it is entered, stored, and managed and the process of addressing data
    quality (referred to most often as quality assurance, **data quality assurance**
    (**DQA**)) requires a routine and regular review and evaluation of the data and,
    performing on-going processes termed profiling and scrubbing. (This is vital even
    if the data is stored in multiple disparate systems making these processes difficult.)
  prefs: []
  type: TYPE_NORMAL
- en: Although the concept of data quality assurance and tidying data are similar
    in many ways, DQA is typically much more focused on repeatable processes, while
    tidying is most often as needed and at the discretion of the data scientist, based
    on the objectives of the statistical model (although the experienced data scientist
    would most likely make an effort to create reusable routines or scripts that can
    be used by them later to manipulate or tidy data on this particular project or
    others).
  prefs: []
  type: TYPE_NORMAL
- en: Relevance
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: A lot of noteworthy emphases can be found on statistical relevance. The relevance
    of statistical information reflects the degree to which it meets the real needs
    of a particular project. It is concerned with whether the available information
    sheds light on the concerns that are important to the project. Assessing relevance
    is subjective and depends on the varying needs of users.
  prefs: []
  type: TYPE_NORMAL
- en: One of the key methods to establish and measure the relevance of data is through
    a process known as **adding context** or **profiling**.
  prefs: []
  type: TYPE_NORMAL
- en: Let's see, what is this profiling?
  prefs: []
  type: TYPE_NORMAL
- en: Generally speaking, similarly looking data can actually mean very different
    things. For example, the average **revolutions per minute** (**RPM**) carries
    a different connotation if the data represents sports cars compared to economy
    cars or even trucks.
  prefs: []
  type: TYPE_NORMAL
- en: With data, context clues should be developed, through the process we've mentioned
    referred to as profiling, so that the data consumer can better understand (the
    data) when used. Additionally, having context and perspective on the data you
    are working with is a vital step in determining what kind of assessments should
    be performed or, in the case to a non-statistical model, perhaps the kind of performance
    evaluations might best suit.
  prefs: []
  type: TYPE_NORMAL
- en: Another motive to add context to data might be to gain a new perspective on
    the data. An example of this might be recognizing and examining a comparison present
    in the data. For example, home or housing values could be compared by zip code
    or other criteria.
  prefs: []
  type: TYPE_NORMAL
- en: Adding context to data (statistical or otherwise) as part of the development
    and assessment process (recall that we mentioned the two go hand in hand) can
    certainly make it (the data) more relevant, but context still can't serve as a
    substitute for value.
  prefs: []
  type: TYPE_NORMAL
- en: Before you consider any variables within your data, such as average rpm, torque,
    top speed, wheelbase, weight (or whatever), first and foremost, assessment testing
    needs to benefit those who are going to consume it or, in other words, whatever
    the data scientist is interested in predicting. For example, if we were to extend
    this vehicle data example, the expected MPG or miles per gallon, so establishing
    appropriate context requirements will be critical.
  prefs: []
  type: TYPE_NORMAL
- en: 'For data profiling (or adding context to the data you will be using in a project),
    the rule is as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Before Context, Think −>** **Value**'
  prefs: []
  type: TYPE_NORMAL
- en: 'Similar to how we categorized the types of data quality issues, there are several
    contextual categories, which can be used to argument or increase the value and
    understanding of data for visualization:'
  prefs: []
  type: TYPE_NORMAL
- en: Definitions and explanations
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Comparisons
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Contrasts
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Tendencies
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Dispersion
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Assessment value and data quality, or even data or data model value, although
    may have areas of overlap, have different objectives.
  prefs: []
  type: TYPE_NORMAL
- en: Cross-validation
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: We cannot have a chapter in a book focusing on statistics (and assessing statistical
    models) without a least a section on cross-validation. You may hear some data
    scientists refer to cross-validation as rotation estimation or simply a general
    technique to assess models.
  prefs: []
  type: TYPE_NORMAL
- en: Cross-validation is one of the most common methods a data scientist may use
    to assess how accurately a statistical model will perform. The key concept of
    cross-validation is testing a model's ability to generalize or, specifically,
    how well the model applies what it infers from training on data samples (to an
    entire population or dataset).
  prefs: []
  type: TYPE_NORMAL
- en: There are two goals in cross-validation—estimating the performance of a model
    from available data using one algorithm, and comparing the performance of two
    or more different algorithms and finding out the best algorithm for the available
    data**.**
  prefs: []
  type: TYPE_NORMAL
- en: At a high level, the process of cross-validation is to identify a known dataset
    called the **validation dataset**, train on that dataset, then the second dataset
    of unknown data (or first seen data) against which the algorithm or data model
    will be tested (this is known as your **testing dataset**). The objective here
    is to try to ensure that complications like overfitting (allowing non-inclusive
    information to influence results) are controlled, as well as to provide some understanding
    on how the model will generalize a real problem or on a real data file.
  prefs: []
  type: TYPE_NORMAL
- en: Preparing data
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: To perform cross-validation, the data scientist must prepare the data. This
    work will consist of gaining an understanding of the data through profiling (which
    we mentioned in an earlier section of this chapter) so that the data can be separated
    into samples of comparable subsets. One subset of the data is then determined
    to be the training set and the analysis is performed on it. Next, once the analysis
    (or training) is completed, the result (or performance) is validated using the
    other subset (called the **validation set** or **testing set**).
  prefs: []
  type: TYPE_NORMAL
- en: To reduce variability, multiple iterations (also called **folds** or **rounds**)
    of cross-validation are performed using different partitions, and the validation
    results are averaged over the rounds.
  prefs: []
  type: TYPE_NORMAL
- en: 'Typically, a data scientist will use a model''s stability to determine the
    actual number of rounds of cross-validation that should be performed:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/593151c3-a6b3-484c-8c15-7fc4568abd40.png)'
  prefs: []
  type: TYPE_IMG
- en: 'As you can see in the preceding screenshot, the **Cross Validation** method
    can perhaps be better understood by thinking about the data scientist organizing
    a population of data into two subsets: **Known Data** and **Unknown Data** (you''ll
    see an example of how this can be done in the next section of this chapter). The
    data scientist then performs an analysis of the data and manually calculates results.
    Once the expected or correct results are established, they can be compared to
    the statistical model-produced results (using that separate unknown subset of
    data).'
  prefs: []
  type: TYPE_NORMAL
- en: The preceding is one round. Multiple rounds would be performed and the compared
    results would then be averaged and reviewed, eventually providing a fair estimate
    of a model's prediction performance.
  prefs: []
  type: TYPE_NORMAL
- en: Let's think of a real-world use case.
  prefs: []
  type: TYPE_NORMAL
- en: In [Chapter 6](46966f7a-6d7f-4e47-b230-e71ef7d5ad01.xhtml), *Regularization
    for Database Improvement*, we again reviewed some sample data consisting of consulting
    project results. In that example, we explored the relationship between the total
    hours billed to the project, the total project management hours spent on the project,
    and the project's supposed profitability.
  prefs: []
  type: TYPE_NORMAL
- en: 'Looking back at that data to illustrate a point here, we can consider the various
    project characteristics (rather than variables):'
  prefs: []
  type: TYPE_NORMAL
- en: Was the project within the organization's core technology strength?
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Was there a full-time project manager assigned to the project?
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Was there a full-time client resource assigned to the project?
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Was the project work sub-contracted?
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Was the project a time and materials type of project?
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Was the project a not to exceed type of project?
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Was there a formal **quality assurance** (**QA**) part of the project?
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Was the work performed primarily on-site?
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Was the work performed primarily remote (from the customer site)?
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Again, our predictive model wants to predict what characteristics a profitable
    consulting project had.
  prefs: []
  type: TYPE_NORMAL
- en: 'The following is a representation of the results of using a five-round cross-validation
    process to predict our model''s expected accuracy:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/2ae6f612-eabc-419b-81a9-2ecd551ca059.png)'
  prefs: []
  type: TYPE_IMG
- en: Given the preceding figure, I'd say our predictive model is expected to be very
    accurate!
  prefs: []
  type: TYPE_NORMAL
- en: In summary, cross-validation combines (averages) measures of fit (prediction
    error) to derive a more accurate estimate of model prediction performance. This
    method is typically used in cases where there is not enough data available to
    test without losing significant modeling or testing quality.
  prefs: []
  type: TYPE_NORMAL
- en: Let's now move on to the final section of this chapter and look at some assessment
    examples using the R programming language.
  prefs: []
  type: TYPE_NORMAL
- en: R and statistical assessment
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: So, let's get started with some statistical assessment work!
  prefs: []
  type: TYPE_NORMAL
- en: As we discussed in the previous section, instead of using all the data (the
    entire population of observations) to train a statistical model (and then test
    using some of that data), cross-validation divides the data into training and
    testing datasets.
  prefs: []
  type: TYPE_NORMAL
- en: The first step that a data scientist needs to take when he or she is interested
    in using cross-validation to assess the performance of a statistical model is
    to organize (or split) the data into two separate subsets.
  prefs: []
  type: TYPE_NORMAL
- en: 'There are actually several approaches of cross-validation:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Leave-one-out cross-validation** (**LOOCV**)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Holdout
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: k-fold and repeated k-fold
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Re-substitution (most agree that this method is the simplest method)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: This cross-validation approaches all focus on how to split the data for the
    training, testing, and validation. Each has its own merit (pros and cons).
  prefs: []
  type: TYPE_NORMAL
- en: 'There are (as always) many approaches to programming a problem. The following
    is one such simple method. This example randomly splits the total file using a
    70 to 30 split:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: Once we have created the files we want, we can proceed with training and validate
    our statistical model.
  prefs: []
  type: TYPE_NORMAL
- en: As we have mentioned from time to time throughout this book, a proven practice
    is to save the preceding code so that it can be used again and again with new
    datasets.
  prefs: []
  type: TYPE_NORMAL
- en: Questions to ask
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In the previous sections of this chapter, we discussed the various approaches
    or methods for cross-validation, the number of rounds of cross-validation (in
    fact, we showed the results of a five-round cross validation effort), as well
    as how to organize and split the data for the purpose of performing cross-validation
    on a statistical model.
  prefs: []
  type: TYPE_NORMAL
- en: 'Before proceeding with the cross-validation process, a number of points need
    to be considered. (A plan is created!) This brings up the following questions:'
  prefs: []
  type: TYPE_NORMAL
- en: Which method or approach for cross-validation should I use? The answer is the
    method that is the best. Then again a new question arises—what does best mean?
    Each approach has its own strengths and weaknesses. The best cross-validation
    approach is one that best suits your data and objectives. More often than not,
    which approach you should use may not be revealed until other approaches are attempted.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: What is the appropriate number of rounds or folds one should be performing?
    Usually, the more the better! However, this will be determined by factors such
    as which cross-validation approach you choose to use and the amount of available
    data and time.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: What is the method to create each of the round's data? Again, this will be determined
    by factors such as the cross-validation approach you choose to use, the amount
    of available data and time, and the data scientist's abilities!
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Learning curves
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Another method of assessing a statistical model's performance is by evaluating
    the model's growth of learning or the model's ability to improve learning (obtain
    a better score) with additional experience (for example, more rounds of cross-validation).
  prefs: []
  type: TYPE_NORMAL
- en: The phrase, **with additional experience**, is vitally important in statistics
    as we not only look for a statistical model to perform well on a given population
    of data, but we hope that the model's performance will improve as it is trained
    and tested on more and more data.
  prefs: []
  type: TYPE_NORMAL
- en: The information indicating a model's performance, result, or score with a data
    file population is usually combined with other scores to show a line or curve—this
    is known as the statistical model's learning curve.
  prefs: []
  type: TYPE_NORMAL
- en: This means that the learning curve is a graphical representation of the growth
    of learning (the scores shown in a vertical axis) with practice (the individual
    data files or rounds shown in the horizontal axis).
  prefs: []
  type: TYPE_NORMAL
- en: 'This can also be conceptualized as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: The same task repeated in a series
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: A body of knowledge learned over time
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Example of a learning curve
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: For illustration, suppose we wanted to visualize the rate of growth of learning
    of a statistical model over multiple rounds of performance results, comparing
    test versus training data for a selected characteristic.
  prefs: []
  type: TYPE_NORMAL
- en: 'This was shown in an earlier section of this chapter:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/98aed56b-2606-4146-bcab-7d10d472c76e.png)'
  prefs: []
  type: TYPE_IMG
- en: 'The following is a visualization showing the learning curve that indicates
    the rate of learning of a predictive model using the preceding resultant scores
    of cross-validation rounds for the selected characteristic:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/907f4198-ee8b-41ba-84f3-5285859883d3.png)'
  prefs: []
  type: TYPE_IMG
- en: Core Technology
  prefs: []
  type: TYPE_NORMAL
- en: 'The following is the sample R code that generated the preceding visualization:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: Again, learning curves relating a statistical model's performance to experience
    are commonly found to be used when performing model assessments, especially when
    performing many rounds of tests (or in an analysis effort to determine the correct
    cross-validation method to use on a statistical model).
  prefs: []
  type: TYPE_NORMAL
- en: To this point, simply performing the rounds of testing and then reviewing the
    results is not quite enough. A seasoned data scientist will make sure to properly
    document each iteration of the testing, along with its corresponding results and
    conclusions.
  prefs: []
  type: TYPE_NORMAL
- en: Looking again at the preceding example, we can add to use of the R function
    `png`, which can be used to automatically create and save an image file of any
    visualization you create during the assessment processing that you do. If you
    predefine a file structure to save your assessment results and this or a similar
    approach, it will save much time later.
  prefs: []
  type: TYPE_NORMAL
- en: The R function `png` can easily be converted to many other bitmap formats, and
    both can be displayed in modern web browsers!
  prefs: []
  type: TYPE_NORMAL
- en: 'The following is our example R code statements that show the setup of the data,
    the creation of an image file, and the generation of the plot visualization:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: You should note that, if you're expecting an interactive result, you won't receive
    it! The preceding code uses `png` and this simply writes the output (of the `plot`
    function) to that file.
  prefs: []
  type: TYPE_NORMAL
- en: 'Good practice advice: use the `dev.off()` to make sure that the file is closed.'
  prefs: []
  type: TYPE_NORMAL
- en: 'This creates the following graphic as a file:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/f093697c-ffb6-427c-b5ad-d907cda34f2d.png)'
  prefs: []
  type: TYPE_IMG
- en: Summary
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this chapter, we defined assessment and then examined the similarities and
    differences between assessment and statistical assessment. Next, we covered development
    versus assessment and then explained how data assessment and data quality assurance
    have some overlap, and go hand in hand, but also have different objectives. Finally,
    we applied the idea of statistical assessment using the programming tool R.
  prefs: []
  type: TYPE_NORMAL
- en: In the next chapter, we will define the neural network model and draw from a
    developer's knowledge of data models to help understand the purpose and use of
    neural networks in data science.
  prefs: []
  type: TYPE_NORMAL
