- en: Database Structures and Machine Learning
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this final chapter, we will focus on the concepts and types of machine learning.
  prefs: []
  type: TYPE_NORMAL
- en: In keeping with the overall theme of this book, we'll start by offering an explanation
    of statistical machine learning and related concepts, and then move on to drawing
    out some similarities between statistical machine learning and basic notions that
    a reader who has a data or database developer background should be able to relate
    to.
  prefs: []
  type: TYPE_NORMAL
- en: 'This chapter is organized into the following areas:'
  prefs: []
  type: TYPE_NORMAL
- en: Is a data structure a data model?
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: An overview of machine learning concepts
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The types of machine learning
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Data developers and machine learning
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Using R to apply machine learning techniques to a database
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Data structures and data models
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: When you have ample of data, but no idea where  It's very important to structure
    the data, analyze it, and put to good use (wherever needed). In this section,
    we will be zooming the spotlight on data structures and data models, and also
    understanding the difference between both.
  prefs: []
  type: TYPE_NORMAL
- en: Data structures
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Data developers will agree that whenever one is working with large amounts of
    data, the organization of that data is imperative. If that data is not organized
    effectively, it will be very difficult to perform any task on that data, or at
    least be able to perform the task in an efficient manner. If the data is organized
    effectively, then practically any operation can be performed easily on that data.
  prefs: []
  type: TYPE_NORMAL
- en: 'A data or database developer will then organize the data into what is known
    as **data** **structures**. Following image is a simple binary tree, where the
    data is organized efficiently by structuring it:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/84c90422-84f3-4170-97ad-7878723da117.png)'
  prefs: []
  type: TYPE_IMG
- en: '*A data structure can be defined as a method of organizing large amounts of
    data more efficiently so that any operation on that data becomes easy.*'
  prefs: []
  type: TYPE_NORMAL
- en: Data structures are created in such a way as to implement one or more particular
    **abstract data type** (**ADT**), which in turn will stipulate what operations
    can be performed on the data structure, as well as the computational complexity
    of those operations.
  prefs: []
  type: TYPE_NORMAL
- en: In the field of statistics, an ADT is a model for data types where a data type
    is defined by its behavior from the **point of view** (**POV**) of users of that
    data, explicitly showing the possible values, the possible operations on data
    of this type, and the behavior of all of these operations.
  prefs: []
  type: TYPE_NORMAL
- en: Database design is then the process of using the defined data structures to
    produce a detailed data model, which will become the database. This data model
    must contain all of the required logical and physical design selections, as well
    as the physical storage parameters needed to produce a design in a **D****ata
    Definition Language** (**DDL**), which can then be used to create an actual database.
  prefs: []
  type: TYPE_NORMAL
- en: There are varying degrees of the data model, for example, a fully attributed
    data model would also contain detailed attributes for each entity in the model.
  prefs: []
  type: TYPE_NORMAL
- en: So, is a data structure a data model?
  prefs: []
  type: TYPE_NORMAL
- en: No, a data structure is used to create a data model. Is this data model the
    same as data models used in statistics? Let's see in the further section.
  prefs: []
  type: TYPE_NORMAL
- en: Data models
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: You will find that statistical data models are at the heart of statistical analytics.
  prefs: []
  type: TYPE_NORMAL
- en: 'In the simplest terms, a statistical data model is defined as the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '*A representation of a state, process, or system that we want to understand
    and reason about*'
  prefs: []
  type: TYPE_NORMAL
- en: In the scope of the previous definition, the data or database developer might
    agree that in theory or in concept, one could use the same terms to define a financial
    reporting database, as it is designed to contain business transactions and is
    arranged in data structures that allow business analysts to efficiently review
    the data, so that they can understand or reason about particular interests they
    may have concerning the business.
  prefs: []
  type: TYPE_NORMAL
- en: Data scientists develop statistical data models so that they can draw inferences
    from them and, more importantly, make predictions about a topic of concern. Data
    developers develop databases so that they can similarly draw inferences from them
    and, more importantly, make predictions about a topic of concern (although perhaps
    in some organizations, databases are more focused on past and current events (transactions)
    than forward-thinking ones (predictions)).
  prefs: []
  type: TYPE_NORMAL
- en: Statistical data models come in a multitude of different formats and flavours
    (as do databases). These models can be equations linking quantities that we can
    observe or measure; they can also be simply sets of rules.
  prefs: []
  type: TYPE_NORMAL
- en: Databases can be designed or formatted to simplify the entering of online transactions—say,
    in an order entry system—or for financial reporting when the accounting department
    must generate a balance sheet, income statement, or profit and loss statement
    for shareholders.
  prefs: []
  type: TYPE_NORMAL
- en: 'I found this example of a simple statistical data model: *Newton''s Second
    Law of Motion*, which states that the net sum of force acting on an object causes
    the object to accelerate in the direction of the force applied, and at a rate
    proportional to the resulting magnitude of the force and inversely proportional
    to the object''s mass.'
  prefs: []
  type: TYPE_NORMAL
- en: What's the difference?
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Where or how does the reader find the difference between a data structure or
    database and a statistical model? At a high level, as we speculated in previous
    sections, one can conclude that a data structure/database is practically the same
    thing as a statistical data model, as shown in the following image:'
  prefs: []
  type: TYPE_NORMAL
- en: '**![](img/ded56d04-54ef-402e-8032-04baa4e5974c.png)**'
  prefs: []
  type: TYPE_NORMAL
- en: At a high level, as we speculated in previous sections, one can conclude that
    a data structure/database is practically the same thing as a statistical data
    model.
  prefs: []
  type: TYPE_NORMAL
- en: 'When we take the time to drill deeper into the topic, you should consider the
    following key points:'
  prefs: []
  type: TYPE_NORMAL
- en: Although both the data structure/database and the statistical model could be
    said to represent a set of assumptions, the statistical model typically will be
    found to be much more keenly focused on a particular set of assumptions concerning
    the generation of some sample data, and similar data from a larger population,
    while the data structure/database more often than not will be more broadly based
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: A statistical model is often in a rather idealized form, while the data structure/database
    may be less perfect in the pursuit of a specific assumption
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Both a data structure/database and a statistical model are built around relationships
    between variables
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'The data structure/database relationship may focus on answering certain questions,
    such as:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: What are the total orders for specific customers?
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: What are the total orders for a specific customer who has purchased from a certain
    salesperson?
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: Which customer has placed the most orders?
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Statistical model relationships are usually very simple, and focused on proving
    certain questions:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Females are shorter than males by a fixed amount
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: Body mass is proportional to height
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: The probability that any given person will partake in a certain sport is a function
    of age, sex, and socioeconomic status
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Data structures/databases are all about the act of summarizing data based on
    relationships between variables
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Relationships
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The relationships between variables in a statistical model may be found to be
    much more complicated than simply straightforward to recognize and understand.
    An illustration of this is awareness of effect statistics. An effect statistic
    is one that shows or displays a difference in value to one that is associated
    with a difference related to one or more other variables.
  prefs: []
  type: TYPE_NORMAL
- en: Can you image the SQL query statements you'd use to establish a relationship
    between two database variables based upon one or more effect statistic?
  prefs: []
  type: TYPE_NORMAL
- en: On this point, you may find that a data structure/database usually aims to characterize
    relationships between variables, while with statistical models, the data scientist
    looks to fit the model to prove a point or make a statement about the population in
    the model. That is, a data scientist endeavors to make a statement about the accuracy
    of an estimate of the effect statistic(s) describing the model!
  prefs: []
  type: TYPE_NORMAL
- en: One more note of interest is that both a data structure/database and a statistical
    model can be seen as tools or vehicles that aim to generalize a population; a
    database uses SQL to aggregate or summarize data, and a statistical model summarizes
    its data using effect statistics.
  prefs: []
  type: TYPE_NORMAL
- en: Okay, hopefully, we have successfully presented the notion that data structures/databases
    and statistical data models are, in many ways, very similar.
  prefs: []
  type: TYPE_NORMAL
- en: At this point, let us move on to machine learning.
  prefs: []
  type: TYPE_NORMAL
- en: Machine learning
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'There are many deep definitions of statistical machine learning, but let''s
    start off with the simplest or most basic version:'
  prefs: []
  type: TYPE_NORMAL
- en: '*Machine learning is the process that aims to teach a computer to make realistic
    predictions (or improve on predictions) based on some flow or source of data.*'
  prefs: []
  type: TYPE_NORMAL
- en: The reader should take note that the data source explicitly depends upon the
    problem the data scientist is solving (trying to solve). For example, the subscription
    entertainment service Netflix would not use patient dental record data as input
    in an attempt to predict subscriber viewing behaviours!
  prefs: []
  type: TYPE_NORMAL
- en: 'An explanation that''s a little deeper can be provided:'
  prefs: []
  type: TYPE_NORMAL
- en: Machine learning is a sub-field of computer science that evolved from the study
    of pattern recognition and computational learning theory in artificial intelligence.
    In 1959, Arthur Samuel defined machine learning as a "Field of study that gives
    computers the ability to learn without being explicitly programmed."
  prefs: []
  type: TYPE_NORMAL
- en: ; -[https://scratch.mit.edu/studios/3475398/activity](https://scratch.mit.edu/studios/3475398/activity/)
  prefs: []
  type: TYPE_NORMAL
- en: In machine learning, the data scientist will spend his or her time exploring,
    studying, and building processes that they can learn from and make predictions
    on a source of data.
  prefs: []
  type: TYPE_NORMAL
- en: The way these machine learning processes or algorithms actually work is by building
    a statistical model using example data source inputs. This is different than typical
    computer algorithms (that is, traditional computer programming) that work by following
    strictly static program instructions written by a team of developers.
  prefs: []
  type: TYPE_NORMAL
- en: You will find machine learning employed where designing and programming explicit
    program instructions are infeasible, for example, applications such as image recognition
    and computer vision.
  prefs: []
  type: TYPE_NORMAL
- en: Later in this chapter, we will take some time and list more examples of where
    one will find machine learning at work in today's world.
  prefs: []
  type: TYPE_NORMAL
- en: Overview of machine learning concepts
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In the preceding section of this chapter, we have mentioned the concept of traditional
    programming. With traditional programming, the data and program are run on the
    computer to produce the desired output. With machine learning, the data and output
    are run on the computer to create a program. This program can then be used in
    traditional programming.
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/b7f0e20c-5ef8-4920-99e6-76d8a2e7271d.png)'
  prefs: []
  type: TYPE_IMG
- en: A somewhat popular and perhaps fun analogy for describing machine learning is
    *farming*.
  prefs: []
  type: TYPE_NORMAL
- en: Here, one might think of the machine learning algorithms used as the *seeds*,
    the data source as the *fertilizer*, and the data scientists as the *farmers*
    who plant and feed the seeds and in the end, reap the results!
  prefs: []
  type: TYPE_NORMAL
- en: Key elements of machine learning
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: There are a good number of machine learning algorithms in use by data scientists
    today. In fact, some research indicates that there are perhaps tens of thousands.
    In addition, hundreds of new algorithms are put forward for use every year.
  prefs: []
  type: TYPE_NORMAL
- en: 'Based on popular opinion, all machine learning algorithms today are made up
    of three components. They are as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: Representation
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Evaluation
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Optimization
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '![](img/197e5f06-e6f6-46e0-b715-ae49ad16ac4a.png)'
  prefs: []
  type: TYPE_IMG
- en: Representation
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: This is how the information is represented. Examples include decision trees,
    sets of rules, instances, graphical models, neural networks, support vector machines,
    model ensembles, and others.
  prefs: []
  type: TYPE_NORMAL
- en: Evaluation
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: This is how candidate programs (hypotheses) will be evaluated. Examples include
    accuracy, prediction and recall, squared error, likelihood, posterior probability,
    cost, margin, entropy Kullback-Leibler (KL-divergence) divergence, and others.
  prefs: []
  type: TYPE_NORMAL
- en: Optimization
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: This is the way candidate programs are generated, also known as the **search
    process**, for example, combinatorial optimization, convex optimization, and constrained
    optimization.
  prefs: []
  type: TYPE_NORMAL
- en: Types of machine learning
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Today, there are four types or categories of machine learning.
  prefs: []
  type: TYPE_NORMAL
- en: 'These types are the following:'
  prefs: []
  type: TYPE_NORMAL
- en: Supervised
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Unsupervised
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Semi-supervised
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Reinforcement
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: It is important to understand each type of learning.
  prefs: []
  type: TYPE_NORMAL
- en: Supervised learning
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: This type of learning is also referred to as **inductive learning**. This is
    where the training data will include the desired outputs; the algorithm infers
    from labeled or categorized training data. The training data is a set of training
    examples.
  prefs: []
  type: TYPE_NORMAL
- en: Unsupervised learning
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Unlike supervised machine learning, here, the training data does not include
    desired outputs. This is the machine learning task of inferring a function to
    describe a hidden structure from unlabeled or uncategorized data. Since the examples
    given to the learner are unlabeled, there is no error or reward signal to evaluate
    a potential solution.
  prefs: []
  type: TYPE_NORMAL
- en: Semi-supervised learning
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this type of machine learning, the training data includes a few samples of
    desired outputs. Semi-supervised learning is actually considered a type of supervised
    machine learning that makes use of unlabeled or uncategorized data for training,
    typically a small amount of labeled data with a large amount of unlabeled data.
  prefs: []
  type: TYPE_NORMAL
- en: Reinforcement learning
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Rewards from a sequence of actions, **Artificial intelligence** (**AI**) types
    like it, as it is the most ambitious type of learning. **Reinforcement learning**
    (**RL**) is a type of machine learning that allows machines and software agents
    to automatically determine the ideal behaviour within a specific context, in order
    to maximize its performance.
  prefs: []
  type: TYPE_NORMAL
- en: Most popular
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Supervised learning is the most mature as it's been around the longest. It is
    the most studied and the type of learning used by most machine learning algorithms.
  prefs: []
  type: TYPE_NORMAL
- en: Learning with supervision is much easier than learning without supervision.
  prefs: []
  type: TYPE_NORMAL
- en: Before moving on to an illustrative machine learning example, let's review a
    few machine learning applications.
  prefs: []
  type: TYPE_NORMAL
- en: Applications of machine learning
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: If it's not clear just yet why the topic of machine learning is so significant,
    perhaps reviewing a list of real-world machine learning use cases will help.
  prefs: []
  type: TYPE_NORMAL
- en: In this section, we'll take a little of your time to list some real-world machine
    learning applications.
  prefs: []
  type: TYPE_NORMAL
- en: 'Sample applications of machine learning that are in use today (in fact, almost
    every day) include the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '| Searching | You probably use this every day on multiple devices. Machine
    learning results are used to develop web search ranking pages. Ranking pages are
    lists of what the individual is most likely to be interested in and click on.
    |'
  prefs: []
  type: TYPE_TB
- en: '| Digitrecognition | Given a zip code handwritten on an envelope, identify
    the digit for each handwritten character. A model of this problem would allow
    a computer program to read and understand handwritten zip codes and sort envelopes
    by geographical region. |'
  prefs: []
  type: TYPE_TB
- en: '| Biology | Rationally designs drugs on the computer based on past experiments.
    |'
  prefs: []
  type: TYPE_TB
- en: '| Bankingandfinance | Used to determine who to send what credit card offers
    to. Evaluation of risk on credit offers. How to decide where to invest money.
    |'
  prefs: []
  type: TYPE_TB
- en: '| E-commerce | Predicting customer churn, fraud detection, and bot detection.
    |'
  prefs: []
  type: TYPE_TB
- en: '| Understanding speech | Given an utterance from a user, identify the specific
    request made by the user. A model of this problem would allow a program to understand
    and make an attempt to fulfil that request. The iPhone, with Siri, has this capability.
    |'
  prefs: []
  type: TYPE_TB
- en: '| Facedetection | Given a digital photo album of many hundreds of digital photographs,
    identify those photos that include a given person. A model of this decision process
    would allow a program to organize photos by person. Some cameras and software,
    such as iPhoto, have this capability. |'
  prefs: []
  type: TYPE_TB
- en: '| Spaceexplorations | Space probes and radio astronomy. |'
  prefs: []
  type: TYPE_TB
- en: '| Shapedetection | Given a user''s hand drawing a shape on a touch screen,
    and a database of known shapes, determine which shape the user was trying to draw.
    A model of this decision would allow a program to show the platonic version of
    the shape the user drew to make crisp diagrams. |'
  prefs: []
  type: TYPE_TB
- en: '| Robotics | How to handle uncertainty in new environments; autonomous self-driving
    cars. |'
  prefs: []
  type: TYPE_TB
- en: '| Information extraction | The ability to ask questions over databases across
    the web. |'
  prefs: []
  type: TYPE_TB
- en: '| Socialnetworking | Data on relationships and preferences. Machine learning
    to extract value from data. |'
  prefs: []
  type: TYPE_TB
- en: '| Product recommendation | Given a purchase history for a customer and a large
    inventory of products, identify those products in which that customer will be
    interested and is likely to purchase. A model of this decision process would allow
    a program to make recommendations to a customer and motivate product purchases.
    Amazon has this capability. Also think of Facebook and  GooglePlus, which recommend
    users to connect with you after you sign up. |'
  prefs: []
  type: TYPE_TB
- en: '| Debugging | Used in computer science problems, such as debugging. Labor intensive
    process. Could suggest where the bug could be. |'
  prefs: []
  type: TYPE_TB
- en: Machine learning in practice
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: If we continue to compare data/database development and machine learning, focusing
    on a typical project, we'll see similarities.
  prefs: []
  type: TYPE_NORMAL
- en: 'At this point, a rather nice piece presented by Jason Brownlee provides a good
    illustration of this. In Jason''s article, he reminds us that a machine learning
    project includes more than just running algorithms:'
  prefs: []
  type: TYPE_NORMAL
- en: Machine learning algorithms are only a very small part of using machine learning
    in practice as a data analyst or data scientist.
  prefs: []
  type: TYPE_NORMAL
- en: You can find Jason's article online at [https://machinelearningmastery.com/basic-concepts-in-machine-learning](https://machinelearningmastery.com/basic-concepts-in-machine-learning/).
  prefs: []
  type: TYPE_NORMAL
- en: 'In practice, Jason indicates that the phases followed in a typical statistical
    project involving machine learning will most likely be iterative and look like
    the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/7abcd736-5e03-46f6-a0ae-6f6cdcdd5fc3.png)'
  prefs: []
  type: TYPE_IMG
- en: Understanding
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The initial phase of the project will involve establishing a good understanding
    of the required domain knowledge and the goals of the project. The data scientist
    will talk to domain experts (or subject matter experts) to clarify the project
    goals. It is not uncommon to have vague or unclear goals at the start of the project.
    You often have more things to test then you can possibly implement.
  prefs: []
  type: TYPE_NORMAL
- en: This phase of the project is directly comparable to the first phase of a data/database
    development project as data developers will always need to gather information
    from the domain experts to obtain a detailed understanding of the project goals
    before designing data structures or database models.
  prefs: []
  type: TYPE_NORMAL
- en: Preparation
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this phase, data integration, selection, cleaning, and pre-processing of
    the data is performed. This is often the most time-consuming part but perhaps
    the most important step, as it is important to have high-quality data. The more
    data you have, the more the data is *dirty*.
  prefs: []
  type: TYPE_NORMAL
- en: Again, this phase is relatable to a database development project. System integration,
    query and selection, cleaning, and other data preprocessing steps (to be able
    to use it in a new database model) is expected. This will often involve aggregating
    the data, building key-foreign key relationships, cleansing, and so on.
  prefs: []
  type: TYPE_NORMAL
- en: Learning
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: This phase is the fun part, where machine learning algorithms are applied to
    the data.
  prefs: []
  type: TYPE_NORMAL
- en: This phase of the project is most related to the data modeling or data model
    design phase of a database development project. Keep in mind that in a machine
    learning statistical project, the learning is more machine oriented, while in
    a database development project, the modeling is more human-oriented.
  prefs: []
  type: TYPE_NORMAL
- en: Interpretation
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this phase, the results of the prior phases are reviewed and interpreted
    by the data scientists and the statistical team. Sometimes, it does not matter
    how the model works as long it delivers good results. In some projects, there
    are high demands for the results to be easily understandable. Experts will challenge
    the results.
  prefs: []
  type: TYPE_NORMAL
- en: This phase will relate to the acceptance testing phase of a database development
    project in that after the database is constructed, domain experts will review
    and test the model and interpret the results to determine whether the database
    is providing acceptable results (based upon the requirements of the project established
    in phase one).
  prefs: []
  type: TYPE_NORMAL
- en: Deployment
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this final phase, the results of the previous phases (the discovered knowledge)
    are consolidated and deployed.
  prefs: []
  type: TYPE_NORMAL
- en: It is not uncommon for a machine learning project to be successful in the lab
    but never fully put into practice. More often than not, "another round" of phases
    of the project are performed, usually with more or updated data.
  prefs: []
  type: TYPE_NORMAL
- en: In this phase, we see the database going live or deployed into a production
    environment for use by the owners of the data.
  prefs: []
  type: TYPE_NORMAL
- en: Iteration
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Finally, Jason also notes that:'
  prefs: []
  type: TYPE_NORMAL
- en: '*It is not a one-shot process, it is a cycle. The data scientist may need to
    run the loop (possibly redo phases 1 through 5) until a result that can be used
    in practice is established. Also, the data can change, require a new loop, and
    so on.*'
  prefs: []
  type: TYPE_NORMAL
- en: This might be where a database development project varies from a machine learning
    statistical project. While it is not unheard of for a database project to have
    more than one iteration of the aforementioned project phases (perhaps to address
    certain issues identified during acceptance testing), most database projects typically
    end with a database that is actually used in practice by the owners of the data.
  prefs: []
  type: TYPE_NORMAL
- en: Using R to apply machine learning techniques to a database
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: We've used the R programming language pretty much throughout this book since
    it is used by most data scientists and is very easy for people just getting started
    in statistics to comprehend. In this chapter, we'll again use R, this time to
    suggest how machine learning techniques might be applicable to a data or database
    developer.
  prefs: []
  type: TYPE_NORMAL
- en: We'll use a post offered by Will Stanton, a data scientist, to get us started.
    In his post, he offers a clever example of creating a simple classification model
    in R, using the `caret` package.
  prefs: []
  type: TYPE_NORMAL
- en: The R `caret` package Will uses in his example is very easy to use, containing
    wrapper functions that allow you to use the exact same functions for training
    and predicting with dozens of different algorithms. On top of that, it includes
    sophisticated, built-in methods for evaluating the effectiveness of the predictions
    you get from the model.
  prefs: []
  type: TYPE_NORMAL
- en: In this example (although it's perhaps a bit morbid), the task at hand is to
    build a statistical model that has the ability to look at the characteristics
    of individuals who were on the Titanic, and then predict the likelihood that they
    would have survived the disaster.
  prefs: []
  type: TYPE_NORMAL
- en: Understanding the data
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Data is provided that contains information on who survived and who perished:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/f7dad86d-436e-4222-a891-2a885928f42e.png)'
  prefs: []
  type: TYPE_IMG
- en: 'This data is in the form of a downloadable text CSV file, which contains several
    useful variables for each person:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Pclass**: Passenger class (1st, 2nd, or 3rd)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Sex**'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Age**'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**SibSp**: Number of siblings/spouses aboard'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Parch**: Number of parents/children aboard'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Fare**: How much the passenger paid'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Embarked**: Where they got on the boat (**C** = Cherbourg; **Q** = Queenstown;
    **S** = Southampton)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The step-by-step lines of R code required to install and load the R packages,
    as well as loading the aforementioned datasets, can be found online at [http://will-stanton.com/machine-learning-with-r-an-irresponsibly-fast-tutorial](http://will-stanton.com/machine-learning-with-r-an-irresponsibly-fast-tutorial/).
  prefs: []
  type: TYPE_NORMAL
- en: The example given does an outstanding job of outlining both the methodology
    and the process steps required to create a simple classification model in R, in
    order to illustrate a form of machine learning.
  prefs: []
  type: TYPE_NORMAL
- en: The methodology used aligns with what we've offered earlier in the *Machine
    learning in practice* section of this chapter.
  prefs: []
  type: TYPE_NORMAL
- en: The first steps are understanding the problem or challenge, and the preparation,
    in order to be ready to perform the actual machine learning.
  prefs: []
  type: TYPE_NORMAL
- en: Preparing
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'In the R example, we understand that the challenge is to predict the likelihood
    that a passenger would have survived; we then prepare, by loading the data so
    that it can be reviewed and the appropriate or best variables can be identified
    (to be used in a learning algorithm):'
  prefs: []
  type: TYPE_NORMAL
- en: The post provides the R commands to read on the  `train.csv `file, using the  `,` delimiter, including
    the header row as the column names, and assigning it to an R object. It also reads
    in the `testSet.csv` , and finally uses the R `Head` function to display the first
    few rows of the datasets where the reader then sees that each row has a `Survived `column,
    which is a value of 1 if the person survived, or a value of 0 if they didn't (you
    can see this information in the image of the data file provided previously in
    this section).
  prefs: []
  type: TYPE_NORMAL
- en: Going on, the example explains that comparing the training set to the test set,
    shows the big difference between the training set and the test set; this is that
    the training set is labeled, but the test set is unlabeled. The job at hand is
    to make predictions on the unlabeled test set and be scored based on the percentage
    of passengers correctly labeled.
  prefs: []
  type: TYPE_NORMAL
- en: The article also informs the reader that most of the machine learning is really
    about picking the best features to use in the model. In machine learning, a feature
    is really just a variable or some sort of combination of variables (such as the
    sum or product of two variables).
  prefs: []
  type: TYPE_NORMAL
- en: So, in the statistical classification model example, *the Titanic challenge*,
    picking the most useful variables to use is accomplished using crosstabs and conditional boxplots.
  prefs: []
  type: TYPE_NORMAL
- en: Crosstabs show the interactions between two variables in a very easy-to-read
    way. In the example, to determine which variables are the best predictors of survival,
    the R table function is used to look at the crosstabs between survival and each
    other variable.
  prefs: []
  type: TYPE_NORMAL
- en: Box plots can be handy to identify useful continuous variables. The R example
    given uses conditional box plots to compare the distribution of each continuous
    variable in the data, conditioned on whether the passengers survived or not.
  prefs: []
  type: TYPE_NORMAL
- en: 'In the analysis performed, one can see that Pclass has a strong predictive
    value for whether someone survived or not based upon the indicated survival rates:'
  prefs: []
  type: TYPE_NORMAL
- en: '| **Class of Passenger** | **Outcome** | **Survival****Rate** |'
  prefs: []
  type: TYPE_TB
- en: '| Class 1 | 136 survived and 80 died | 63% |'
  prefs: []
  type: TYPE_TB
- en: '| Class 2 | 87 survived and 97 died | 47% |'
  prefs: []
  type: TYPE_TB
- en: '| Class 3 | 119 survived and 372 died | 24% |'
  prefs: []
  type: TYPE_TB
- en: Data developer
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: How does the preceding example compare to a data or database developer? What
    might be a relatable example?
  prefs: []
  type: TYPE_NORMAL
- en: Starting from the top, suppose you are in charge of a database owned by a gaming
    company. The company purchases and places various slot-type gaming machines on
    the floors of their casinos and clubs.
  prefs: []
  type: TYPE_NORMAL
- en: Slot machines are a type of casino gambling machine with three or more reels,
    which spin when a button is pushed. The machine is worked by the insertion of
    a coin.
  prefs: []
  type: TYPE_NORMAL
- en: 'The database contains many useful variables for each slot-type gaming machine:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Theme**: Traditional slot machines featured fruit and bars as symbols, but
    themes are becoming the predominant feature of slot machine games'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Denomination**: Five cents, 10 cents, 25 cents, 50 cents, and so on'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Payout** **frequency**: Loose, medium, or tight'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Player position**: Low-level or upright'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Reel type**: Mechanical or virtual'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Number of players**: Standalone or community'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Here, our challenge is to predict whether a particular machine will be a popular
    machine for the gaming company or not, based on the machine's characteristics,
    or known variables.
  prefs: []
  type: TYPE_NORMAL
- en: In the R example, the data scientist was fortunate enough to have a data file
    provided. As a data or database developer, though, we're usually not that lucky,
    although this really isn't such a big deal.
  prefs: []
  type: TYPE_NORMAL
- en: Knowing the data structures/database model (as we discussed at the start of
    this chapter), the data developer can construct appropriate SQL queries to locate
    the data we might be interested in for our project (some refer to this process
    as mining the data).
  prefs: []
  type: TYPE_NORMAL
- en: Data mining is the process of discovering patterns in data involving methods
    at the intersection of artificial intelligence, machine learning, statistics,
    and database systems.
  prefs: []
  type: TYPE_NORMAL
- en: 'Additionally, once the data has been located within the database, it is a routine
    matter to write the information to a CSV text file to be consumed by our statistical
    project:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: But in fact, the data developer might actually go as far as performing the data
    analyses, variable review, and feature selection on the data while the data is
    still in the database; that way, once the strongest predictors are identified,
    others (considered to be perhaps noise in the context of our challenge) would
    not have to be extracted into our file. This saves time and makes the data perhaps
    a bit more manageable.
  prefs: []
  type: TYPE_NORMAL
- en: '*Noise* was covered in [Chapter 10](d114349e-1538-42d5-b9a6-939081494991.xhtml),
    *Boosting and Your Database*.'
  prefs: []
  type: TYPE_NORMAL
- en: Understanding the challenge
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: After fully understanding the challenge at hand, perhaps we have come to know
    that if a gaming machine type has an average coin-in (the total dollar amount
    of the coins played on a slot machine) value of more than ten thousand dollars
    per day, it is considered by the organization to be a popular gaming machine.
  prefs: []
  type: TYPE_NORMAL
- en: With this information in mind, we can construct a query (or most likely, several)
    designed to calculate and pull this variable's amount for each of our machine
    observations.
  prefs: []
  type: TYPE_NORMAL
- en: At that point, we would have data with observations (records) for each machine
    in service by the company, along with a list of each machine's characteristics
    (the variables we want to examine), as well as the determined result (popular
    or not).
  prefs: []
  type: TYPE_NORMAL
- en: Sound familiar? It should!
  prefs: []
  type: TYPE_NORMAL
- en: 'Suppose in our database example we see that denomination is the strongest predictor
    of whether a gaming machine is a popular machine or not:'
  prefs: []
  type: TYPE_NORMAL
- en: '| **Denomination** | **Outcome/average coin-in value** | **Popular** |'
  prefs: []
  type: TYPE_TB
- en: '| 10 cents | $7,500 | No |'
  prefs: []
  type: TYPE_TB
- en: '| 25 cents | $18,000 | Yes |'
  prefs: []
  type: TYPE_TB
- en: '| 50 cents | $9,000 | No |'
  prefs: []
  type: TYPE_TB
- en: We can see from the comparison of these examples that there are plenty of opportunities
    for data developers to locate and use information stored within databases as input
    to statistical models.
  prefs: []
  type: TYPE_NORMAL
- en: Cross-tabbing and plotting
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: We previously stated that crosstabs were used to show the interactions between
    two variables in a very easy to read format. To look at the crosstabs between
    `Survived` and each other variable, the R function table was used.
  prefs: []
  type: TYPE_NORMAL
- en: Data developers have a similar tool, PIVOT. PIVOT is one of the new relational
    operators introduced in SQL Server 2005\. It provides an easy mechanism in SQL
    Server to transform rows into columns.
  prefs: []
  type: TYPE_NORMAL
- en: The R example we are focusing on here also used *box plot visualizations* to
    identify continuous variables within the data. Although native SQL doesn't really
    provide us with plotting abilities, the data developer might consider leveraging
    something like **SQL** **Server Reporting Services** (**SSRS**) to plot the data
    mined from the database; however, since the next phase will require us to create
    a classification model, I would suggest leveraging the visualization power of
    R to create our charts and graphs.
  prefs: []
  type: TYPE_NORMAL
- en: 'There is an excellent resource online that is worthy of the reader''s time,
    and deals with the topic *Create graphs and plots using SQL and R (walkthrough)*:'
  prefs: []
  type: TYPE_NORMAL
- en: '[https://docs.microsoft.com/en-us/sql/advanced-analytics/tutorials/walkthrough-create-graphs-and-plots-using-r](https://docs.microsoft.com/en-us/sql/advanced-analytics/tutorials/walkthrough-create-graphs-and-plots-using-r)'
  prefs: []
  type: TYPE_NORMAL
- en: At this point, you can move on to the learning, evaluation, and deployment phases
    we discussed earlier.
  prefs: []
  type: TYPE_NORMAL
- en: Summary
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this chapter, we started out by reviewing the idea of data structures, data
    models, and databases, and found similarities and differences between them.
  prefs: []
  type: TYPE_NORMAL
- en: Next, we provided an overview of machine learning and related concepts, and
    then compared the practice of a machine learning statistical project to a database
    development project.
  prefs: []
  type: TYPE_NORMAL
- en: Finally, we touched on a conceptual use of R and applying machine learning techniques
    to data from a database.
  prefs: []
  type: TYPE_NORMAL
- en: As this book was aimed at helping the typical data or database developer transition
    into the world of statistics, we hope the reader has established a sound understanding
    of the relevant topics in statistics and data science.
  prefs: []
  type: TYPE_NORMAL
- en: Good luck!
  prefs: []
  type: TYPE_NORMAL
