<html><head></head><body><div><h1 class="header-title">Database Structures and Machine Learning</h1>
                
            
            
                
<p class="calibre4">In this final chapter, we will focus on the concepts and types of machine learning.</p>
<p class="calibre4">In keeping with the overall theme of this book, we'll start by offering an explanation of statistical machine learning and related concepts, and then move on to drawing out some similarities between statistical machine learning and basic notions that a reader who has a data or database developer background should be able to relate to.</p>
<p class="calibre4">This chapter is organized into the following areas:</p>
<ul class="calibre18">
<li class="calibre19">Is a data structure a data model?</li>
<li class="calibre19">An overview of machine learning concepts</li>
<li class="calibre19">The types of machine learning</li>
<li class="calibre19">Data developers and machine learning</li>
<li class="calibre19">Using R to apply machine learning techniques to a database</li>
</ul>


            

            
        
    </div>



  
<div><h1 class="header-title">Data structures and data models</h1>
                
            
            
                
<p class="calibre4">When you have ample of data, but no idea where  It's very important to structure the data, analyze it, and put to good use (wherever needed). In this section, we will be zooming the spotlight on data structures and data models, and also understanding the difference between both.</p>


            

            
        
    </div>



  
<div><h1 class="header-title">Data structures</h1>
                
            
            
                
<p class="calibre4">Data developers will agree that whenever one is working with large amounts of data, the organization of that data is imperative. If that data is not organized effectively, it will be very difficult to perform any task on that data, or at least be able to perform the task in an efficient manner. If the data is organized effectively, then practically any operation can be performed easily on that data.</p>
<p class="calibre4">A data or database developer will then organize the data into what is known as <strong class="calibre7">data</strong> <strong class="calibre7">structures</strong>. Following image is a simple binary tree, where the data is organized efficiently by structuring it: </p>
<div><img class="image-border54" src="img/84c90422-84f3-4170-97ad-7878723da117.png"/></div>
<p class="calibre4"><em class="calibre21">A data structure can be defined as a method of organizing large amounts of data more efficiently so that any operation on that data becomes easy.</em></p>
<p class="calibre4">Data structures are created in such a way as to implement one or more particular <strong class="calibre7">abstract data type</strong> (<strong class="calibre7">ADT</strong>), which in turn will stipulate what operations can be performed on the data structure, as well as the computational complexity of those operations.</p>
<p>In the field of statistics, an ADT is a model for data types where a data type is defined by its behavior from the <strong class="calibre3">point of view</strong> (<strong class="calibre3">POV</strong>) of users of that data, explicitly showing the possible values, the possible operations on data of this type, and the behavior of all of these operations.</p>
<p class="calibre4">Database design is then the process of using the defined data structures to produce a detailed data model, which will become the database. This data model must contain all of the required logical and physical design selections, as well as the physical storage parameters needed to produce a design in a <strong class="calibre7">D</strong><strong class="calibre7">ata Definition Language</strong> (<strong class="calibre7">DDL</strong>), which can then be used to create an actual database.</p>
<p>There are varying degrees of the data model, for example, a fully attributed data model would also contain detailed attributes for each entity in the model.</p>
<p class="calibre4">So, is a data structure a data model?</p>
<p class="calibre4">No, a data structure is used to create a data model. Is this data model the same as data models used in statistics? Let's see in the further section.</p>


            

            
        
    </div>



  
<div><h1 class="header-title">Data models</h1>
                
            
            
                
<p class="calibre4">You will find that statistical data models are at the heart of statistical analytics.</p>
<p class="calibre4">In the simplest terms, a statistical data model is defined as the following:</p>
<p class="calibre4"><em class="calibre21">A representation of a state, process, or system that we want to understand and reason about</em></p>
<p class="calibre4">In the scope of the previous definition, the data or database developer might agree that in theory or in concept, one could use the same terms to define a financial reporting database, as it is designed to contain business transactions and is arranged in data structures that allow business analysts to efficiently review the data, so that they can understand or reason about particular interests they may have concerning the business.</p>
<p class="calibre4">Data scientists develop statistical data models so that they can draw inferences from them and, more importantly, make predictions about a topic of concern. Data developers develop databases so that they can similarly draw inferences from them and, more importantly, make predictions about a topic of concern (although perhaps in some organizations, databases are more focused on past and current events (transactions) than forward-thinking ones (predictions)).</p>
<p class="calibre4">Statistical data models come in a multitude of different formats and flavours (as do databases). These models can be equations linking quantities that we can observe or measure; they can also be simply sets of rules.</p>
<p class="calibre4">Databases can be designed or formatted to simplify the entering of online transactions—say, in an order entry system—or for financial reporting when the accounting department must generate a balance sheet, income statement, or profit and loss statement for shareholders.</p>
<p>I found this example of a simple statistical data model: <em class="calibre20">Newton's Second Law of Motion</em>, which states that the net sum of force acting on an object causes the object to accelerate in the direction of the force applied, and at a rate proportional to the resulting magnitude of the force and inversely proportional to the object's mass.</p>


            

            
        
    </div>



  
<div><h1 class="header-title">What's the difference?</h1>
                
            
            
                
<p class="calibre4">Where or how does the reader find the difference between a data structure or database and a statistical model? At a high level, as we speculated in previous sections, one can conclude that a data structure/database is practically the same thing as a statistical data model, as shown in the following image:</p>
<div><strong class="calibre3"><img class="image-border55" src="img/ded56d04-54ef-402e-8032-04baa4e5974c.png"/></strong></div>
<p class="calibre4">At a high level, as we speculated in previous sections, one can conclude that a data structure/database is practically the same thing as a statistical data model.</p>
<p class="calibre4">When we take the time to drill deeper into the topic, you should consider the following key points:</p>
<ul class="calibre18">
<li class="calibre19">Although both the data structure/database and the statistical model could be said to represent a set of assumptions, the statistical model typically will be found to be much more keenly focused on a particular set of assumptions concerning the generation of some sample data, and similar data from a larger population, while the data structure/database more often than not will be more broadly based</li>
<li class="calibre19">A statistical model is often in a rather idealized form, while the data structure/database may be less perfect in the pursuit of a specific assumption</li>
<li class="calibre19">Both a data structure/database and a statistical model are built around relationships between variables</li>
<li class="calibre19">The data structure/database relationship may focus on answering certain questions, such as:
<ul class="calibre18">
<li class="calibre19">What are the total orders for specific customers?</li>
<li class="calibre19">What are the total orders for a specific customer who has purchased from a certain salesperson?</li>
<li class="calibre19">Which customer has placed the most orders?</li>
</ul>
</li>
<li class="calibre19">Statistical model relationships are usually very simple, and focused on proving certain questions:
<ul class="calibre18">
<li class="calibre19">Females are shorter than males by a fixed amount</li>
<li class="calibre19">Body mass is proportional to height</li>
</ul>
</li>
<li class="calibre19">The probability that any given person will partake in a certain sport is a function of age, sex, and socioeconomic status</li>
<li class="calibre19">Data structures/databases are all about the act of summarizing data based on relationships between variables</li>
</ul>


            

            
        
    </div>



  
<div><h1 class="header-title">Relationships</h1>
                
            
            
                
<p class="calibre4">The relationships between variables in a statistical model may be found to be much more complicated than simply straightforward to recognize and understand. An illustration of this is awareness of effect statistics. An effect statistic is one that shows or displays a difference in value to one that is associated with a difference related to one or more other variables.</p>
<p class="calibre4">Can you image the SQL query statements you'd use to establish a relationship between two database variables based upon one or more effect statistic?</p>
<p class="calibre4">On this point, you may find that a data structure/database usually aims to characterize relationships between variables, while with statistical models, the data scientist looks to fit the model to prove a point or make a statement about the population in the model. That is, a data scientist endeavors to make a statement about the accuracy of an estimate of the effect statistic(s) describing the model!</p>
<p class="calibre4">One more note of interest is that both a data structure/database and a statistical model can be seen as tools or vehicles that aim to generalize a population; a database uses SQL to aggregate or summarize data, and a statistical model summarizes its data using effect statistics.</p>
<p class="calibre4">Okay, hopefully, we have successfully presented the notion that data structures/databases and statistical data models are, in many ways, very similar.</p>
<p class="calibre4">At this point, let us move on to machine learning.</p>


            

            
        
    </div>



  
<div><h1 class="header-title">Machine learning</h1>
                
            
            
                
<p class="calibre4">There are many deep definitions of statistical machine learning, but let's start off with the simplest or most basic version:</p>
<p class="calibre4"><em class="calibre21">Machine learning is the process that aims to teach a computer to make realistic predictions (or improve on predictions) based on some flow or source of data.</em></p>
<p class="calibre4">The reader should take note that the data source explicitly depends upon the problem the data scientist is solving (trying to solve). For example, the subscription entertainment service Netflix would not use patient dental record data as input in an attempt to predict subscriber viewing behaviours!</p>
<p class="calibre4">An explanation that's a little deeper can be provided:</p>
<p>Machine learning is a sub-field of computer science that evolved from the study of pattern recognition and computational learning theory in artificial intelligence. In 1959, Arthur Samuel defined machine learning as a "Field of study that gives computers the ability to learn without being explicitly programmed."    <em class="calibre20"> </em>    <br class="calibre2"/>
                                               ; -<a href="https://scratch.mit.edu/studios/3475398/activity/" target="_blank" class="pcalibre pcalibre3 pcalibre1 calibre8 pcalibre2">https://scratch.mit.edu/studios/3475398/activity</a></p>
<p class="calibre4">In machine learning, the data scientist will spend his or her time exploring, studying, and building processes that they can learn from and make predictions on a source of data.</p>
<p class="calibre4">The way these machine learning processes or algorithms actually work is by building a statistical model using example data source inputs. This is different than typical computer algorithms (that is, traditional computer programming) that work by following strictly static program instructions written by a team of developers.</p>
<p class="calibre4">You will find machine learning employed where designing and programming explicit program instructions are infeasible, for example, applications such as image recognition and computer vision.</p>
<p class="calibre4">Later in this chapter, we will take some time and list more examples of where one will find machine learning at work in today's world.</p>


            

            
        
    </div>



  
<div><h1 class="header-title">Overview of machine learning concepts</h1>
                
            
            
                
<p class="calibre4">In the preceding section of this chapter, we have mentioned the concept of traditional programming. With traditional programming, the data and program are run on the computer to produce the desired output. With machine learning, the data and output are run on the computer to create a program. This program can then be used in traditional programming.</p>
<div><img class="image-border56" src="img/b7f0e20c-5ef8-4920-99e6-76d8a2e7271d.png"/></div>
<p class="calibre4">A somewhat popular and perhaps fun analogy for describing machine learning is <em class="calibre21">farming</em>.</p>
<p class="calibre4">Here, one might think of the machine learning algorithms used as the <em class="calibre21">seeds</em>, the data source as the <em class="calibre21">fertilizer</em>, and the data scientists as the <em class="calibre21">farmers</em> who plant and feed the seeds and in the end, reap the results!</p>


            

            
        
    </div>



  
<div><h1 class="header-title">Key elements of machine learning</h1>
                
            
            
                
<p class="calibre4">There are a good number of machine learning algorithms in use by data scientists today. In fact, some research indicates that there are perhaps tens of thousands. In addition, hundreds of new algorithms are put forward for use every year.</p>
<p class="calibre4">Based on popular opinion, all machine learning algorithms today are made up of three components. They are as follows:</p>
<ul class="calibre18">
<li class="calibre19">Representation</li>
<li class="calibre19">Evaluation</li>
<li class="calibre19">Optimization</li>
</ul>
<div><img class="image-border57" src="img/197e5f06-e6f6-46e0-b715-ae49ad16ac4a.png"/></div>


            

            
        
    </div>



  
<div><h1 class="header-title">Representation</h1>
                
            
            
                
<p class="calibre4">This is how the information is represented. Examples include decision trees, sets of rules, instances, graphical models, neural networks, support vector machines, model ensembles, and others.</p>


            

            
        
    </div>



  
<div><h1 class="header-title">Evaluation</h1>
                
            
            
                
<p class="calibre4">This is how candidate programs (hypotheses) will be evaluated. Examples include accuracy, prediction and recall, squared error, likelihood, posterior probability, cost, margin, entropy Kullback-Leibler (KL-divergence) divergence, and others.</p>


            

            
        
    </div>



  
<div><h1 class="header-title">Optimization</h1>
                
            
            
                
<p class="calibre4">This is the way candidate programs are generated, also known as the <strong class="calibre7">search process</strong>, for example, combinatorial optimization, convex optimization, and constrained optimization.</p>


            

            
        
    </div>



  
<div><h1 class="header-title">Types of machine learning</h1>
                
            
            
                
<p class="calibre4">Today, there are four types or categories of machine learning.</p>
<p class="calibre4">These types are the following:</p>
<ul class="calibre18">
<li class="calibre19">Supervised</li>
<li class="calibre19">Unsupervised</li>
<li class="calibre19">Semi-supervised </li>
<li class="calibre19">Reinforcement</li>
</ul>
<p class="calibre4">It is important to understand each type of learning.</p>


            

            
        
    </div>



  
<div><h1 class="header-title">Supervised learning</h1>
                
            
            
                
<p class="calibre4">This type of learning is also referred to as <strong class="calibre7">inductive learning</strong>. This is where the training data will include the desired outputs; the algorithm infers from labeled or categorized training data. The training data is a set of training examples.</p>


            

            
        
    </div>



  
<div><h1 class="header-title">Unsupervised learning</h1>
                
            
            
                
<p class="calibre4">Unlike supervised machine learning, here, the training data does not include desired outputs. This is the machine learning task of inferring a function to describe a hidden structure from unlabeled or uncategorized data. Since the examples given to the learner are unlabeled, there is no error or reward signal to evaluate a potential solution.</p>


            

            
        
    </div>



  
<div><h1 class="header-title">Semi-supervised learning</h1>
                
            
            
                
<p class="calibre4">In this type of machine learning, the training data includes a few samples of desired outputs. Semi-supervised learning is actually considered a type of supervised machine learning that makes use of unlabeled or uncategorized data for training, typically a small amount of labeled data with a large amount of unlabeled data.</p>


            

            
        
    </div>



  
<div><h1 class="header-title">Reinforcement learning</h1>
                
            
            
                
<p class="calibre4">Rewards from a sequence of actions, <strong class="calibre7">Artificial intelligence</strong> (<strong class="calibre7">AI</strong>) types like it, as it is the most ambitious type of learning. <strong class="calibre7">Reinforcement learning</strong> (<strong class="calibre7">RL</strong>) is a type of machine learning that allows machines and software agents to automatically determine the ideal behaviour within a specific context, in order to maximize its performance.</p>


            

            
        
    </div>



  
<div><h1 class="header-title">Most popular</h1>
                
            
            
                
<p class="calibre4">Supervised learning is the most mature as it's been around the longest. It is the most studied and the type of learning used by most machine learning algorithms.</p>
<p class="calibre4">Learning with supervision is much easier than learning without supervision.</p>
<p class="calibre4">Before moving on to an illustrative machine learning example, let's review a few machine learning applications.</p>


            

            
        
    </div>



  
<div><h1 class="header-title">Applications of machine learning</h1>
                
            
            
                
<p class="calibre4">If it's not clear just yet why the topic of machine learning is so significant, perhaps reviewing a list of real-world machine learning use cases will help.</p>
<p class="calibre4">In this section, we'll take a little of your time to list some real-world machine learning applications.</p>
<p class="calibre4">Sample applications of machine learning that are in use today (in fact, almost every day) include the following:</p>
<table class="calibre9">
<tbody class="calibre10">
<tr class="calibre11">
<td class="calibre12">
<p class="calibre13">Searching</p>
</td>
<td class="calibre12">
<p class="calibre13">You probably use this every day on multiple devices. Machine learning results are used to develop web search ranking pages. Ranking pages are lists of what the individual is most likely to be interested in and click on.</p>
</td>
</tr>
<tr class="calibre15">
<td class="calibre12">
<p class="calibre13">Digit</p>
<p class="calibre13">recognition</p>
</td>
<td class="calibre12">
<p class="calibre13">Given a zip code handwritten on an envelope, identify the digit for each handwritten character. A model of this problem would allow a computer program to read and understand handwritten zip codes and sort envelopes by geographical region.</p>
</td>
</tr>
<tr class="calibre11">
<td class="calibre12">
<p class="calibre13">Biology</p>
</td>
<td class="calibre12">
<p class="calibre13">Rationally designs drugs on the computer based on past experiments.</p>
</td>
</tr>
<tr class="calibre15">
<td class="calibre12">
<p class="calibre13">Banking</p>
<p class="calibre13">and</p>
<p class="calibre13">finance</p>
</td>
<td class="calibre12">
<p class="calibre13">Used to determine who to send what credit card offers to. Evaluation of risk on credit offers. How to decide where to invest money.</p>
</td>
</tr>
<tr class="calibre11">
<td class="calibre12">
<p class="calibre13">E-commerce</p>
</td>
<td class="calibre12">
<p class="calibre13">Predicting customer churn, fraud detection, and bot detection.</p>
</td>
</tr>
<tr class="calibre15">
<td class="calibre12">
<p class="calibre13">Understanding speech</p>
</td>
<td class="calibre12">
<p class="calibre13">Given an utterance from a user, identify the specific request made by the user. A model of this problem would allow a program to understand and make an attempt to fulfil that request. The iPhone, with Siri, has this capability.</p>
</td>
</tr>
<tr class="calibre11">
<td class="calibre12">
<p class="calibre13">Face</p>
<p class="calibre13">detection</p>
<p class="calibre13"> </p>
</td>
<td class="calibre12">
<p class="calibre13">Given a digital photo album of many hundreds of digital photographs, identify those photos that include a given person. A model of this decision process would allow a program to organize photos by person. Some cameras and software, such as iPhoto, have this capability.</p>
</td>
</tr>
<tr class="calibre15">
<td class="calibre12">
<p class="calibre13">Space</p>
<p class="calibre13">explorations</p>
</td>
<td class="calibre12">
<p class="calibre13">Space probes and radio astronomy.</p>
</td>
</tr>
<tr class="calibre11">
<td class="calibre12">
<p class="calibre13">Shape</p>
<p class="calibre13">detection</p>
</td>
<td class="calibre12">
<p class="calibre13">Given a user's hand drawing a shape on a touch screen, and a database of known shapes, determine which shape the user was trying to draw. A model of this decision would allow a program to show the platonic version of the shape the user drew to make crisp diagrams.</p>
</td>
</tr>
<tr class="calibre15">
<td class="calibre12">
<p class="calibre13">Robotics</p>
</td>
<td class="calibre12">
<p class="calibre13">How to handle uncertainty in new environments; autonomous self-driving cars.</p>
</td>
</tr>
<tr class="calibre11">
<td class="calibre12">
<p class="calibre13">Information extraction</p>
</td>
<td class="calibre12">
<p class="calibre13">The ability to ask questions over databases across the web.</p>
</td>
</tr>
<tr class="calibre15">
<td class="calibre12">
<p class="calibre13">Social</p>
<p class="calibre13">networking</p>
</td>
<td class="calibre12">
<p class="calibre13">Data on relationships and preferences. Machine learning to extract value from data.</p>
</td>
</tr>
<tr class="calibre11">
<td class="calibre12">
<p class="calibre13">Product recommendation</p>
</td>
<td class="calibre12">
<p class="calibre13">Given a purchase history for a customer and a large inventory of products, identify those products in which that customer will be interested and is likely to purchase. A model of this decision process would allow a program to make recommendations to a customer and motivate product purchases. Amazon has this capability. Also think of Facebook and  GooglePlus, which recommend users to connect with you after you sign up.</p>
</td>
</tr>
<tr class="calibre16">
<td class="calibre12">
<p class="calibre13">Debugging</p>
</td>
<td class="calibre12">
<p class="calibre13">Used in computer science problems, such as debugging. Labor intensive process. Could suggest where the bug could be.</p>
</td>
</tr>
</tbody>
</table>


            

            
        
    </div>



  
<div><h1 class="header-title">Machine learning in practice</h1>
                
            
            
                
<p class="calibre4">If we continue to compare data/database development and machine learning, focusing on a typical project, we'll see similarities.</p>
<p class="calibre4">At this point, a rather nice piece presented by Jason Brownlee provides a good illustration of this. In Jason's article, he reminds us that a machine learning project includes more than just running algorithms:</p>
<p>Machine learning algorithms are only a very small part of using machine learning in practice as a data analyst or data scientist.</p>
<p>You can find Jason's article online at <a href="https://machinelearningmastery.com/basic-concepts-in-machine-learning/" target="_blank" class="pcalibre pcalibre3 pcalibre1 calibre8 pcalibre2">https://machinelearningmastery.com/basic-concepts-in-machine-learning</a>.</p>
<p class="calibre4">In practice, Jason indicates that the phases followed in a typical statistical project involving machine learning will most likely be iterative and look like the following:</p>
<div><img class="image-border58" src="img/7abcd736-5e03-46f6-a0ae-6f6cdcdd5fc3.png"/></div>


            

            
        
    </div>



  
<div><h1 class="header-title">Understanding</h1>
                
            
            
                
<p class="calibre4">The initial phase of the project will involve establishing a good understanding of the required domain knowledge and the goals of the project. The data scientist will talk to domain experts (or subject matter experts) to clarify the project goals. It is not uncommon to have vague or unclear goals at the start of the project. You often have more things to test then you can possibly implement.</p>
<p>This phase of the project is directly comparable to the first phase of a data/database development project as data developers will always need to gather information from the domain experts to obtain a detailed understanding of the project goals before designing data structures or database models.</p>


            

            
        
    </div>



  
<div><h1 class="header-title">Preparation</h1>
                
            
            
                
<p class="calibre4">In this phase, data integration, selection, cleaning, and pre-processing of the data is performed. This is often the most time-consuming part but perhaps the most important step, as it is important to have high-quality data. The more data you have, the more the data is <em class="calibre21">dirty</em>.</p>
<p>Again, this phase is relatable to a database development project. System integration, query and selection, cleaning, and other data preprocessing steps (to be able to use it in a new database model) is expected. This will often involve aggregating the data, building key-foreign key relationships, cleansing, and so on.</p>


            

            
        
    </div>



  
<div><h1 class="header-title">Learning</h1>
                
            
            
                
<p class="calibre4">This phase is the fun part, where machine learning algorithms are applied to the data.</p>
<p>This phase of the project is most related to the data modeling or data model design phase of a database development project. Keep in mind that in a machine learning statistical project, the learning is more machine oriented, while in a database development project, the modeling is more human-oriented.</p>


            

            
        
    </div>



  
<div><h1 class="header-title">Interpretation</h1>
                
            
            
                
<p class="calibre4">In this phase, the results of the prior phases are reviewed and interpreted by the data scientists and the statistical team. Sometimes, it does not matter how the model works as long it delivers good results. In some projects, there are high demands for the results to be easily understandable. Experts will challenge the results.</p>
<p>This phase will relate to the acceptance testing phase of a database development project in that after the database is constructed, domain experts will review and test the model and interpret the results to determine whether the database is providing acceptable results (based upon the requirements of the project established in phase one).</p>


            

            
        
    </div>



  
<div><h1 class="header-title">Deployment</h1>
                
            
            
                
<p class="calibre4">In this final phase, the results of the previous phases (the discovered knowledge) are consolidated and deployed.</p>
<p>It is not uncommon for a machine learning project to be successful in the lab but never fully put into practice. More often than not, "another round" of phases of the project are performed, usually with more or updated data.</p>
<p class="calibre4">In this phase, we see the database going live or deployed into a production environment for use by the owners of the data.</p>


            

            
        
    </div>



  
<div><h1 class="header-title">Iteration</h1>
                
            
            
                
<p class="calibre4">Finally, Jason also notes that:</p>
<p class="calibre4"><em class="calibre21">It is not a one-shot process, it is a cycle. The data scientist may need to run the loop (possibly redo phases 1 through 5) until a result that can be used in practice is established. Also, the data can change, require a new loop, and so on.</em></p>
<p class="calibre4">This might be where a database development project varies from a machine learning statistical project. While it is not unheard of for a database project to have more than one iteration of the aforementioned project phases (perhaps to address certain issues identified during acceptance testing), most database projects typically end with a database that is actually used in practice by the owners of the data.</p>


            

            
        
    </div>



  
<div><h1 class="header-title">Using R to apply machine learning techniques to a database</h1>
                
            
            
                
<p class="calibre4">We've used the R programming language pretty much throughout this book since it is used by most data scientists and is very easy for people just getting started in statistics to comprehend. In this chapter, we'll again use R, this time to suggest how machine learning techniques might be applicable to a data or database developer.</p>
<p class="calibre4">We'll use a post offered by Will Stanton, a data scientist, to get us started. In his post, he offers a clever example of creating a simple classification model in R, using the <kbd class="calibre22">caret</kbd> package.</p>
<p class="calibre4">The R <kbd class="calibre22">caret</kbd> package Will uses in his example is very easy to use, containing wrapper functions that allow you to use the exact same functions for training and predicting with dozens of different algorithms. On top of that, it includes sophisticated, built-in methods for evaluating the effectiveness of the predictions you get from the model.</p>
<p class="calibre4">In this example (although it's perhaps a bit morbid), the task at hand is to build a statistical model that has the ability to look at the characteristics of individuals who were on the Titanic, and then predict the likelihood that they would have survived the disaster.</p>


            

            
        
    </div>



  
<div><h1 class="header-title">Understanding the data</h1>
                
            
            
                
<p class="calibre4">Data is provided that contains information on who survived and who perished:</p>
<div><img class="alignnone35" src="img/f7dad86d-436e-4222-a891-2a885928f42e.png"/></div>
<p class="calibre4">This data is in the form of a downloadable text CSV file, which contains several useful variables for each person:</p>
<ul class="calibre18">
<li class="calibre19"><strong class="calibre3">Pclass</strong>: Passenger class (1st, 2nd, or 3rd)</li>
<li class="calibre19"><strong class="calibre3">Sex</strong></li>
<li class="calibre19"><strong class="calibre3">Age</strong></li>
<li class="calibre19"><strong class="calibre3">SibSp</strong>: Number of siblings/spouses aboard</li>
<li class="calibre19"><strong class="calibre3">Parch</strong>: Number of parents/children aboard</li>
<li class="calibre19"><strong class="calibre3">Fare</strong>: How much the passenger paid</li>
<li class="calibre19"><strong class="calibre3">Embarked</strong>: Where they got on the boat (<strong class="calibre3">C</strong> = Cherbourg; <strong class="calibre3">Q</strong> = Queenstown; <strong class="calibre3">S</strong> = Southampton)</li>
</ul>
<p>The step-by-step lines of R code required to install and load the R packages, as well as loading the aforementioned datasets, can be found online at <a href="http://will-stanton.com/machine-learning-with-r-an-irresponsibly-fast-tutorial/" target="_blank" class="pcalibre pcalibre3 pcalibre1 calibre8 pcalibre2">http://will-stanton.com/machine-learning-with-r-an-irresponsibly-fast-tutorial</a>.</p>
<p class="calibre4">The example given does an outstanding job of outlining both the methodology and the process steps required to create a simple classification model in R, in order to illustrate a form of machine learning.</p>
<p class="calibre4">The methodology used aligns with what we've offered earlier in the <em class="calibre21">Machine learning in practice</em> section of this chapter.</p>
<p class="calibre4">The first steps are understanding the problem or challenge, and the preparation, in order to be ready to perform the actual machine learning.</p>


            

            
        
    </div>



  
<div><h1 class="header-title">Preparing</h1>
                
            
            
                
<p class="calibre4">In the R example, we understand that the challenge is to predict the likelihood that a passenger would have survived; we then prepare, by loading the data so that it can be reviewed and the appropriate or best variables can be identified (to be used in a learning algorithm):</p>
<p class="calibre4">The post provides the R commands to read on the  <kbd class="calibre22">train.csv </kbd>file, using the  <kbd class="calibre22">,</kbd> delimiter, including the header row as the column names, and assigning it to an R object. It also reads in the <kbd class="calibre22">testSet.csv</kbd> , and finally uses the R <kbd class="calibre22">Head</kbd> function to display the first few rows of the datasets where the reader then sees that each row has a <kbd class="calibre22">Survived </kbd>column, which is a value of 1 if the person survived, or a value of 0 if they didn't (you can see this information in the image of the data file provided previously in this section).</p>
<p class="calibre4">Going on, the example explains that comparing the training set to the test set, shows the big difference between the training set and the test set; this is that the training set is labeled, but the test set is unlabeled. The job at hand is to make predictions on the unlabeled test set and be scored based on the percentage of passengers correctly labeled.</p>
<p class="calibre4">The article also informs the reader that most of the machine learning is really about picking the best features to use in the model. In machine learning, a feature is really just a variable or some sort of combination of variables (such as the sum or product of two variables).</p>
<p class="calibre4">So, in the statistical classification model example, <em class="calibre21">the Titanic challenge</em>, picking the most useful variables to use is accomplished using crosstabs and conditional boxplots.</p>
<p class="calibre4">Crosstabs show the interactions between two variables in a very easy-to-read way. In the example, to determine which variables are the best predictors of survival, the R table function is used to look at the crosstabs between survival and each other variable.</p>
<p class="calibre4">Box plots can be handy to identify useful continuous variables. The R example given uses conditional box plots to compare the distribution of each continuous variable in the data, conditioned on whether the passengers survived or not.</p>
<p class="calibre4">In the analysis performed, one can see that Pclass has a strong predictive value for whether someone survived or not based upon the indicated survival rates:</p>
<table class="calibre9">
<tbody class="calibre10">
<tr class="calibre11">
<td class="calibre12">
<p class="calibre13"><strong class="calibre7">Class of Passenger</strong></p>
</td>
<td class="calibre12">
<p class="calibre13"><strong class="calibre7">Outcome</strong></p>
</td>
<td class="calibre12">
<p class="calibre13"><strong class="calibre7">Survival</strong></p>
<p class="calibre13"><strong class="calibre7">Rate</strong></p>
</td>
</tr>
<tr class="calibre15">
<td class="calibre12">
<p class="calibre13">Class 1</p>
</td>
<td class="calibre12">
<p class="calibre13">136 survived and 80 died</p>
</td>
<td class="calibre12">
<p class="calibre13">63%</p>
</td>
</tr>
<tr class="calibre11">
<td class="calibre12">
<p class="calibre13">Class 2</p>
</td>
<td class="calibre12">
<p class="calibre13">87 survived and 97 died</p>
</td>
<td class="calibre12">
<p class="calibre13">47%</p>
</td>
</tr>
<tr class="calibre16">
<td class="calibre12">
<p class="calibre13">Class 3</p>
</td>
<td class="calibre12">
<p class="calibre13">119 survived and 372 died</p>
</td>
<td class="calibre12">
<p class="calibre13">24%</p>
</td>
</tr>
</tbody>
</table>


            

            
        
    </div>



  
<div><h1 class="header-title">Data developer</h1>
                
            
            
                
<p class="calibre4">How does the preceding example compare to a data or database developer? What might be a relatable example?</p>
<p class="calibre4">Starting from the top, suppose you are in charge of a database owned by a gaming company. The company purchases and places various slot-type gaming machines on the floors of their casinos and clubs.</p>
<p>Slot machines are a type of casino gambling machine with three or more reels, which spin when a button is pushed. The machine is worked by the insertion of a coin.</p>
<p class="calibre4">The database contains many useful variables for each slot-type gaming machine:</p>
<ul class="calibre18">
<li class="calibre19"><strong class="calibre3">Theme</strong>: Traditional slot machines featured fruit and bars as symbols, but themes are becoming the predominant feature of slot machine games</li>
<li class="calibre19"><strong class="calibre3">Denomination</strong>: Five cents, 10 cents, 25 cents, 50 cents, and so on</li>
<li class="calibre19"><strong class="calibre3">Payout</strong> <strong class="calibre3">frequency</strong>: Loose, medium, or tight</li>
<li class="calibre19"><strong class="calibre3">Player position</strong>: Low-level or upright</li>
<li class="calibre19"><strong class="calibre3">Reel type</strong>: Mechanical or virtual</li>
<li class="calibre19"><strong class="calibre3">Number of players</strong>: Standalone or community</li>
</ul>
<p class="calibre4">Here, our challenge is to predict whether a particular machine will be a popular machine for the gaming company or not, based on the machine's characteristics, or known variables.</p>
<p class="calibre4">In the R example, the data scientist was fortunate enough to have a data file provided. As a data or database developer, though, we're usually not that lucky, although this really isn't such a big deal.</p>
<p class="calibre4">Knowing the data structures/database model (as we discussed at the start of this chapter), the data developer can construct appropriate SQL queries to locate the data we might be interested in for our project (some refer to this process as mining the data).</p>
<p>Data mining is the process of discovering patterns in data involving methods at the intersection of artificial intelligence, machine learning, statistics, and database systems.</p>
<p class="calibre4">Additionally, once the data has been located within the database, it is a routine matter to write the information to a CSV text file to be consumed by our statistical project:</p>
<pre class="calibre29">select * into outfile 'd:/report.csv' fields terminated by ',' from tableName;</pre>
<p class="calibre4">But in fact, the data developer might actually go as far as performing the data analyses, variable review, and feature selection on the data while the data is still in the database; that way, once the strongest predictors are identified, others (considered to be perhaps noise in the context of our challenge) would not have to be extracted into our file. This saves time and makes the data perhaps a bit more manageable.</p>
<div><em class="calibre20">Noise</em> was covered in <a href="d114349e-1538-42d5-b9a6-939081494991.xhtml" target="_blank" class="pcalibre pcalibre3 pcalibre1 calibre8 pcalibre2">Chapter 10</a>, <em class="calibre20">Boosting and Your Database</em>.</div>


            

            
        
    </div>



  
<div><h1 class="header-title">Understanding the challenge</h1>
                
            
            
                
<p class="calibre4">After fully understanding the challenge at hand, perhaps we have come to know that if a gaming machine type has an average coin-in (the total dollar amount of the coins played on a slot machine) value of more than ten thousand dollars per day, it is considered by the organization to be a popular gaming machine.</p>
<p class="calibre4">With this information in mind, we can construct a query (or most likely, several) designed to calculate and pull this variable's amount for each of our machine observations.</p>
<p class="calibre4">At that point, we would have data with observations (records) for each machine in service by the company, along with a list of each machine's characteristics (the variables we want to examine), as well as the determined result (popular or not).</p>
<p class="calibre4">Sound familiar? It should!</p>
<p class="calibre4">Suppose in our database example we see that denomination is the strongest predictor of whether a gaming machine is a popular machine or not:</p>
<table class="calibre9">
<tbody class="calibre10">
<tr class="calibre11">
<td class="calibre12">
<p class="calibre13"><strong class="calibre7">Denomination</strong></p>
</td>
<td class="calibre12">
<p class="calibre13"><strong class="calibre7">Outcome/average coin-in value</strong></p>
</td>
<td class="calibre12">
<p class="calibre13"><strong class="calibre7">Popular</strong></p>
</td>
</tr>
<tr class="calibre15">
<td class="calibre12">
<p class="calibre13">10 cents</p>
</td>
<td class="calibre12">
<p class="calibre13">$7,500</p>
</td>
<td class="calibre12">
<p class="calibre13">No</p>
</td>
</tr>
<tr class="calibre11">
<td class="calibre12">
<p class="calibre13">25 cents</p>
</td>
<td class="calibre12">
<p class="calibre13">$18,000</p>
</td>
<td class="calibre12">
<p class="calibre13">Yes</p>
</td>
</tr>
<tr class="calibre16">
<td class="calibre12">
<p class="calibre13">50 cents</p>
</td>
<td class="calibre12">
<p class="calibre13">$9,000</p>
</td>
<td class="calibre12">
<p class="calibre13">No</p>
</td>
</tr>
</tbody>
</table>
<p class="calibre4">We can see from the comparison of these examples that there are plenty of opportunities for data developers to locate and use information stored within databases as input to statistical models.</p>


            

            
        
    </div>



  
<div><h1 class="header-title">Cross-tabbing and plotting</h1>
                
            
            
                
<p class="calibre4">We previously stated that crosstabs were used to show the interactions between two variables in a very easy to read format. To look at the crosstabs between <kbd class="calibre22">Survived</kbd> and each other variable, the R function table was used.</p>
<p class="calibre4">Data developers have a similar tool, PIVOT. PIVOT is one of the new relational operators introduced in SQL Server 2005. It provides an easy mechanism in SQL Server to transform rows into columns.</p>
<p class="calibre4">The R example we are focusing on here also used <em class="calibre21">box plot visualizations</em> to identify continuous variables within the data. Although native SQL doesn't really provide us with plotting abilities, the data developer might consider leveraging something like <strong class="calibre7">SQL</strong> <strong class="calibre7">Server Reporting Services</strong> (<strong class="calibre7">SSRS</strong>) to plot the data mined from the database; however, since the next phase will require us to create a classification model, I would suggest leveraging the visualization power of R to create our charts and graphs.</p>
<p class="calibre4">There is an excellent resource online that is worthy of the reader's time, and deals with the topic <em class="calibre21">Create graphs and plots using SQL and R (walkthrough)</em>:</p>
<p class="calibre4"><a href="https://docs.microsoft.com/en-us/sql/advanced-analytics/tutorials/walkthrough-create-graphs-and-plots-using-r" target="_blank" class="pcalibre pcalibre3 pcalibre1 calibre8 pcalibre2">https://docs.microsoft.com/en-us/sql/advanced-analytics/tutorials/walkthrough-create-graphs-and-plots-using-r</a></p>
<p class="calibre4">At this point, you can move on to the learning, evaluation, and deployment phases we discussed earlier.</p>


            

            
        
    </div>



  
<div><h1 class="header-title">Summary</h1>
                
            
            
                
<p class="calibre4">In this chapter, we started out by reviewing the idea of data structures, data models, and databases, and found similarities and differences between them.</p>
<p class="calibre4">Next, we provided an overview of machine learning and related concepts, and then compared the practice of a machine learning statistical project to a database development project.</p>
<p class="calibre4">Finally, we touched on a conceptual use of R and applying machine learning techniques to data from a database.</p>
<p class="calibre4">As this book was aimed at helping the typical data or database developer transition into the world of statistics, we hope the reader has established a sound understanding of the relevant topics in statistics and data science.</p>
<p class="calibre4">Good luck!</p>
<p class="calibre4"> </p>
<p class="calibre4"> </p>


            

            
        
    </div>



  </body></html>