- en: Databases and Neural Networks
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this chapter, we will look at and define **Artificial Neural Network** (**ANN**)
    and draw data from a data developer's knowledge of data, databases, and data models
    to help him or she understand the purpose and use of neural networks, and why
    neural networks are so significant to data science and statistics.
  prefs: []
  type: TYPE_NORMAL
- en: 'We have organized the information in this chapter into the following key areas:'
  prefs: []
  type: TYPE_NORMAL
- en: Definition of a neural network
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Relating a neural network model to a database model
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Looking at R-based neural networks
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Use cases
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Ask any data scientist
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Today, if you ask any data scientist about the statistical methods, (or even
    a few) you will most likely discover that there are two most well-known statistical
    methods used within the practice of data science and the statistics industry today
    for predictive modeling. We introduced these two methods in [Chapter 6](8a0b3272-dfa0-46ca-9e90-f6050f2007cd.xhtml)*,
    Database Progression to Database Regression*.
  prefs: []
  type: TYPE_NORMAL
- en: 'These two methods are as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: Linear regression
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Logistic regression
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The **linear regression** method is probably considered to be the *classic*
    or most common starting point for problems, where the goal is to predict a numerical
    quantity. The **Linear Regression** (or **LR**) model is based on a linear combination
    of input features.
  prefs: []
  type: TYPE_NORMAL
- en: The **logistic regression** method uses a nonlinear transformation of this linear
    feature combination in order to restrict the range of the output in the interval
    [0, 1]. In doing so, it predicts the probability that the output belongs to one
    of two classes. Thus, it is a very well-known technique for classification.
  prefs: []
  type: TYPE_NORMAL
- en: Recall that classification is the process of recognizing to which set of categories
    (or sub-populations) a new or different observation belongs, on the basis of a
    training set of data.
  prefs: []
  type: TYPE_NORMAL
- en: Both of these methods have their individual strengths, but both also share the
    same disadvantage in that they are not very good at predicting if they have to
    deal with the situation of a high volume of input features.
  prefs: []
  type: TYPE_NORMAL
- en: In this chapter (as an alternative to linear and logistic regression), we want
    to introduce the concept of ANNs, which is technically a nonlinear approach to
    solving both regression and classification problems.
  prefs: []
  type: TYPE_NORMAL
- en: They (ANNs) are significantly more robust when dealing with a higher dimensional
    input feature space and, for classification, they possess a **natural** way to
    handle more than two output classes. We'll talk more about the advantages of  ANNs
    later in this chapter.
  prefs: []
  type: TYPE_NORMAL
- en: Artificial neural networks are a **biologically inspired** statistical method
    or model (based on the structure and functions of biological neural networks),
    with their roots dating all the way back to the 1940s.
  prefs: []
  type: TYPE_NORMAL
- en: 'Another interesting viewpoint:'
  prefs: []
  type: TYPE_NORMAL
- en: Neural Networks are a machine learning framework that attempts to mimic the
    learning pattern of natural biological neural networks.
  prefs: []
  type: TYPE_NORMAL
- en: '- Jose Portilla, Udemy Data Science Instructor.'
  prefs: []
  type: TYPE_NORMAL
- en: Interest in artificial neural networks has varied greatly since then--mostly
    because the first artificial neural network models were very rudimentary and therefore
    found to be limited in practice compared to the expectations at the time.
  prefs: []
  type: TYPE_NORMAL
- en: Neural networks have not always been popular, partly because they were, and
    still are in some cases, computationally expensive and partly because they did
    not seem to yield better results when compared with simpler methods such as **support
    vector machines** (**SVMs**). Nevertheless, neural networks have, once again,
    raised attention and become popular.
  prefs: []
  type: TYPE_NORMAL
- en: -Michy Alice, September 2015.
  prefs: []
  type: TYPE_NORMAL
- en: Furthermore, training a large artificial neural network does necessitate substantial
    computational resources. Recently, there has been a huge resurgence in the interest
    in artificial neural networks as distributed on-demand computing resources are
    now becoming widespread, and an important area of machine learning, known as **deep
    learning**, is already extremely popular and showing great promise.
  prefs: []
  type: TYPE_NORMAL
- en: The timing is right!
  prefs: []
  type: TYPE_NORMAL
- en: For this reason, it is a great time for a data developer to begin learning about ANNs
    models.
  prefs: []
  type: TYPE_NORMAL
- en: Deep learning (also known as **deep structured learning**, **hierarchical learning**,
    or **deep machine learning**) is a class of machine learning algorithms that use
    a cascade of many layers of nonlinear processing units for feature extraction
    and transformation ([en.wikipedia.org/wiki/Deep_learning](https://en.wikipedia.org/wiki/Deep_learning)).
  prefs: []
  type: TYPE_NORMAL
- en: Let's get started!
  prefs: []
  type: TYPE_NORMAL
- en: Defining neural network
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Our approach is to always start with a solid definition. So--what exactly is
    an artificial neural network? Perhaps:'
  prefs: []
  type: TYPE_NORMAL
- en: A computer system modeled on the human brain and nervous system.
  prefs: []
  type: TYPE_NORMAL
- en: 'A popular understanding or, if we check online for a definition:'
  prefs: []
  type: TYPE_NORMAL
- en: '*In machine learning and cognitive science, artificial neural networks (ANNs)
    are a family of models inspired by biological neural networks (the central nervous
    systems of animals, in particular, the brain) and are used to estimate or approximate
    functions that can depend on a large number of inputs and are generally unknown.*'
  prefs: []
  type: TYPE_NORMAL
- en: So there are many definitions, but in summarization, the common theme through
    all of the definitions you'll find for an  ANNs is that it is defined as a computer
    data model based upon the concepts of how a human brain works.
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/12fda3d1-48fb-47aa-87ad-2d26010bf6b6.jpg)'
  prefs: []
  type: TYPE_IMG
- en: ANN model representation
  prefs: []
  type: TYPE_NORMAL
- en: 'As the preceding screenshot suggests, the construction of a typical artificial
    neural network is based on some number of the following:'
  prefs: []
  type: TYPE_NORMAL
- en: Nodes
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Layers
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Connections
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Nodes
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Each of the layers is made up of a number of interconnected nodes--each node
    containing what is referred to as an **activation function**.
  prefs: []
  type: TYPE_NORMAL
- en: There will be at least one node in the input layer for each predictor variable
    that exists within the data. The input nodes feed the input values (the **problem
    to be solved**) to each of the nodes in the (next) hidden layer.
  prefs: []
  type: TYPE_NORMAL
- en: The input(s) to each node are summed to give a single value, *x*. This is then
    inputted to the node's activation function, and the output of the node is the
    output of its activation function, *f*(*x*).
  prefs: []
  type: TYPE_NORMAL
- en: There are a number of functions that can be used in artificial neural network
    nodes, including the radial basis function or a simple linear function, but the
    most common is the sigmoid or logistic function.
  prefs: []
  type: TYPE_NORMAL
- en: A sigmoid function is typically the most common and perhaps easiest to understand.
    The sigmoid function is a mathematical function having a characteristic S-shaped
    curve or sigmoid curve. Sigmoid functions have a domain of all real numbers, with
    the return value monotonically increasing most often from 0 to 1 or alternatively
    from −1 to 1, depending on convention. ([https://en.wikipedia.org/wiki/Sigmoid_function](https://en.wikipedia.org/wiki/Sigmoid_function))
  prefs: []
  type: TYPE_NORMAL
- en: The nodes within an artificial neural network will always produce or calculate
    a value between 0 and 1, so the output of a node can only ever be in the collection
    0 to 1.
  prefs: []
  type: TYPE_NORMAL
- en: Layers
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The **layer** is a universal term used to define a collection of **nodes** operating
    together at a specific depth within an artificial neural network.
  prefs: []
  type: TYPE_NORMAL
- en: Hidden layers will have a variable number of nodes (determined by the training
    algorithm used). Each of those nodes will contain numerous functions with logic
    to process the inputs and calculate a result. The resulting value is then passed
    to the next layer.
  prefs: []
  type: TYPE_NORMAL
- en: 'The layer summary is as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Input layer**: This contains your data, with one node per variable'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Hidden layer(s)**: Each layer attempts to learn a different aspect about
    your data by minimizing an error/cost function'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Output layer**: This is the simplest layer, usually consisting of a single
    output for classification problems'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Training
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Recalling from the previous section describing artificial neural network nodes,
    if all the nodes work the same way or, at least produce the same result (0 or
    1), how does the network differentiate between classes?
  prefs: []
  type: TYPE_NORMAL
- en: It uses assigned weights to each node's inputs. This is a feature (or variable
    in the data) that can have a large or small weighting, which then results in varying
    the contribution that the variable or feature makes to the *sum* in any node.
  prefs: []
  type: TYPE_NORMAL
- en: In practice, a variable can be assigned a large weight feeding into one node
    and an almost zero weight feeding into another node, which would mean that the
    variable would have a strong influence on the first and practically none on the
    second.
  prefs: []
  type: TYPE_NORMAL
- en: The sigmoid function (which we also mentioned in the previous section) indicates
    that the node's output switches from a zero to a one when its *x* value crosses
    a threshold. This can transpire in numerous ways, such as if one highly weighted
    input has a high value or if a collection of medium-weighted inputs have high
    values.
  prefs: []
  type: TYPE_NORMAL
- en: Training the artificial neural network is the process of systematically discovering
    the best values of weights to maximize the accurateness of classification.
  prefs: []
  type: TYPE_NORMAL
- en: Solution
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The value coming out of a node in the hidden layer is multiplied by a weight
    associated with the node that did the calculation and adds to the weighted values
    of other nodes. This summation becomes the artificial neural network model's output
    or solution. (Observe that the term used for this varies between data scientists,
    some say output, others solution, result, or even outcome).
  prefs: []
  type: TYPE_NORMAL
- en: Again, the problems are presented to the artificial neural network (through
    the model's input layer), which will communicate to one or (most likely) more
    hidden layers where the actual processing is done via a system of weighted connections.
    The hidden layers then link to an output layer where the solution is given.
  prefs: []
  type: TYPE_NORMAL
- en: Most artificial neural network models contain some form of an algorithm that
    governs how the model **learns**. This is the algorithm that we discussed earlier
    as the process that **adjusts the weights** of the node connections according
    to the (input) problems that have been submitted to it.
  prefs: []
  type: TYPE_NORMAL
- en: This **adjusting of the node's weights** (some call **right-regulating**) is
    similar to the idea of learning to recognize an image (or **determining a solution**)
    based on experience (in this case, the experience might be reviewing example after
    example).
  prefs: []
  type: TYPE_NORMAL
- en: Understanding the concepts
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: To gain an understanding of a new concept, it always helps to draw similarities
    between the familiar and the new.
  prefs: []
  type: TYPE_NORMAL
- en: To that point, to better comprehend the notion of artificial neural networks,
    it would be helpful for us to compare the concepts of ANNs to how a conventional
    database algorithm processes data and information (or how it works).
  prefs: []
  type: TYPE_NORMAL
- en: In the next section, we will compare concepts concerning artificial neural network
    models to those of common data or database models.
  prefs: []
  type: TYPE_NORMAL
- en: Neural network models and database models
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: As we noted in the previous section of this chapter, neural network models are
    a **system of processing nodes**, interconnected across layers that do not process
    data in a sequential manner. How does this scheme compare to a conventional database model or
    program?
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/2370e20b-d11c-4195-a1c3-82bfa4fe1780.png)'
  prefs: []
  type: TYPE_IMG
- en: A conventional database model representation
  prefs: []
  type: TYPE_NORMAL
- en: As we noted in the previous section of this chapter, neural network models are
    a **system of processing nodes**, interconnected across layers that do not process
    data in a sequential manner. How does this scheme compare to a conventional database
    model or program?
  prefs: []
  type: TYPE_NORMAL
- en: In the technology industry, a conventional (database) model is sometimes called
    a **serial processing component**, which means that this type of model has a central
    processing unit or CPU (perhaps you can think of this as a large, central *processing
    node*) that accesses raw data and instructions (already stored in memory).
  prefs: []
  type: TYPE_NORMAL
- en: In a conventional database model, the central processor carries out calculations
    or logic (an algorithm) on input or selected data, stores the calculated results
    (in a specified memory location), then goes on to the next instruction (and data),
    and so on—until a solution or result is reached.
  prefs: []
  type: TYPE_NORMAL
- en: 'This idea is somewhat analogous to the concept of a solitary processing *stream* within
    a neural network:'
  prefs: []
  type: TYPE_NORMAL
- en: A node accepts or consumes data
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: A node applies logic
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: A node outputs its results
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Similar, but keep in mind that conventional database models are serial in that
    they perform each task (or instruction) in a linear, or one after the other, fashion,
    while multiple node streams within an artificial neural network model perform
    tasks in parallel.
  prefs: []
  type: TYPE_NORMAL
- en: So, in a serial system, the computational steps are deterministic, sequential,
    and logical, and the state of a given variable can be tracked from one operation
    to another. In comparison, ANNs are not sequential or necessarily deterministic.
  prefs: []
  type: TYPE_NORMAL
- en: There are other key differences, which include the following notions which are
    explained in the following sub-sections.
  prefs: []
  type: TYPE_NORMAL
- en: No single or main node
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Rather than a single, complex central processor (or node), there are many simple
    nodes--which generally do nothing more than taking the weighted sum of their inputs
    from other nodes.
  prefs: []
  type: TYPE_NORMAL
- en: Not serial
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: ANNs do not execute programmed instructions linearly or serially; they respond
    in parallel (either simulated or actual) to the inputs presented to them.
  prefs: []
  type: TYPE_NORMAL
- en: No memory address to store results
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: There are also no separate memory addresses to store data within an artificial
    neural network model.
  prefs: []
  type: TYPE_NORMAL
- en: Instead, information is contained in the overall activation *state* of the model.
    **Knowledge** is therefore represented by the artificial neural network model
    itself, which is quite literally more than the sum of its individual components.
  prefs: []
  type: TYPE_NORMAL
- en: As a final point, for the data developer, the notion of an artificial neural
    network might be imagined as **kicking-off** and running multiple SQL queries
    asynchronously. Imagine creating a SQL **DTS** (**Data Transformation Services**)
    or **SQL Server Integration Services** (**SSIS**) package with a simple branching
    task flow so that DTS will launch tasks in individual **spids** (**Server Process
    ID**). Each of the spids then would align to the idea of a neural network node
    stream, all working in parallel to create a result or solution.
  prefs: []
  type: TYPE_NORMAL
- en: A very good explanation of how a neural network works--using a data developer-type
    practical example—can be found online authored by Sunil Ray.
  prefs: []
  type: TYPE_NORMAL
- en: 'Understanding and coding Neural Networks from Scratch in Python and R, which,
    as of writing this, can be found at [www.analyticsvidhya.com](http://www.analyticsvidhya.com)
    under: [/blog/2017/05/neural-network-from-scratch-in-python-and-r](https://www.analyticsvidhya.com/blog/2017/05/neural-network-from-scratch-in-python-and-r/).'
  prefs: []
  type: TYPE_NORMAL
- en: 'He terms the following quote:'
  prefs: []
  type: TYPE_NORMAL
- en: '*"If you have been a developer or seen one work you know how it is to search
    for bugs in a code. You would fire various test cases by varying the inputs or
    circumstances and look for the output. The change in output provides you a hint
    on where to look for the bug--which module to check, which lines to read. Once
    you find it, you make the changes and the exercise continues until you have the
    right code/application.*'
  prefs: []
  type: TYPE_NORMAL
- en: '*Neural networks work in very similar manner. It takes several input, processes
    it through multiple neurons from multiple hidden layers and returns the result
    using an output layer. This result estimation process is technically known as
    **Forward Propagation**.*'
  prefs: []
  type: TYPE_NORMAL
- en: '*Next, we compare the result with actual output. The task is to make the output
    to neural network as close to actual (desired) output. Each of these neurons are
    contributing some error to final output. How do you reduce the error?*'
  prefs: []
  type: TYPE_NORMAL
- en: '*We try to minimize the value/ weight of neurons those are contributing more
    to the error and this happens while traveling back to the neurons of the neural
    network and finding where the error lies. This process is known as **Backward
    Propagation**."*'
  prefs: []
  type: TYPE_NORMAL
- en: Okay, that was a lot to take in--but now that we, with any luck, have a respectable
    understanding of what an artificial neural network is and how it works, let's
    look at ANNs and the R programming language.
  prefs: []
  type: TYPE_NORMAL
- en: R-based neural networks
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Now that we know a bit about how artificial neural networks work, let's review
    some fundamental information on how to implement one with the R programming language.
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/0798f4c1-d3a5-4031-966e-cb4336004936.png)'
  prefs: []
  type: TYPE_IMG
- en: R-based ANN packages
  prefs: []
  type: TYPE_NORMAL
- en: The idea here is not to give a detailed step-by-step instruction manual on how
    to create an intricate and powerful ANN, but more to show how one can easily create
    an ANN model using R—with literally only basic R skills or experience.
  prefs: []
  type: TYPE_NORMAL
- en: References
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Yes, you will find that there is plenty of respectable, easy-to-understand,
    and valuable information and examples on artificial neural networks generously
    obtainable on the internet.
  prefs: []
  type: TYPE_NORMAL
- en: One such resource is offered by Gekko Quant ([http://gekkoquant.com/author/gekkoquant/](http://gekkoquant.com/author/gekkoquant/)) and
    is worth taking some time to locate and read.
  prefs: []
  type: TYPE_NORMAL
- en: This information offers a very nice tutorial that produces an artificial neural
    network that takes a single input (a number that you want to calculate a square
    root for) and produces a single output (the square root of the number input).
  prefs: []
  type: TYPE_NORMAL
- en: 'The output of this artificial neural network example model is nicely displayed
    in an easy-to-understand format and I''ll show it here as a great example of how
    the results of an ANN model should look:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/1cb8d94b-329a-4072-b8b4-4d4c41afd8f4.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Results of an ANN
  prefs: []
  type: TYPE_NORMAL
- en: From the output information shown here, you can see (as the author declares)
    that the neural network does a reasonable job at finding the square root (of each
    input number).
  prefs: []
  type: TYPE_NORMAL
- en: Before a data scientist can begin the process of fitting an artificial neural
    network, some important time-saving groundwork needs to be accomplished, which
    we'll discuss in the next few sections.
  prefs: []
  type: TYPE_NORMAL
- en: To be sure, artificial neural networks are not easy to understand, train, and
    tune; some preparatory or preprocessing first is strongly recommended.
  prefs: []
  type: TYPE_NORMAL
- en: Data prep and preprocessing
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Let's start with the obvious—our data!
  prefs: []
  type: TYPE_NORMAL
- en: The more experience a data scientist gains with working with ANN models, the
    more he or she will come to understand the importance of formally reviewing and
    preparing the data ahead of he or she can begin attempting to train or fit the
    model.
  prefs: []
  type: TYPE_NORMAL
- en: We discussed data cleaning in [Chapter 3](01c3daac-ead5-44c1-b17b-d49862f3067d.xhtml)*, 
    A Developer Approach to Data Cleaning,* so you should have a good understanding
    of the importance of and the process of data cleaning and cleansing at this point,
    so we'll focus here on some data preparation efforts more specific to our topic
    of artificial neural network models.
  prefs: []
  type: TYPE_NORMAL
- en: It is a popular opinion among data scientists that it may be good practice to
    normalize your data before training an artificial neural network on it. Depending
    on your data, not performing any data normalization may lead to unusable results
    or at least to a very difficult training process; most of the time, the algorithm
    will not converge before the number of maximum iterations allowed--in other words,
    it runs out of attempts!
  prefs: []
  type: TYPE_NORMAL
- en: Based on industry experience, the artificial neural network may have difficulty
    converging before the maximum number of iterations allowed if the data is not
    normalized.
  prefs: []
  type: TYPE_NORMAL
- en: Although there are numerous and diverse methods to accomplish normalization
    or normalizing of your data, one of the most universally used is the R built-in `scale()`
    function, which can easily accomplish this task.
  prefs: []
  type: TYPE_NORMAL
- en: The scale function is a generic R function whose default method centers and/or
    scales (normalized) the columns of a numeric matrix for you.
  prefs: []
  type: TYPE_NORMAL
- en: I like the following scale example using simple R code statements because it
    makes it obvious that the scale function works correctly (as expected?) and is
    a lot more effective than attempting to perform *manual* scaling, that is, writing
    the R code statements to scale the values.
  prefs: []
  type: TYPE_NORMAL
- en: 'Take a quick look:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: 'Finally, here is the output, showing the same results produced out of both
    the manual scale approach as well as out of the scale function:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/6b7c3f65-d1bc-41a9-a137-a6da235050b3.png)'
  prefs: []
  type: TYPE_IMG
- en: Awesome!
  prefs: []
  type: TYPE_NORMAL
- en: Data splitting
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The next step in our preprocessing is *splitting the data*. We covered data
    *splitting* in detail in [Chapter 8](29276841-ef5a-4a37-bd4b-ff17f364a93a.xhtml),
    *Database Development and Assessment*, so we won't revisit the topic here.
  prefs: []
  type: TYPE_NORMAL
- en: However, recall that the process of data splitting will have the objective of
    creating both a training subset of data as well as a testing subset of data, from
    the original dataset or source (based on appropriate logic).
  prefs: []
  type: TYPE_NORMAL
- en: For example, we could accomplish our data split by *randomly* splitting the
    data into a train and a test set, then fit a linear regression model and test
    it on the test dataset (or use the split method we used in the last chapter, to
    create a 70/30 split of our data).
  prefs: []
  type: TYPE_NORMAL
- en: Model parameters
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: There is no best practice or recommended rule or policy that will tell the data
    scientist how many layers and/or nodes to use (although there are several more
    or less industry--accepted rules) in an artificial neural network model.
  prefs: []
  type: TYPE_NORMAL
- en: Customarily, if at all necessary, one hidden layer is enough for most or, a
    vast number of, artificial neural network statistical applications (although you
    may have observed that we showed three hidden layers in our graphical image at
    the beginning of this chapter).
  prefs: []
  type: TYPE_NORMAL
- en: As far as the number of nodes, the number should frequently be between the input
    layer size and the output layer size, usually 2/3 of the input size.
  prefs: []
  type: TYPE_NORMAL
- en: Bottom line—when the data scientist is determining the number of layers and
    nodes to have in his or her artificial neural network model, they will test, test,
    and test again (and again and again) to find the best or most optimal solution
    to meet the current requirements, as there is no guarantee that any past experience
    or *rules* will fit your statistical model best.
  prefs: []
  type: TYPE_NORMAL
- en: Cross-validation
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: '**Cross-validation** is an important topic that we introduced in [Chapter 2](5f479943-b0ab-4276-b173-c571647b1c5c.xhtml)*,
    Declaring the Objectives*, and again we recall that it IS a very important step
    in building any predictive model.'
  prefs: []
  type: TYPE_NORMAL
- en: 'While there are many different kinds of cross-validation methods, the basic
    idea is a data scientist repeating the following process a number of times:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Train me, test me, split me**:'
  prefs: []
  type: TYPE_NORMAL
- en: Do the train-test split.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Fit the model to the train set.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Test the model on the test set.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Calculate and review the prediction error.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Repeat (*n* number of times).
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: By conducting the preceding process a number of times, the data scientist will
    then be able to calculate the average error that is then used to assess how the
    statistical model is performing (performance is another important topic, one which
    we discussed in [Chapter 8](29276841-ef5a-4a37-bd4b-ff17f364a93a.xhtml)*, Database
    Development and Assessment*).
  prefs: []
  type: TYPE_NORMAL
- en: R packages for ANN development
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: So, how can a data scientist create his or her own **artificial neural network**
    (**ANN**)?
  prefs: []
  type: TYPE_NORMAL
- en: The R programming language provides (as of writing this) a nice variety of packages
    to create various types of artificial neural networks. These packages currently
    include the following.
  prefs: []
  type: TYPE_NORMAL
- en: ANN
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: This package provides a feed-forward artificial neural network optimized by
    **genetic algorithm** (**GA**).
  prefs: []
  type: TYPE_NORMAL
- en: ANN2
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: This provides the training of general classification and regression neural networks
    using gradient descent.
  prefs: []
  type: TYPE_NORMAL
- en: NNET
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The package NNET created by Ripley provides methods to use feedforward neural
    networks with a single hidden layer and for multinomial log-linear models. Specifically,
    this chapter of the book will portray the NNET method. Here, we have briefly described
    the method and parameters used.
  prefs: []
  type: TYPE_NORMAL
- en: 'Note that I am splitting the data in this way: 90% train set and 10% test set
    in a random way for 10 times.'
  prefs: []
  type: TYPE_NORMAL
- en: I am also initializing a progress bar using the `plyr` library because I want
    to keep an eye on the status of the process as the fitting of the neural network
    may take a while.
  prefs: []
  type: TYPE_NORMAL
- en: Black boxes
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: ANNs can be very challenging to comprehend (even for the most advanced or seasoned
    data scientist). Explaining their outcome (or results) is much more demanding
    than explaining the outcome of a simpler model such as a linear model.
  prefs: []
  type: TYPE_NORMAL
- en: Sometimes, data scientists will understand an artificial neural network model
    at only a very high level. Although one can have only this level of understanding
    and still be able to be productive, not fully understanding the interworkings
    of artificial neural network models can result in a situation referred to as a
    **BBU** model or **black box understood model** or method.
  prefs: []
  type: TYPE_NORMAL
- en: A black box model, method, or system is one that can be viewed in terms of its
    inputs and outputs, without any knowledge of its internal workings.
  prefs: []
  type: TYPE_NORMAL
- en: Consequently, depending on the kind of application you need, you might want
    to keep in mind that you will have to properly explain the results of the model
    (not just run the model and producing a result) before the results can be useful,
    and therefore invest the time in gaining a proper, detailed understanding of the
    model and methods being used.
  prefs: []
  type: TYPE_NORMAL
- en: A use case
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'It has been said (most likely not by a data scientist!) that:'
  prefs: []
  type: TYPE_NORMAL
- en: '*A neural network model cannot learn anything that a reasonably intelligent
    human could not learn given enough time from the same data.*'
  prefs: []
  type: TYPE_NORMAL
- en: The key term in this statement is enough time. Data scientists (and human beings
    in general) almost never, ever have the luxury of enough time--and time may be
    the difference between your organization's success and the competition.
  prefs: []
  type: TYPE_NORMAL
- en: 'In defense of using artificial neural networks (rather than a *reasonably intelligent*
    human) are some of the following additional advantages of artificial neural network
    models:'
  prefs: []
  type: TYPE_NORMAL
- en: Make discoveries no one has even imagined yet
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Find solutions in much less time than even a team of people
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Produce results at a much lower cost
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Produce consistent results with the inputs they've been trained on and should
    generalize well if tweaked properly
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: NNs never get bored or distracted
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: With all of these advantages, let's consider some practical use case scenarios
    for artificial neural network models.
  prefs: []
  type: TYPE_NORMAL
- en: Popular use cases
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: There are many uses for artificial neural networks. Surveying the industry,
    the most established artificial neural network use cases are the following applications.
  prefs: []
  type: TYPE_NORMAL
- en: Character recognition
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Neural networks can be used to recognize handwritten characters, converting
    handwriting in real time to control a computer or for **automatic number-plate
    recognition** (**ANPR)** to automatically read vehicle registration plates.
  prefs: []
  type: TYPE_NORMAL
- en: Image compression
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Neural networks can receive and process enormous amounts of information at once,
    making them useful in image compression. With the explosion of big data, applying
    ANN to digital images in order to reduce their cost for storage or transmission
    is a growing opportunity.
  prefs: []
  type: TYPE_NORMAL
- en: Stock market prediction
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The real-time movements of the stock market are extremely complicated due to
    the influence of a large number of factors. Many factors weigh in like high, low,
    open and close price, volume, the price of other securities as well as economic
    indicators. As neural networks can scrutinize large amounts of information rapidly,
    they can be used to predict stock prices.
  prefs: []
  type: TYPE_NORMAL
- en: Fraud detection
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In recent years, the development of new technologies has also provided further
    ways in which criminals may commit fraud. Neural networks can learn suspicious
    patterns from samples to detect approximate classes, clusters, or patterns of
    suspicious behaviour and use them later to detect frauds.
  prefs: []
  type: TYPE_NORMAL
- en: Neuroscience
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Theoretical and computational neuroscience is the study of theoretical analysis
    and the computational modeling of biological neural systems. As neural systems
    attempt to replicate cognitive processes and behaviour, the field is closely related
    to cognitive and behavioural modeling.
  prefs: []
  type: TYPE_NORMAL
- en: Summary
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this chapter, we defined neural networks and, from a data developer's knowledge
    of databases and data models, grew to understand the purpose and use of neural
    networks and why neural networks are so important to data science. We also looked
    at an R-based ANN and listed some popular use case examples.
  prefs: []
  type: TYPE_NORMAL
- en: In the next chapter, we will introduce the idea of using statistical boosting
    to better understand data in a database.
  prefs: []
  type: TYPE_NORMAL
