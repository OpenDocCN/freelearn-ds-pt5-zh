- en: An Ideal Data Science Team
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Since you are reading this book, it's likely you already understand the importance
    of teamwork. You can complete a complex project with a team more efficiently than
    in isolation. Of course, one person can build a house alone, but by working with
    others, they will finish the house faster, and the result will be better.
  prefs: []
  type: TYPE_NORMAL
- en: When you work with a team, everyone can specialize in performing several closely-related
    types of work. To explore different specialties, let's look at an example of how
    houses are built. Building a roof requires one set of skills, while setting up
    electricity is completely different. As a manager, you need to have a basic understanding
    of all specialties, so as to understand all components necessary for completing
    a task. In the *What is Data Science?* section, you were introduced to the central
    concepts of data science. Then, we will use this knowledge to derive roles and
    specialties in a data science team. In this chapter, we will define, explore,
    and understand different team roles as well as each role's key skills and responsibilities.
    We will also look at two case studies.
  prefs: []
  type: TYPE_NORMAL
- en: 'In this chapter, we will cover the following topics:'
  prefs: []
  type: TYPE_NORMAL
- en: Defining data science team roles
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Exploring data science team roles and their responsibilities
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Defining data science team roles
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Data science teams need to deliver complex projects where system analysis, software
    engineering, data engineering, and data science are used to deliver the final
    solution. In this section, we will explore the main data science project roles.
    The project role depicts a set of related activities that can be performed by
    an expert. Role-expert is not strictly a one-to-one correspondence, as many experts
    have the expertise to handle multiple roles at once.
  prefs: []
  type: TYPE_NORMAL
- en: An average data science team will include a business analyst, a system analyst,
    a data scientist, a data engineer, and a data science team manager. More complex
    projects may also benefit from the participation of a software architect and backend/frontend
    development teams.
  prefs: []
  type: TYPE_NORMAL
- en: 'Here are the core responsibilities of each team role:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Project stakeholders**: Represent people who are interested in the project;
    in other words, your customers. They generate and prioritize high-level requirements
    and goals for the project.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Project users**: People who will use the solution you are building. They
    should be involved in the requirements-specification process to present a practical
    view on the system''s usability.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Let''s look at the core responsibilities in the analysis team:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Business analysts**: The main business expert of the team. They help to shape
    business requirements and help data scientists to understand the details about
    the problem domain. They define business requirements in the form of a **business
    requirements document** (**BRD**), or stories, and may act as a product owner
    in agile teams.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**System analysts**: They define, shape, and maintain software and integration
    requirements. They create a **software requirements document** (**SRD**). In simple
    projects or **Proof of Concepts** (**PoC**), this role can be handled by other
    team members.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Data analysts**: Analysis in data science projects often requires building
    complex database queries and visualizing data. Data analysts can support other
    team members by creating datamarts and interactive dashboards and derive insights
    from data.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Let''s look at the core responsibilities in the datateam:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Data scientists**: They create models, perform statistical analysis, and
    handle other tasks related to data science. For most projects, it will be sufficient
    to select and apply existing algorithms. An expert who specializes in applying
    existing algorithms to solve practical problems is called a **machine** or **deep
    learning engineer**. However, some projects may ask for research and the creation
    of new state-of-the-art models. For these tasks, a machine or deep learning researcher
    will be a better fit. For those readers with computer science backgrounds, we
    can loosely describe the difference between a machine learning engineer and research
    scientist as the difference between a software engineer and a computer scientist.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Data engineers**: They handle all data preparation and data processing. In
    simple projects, data scientists with data engineering skills can handle this
    role. However, do not underestimate the importance of data engineers in projects
    with serious data processing requirements. Big data technology stacks are very
    complicated to set up and work with on a large scale, and there is no one better
    to handle this task than data engineers.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Data science team manager**: They coordinate all tasks for the data team,
    plan activities, and control deadlines.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Let''s look at the core responsibilities in the softwareteam:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Software teams** should handle all additional requirements for building mobile,
    web, and desktop applications. Depending on the ramifications, the software development
    can be handled by a single developer, a single team, or even several teams.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: In large projects that comprise multiple systems, you may need the help of a
    **software architect**.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Let''s now see the general flow of how roles can work together to build the
    final solution:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/b4d290fb-f368-4763-8a1c-9b8502e1341b.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Let''s look at the flow and delivery artifacts of each step:'
  prefs: []
  type: TYPE_NORMAL
- en: The **business** **analyst **documents business requirements based on querying
    project stakeholders and users.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: The **system analyst **documents system (technical) requirements based on business
    requirements and querying project stakeholders and users.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: The **data analyst **supports the team by creating requested datamarts and dashboards.
    They can be used by everyone on the team in the development process, as well as
    in production. If the data analyst uses a Business Intelligence tool, they can
    build dashboards directly for end users.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: The **data scientist (researcher) **uses documented requirements and raw data
    to build a model training pipeline and document data processing requirements that
    should be used to prepare training, validation, and testing datasets.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: The **data engineer **builds a production-ready data pipeline based on the prototype
    made in *Step 3*.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: The **data scientist (engineer) **uses processed data to build a production-ready
    model for training and prediction pipelines and all necessary integrations, including
    model APIs.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: The **software team **uses the complete model training and prediction pipelines
    to build the final solution.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Please note that this process can be simplified or more granular depending
    on project complexity. For example, large projects may require splitting analysis
    experts into two groups: data and software analysis. Then, the software team will
    have separate requirements documentation. Simpler projects might fuse some steps
    or roles together, or omit them.'
  prefs: []
  type: TYPE_NORMAL
- en: In the next section, we will look at how to assemble teams and assign project
    roles to experts depending on project complexity.
  prefs: []
  type: TYPE_NORMAL
- en: Exploring data science team roles and their responsibilities
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: To complete a data science project, you will need a data scientist. Can a single
    expert lead a project? To answer this question, we can break down data science
    projects into stages and tasks that are, to some extent, present in all projects.
  prefs: []
  type: TYPE_NORMAL
- en: Before starting a project, you need an idea that will allow your client to achieve
    their goals and simplify their life. In business, you will look to improve key
    business processes within a company. Sometimes, the idea is already worked out,
    and you may start directly from implementation, but more often, your team will
    be the driver of the process. So, our ideal expert must be able to come up with
    an idea of a data science project that will provide value for the client.
  prefs: []
  type: TYPE_NORMAL
- en: Next, we will study two project examples to look at how simple projects can
    be handled with small teams or even one cross-functional expert, while larger
    projects need more diverse teams, where each team member handles one or two specific
    roles.
  prefs: []
  type: TYPE_NORMAL
- en: Case study 1 – Applying machine learning to prevent fraud in banks
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: To explore what data science projects can be like, we will look at a case study.
    Mary is working as a data scientist in a bank where the fraud analysis department
    became interested in **machine learning** (**ML**). She is experienced in creating
    machine learning models and integrating them into existing systems by building
    APIs. Mary also has experience in presenting the results of her work to the customer.
  prefs: []
  type: TYPE_NORMAL
- en: One of the main activities of this department is to detect and prevent credit
    card fraud. They do this by using a rule-based, fraud detection system. This system
    looks over all credit card transactions happening in the bank and checks whether
    any series of transactions should be considered fraudulent. Each check is hardcoded
    and predetermined. They have heard that ML brings benefits over traditional, rule-based,
    fraud detection systems. So, they have asked Mary to implement a fraud detection
    model as a plugin for their existing system. Mary has inquired about the datasets
    and operators of the current fraud detection system, and the department confirmed
    that they will provide all necessary data from the system itself. The only thing
    they need is a working model, and a simple software integration. The staff were
    already familiar with common classification metrics, so they were advised to use
    F1-score with k-fold cross-validation.
  prefs: []
  type: TYPE_NORMAL
- en: 'In this project setup, project stakeholders have already finished the business
    analysis stage. They have an idea and a success criterion. Mary has clean and
    easy access to the data source from a single system, and stakeholders can define
    a task in terms of a classification problem. They have also defined a clear way
    to test the results. The software integration requirements are also simple. Thus,
    the role flow of the project is simplified to just a few steps, which are all
    performed by a single data scientist role:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/a7480602-35dc-42a7-94e1-76a59257f205.png)'
  prefs: []
  type: TYPE_IMG
- en: 'As a result, Mary has laid out the following steps to complete the tasks:'
  prefs: []
  type: TYPE_NORMAL
- en: Create a machine learning model.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Test it.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Create a model training pipeline.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Create a simple integration API.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Document and communicate the results to the customer.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: This project looks simple and well-defined. Based on this description, we can
    believe that Mary can handle it by herself, with little supervision.
  prefs: []
  type: TYPE_NORMAL
- en: Case study 2 – Finding a home for machine learning in a retail company
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Now, let's look into another case. The retail company where our friend Jonathan
    works asked him to generate ideas of how they can apply data science and analytics
    to improve their business. Jonathan worked in retail for many years, so he knows
    the business side pretty well. He has also read some books and attended several
    data science events, so he understands the practical capabilities of data science.
    With knowledge of both business and data science, Jonathan can see how data science
    can change his environment. After writing out a list of ideas, he will evaluate
    them from the business viewpoint. Projects with the lowest complexity and highest
    value will become candidates for implementation.
  prefs: []
  type: TYPE_NORMAL
- en: The retail company has over 10,000 stores across the country, and ensuring the
    proper level of service quality for all stores is becoming difficult. Each store
    has a fixed number of staff members working full-time. However, each store has
    a different number of visitors. This number depends on the geographical location
    of the store, holidays, and possibly many more unknown factors. As a result, some
    stores are overcrowded and some experience a low number of visits. Jonathan's
    idea is to change the staff employment strategy so that customer satisfaction
    will rise, and the employee burden will even out.
  prefs: []
  type: TYPE_NORMAL
- en: Instead of hiring a fixed store team, he suggests making it elastic. He wants
    to create a special mobile application that will allow stores to adjust their
    staff list with great speed. In this application, a store manager can create a
    task for a worker. The task can be as short as one hour or as long as one year. A
    pool of workers will see all vacant slots in nearby stores. If a worker with the
    necessary skills sees a task that interests them, they can accept it and go to
    the store. An algorithm will prepare task suggestions for the store manager, who
    will issue work items to the pool. This algorithm will use multiple machine learning
    models to recommend tasks. One model would forecast the expected customer demand
    for each store. The second model, a computer vision algorithm, will measure the
    length of the lines in the store. This way, each store will use the right amount
    of workforce, changing it based on demand levels. With the new app, store employees
    will be able to plan vacations and ask for a temporary replacement. Calculations
    show that this model will keep 50,000 workers with an average load of 40 hours
    per week for each worker, and a pool of 10,000 part-time workers with an average
    load of 15 hours per week. Management considered this model to be more economically
    viable and agreed to perform a test of the system in one store. If the test is
    successful, they will continue expanding the new policy.
  prefs: []
  type: TYPE_NORMAL
- en: 'The next thing they ask Jonathan is to come up with an implementation plan.
    He now needs to decompose the project into a series of tasks that are necessary
    to deploy the system in one store. Jonathan prepared the following decomposition:'
  prefs: []
  type: TYPE_NORMAL
- en: Collect and document initial requirements for the mobile app, forecasting, and
    computer vision models.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Collect and document non-functional requirements and Service Level Agreements
    for the system.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Decide on necessary hardware resources for development, testing, and production.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Find data sources with training data.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Create data adapters for exporting data from source systems.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Create a software system architecture. Choose the technology stack.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Create development, test, and production environments.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Develop a forecasting model (full ML project life cycle).
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Develop a line-length recognition model (full ML project life cycle).
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Develop a mobile app.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Integrate the mobile app with the models.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Deploy the system to the test environment and perform an end-to-end system test.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Deploy the system to the production environment.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Start the system test in one store.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Each point in this plan could be broken down further into 10-20 additional tasks.
    A full task decomposition for this project could easily include 200 points, but
    we will stop at this level, as it is sufficient for discussion purposes.
  prefs: []
  type: TYPE_NORMAL
- en: In reality, plans constantly change, so Jonathan has also decided to use a software
    development project management framework, such as SCRUM, to manage deadlines,
    requirement changes, and stakeholder expectations.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let''s now see what areas of expertise Jonathan needs to be proficient in order
    to complete this project. He needs to be adept in the following areas:'
  prefs: []
  type: TYPE_NORMAL
- en: Retail business
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Software project management
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Requirements-collection
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Software and hardware architecture
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Data engineering
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Data science
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Machine learning
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Deep learning and computer vision
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Mobile application development
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Backend software development
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Software integration
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Software testing
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Development operations
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Can Jonathan possess all those skills on a level necessary to deliver a working
    software system? We can be sure that there are a few people who can do this, but
    it is far more likely to meet an expert who knows several closely related domains.
    In particular, a data engineer is likely to be good with databases, database administration,
    and software integration. Many data scientists are also good with backend software
    development. Some are proficient in creating data visualization dashboards. In
    terms of the role flow of the project, the full diagram can be used for this project.
  prefs: []
  type: TYPE_NORMAL
- en: 'In an average data science project, expect to fill in the following team roles:'
  prefs: []
  type: TYPE_NORMAL
- en: Data scientist
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Machine or deep learning engineer
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: Machine or deep learning researcher
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: Data engineer
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Data analyst
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Systems analyst
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Business analyst
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Backend software developer
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Frontend software developer
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Technical team leader
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Project manager
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Depending on the project's complexity, you can merge some of these roles. The
    bigger your project scale, the more diverse and large your team will be. Next,
    we will look at the key skills and responsibilities of data science team roles.
  prefs: []
  type: TYPE_NORMAL
- en: Key skills of a data scientist
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: A data scientist is a relatively new profession, and vague definitions of their
    responsibilities are common. This uncertainty leads to many problems. Generic
    position descriptions on job boards are unappealing to good candidates. Professionals
    looking for a job won't be able to figure out what's required from them to get
    this position if you don't crystallize this definition in your head first. If
    someone goes to a job without knowing what is expected of them, it becomes even
    worse. Without a clear goal, or at least a clear definition, of the next milestone,
    your team will get lost. Defining clear responsibilities for team roles is the
    basis that will allow your team to function coherently.
  prefs: []
  type: TYPE_NORMAL
- en: 'An ideal data scientist is often described as a mix of the following three
    things:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Domain expertise**: This includes knowledge of an environment data scientists
    are working in, such as healthcare, retail, insurance, or finance.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Software engineering**: Even the most advanced model won''t make a difference
    if it can only present pure mathematical abstractions. Data scientists need to
    know how to shape their ideas into a usable form.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Data science**: Data scientists need to be proficient in mathematics, statistics,
    and one or more key areas of data science, such as machine learning, deep learning,
    or time series analysis.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: It is important to understand why each area of expertise is present in this
    list. We will start with the domain expertise. You are very unlikely to find a
    world-class business expert who can also train state-of-the-art deep learning
    models. The good thing is that you don't need to search for unicorns. A data scientist
    needs domain expertise mainly to understand data. It is also handy when working
    with requirements and stakeholder expectations. A basic to medium understanding
    of insurance business can help data scientists throughout the process of building
    a model.
  prefs: []
  type: TYPE_NORMAL
- en: 'For example, let''s look at how business expertise can help to build models
    for an insurance company:'
  prefs: []
  type: TYPE_NORMAL
- en: Speaking with insurance experts in the same language can help to discover their
    pain and desires, so the data scientist can adjust their goals to achieve better
    results.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Insurance expertise will help in exploring and understanding the raw data from
    the company's databases.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Insurance expertise can help in data preprocessing. It aids data scientists
    in assembling datasets for machine learning models.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Thus, domain expertise is not the prime skill for a data scientist, but a basic
    to medium level of understanding can improve results by a large margin.
  prefs: []
  type: TYPE_NORMAL
- en: The next component, software engineering expertise, is often overlooked. Algorithms
    are often tied to the most critical processes of an organization, hence, the availability
    and stability requirements for these algorithms are high. Data scientists never
    create an abstract model. Even in research organizations, data scientists write
    code. And the closer you are to real-world applications, the more good code matters.
    Good programming skills allow data scientists to write well-architected, well-documented,
    and reusable code other team members can understand. Software engineering expertise
    enables them to build systems that do not fail under high loads and can scale
    from simple proof-of-concept tests to organization-wide deployments.
  prefs: []
  type: TYPE_NORMAL
- en: And last, but not least, are the data science skills. They are key tools without
    which no one can build a working model. However, data science is a very wide field.
    Be sure to understand what algorithms you will need to use, and understand what
    kind of expert you need. A computer vision expert won't be the best fit for a
    movie recommender project. If you hire a data scientist, it does not automatically
    mean that they are proficient in all areas of machine learning and mathematical
    statistics.
  prefs: []
  type: TYPE_NORMAL
- en: Discovering the purpose of the interview process
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: First, you should figure out why you need to do interviews. Let's do a quick
    exercise. Ask yourself why and write out answers until there is nothing left to
    say. After that, recall the last interview that you did. Was it well aligned with
    your goals? The results should give you an instant vector for improvement.
  prefs: []
  type: TYPE_NORMAL
- en: From the employer's side, the sole purpose of the interview is to fill the position
    with a capable candidate. From the side of the employee, the purpose of the interview
    is to find a good team, an interesting project, a reliable company to work with,
    and satisfactory compensation. We often forget that the interview is a dialogue,
    not a mere test of skill.
  prefs: []
  type: TYPE_NORMAL
- en: Unfortunately, there is no clear and ubiquitous definition of the main interview
    goal. That is because each goal is unique for each position. You should define
    this goal based on the detailed understanding of the job you are interviewing
    for. If you are looking for a data scientist, define rigorously what you expect
    them to do. What tasks will the new team member solve? Think deeply about what
    the first working day in this position will look like. What are the core responsibilities?
    What skills are useful but not mandatory? Based on that, you can start drafting
    a set of desired skills for the candidates. Be specific. If you demand knowledge
    of SQL, then be sure to have a definite reason for this requirement.
  prefs: []
  type: TYPE_NORMAL
- en: If your interview goal is to find an ideal, top 0.1 percentile, world-class
    expert, then think again. The primary goal is to find an able person who can do
    the job. It might be that this person must be the best expert in the world. If
    so, this requirement should be explained and justified. To create this understanding,
    you need to describe what the job will be like. After you decide that the description
    is finished, rewrite it with the candidate in mind. It should be short, easy to
    read, and give a complete idea of that the job will be like and what the expectations
    are. The ambiguity of job descriptions often comes from a lack of this understanding.
    *We just need someone*, their job description says. Yours should say *We know
    exactly what we need, and you can rely on us*. If you can't, do you really need
    to post a new job?
  prefs: []
  type: TYPE_NORMAL
- en: 'Concrete understanding of your goals will be helpful in several ways:'
  prefs: []
  type: TYPE_NORMAL
- en: You will understand what kind of expert you should search for.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Candidates looking at your job description will know exactly what you expect
    of them. It will be easier to judge whether their experience is relevant or not.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Clear goal definitions will allow you to design purposeful and insightful interview
    questions.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: If your requirements list looks too long, try to simplify it. Maybe you were
    overzealous and some skills you have listed are not vital. Or perhaps you could
    consider hiring two people with different backgrounds? If you are posting a job
    description with a wide cross-functional set of requirements, be sure to have
    a reason behind it.
  prefs: []
  type: TYPE_NORMAL
- en: 'If your job description is complex, then you will find the following is true:'
  prefs: []
  type: TYPE_NORMAL
- en: The candidate search will take longer since you are demanding more skills and
    experience.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The candidates will expect a higher salary.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The interview process will be long and could extend to several sessions.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: You will have fewer options to choose from.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: All those restrictions should have good supporting arguments. If you have none,
    consider simplifying.
  prefs: []
  type: TYPE_NORMAL
- en: Having a good goal is not all you need, the execution matters too. We will now
    look at the interview process from the candidate's standpoint to discuss the topics
    of bias and empathy.
  prefs: []
  type: TYPE_NORMAL
- en: Key skills of a data engineer
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: As a project becomes more complex, managing data becomes difficult. Your system
    may consume data from many sources, some of them being real-time data streams,
    while others may be static databases. Volumes of data that your system will need
    to process can also be large. All this leads to the creation of a data processing
    subsystem that manages and orchestrates all data streams. Managing large volumes
    of data and creating systems that can process large volumes of data quickly requires
    the usage of highly specialized software stacks suited to this task.
  prefs: []
  type: TYPE_NORMAL
- en: 'Hence, a separate role of a data engineer emerges. The key areas of knowledge
    for data engineers are as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Software engineering**'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Big** **data engineering**: This includes distributed data processing frameworks,
    data streaming technologies, and various orchestration frameworks. Data engineers
    also need to be proficient with the main software architecture patterns related
    to data processing.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Database management and data warehousing**: Relational, NoSQL, and in-memory
    databases.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Software engineering skills are very important for data engineers. Data transformation
    code frequently suffers from bad design choices. Following the best practices
    of software design will ensure that all data processing jobs will be modular,
    reusable, and easily readable.
  prefs: []
  type: TYPE_NORMAL
- en: Working with big data involves creating highly parallel code, so a knowledge
    of distributed processing systems is also essential. Major software platforms,
    such as the Hadoop ecosystem, Apache Spark, and Apache Kafka, all require a good
    understanding of their internals to write performant and stable code.
  prefs: []
  type: TYPE_NORMAL
- en: Understanding classical relational database systems and data warehousing methodologies
    is also an important skill for a data engineer. Relational databases are a very
    frequent choice for data storage in large corporations. SQL is so widespread that
    we can consider it the *lingua franca* of data. So you can expect **Relational
    Database Management Systems** (**RDBMS**) to be a frequent data source in your
    projects. Relational databases are very good at storing and querying structured
    data, so there is a good chance that your project will also use them if the data
    volumes are moderate. Experience with popular NoSQL databases is also convenient.
  prefs: []
  type: TYPE_NORMAL
- en: Key skills of a data science manager
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'In this section, we will look at a few of the skills a data science manager
    needs to have, namely:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Management**: A data science team manager should have a good understanding
    of the main software management methodologies, such as SCRUM and Kanban. They
    should also know approaches and specific strategies for managing data science
    projects.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Domain expertise**: They should know the business domain well. Without it,
    task decomposition and prioritization becomes impossible, and the project will
    inevitably go astray.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Data science**: A good understanding of the basic concepts behind data science
    and machine learning is essential. Without it, you will be building a house without
    knowing what a house is. It will streamline communication and help to create good
    task decompositions and stories.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Software engineering**: Knowledge of basic software engineering will ensure
    that the manager can keep an eye on crucial aspects of a project, such as software
    architecture and technical debt. Good software project managers have development
    experience. This experience taught them to write automated tests, refactoring,
    and building a good architecture. Unfortunately, many data science projects suffer
    from bad software design choices. Taking shortcuts is only good in the short term;
    in the long term, they will come back to bite you. Projects tend to scale with
    time; as the team increases, a number of integrations grow, and new requirements
    arrive. Bad software design paralyzes the project, leaving you with only one option—a
    complete rewrite of the system.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Getting help from the development team
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Creating data products is tied to creating new software systems. Large-scale
    projects may have many software requirements, including building a UI, developer
    APIs, and creating role-based workflows in your system. Be sure to get help from
    a software development team with software engineers, analysts, and architects
    when you feel that the data science team cannot handle everything by themselves.
    You may be good to go with a data science team if the only thing you need to build
    besides a machine learning model is a couple of REST services, data integration
    jobs, and a simple admin UI. But be sure to expand your team if you need to handle
    something more complex than that.
  prefs: []
  type: TYPE_NORMAL
- en: Summary
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this chapter, we first covered what a data scientist is. Then, we looked
    at two examples that showed us whether a data scientist can work in isolation
    or needs a team. Next, we looked at the various skills and qualities that a data
    scientist, a data engineer, and a data science manager need to have. We also briefly
    explored when we need to ask for help from the development team.
  prefs: []
  type: TYPE_NORMAL
- en: Finally, we defined the key domains of a data science team, which are analysis,
    data, and software. In those domains, we defined project roles that will allow
    you to create a balanced and powerful team. We may solve simple projects with
    small teams where team members share responsibilities for different roles. But
    when the project's complexity grows, your organizational structure will need to
    scale with it. We also noted the importance of following the best practices of
    software engineering and sourcing help from software development teams.
  prefs: []
  type: TYPE_NORMAL
- en: Knowing that defining responsibilities and expectations is critical for delivering
    complex data science projects, we will use those ideas in the next chapter, where
    we will explore how to create effective hiring procedures for data science teams.
  prefs: []
  type: TYPE_NORMAL
