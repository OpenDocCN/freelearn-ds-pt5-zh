["```py\n{\n  \"id\":{\n    \"$t\":\"https://spreadsheets.google.com/feeds/list/1mWIAk_5KN oQHr4vFgPHdm7GX8Vh22WjgAUYYHUyXSNM/od6/public/basic/cokwr\"\n  },\n  \"updated\":{\"$t\":\"2014-12-17T20:02:57.196Z\"},\n  \"category\":[{\n    \"scheme\":\"http://schemas.google.com/spreadsheets/2006\",\n    \"term\"  :\"http://schemas.google.com/spreadsheets/2006#list\"\n  }],\n  \"title\":{\n    \"type\":\"text\",\n    \"$t\"  :\"Yale University \"\n  },\n  \"content\":{\n    \"type\":\"text\",\n    \"$t\"  :\"_cokwr: 26\"\n  },\n  \"link\": [{\n    \"rel\" :\"self\",\n    \"type\":\"application/atom+xml\",\n    \"href\":\"https://spreadsheets.google.com/feeds/list/1mWIAk_5KN oQHr4vFgPHdm7GX8Vh22WjgAUYYHUyXSNM/od6/public/basic/cokwr\"\n  }]\n}\n```", "```py\nSELECT concat(firstName,  \" \", lastName) as name, email_id\nFROM employeelist\nORDER BY lastName;\n```", "```py\n{\n  \"name\": \"Lysa Akin\",\n  \"email_id\": \"lysa.akin@enron.com\"\n}\n```", "```py\nSELECT concat(firstName,  \" \", lastName) as name, email_id\nINTO OUTFILE 'enronEmployees.csv'\nFIELDS TERMINATED BY ',' OPTIONALLY ENCLOSED BY '\"'\nLINES TERMINATED BY '\\n'\nFROM employeelist;\n```", "```py\n<?php\n// connect to db, set up query, run the query\n$dbc = mysqli_connect('localhost','username','password','enron')\nor die('Error connecting to database!' . mysqli_error());\n\n$select_query = \"SELECT concat(firstName,  \\\" \\\", lastName) as name, email_id FROM  employeelist ORDER BY lastName\";\n\n$select_result = mysqli_query($dbc, $select_query);\n\nif (!$select_result)\n    die (\"SELECT failed! [$select_query]\" .  mysqli_error());\n\n// ----JSON output----\n// build a new array, suitable for json\n$counts = array();\nwhile($row = mysqli_fetch_array($select_result))\n{\n// add onto the json array\n    array_push($counts, array('name'     => $row['name'],\n    'email_id' => $row['email_id']));\n}\n// encode query results array as json\n$json_formatted = json_encode($counts);\n\n// write out the json file\nfile_put_contents(\"enronEmail.json\", $json_formatted);\n?>\n```", "```py\n<?php\n// connect to db, set up query, run the query\n  $dbc = mysqli_connect('localhost','username','password','enron')\n  or die('Error connecting to database!' . mysqli_error());\n\n$select_query = \"SELECT concat(firstName,  \\\" \\\", lastName) as name, email_id FROM  employeelist ORDER BY lastName\";\n\n$select_result = mysqli_query($dbc, $select_query);\n\nif (!$select_result)\n    die (\"SELECT failed! [$select_query]\" .  mysqli_error());\n\n// ----CSV output----\n// set up a file stream\n$file = fopen('php://output', 'w');\nif ($file && $select_result)\n{\n    header('Content-Type: text/csv');\n    header('Content-Disposition: attachment;\n    filename=\"enronEmail.csv\"');\n    // write each result row to the file in csv format\n    while($row = mysqli_fetch_assoc($select_result))\n    {\n      fputcsv($file, array_values($row));\n    }\n}\n?>\n```", "```py\n\"Lysa Akin\",lysa.akin@enron.com\n\"Phillip Allen\",k..allen@enron.com\n\"Harry Arora\",harry.arora@enron.com\n```", "```py\nSELECT CONCAT(firstName,  \" \", lastName) AS name, email_id\nFROM employeelist\nWHERE email_id LIKE \"%..%\"\nORDER BY name ASC;\n```", "```py\n<?php\n// read in the file\n$json = file_get_contents(\"outfile.json\");\n// convert JSON to an associative array\n$array = json_decode ($json, true);\n// open the file stream\n$file = fopen('php://output', 'w');\nheader('Content-Type: text/csv');\nheader('Content-Disposition: attachment;\nfilename=\"enronEmail.csv\"');\n// loop through the array and write each item to the file\nforeach ($array as $line)\n{\n    fputcsv($file, $line);\n}\n?>\n```", "```py\n<?php\n$file = fopen('enronEmail.csv', 'r');\n$headers = fgetcsv($file, 0, ',');\n$complete = array();\n\nwhile ($row = fgetcsv($file, 0, ','))\n{\n    $complete[] = array_combine($headers, $row);\n}\nfclose($file);\n$json_formatted = json_encode($complete);\nfile_put_contents('enronEmail.json',$json_formatted);\n?>\n```", "```py\n[{\"name\":\"Lysa Akin\",\"email_id\":\"lysa.akin@enron.com\"},\n{\"name\":\"Phillip Allen\",\"email_id\":\"k..allen@enron.com\"},\n{\"name\":\"Harry Arora\",\"email_id\":\"harry.arora@enron.com\"}…]\n```", "```py\nname,email_id\n\"Lysa Akin\",lysa.akin@enron.com\n\"Phillip Allen\",k..allen@enron.com\n\"Harry Arora\",harry.arora@enron.com\n```", "```py\nimport json\nimport csv\n\n# read in the CSV file\nwith open('enronEmail.csv') as file:\n    file_csv = csv.DictReader(file)\n    output = '['\n    # process each dictionary row\n    for row in file_csv:\n      # put a comma between the entities\n      output += json.dumps(row) + ','\n    output = output.rstrip(',') + ']'\n# write out a new file to disk\nf = open('enronEmailPy.json','w')\nf.write(output)\nf.close()\n```", "```py\n[{\"email_id\": \"lysa.akin@enron.com\", \"name\": \"Lysa Akin\"},\n{\"email_id\": \"k..allen@enron.com\", \"name\": \"Phillip Allen\"},…]\n```", "```py\ncsvjson enronEmail.csv > enronEmail.json\n\n```", "```py\ncsvcut bigFile.csv –c 1,3 > firstThirdCols.csv\n\n```", "```py\nimport json\nimport csv\n\nwith open('enronEmailPy.json', 'r') as f:\n    dicts = json.load(f)\nout = open('enronEmailPy.csv', 'w')\nwriter = csv.DictWriter(out, dicts[0].keys())\nwriter.writeheader()\nwriter.writerows(dicts)\nout.close()\n```", "```py\nnodedef>name VARCHAR,label VARCHAR,sex VARCHAR,locale VARCHAR,agerank INT\n  1234,Bugs Bunny,male,en_US,296\n  2345,Daffy Duck,male,en_US,295\n  3456,Minnie Mouse,female,en_US,294\n```", "```py\nedgedef>node1 VARCHAR,node2 VARCHAR \n1234,2345\n1234,3456\n3456,9876\n```", "```py\n{\"nodes\": [\n  {\"name\":\"Bugs Bunny\"},\n  {\"name\":\"Daffy Duck\"},\n  {\"name\":\"Minnie Mouse\"}],\n  \"edges\": [\n  {\"source\": 0,\"target\": 2},\n  {\"source\": 1,\"target\": 3},\n  {\"source\": 2,\"target\": 3}]}\n```", "```py\n    id,name,gender,lang,num\n    1234,Bugs Bunny,male,en_US,296\n    2345,Daffy Duck,male,en_US,295\n    9876,Minnie Mouse,female,en_US,294\n\n    source,target\n    1234,2345\n    1234,9876\n    2345,9876\n    ```", "```py\n    csvcut -c 1,2 nodes.gdf > nodesCut.gdf\n\n    ```", "```py\n    source,target\n    1234,2345\n    1234,9876\n    2345,9876\n    ```", "```py\n    source,target\n    0,1\n    0,2\n    1,2\n    ```", "```py\n    import csv\n\n    # read in the nodes\n    with open('nodesCut.gdf', 'r') as nodefile:\n        nodereader = csv.reader(nodefile)\n        nodeid, name = zip(*nodereader)\n\n    # read in the source and target of the edges\n    with open('edges.gdf', 'r') as edgefile:\n        edgereader = csv.reader(edgefile)\n        sourcearray, targetarray = zip(*edgereader)\n    slist = list(sourcearray)\n    tlist = list(targetarray)\n\n    # find the node index value for each source and target\n    for n,i in enumerate(nodeid):\n        for j,s in enumerate(slist):\n            if s == i:\n                slist[j]=n-1\n        for k,t in enumerate(tlist):\n            if t == i: \n                tlist[k]=n-1\n    # write out the new edge list with index values\n    with open('edgelistIndex.csv', 'wb') as indexfile:\n        iwriter = csv.writer(indexfile)\n        for c in range(len(slist)):\n            iwriter.writerow([ slist[c], tlist[c]])\n    ```", "```py\n    csvcut -c 2 nodesCut.gdf > nodesCutName.gdf\n\n    ```", "```py\n    import csv\n    import json\n\n    # read in the nodes file\n    with open('nodesCutName.gdf') as nodefile:\n        nodefile_csv = csv.DictReader(nodefile)\n        noutput = '['\n        ncounter = 0;\n\n        # process each dictionary row\n        for nrow in nodefile_csv:\n            # look for ' in node names, like O'Connor\n            nrow[\"name\"] = \\\n            str(nrow[\"name\"]).replace(\"'\",\"\")\n            # put a comma between the entities\n            if ncounter > 0:\n                noutput += ','\n            noutput += json.dumps(nrow)\n            ncounter += 1\n        noutput += ']'\n        # write out a new file to disk\n        f = open('complete.json','w')\n        f.write('{')\n        f.write('\\\"nodes\\\":' )\n        f.write(noutput)\n\n    # read in the edge file\n    with open('edgelistIndex.csv') as edgefile:\n        edgefile_csv = csv.DictReader(edgefile)\n        eoutput = '['\n        ecounter = 0;\n        # process each dictionary row\n        for erow in edgefile_csv:\n            # make sure numeric data is coded as number not # string\n            for ekey in erow:\n                try:\n                    erow[ekey] = int(erow[ekey])\n                except ValueError:\n                    # not an int\n                    pass\n            # put a comma between the entities\n            if ecounter > 0:\n                eoutput += ','\n            eoutput += json.dumps(erow)\n            ecounter += 1\n        eoutput += ']'\n\n        # write out a new file to disk\n        f.write(',')\n        f.write('\\\"links\\\":')\n        f.write(eoutput)\n        f.write('}')\n        f.close()\n    ```", "```py\n<!DOCTYPE html>\n<!-- this code is based on the force-directed graph D3 example given at : https://gist.github.com/mbostock/4062045 -->\n\n<meta charset=\"utf-8\">\n<style>\n\n.node {\n  stroke: #fff;\n  stroke-width: 1.5px;\n}\n\n.link {\n  stroke: #999;\n  stroke-opacity: .6;\n}\n\n</style>\n<body>\n<!-- make sure you have downloaded the D3 libraries and stored them locally -->\n<script src=\"img/d3.min.js\"></script>\n<script>\n\nvar width = 960, height = 500;\nvar color = d3.scale.category20();\nvar force = d3.layout.force()\n    .charge(-25)\n    .linkDistance(30)\n    .size([width, height]);\n\nvar svg = d3.select(\"body\").append(\"svg\")\n    .attr(\"width\", width)\n    .attr(\"height\", height);\n\nd3.json(\"complete.json\", function(error, graph) {\n  force\n      .nodes(graph.nodes)\n      .links(graph.links)\n      .start();\n\n  var link = svg.selectAll(\".link\")\n      .data(graph.links)\n    .enter().append(\"line\")\n      .attr(\"class\", \"link\")\n      .style(\"stroke-width\", function(d) { return Math.sqrt(d.value); });\n\n  var node = svg.selectAll(\".node\")\n      .data(graph.nodes)\n    .enter().append(\"circle\")\n      .attr(\"class\", \"node\")\n      .attr(\"r\", 5)\n      .style(\"fill\", function(d) { return color(d.group); })\n      .call(force.drag);\n\n  node.append(\"title\")\n      .text(function(d) { return d.name; });\n\n  force.on(\"tick\", function() {\n    link.attr(\"x1\", function(d) { return d.source.x; })\n      .attr(\"y1\", function(d) { return d.source.y; })\n      .attr(\"x2\", function(d) { return d.target.x; })\n      .attr(\"y2\", function(d) { return d.target.y; });\n\n    node.attr(\"cx\", function(d) { return d.x; })\n      .attr(\"cy\", function(d) { return d.y; });\n  });\n});\n</script>\n```", "```py\n*vertices 296\n1234 Bugs_Bunny male en_US 296\n2456 Daffy_Duck male en_US 295\n9876 Minnie_Mouse female en_US 294\n*edges\n1234 2456\n2456 9876\n2456 3456\n```", "```py\n    nodedef>name VARCHAR,label VARCHAR,sex VARCHAR,locale VARCHAR,agerank INT\n    ```", "```py\n    *vertices 296\n    ```", "```py\n    edgedef>node1 VARCHAR,node2 VARCHAR\n    ```", "```py\n    *edges\n    ```", "```py\n    1234,Bugs Bunny,male,en_US,296\n    2456,Daffy Duck,male,en_US,295\n    3456,Minnie Mouse,female,en_US,294\n    ```", "```py\n    1234,Bugs_Bunny,male,en_US,296\n    2456,Daffy_Duck,male,en_US,295\n    3456,Minnie_Mouse,female,en_US,294\n    ```", "```py\n    *vertices 296\n    1234 Bugs_Bunny male en_US 296\n    2456 Daffy_Duck male en_US 295\n    3456 Minnie_Mouse female en_US 294\n    ```", "```py\n    *edges\n    1234 2456\n    2456 9876\n    2456 3456\n    ```", "```py\n    1998988 Capn_Crunch male en_US 137\n    ```", "```py\nimport networkx as net\n\n# read in the file\ng = net.read_pajek('fb_pajek.net')\n\n# how many nodes are in the graph?\n# print len(g)\n\n# create a degree map: a set of name-value pairs linking nodes\n# to the number of edges in my network\ndeg = net.degree(g)\n# sort the degree map and print the top ten nodes with the\n# highest degree (highest number of edges in the network)\nprint sorted(deg.iteritems(), key=lambda(k,v): (-v,k))[0:9]\n```", "```py\n[(u'Bambi', 134), (u'Cinderella', 56), (u'Capn_Crunch', 50), (u'Bugs_Bunny', 47), (u'Minnie_Mouse', 47), (u'Cruella_Deville', 46), (u'Alice_Wonderland', 44), (u'Prince_Charming', 42), (u'Daffy_Duck', 42)]\n```"]