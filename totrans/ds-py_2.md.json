["```py\n    import pandas as pd\n    df = pd.read_csv('weather.csv')\n    ```", "```py\n    levels = len(pd.value_counts(df['Description']))\n    print('There are {} levels in the Description column'.format(levels))\n    ```", "```py\n    import pandas as pd\n    df_dummies = pd.get_dummies(df, drop_first=True)\n    ```", "```py\n    print('There are {} columns in df_dummies'\t.format(df_dummies.shape[1]))\n    ```", "```py\n    from sklearn.utils import shuffle\n    df_shuffled = shuffle(df_dummies, random_state=42)\n    ```", "```py\n    DV = 'Temperature_c'\n    X = df_shuffled.drop(DV, axis=1)\n    y = df_shuffled[DV]\n    ```", "```py\n    from sklearn.model_selection import train_test_split\n    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)\n    ```", "```py\n    from sklearn.linear_model import LinearRegression\n    model = LinearRegression()\n    ```", "```py\n    model.fit(X_train[['Humidity']], y_train)\n    ```", "```py\n    intercept = model.intercept_\n    ```", "```py\n    coefficient = model.coef_\n    ```", "```py\n    print('Temperature = {0:0.2f} + ({1:0.2f} x Humidity)'.format(intercept, coefficient[0]))\n    ```", "```py\n    predictions = model.predict(X_test[['Humidity']])\n    ```", "```py\n    import matplotlib.pyplot as plt\n    from scipy.stats import pearsonr\n    plt.scatter(y_test, predictions)\n    plt.xlabel('Y Test (True Values)')\n    plt.ylabel('Predicted Values')\n    plt.title('Predicted vs. Actual Values (r = {0:0.2f})'.format(pearsonr(y_test, predictions)[0], 2))\n    plt.show()\n    ```", "```py\n    import seaborn as sns\n    from scipy.stats import shapiro\n    sns.distplot((y_test - predictions), bins = 50)\n    plt.xlabel('Residuals')\n    plt.ylabel('Density')\n    plt.title('Histogram of Residuals (Shapiro W p-value = {0:0.3f})'.format(shapiro(y_test - predictions)[1]))\n    plt.show()\n    ```", "```py\n    from sklearn import metrics\n    import numpy as np\n    metrics_df = pd.DataFrame({'Metric': ['MAE', \n                                          'MSE', \n                                          'RMSE', \n                                          'R-Squared'],\n                              'Value': [metrics.mean_absolute_error(y_test, predictions),\n                                        metrics.mean_squared_error(y_test, predictions),\n                                        np.sqrt(metrics.mean_squared_error(y_test, predictions)),\n                                        metrics.explained_variance_score(y_test, predictions)]}).round(3)\n    print(metrics_df)\n    ```", "```py\n    from sklearn.linear_model import LinearRegression\n    model = LinearRegression()\n    ```", "```py\n    model.fit(X_train, y_train) \n    ```", "```py\n    intercept = model.intercept_\n    ```", "```py\n    coefficients = model.coef_\n    ```", "```py\n    print('Temperature = {0:0.2f} + ({1:0.2f} x Humidity) + ({2:0.2f} x Wind Speed) + ({3:0.2f} x Wind Bearing Degrees) + ({4:0.2f} x Visibility) + ({5:0.2f} x Pressure) + ({6:0.2f} x Rain) + ({7:0.2f} x Normal Weather) + ({8:0.2f} x Warm Weather)'.format(intercept,\n    coefficients[0],\n    coefficients[1],\n    coefficients[2],\n    coefficients[3],\n    coefficients[4],\n    coefficients[5],\n    coefficients[6],\n    coefficients[7]))\n    ```", "```py\n    import pandas as pd\n    df = pd.read_csv('weather.csv')\n    ```", "```py\n    import pandas as pd\n    df_dummies = pd.get_dummies(df, drop_first=True)\n    ```", "```py\n    from sklearn.utils import shuffle\n    df_shuffled = shuffle(df_dummies, random_state=42)\n    ```", "```py\n    DV = 'Rain' \n    X = df_shuffled.drop(DV, axis=1) \n    y = df_shuffled[DV] \n    ```", "```py\n    from sklearn.model_selection import train_test_split\n    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)\n    ```", "```py\n    from sklearn.linear_model import LogisticRegression\n    model = LogisticRegression()\n    ```", "```py\n    intercept = model.intercept_\n    ```", "```py\n    coefficients = model.coef_\n    ```", "```py\n    coef_list = list(coefficients[0,:])\n    ```", "```py\n    coef_df = pd.DataFrame({'Feature': list(X_train.columns),\n                            'Coefficient': coef_list})\n    print(coef_df)\n    ```", "```py\n    predicted_prob = model.predict_proba(X_test)[:,1]\n    ```", "```py\n    predicted_class = model.predict(X_test)\n    ```", "```py\n    from sklearn.metrics import confusion_matrix\n    import numpy as np\n    cm = pd.DataFrame(confusion_matrix(y_test, predicted_class))\n    cm['Total'] = np.sum(cm, axis=1)\n    cm = cm.append(np.sum(cm, axis=0), ignore_index=True)\n    cm.columns = ['Predicted No', 'Predicted Yes', 'Total']\n    cm = cm.set_index([['Actual No', 'Actual Yes', 'Total']])\n    print(cm)\n    ```", "```py\n    from sklearn.metrics import classification_report\n    print(classification_report(y_test, predicted_class))\n    ```", "```py\n    import numpy as np\n    grid = {'penalty': ['l1', 'l2'],\n            'C': np.linspace(1, 10, 10),\n            'solver': ['liblinear']}\n    ```", "```py\n    from sklearn.model_selection import GridSearchCV\n    from sklearn.linear_model import LogisticRegression\n    model = GridSearchCV(LogisticRegression(solver='liblinear'), grid, scoring='f1', cv=5)\n    ```", "```py\n    best_parameters = model.best_params_\n    print(best_parameters)\n    ```", "```py\n    import pandas as pd\n    df = pd.read_csv('weather.csv')\n    ```", "```py\n    import pandas as pd\n    df_dummies = pd.get_dummies(df, drop_first=True)\n    ```", "```py\n    from sklearn.utils import shuffle\n    df_shuffled = shuffle(df_dummies, random_state=42)\n    ```", "```py\n    DV = 'Rain'\n    X = df_shuffled.drop(DV, axis=1) \n    y = df_shuffled[DV]\n    ```", "```py\n    from sklearn.model_selection import train_test_split\n    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)\n    ```", "```py\n    from sklearn.preprocessing import StandardScaler\n    model = StandardScaler() \n    X_train_scaled = model.fit_transform(X_train)\n    X_test_scaled = model.transform(X_test)\n    ```", "```py\n    import numpy as np\n    grid = {'C': np.linspace(1, 10, 10),\n            'kernel': ['linear', 'poly', 'rbf', 'sigmoid']}\n    ```", "```py\n    from sklearn.model_selection import GridSearchCV\n    from sklearn.svm import SVC\n    model = GridSearchCV(SVC(gamma='auto'), grid, scoring='f1', cv=5)\n    ```", "```py\n    best_parameters = model.best_params_\n    print(best_parameters)\n    ```", "```py\n    from sklearn.preprocessing import StandardScaler\n    model = StandardScaler()\n    X_train_scaled = model.fit_transform(X_train)\n    X_test_scaled = model.transform(X_test)\n    ```", "```py\n    import numpy as np\n    grid = {'criterion': ['gini', 'entropy'],\n            'min_weight_fraction_leaf': np.linspace(0.0, 0.5, 10),\n            'min_impurity_decrease': np.linspace(0.0, 1.0, 10),\n            'class_weight': [None, 'balanced'],\n    'presort': [True, False]}Instantiate the GridSearchCV model\n    ```", "```py\n    from sklearn.model_selection import GridSearchCV\n    from sklearn.tree import DecisionTreeClassifier\n    model = GridSearchCV(DecisionTreeClassifier(), grid, scoring='f1', cv=5)\n    ```", "```py\n    model.fit(X_train_scaled, y_train)\n    ```", "```py\n    best_parameters = model.best_params_\n    print(best_parameters)\n    ```", "```py\n    print(best_parameters['criterion'])\n    ```", "```py\n    from sklearn.tree import DecisionTreeClassifier\n    model = DecisionTreeClassifier(class_weight=best_parameters['class_weight'],\n                                   criterion=best_parameters['criterion'],\n                          min_impurity_decrease=best_parameters['min_impurity_decrease'],\n                   min_weight_fraction_leaf=best_parameters['min_weight_fraction_leaf'],\n                                   presort=best_parameters['presort'])\n    ```", "```py\n    model.fit(X_train_scaled, y_train)\n    ```", "```py\n    print(model.feature_importances_)\n    The resultant output is shown below:\n    ```", "```py\n    import pandas as pd\n    import matplotlib.pyplot as plt\n    df_imp = pd.DataFrame({'Importance': list(model.feature_importances_)}, index=X.columns)\n    df_imp_sorted = df_imp.sort_values(by=('Importance'), ascending=True)\n    df_imp_sorted.plot.barh(figsize=(5,5))\n    plt.title('Relative Feature Importance')\n    plt.xlabel('Relative Importance')\n    plt.ylabel('Variable')\n    plt.legend(loc=4)\n    plt.show()\n    ```", "```py\n    import pandas as pd\n    df = pd.read_csv('weather.csv')\n    ```", "```py\n    import pandas as pd\n    df_dummies = pd.get_dummies(df, drop_first=True)\n    ```", "```py\n    from sklearn.utils import shuffle\n    df_shuffled = shuffle(df_dummies, random_state=42)\n    ```", "```py\n    DV = 'Temperature_c'\n    X = df_shuffled.drop(DV, axis=1)\n    y = df_shuffled[DV]\n    ```", "```py\n    from sklearn.model_selection import train_test_split\n    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)\n    ```", "```py\n    from sklearn.preprocessing import StandardScaler\n    scaler = StandardScaler()\n    X_train_scaled = scaler.fit_transform(X_train)\n    X_test_scaled = scaler.transform(X_test)\n    ```", "```py\n    from sklearn.ensemble import RandomForestRegressor\n    model = RandomForestRegressor(criterion=best_parameters['criterion'],\n                                  max_features=best_parameters['max_features'],\n                                  min_impurity_decrease=best_parameters['min_impurity_decrease'],\n                                  bootstrap=best_parameters['bootstrap'],\n                                  warm_start=best_parameters['warm_start'])\n    ```", "```py\n    model.fit(X_train_scaled, y_train)\n    ```", "```py\n    import pandas as pd\n    import matplotlib.pyplot as plt\n    df_imp = pd.DataFrame({'Importance': list(model.feature_importances_)}, index=X.columns)\n    df_imp_sorted = df_imp.sort_values(by=('Importance'), ascending=True)\n    df_imp_sorted.plot.barh(figsize=(5,5))\n    plt.title('Relative Feature Importance')\n    plt.xlabel('Relative Importance')\n    plt.ylabel('Variable')\n    plt.legend(loc=4)\n    plt.show()\n    ```"]