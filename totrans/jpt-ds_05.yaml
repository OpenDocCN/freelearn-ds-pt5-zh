- en: R with Jupyter
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this chapter we will be using R coding within Jupyter. I think R is one of
    the primary languages expected to be used within Jupyter. The full extent of the
    language is available to Jupyter users.
  prefs: []
  type: TYPE_NORMAL
- en: How to set up R for Jupyter
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In the past, it was necessary to install the separate components of Jupyter,
    Python, and so on to have a working system. With Continuum Analytics, the process
    of installing Jupyter and adding the R engine to the solution set for Jupyter
    is easy and works on both Windows and Mac.
  prefs: []
  type: TYPE_NORMAL
- en: 'Assuming you have installed conda already, we have one command to add support
    for R programming to Jupyter:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: At this point, when you start Jupyter, one of the kernels listed will now be
    R.
  prefs: []
  type: TYPE_NORMAL
- en: R data analysis of the 2016 US election demographics
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: To get a flavor of the resources available to R developers, we can look at the
    2016 election data. In this case, I am drawing from Wikipedia ([https://en.wikipedia.org/wiki/United_States_presidential_election,_2016](https://en.wikipedia.org/wiki/United_States_presidential_election,_2016)),
    specifically the table named 2016 presidential vote by demographic subgroup. We
    have the following coding below.
  prefs: []
  type: TYPE_NORMAL
- en: 'Define a helper function so we can print out values easily. The new `printf`
    function takes any arguments passed `(...)` and passes them along to `sprintf`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: 'I have stored the separate demographic statistics into different **TSV** (**tab-separated
    value)** files, which can be read in using the following coding. For each table,
    we use the `read.csv` function and specify the field separator as a tab instead
    of the default comma. We then use the `head` function to display information about
    the data frame that was loaded:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: 'Across the top is a display of the columns. Every row displays the values for
    those columns in that row. Each of these `read` operations results in a display
    as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/97bf88f3-65a1-4bf4-b964-990935c907dc.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Now, we can find the dominant characteristics of each turnout:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: 'The results are as follows for Clinton:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/47a91a28-2e1f-4db3-be52-54682ae116d1.png)'
  prefs: []
  type: TYPE_IMG
- en: 'The results for Trump are as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/2a472ea5-a9e7-4038-98f8-1e9d1eaed4e2.png)'
  prefs: []
  type: TYPE_IMG
- en: It's interesting that there was no overlap between the majority groups supporting
    the two candidates. I think the parties targeted different groups on purpose so
    as not to overlap. There must be a guideline for spending money, by advertising
    to known, interested groups and not contend for population segments that are ambiguous.
  prefs: []
  type: TYPE_NORMAL
- en: Analyzing 2016 voter registration and voting
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Similarly, we can look at voter registration versus actual voting (using census
    data from [https://www.census.gov/data/tables/time-series/demo/voting-and-registration/p20-580.html](https://www.census.gov/data/tables/time-series/demo/voting-and-registration/p20-580.html)).
  prefs: []
  type: TYPE_NORMAL
- en: 'First, we load our dataset and display head information to visually check for
    accurate loading:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: '![](img/4618fa6a-47ba-4cf5-a0d7-678c92197df2.png)'
  prefs: []
  type: TYPE_IMG
- en: 'So, we have some registration and voting information by state. Use R to automatically
    plot all the data in *x* and *y* format using the `plot` command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: 'We are specifically looking at the relationship between registering to vote
    and actually voting. We can see in the following graphic that most of the data
    is highly correlated (as evidenced by the 45 degree angles of most of the relationships):'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/4bf0119d-9dd8-4bc4-9c76-aac73e2f99bb.png)'
  prefs: []
  type: TYPE_IMG
- en: We can produce somewhat similar results using Python, but the graphic display
    is not even close.
  prefs: []
  type: TYPE_NORMAL
- en: 'Import all of the packages we are using for the example:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: 'Reading a CSV file in Python is very similar. We call upon pandas to read in
    the file:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: 'pandas will throw an error if there is string data in the data frame, so just
    delete the column (with state names):'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs: []
  type: TYPE_PRE
- en: 'One approximate Python function is the `corr()` function, which prints out
    the numeric values for all of the cross-correlations among the items in the data
    frame. It is up to you to scan through the data, looking for correlation values
    close to `1.0`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs: []
  type: TYPE_PRE
- en: 'Similarly, we have the `corrcoef()` function, which provides color intensity
    to similarly correlated items within the data frame. I did not find a way to label
    the correlated items:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE10]'
  prefs: []
  type: TYPE_PRE
- en: '![](img/2a1a9c23-f2cb-49ba-b7e1-896badf30c62.png)'
  prefs: []
  type: TYPE_IMG
- en: 'We want to see the actual numeric value of the correlation between registration
    and voting. We can do that by calling the `cor` function to pass in the two data
    points of interest, as in:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE11]'
  prefs: []
  type: TYPE_PRE
- en: The actual correlation value may be different from one machine class to another.
    This would have a trickling affect to follow-on values as well.
  prefs: []
  type: TYPE_NORMAL
- en: With a correlation of 99 percent, we are almost perfect.
  prefs: []
  type: TYPE_NORMAL
- en: 'We can use the data points to arrive at a regression line using the `lm` function,
    where we are stating *lm(y ~ (predicted by) x)*:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE12]'
  prefs: []
  type: TYPE_PRE
- en: From this output, given a registered number, we multiply it by 87 percent and
    subtract 4 to get the number of actual voters. Again, the data is correlated.
  prefs: []
  type: TYPE_NORMAL
- en: 'We can display the characteristics of the regression line by calling the `plot`
    function and passing in the `fit` object (the `par` function is used to lay out
    the outputâ€”in this case a 2x2 matrix-like display of the four graphics):'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE13]'
  prefs: []
  type: TYPE_PRE
- en: '![](img/39c72cf4-b879-43c8-814a-2d0a63c48aff.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Then, in the second part of the 2x2 display, we have these two graphics:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/1f8e2def-3158-412a-822b-a97743829b63.png)'
  prefs: []
  type: TYPE_IMG
- en: 'From the preceding plots we can see the following:'
  prefs: []
  type: TYPE_NORMAL
- en: The residual values are close to zero until we get to very large numbers
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The theoretical quantiles versus standardized residuals line up very well for
    most of the range
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The fitted values versus standardized residuals are not as close as I would
    have expected
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The standardized residuals versus leverage show the same tight configuration
    among most of the values.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Overall, we still have a very good model for the data. We can see what the
    residuals look like for the regression calling the `residuals` function, as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/621e7eff-331b-49b4-9a4e-a3261f032a4a.png)'
  prefs: []
  type: TYPE_IMG
- en: '[PRE14]'
  prefs: []
  type: TYPE_PRE
- en: The residual values are bigger than I expected for such highly correlated data.
    I had expected to see very small numbers as opposed to values in the hundreds.
  prefs: []
  type: TYPE_NORMAL
- en: 'As always, let''s display a summary of the model that we arrived at:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE15]'
  prefs: []
  type: TYPE_PRE
- en: You may see different results based on the machine class that you are running
    your script on.
  prefs: []
  type: TYPE_NORMAL
- en: 'There are many data points associated with the model in this display:'
  prefs: []
  type: TYPE_NORMAL
- en: Again, residuals are showing quite a range
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Coefficients are as we saw them earlier, but the standard error is high for
    the intercept
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: R squared of close to 1 is expected
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*p* value minimal is expected'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'We can also use Python to arrive at a linear regression model using:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE16]'
  prefs: []
  type: TYPE_PRE
- en: 'We see the regression results in standard fashion as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/e6fd7aec-ffea-45b8-bd85-da4ec60a339a.png)'
  prefs: []
  type: TYPE_IMG
- en: 'The warnings infer some issues with the data:'
  prefs: []
  type: TYPE_NORMAL
- en: We are using the covariance matrix directly, so it is unclear how we would specify
    this otherwise
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: I imagine there is strong multicollinearity as the data only has the two items
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'We can also plot the actual versus fitted values in Python using a script:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE17]'
  prefs: []
  type: TYPE_PRE
- en: '![](img/4d56bfe5-424a-45ef-b46d-a4c5ecc6ed63.png)'
  prefs: []
  type: TYPE_IMG
- en: I think I like this version of the graph from Python better than the display
    from R. The added intensity circle on the bottom left is confusing.
  prefs: []
  type: TYPE_NORMAL
- en: Analyzing changes in college admissions
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: We can look at trends in college admissions acceptance rates over the last few
    years. For this analysis, I am using the data on [https://www.ivywise.com/ivywise-knowledgebase/admission-statistics](https://www.ivywise.com/ivywise-knowledgebase/admission-statistics).
  prefs: []
  type: TYPE_NORMAL
- en: 'First, we read in our dataset and show the summary points, from head to validate:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE18]'
  prefs: []
  type: TYPE_PRE
- en: 'We see the summary data for school acceptance rates as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/a014b6a0-5c99-4f42-93e2-d3a6497eeedd.png)'
  prefs: []
  type: TYPE_IMG
- en: It's interesting to note that the acceptance rate varies so widely, from a low
    of 5 percent to a high of 41 percent in 2017.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let us look at the data plots, again, to validate that the data points are
    correct:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE19]'
  prefs: []
  type: TYPE_PRE
- en: '![](img/4b197f6e-c19c-4981-acd3-1094da8791f0.png)'
  prefs: []
  type: TYPE_IMG
- en: From the correlation graphics shown, it does not look like we can use the data
    points from 2007\. The graphs show a big divergence between 2007 and the other
    years, whereas the other three have good correlations.
  prefs: []
  type: TYPE_NORMAL
- en: So, we have 3 consecutive years of data from 25 major US universities. We can
    convert the data into a time series using a few steps.
  prefs: []
  type: TYPE_NORMAL
- en: 'First, we create a vector of the average acceptance rates for these colleges
    over the years 2015-2017\. We use the mean function to determine the average across
    all colleges in our data frame. We have some `NA` values in our data frame, so
    we need to tell the mean function to ignore those values (`na.rm=TRUE`):'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE20]'
  prefs: []
  type: TYPE_PRE
- en: 'Next, we convert the vector points into a time series. A time series is passed
    in the vector to use the start and end points, and the frequency of the data points.
    In our case, the frequency is yearly, so `frequency = 1`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE21]'
  prefs: []
  type: TYPE_PRE
- en: 'Then plot the time series to get a good visual:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE22]'
  prefs: []
  type: TYPE_PRE
- en: '![](img/89722722-b336-4205-aae9-f1796b62006f.png)'
  prefs: []
  type: TYPE_IMG
- en: So, the clear trend is to drop acceptance rates across the board, as we see
    the initial acceptance rate at `.15` dropping steadily to `.14` in 2017.
  prefs: []
  type: TYPE_NORMAL
- en: 'The data looks very good and well-fitting, as data points are lining up in
    clean lines. We can use this time series to predict the next few years. There
    are versions of the Holt-Winters algorithm that can predict based on level data,
    level data plus a trend component, and level data plus a trend component plus
    a seasonality component. We have a trend, but no seasonality:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE23]'
  prefs: []
  type: TYPE_PRE
- en: Our coefficients for the exponential smoothing of one-seventh and close to zero
    mean we aren't aggressively dropping acceptance rates, but they are dropping.
  prefs: []
  type: TYPE_NORMAL
- en: 'Now that we have a good time series model of the existing data, we can produce
    a forecast of the next three years and plot it:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE24]'
  prefs: []
  type: TYPE_PRE
- en: '![](img/36892259-bcc9-40ab-b060-abcc4cabde7b.png)'
  prefs: []
  type: TYPE_IMG
- en: 'The trend is clearly negative, but as mentioned earlier, it is not a dramatic
    drop-about half a percent a year. We can also look at similar coding from Python
    that could be used as follows. Import all of the Python packages we will be using:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE25]'
  prefs: []
  type: TYPE_PRE
- en: 'Read in the college acceptance to a data frame:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE26]'
  prefs: []
  type: TYPE_PRE
- en: 'Remove the `School` column as Python cannot calculate from strings:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE27]'
  prefs: []
  type: TYPE_PRE
- en: 'Convert the data to sets by year:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE28]'
  prefs: []
  type: TYPE_PRE
- en: 'We see the dataset transposed to our desired shape as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/a7d30ed7-ed83-43eb-943e-d02215fdaa82.png)'
  prefs: []
  type: TYPE_IMG
- en: 'See what the data looks like:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE29]'
  prefs: []
  type: TYPE_PRE
- en: '![](img/da35730e-65ed-43af-803a-1c2ff0a54640.png)'
  prefs: []
  type: TYPE_IMG
- en: We see the same slight downtrend for acceptance.
  prefs: []
  type: TYPE_NORMAL
- en: Using Holt-Winters forecasting in Python was problematic as it required transforming
    the data further. Overall, it is much more complicated to do the same processing
    that was straightforward in R in the preceding section.
  prefs: []
  type: TYPE_NORMAL
- en: Predicting airplane arrival time
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: R has built-in functionality for splitting up a data frame between training
    and testing sets, building a model based on the training set, predicting results
    using the model and the testing set, and then visualizing how well the model is
    working.
  prefs: []
  type: TYPE_NORMAL
- en: For this example, I am using airline arrival and departure times versus scheduled
    arrival and departure times from [http://stat-computing.org/dataexpo/2009/the-data.html](http://stat-computing.org/dataexpo/2009/the-data.html)
    for 2008\. The dataset is distributed as a `.bz2` file that unpacks into a CSV
    file. I like this dataset, as the initial row count is over 7 million and it all
    works nicely in Jupyter.
  prefs: []
  type: TYPE_NORMAL
- en: 'We first read in the airplane data and display a summary. There are additional
    columns in the dataset that we are not using:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE30]'
  prefs: []
  type: TYPE_PRE
- en: 'Many of the data points have `NA` values. We need to remove these in order
    to build an accurate model:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE31]'
  prefs: []
  type: TYPE_PRE
- en: 'Let''s create our partitions:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE32]'
  prefs: []
  type: TYPE_PRE
- en: 'Let''s build our model of the arrival time (`ArrTime`) based on the fields:'
  prefs: []
  type: TYPE_NORMAL
- en: '`CRSArrTime`: Scheduled arrival time'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`ArrDelay`: Arrival delay'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`DepDelay`: Departure delay'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`Diverted`: Whether the plane used a diverted route'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`CarrierDelay`: Delay by the carrier systems'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`WeatherDelay`: Delay due to weather'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`NASDelay`: Delay due to NAS'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`SecurityDelay`: Delay due to security'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`LateAircraftDelay`: Plane arrived late due to other delay'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '![](img/26026249-083f-40ea-adc1-49a714edff55.png)'
  prefs: []
  type: TYPE_IMG
- en: Two of the data items are just flags (0/1), unfortunately. The greatest predictor
    appears to be the scheduled arrival time. The other various delay factors have
    small effects. I think it just feels as if it's taking an extra 20 minutes for
    a security check or the like; it's a big deal when you are traveling.
  prefs: []
  type: TYPE_NORMAL
- en: 'Now that we have a model, let''s use the testing set to make predictions:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE33]'
  prefs: []
  type: TYPE_PRE
- en: 'Plot out the predicted versus actual data to get a sense of the model''s accuracy:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE34]'
  prefs: []
  type: TYPE_PRE
- en: '![](img/80044d12-8cb5-408f-a16c-db4f00043dec.png)'
  prefs: []
  type: TYPE_IMG
- en: Visually, the predictions match up well with the actuals as shown by the almost
    45 degree line. That whole set of predicted points on the lower-right portion
    of the graphic is troublesome. There appears to be many predictions that are well
    below the actuals. There must be additional factors involved, as I would have
    expected all of the data to plot in one area rather than two.
  prefs: []
  type: TYPE_NORMAL
- en: Summary
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this chapter, we first set up R as one of the engines available for a notebook.
    Then we used some rudimentary R to analyze voter demographics for the presidential
    election. We looked at voter registration versus actual voting. Next, we analyzed
    the trend in college admissions. Finally, we looked at using a predictive model
    to determine whether flights would be delayed or not.
  prefs: []
  type: TYPE_NORMAL
- en: In the next chapter, we will look into wrangling data in different ways under
    Jupyter.
  prefs: []
  type: TYPE_NORMAL
