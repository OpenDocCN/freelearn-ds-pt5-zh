<html><head></head><body><div id="sbo-rt-content" class="calibre1"><div class="calibre2" title="Chapter 8. Network Analysis"><div class="titlepage"><div class="calibre2"><div class="calibre2"><h1 class="title"><a id="ch08" class="pcalibre pcalibre3 pcalibre1 calibre8 pcalibre2"/>Chapter 8. Network Analysis</h1></div></div></div><div class="calibre2"><table border="0" width="100%" cellspacing="0" cellpadding="0" class="blockquote1" summary="Block quote"><tr class="calibre17"><td class="calibre18"> </td><td class="calibre18"><p class="calibre19"><span class="strong1"><em class="calibre13">"The enemy of my enemy is my friend."</em></span></p></td><td class="calibre18"> </td></tr><tr class="calibre17"><td class="calibre18"> </td><td colspan="2" class="calibre20">--<span class="strong1"><span class="strong1"><em class="calibre13">Ancient proverb</em></span></span></td></tr></table></div><p class="calibre11">This chapter concerns itself with graphs in the mathematical rather than the visual sense. A graph is simply a set of vertices connected by the edges and the simplicity of this abstraction means that graphs are everywhere. They are an effective model for structures as diverse as the hyperlink structure of the web, the physical structure of the internet, and all sorts of networks: roads, telecommunications, and social networks.</p><p class="calibre11">Thus, network analysis <a id="id1047" class="calibre4 pcalibre3 pcalibre pcalibre1 pcalibre2"/>is hardly new, but it has become particularly popular with the rise of social network analysis. Among the largest sites on the web are social networks, and Google, Facebook, Twitter, and LinkedIn all make use of large-scale graph processing to mine their users' data. The huge importance of targeted advertising for the monetization of websites means that there is a large financial reward for companies that effectively infer internet users' interests.</p><p class="calibre11">In this chapter, we'll use <a id="id1048" class="calibre4 pcalibre3 pcalibre pcalibre1 pcalibre2"/>publicly available Twitter data to demonstrate the principles of network analysis. We'll apply pattern matching techniques such as triangle counting to look for a structure within the graph and apply whole-graph processing algorithms such as label propagation and PageRank to tease out the network structure of the graph. Ultimately, we'll use these techniques to identify the interests of a set of Twitter communities from their most influential members. We'll do all of this using Spark and a library called GraphX which uses the Spark distributed computation model to process very large graphs.</p><p class="calibre11">But before we scale up, we'll begin our exploration of graphs by considering a different sort of problem: that of graph traversal. For this, we'll make use of the Clojure library Loom.</p><div class="calibre2" title="Download the data"><div class="titlepage"><div class="calibre2"><div class="calibre2"><h1 class="title2"><a id="ch08lvl1sec130" class="pcalibre pcalibre3 pcalibre1 calibre8 pcalibre2"/>Download the data</h1></div></div></div><p class="calibre11">This chapter makes <a id="id1049" class="calibre4 pcalibre3 pcalibre pcalibre1 pcalibre2"/>use of the data of follower data from the Twitter social network. The data is provided as a part of the Stanford Large Network <a id="id1050" class="calibre4 pcalibre3 pcalibre pcalibre1 pcalibre2"/>Dataset Collection. You can download the Twitter data from <a class="calibre4 pcalibre3 pcalibre pcalibre1 pcalibre2" href="https://snap.stanford.edu/data/egonets-Twitter.html">https://snap.stanford.edu/data/egonets-Twitter.html</a>.</p><p class="calibre11">We'll be making use of both the <code class="literal">twitter.tar.gz</code> file and the <code class="literal">twitter_combined.txt.gz</code> files. Both of these files should be downloaded and decompressed inside the sample code's data directory.</p><div class="sidebar" title="Note"><div class="inner"><h3 class="title4"><a id="note72" class="pcalibre pcalibre3 pcalibre1 calibre8 pcalibre2"/>Note</h3><p class="calibre22">The sample code for this chapter is available at <a class="calibre4 pcalibre3 pcalibre pcalibre1 pcalibre2" href="https://github.com/clojuredatascience/ch8-network-analysis">https://github.com/clojuredatascience/ch8-network-analysis</a>.</p></div></div><p class="calibre11">As usual, a script <a id="id1051" class="calibre4 pcalibre3 pcalibre pcalibre1 pcalibre2"/>has been provided that will do this for you. You can run it by executing the following command line from within the project directory:</p><div class="calibre2"><pre class="programlisting">
<span class="strong1"><strong class="calibre12">script/download-data.sh</strong></span>
</pre></div><p class="calibre11">If you'd like to run this chapter's examples, make sure you download the data before continuing.</p><div class="calibre2" title="Inspecting the data"><div class="titlepage"><div class="calibre2"><div class="calibre2"><h2 class="title5"><a id="ch08lvl2sec171" class="pcalibre pcalibre3 pcalibre1 calibre8 pcalibre2"/>Inspecting the data</h2></div></div></div><p class="calibre11">Let's look at <a id="id1052" class="calibre4 pcalibre3 pcalibre pcalibre1 pcalibre2"/>one of the files in the Twitter directory, specifically the <code class="literal">twitter/98801140.edges</code> file. If you open it in a text editor, you'll see that each line of the file consists of a pair of integers separated by a space. The data is in what's known as an edge list format. It's one of the two primary ways of storing graphs (the other being the <a id="id1053" class="calibre4 pcalibre3 pcalibre pcalibre1 pcalibre2"/>adjacency list format, which we'll come to later). The following code uses Clojure's <code class="literal">line-seq</code> function to read the file one line at a time and convert it into a tuple:</p><div class="calibre2"><pre class="programlisting">(defn to-long [l]
  (Long/parseLong l))

(defn line-&gt;edge [line]
  (-&gt;&gt; (str/split line #" ")
       (mapv to-long)))

(defn load-edges [file]
  (-&gt;&gt; (io/resource file)
       (io/reader)
       (line-seq)
       (map line-&gt;edge)))

(defn ex-8-1 []
  (load-edges "twitter/98801140.edges"))</pre></div><p class="calibre11">If you execute <code class="literal">(ex-8-1)</code> in the REPL or run the following on the command line, you should see the following sequence:</p><div class="calibre2"><pre class="programlisting">
<span class="strong1"><strong class="calibre12">lein run –e 8.1</strong></span>
<span class="strong1"><strong class="calibre12">;;([100873813 3829151] [35432131 3829151] [100742942 35432131]</strong></span>
<span class="strong1"><strong class="calibre12">;;  [35432131 27475761] [27475761 35432131])</strong></span>
</pre></div><p class="calibre11">This simple <a id="id1054" class="calibre4 pcalibre3 pcalibre pcalibre1 pcalibre2"/>sequence of pairs of numbers, each representing an edge, is already enough to represent the essence of the graph. It's not intuitive to see how the edges relate to each other, so let's visualize it.</p></div><div class="calibre2" title="Visualizing graphs with Loom"><div class="titlepage"><div class="calibre2"><div class="calibre2"><h2 class="title5"><a id="ch08lvl2sec172" class="pcalibre pcalibre3 pcalibre1 calibre8 pcalibre2"/>Visualizing graphs with Loom</h2></div></div></div><p class="calibre11">For the first <a id="id1055" class="calibre4 pcalibre3 pcalibre pcalibre1 pcalibre2"/>half of this chapter, we'll be using Loom (<a class="calibre4 pcalibre3 pcalibre pcalibre1 pcalibre2" href="https://github.com/aysylu/loom">https://github.com/aysylu/loom</a>) to process our graphs. Loom defines an API to create and manipulate graphs. It also contains many built-in graph traversal <a id="id1056" class="calibre4 pcalibre3 pcalibre pcalibre1 pcalibre2"/>algorithms. We'll come to these shortly.</p><p class="calibre11">Firstly, we'll want to <a id="id1057" class="calibre4 pcalibre3 pcalibre pcalibre1 pcalibre2"/>visualize our graph. For this, Loom relies on a <a id="id1058" class="calibre4 pcalibre3 pcalibre pcalibre1 pcalibre2"/>system-level library called GraphViz. If you like to be able to replicate many of the images in this chapter, you'll need to install GraphViz now. If you're not sure that you have it installed, try running the following on the command line:</p><div class="calibre2"><pre class="programlisting">
<span class="strong1"><strong class="calibre12">dot –V</strong></span>
</pre></div><div class="sidebar" title="Note"><div class="inner"><h3 class="title6"><a id="note73" class="pcalibre pcalibre3 pcalibre1 calibre8 pcalibre2"/>Note</h3><p class="calibre22">GraphViz is <a id="id1059" class="calibre4 pcalibre3 pcalibre pcalibre1 pcalibre2"/>available from <a class="calibre4 pcalibre3 pcalibre pcalibre1 pcalibre2" href="http://graphviz.org/">http://graphviz.org/</a> and there are installers for Linux, MacOS, and Windows. GraphViz isn't a requirement to run all the examples in this chapter, just the ones that visualize the graphs.</p></div></div><p class="calibre11">Loom is able to create a graph from a sequence of edges like the ones we have when we apply the <code class="literal">loom/graph</code> function to the sequence. We'll require <code class="literal">loom.graph</code> as <code class="literal">loom</code> and <code class="literal">loom.io</code> as <code class="literal">lio</code> in the following examples. If you have GraphViz installed, run the following example:</p><div class="calibre2"><pre class="programlisting">(defn ex-8-2 []
  (-&gt;&gt; (load-edges "twitter/98801140.edges")
       (apply loom/graph)
       (lio/view)))</pre></div><p class="calibre11">You should see a result like the following schematic representation:</p><div class="mediaobject"><img src="Images/7180OS_08_100.jpg" alt="Visualizing graphs with Loom" class="calibre324"/></div><p class="calibre11">Depending on your version of GraphViz, you may not get exactly the same layout as the previous version, but it doesn't matter. The relative positions of the nodes and the edges in the image aren't important. The only important fact about the graph is which nodes are connected to which other nodes.</p><p class="calibre11">As a Clojure programmer, you're familiar with tree structures as the nested structure of S-expressions and you've probably noticed that this graph looks a lot like a tree. In fact, a tree is just a special <a id="id1060" class="calibre4 pcalibre3 pcalibre pcalibre1 pcalibre2"/>kind of graph: one that contains no loops. We refer to such graphs as <span class="strong1"><strong class="calibre12">acyclic</strong></span>.</p><p class="calibre11">In this graph there <a id="id1061" class="calibre4 pcalibre3 pcalibre pcalibre1 pcalibre2"/>are only four edges, whereas there were five in the edge list we saw in the first example. This is because edges can be <a id="id1062" class="calibre4 pcalibre3 pcalibre pcalibre1 pcalibre2"/>directed. They go from a node to another <a id="id1063" class="calibre4 pcalibre3 pcalibre pcalibre1 pcalibre2"/>node. We can load directed graphs with Loom using the <code class="literal">loom/digraph</code> function:</p><div class="calibre2"><pre class="programlisting">(defn ex-8-3 []
  (-&gt;&gt; (load-edges "twitter/98801140.edges")
       (apply loom/digraph)
       (lio/view)))</pre></div><p class="calibre11">This code generates the following image:</p><div class="mediaobject"><img src="Images/7180OS_08_110.jpg" alt="Visualizing graphs with Loom" class="calibre325"/></div><p class="calibre11">Notice how the act of adding directions to our edges has fundamentally altered the way we read the graph. In particular, the graph is clearly no longer a tree. Directed graphs are extremely important in cases where we want to represent an action that's performed on something by something else.</p><p class="calibre11">For example, in Twitter's social graph, an account may follow one account, but the act may not be reciprocal. Using Twitter's terminology, we can refer to either the followers or the friends of an account. A follow represents an outgoing edge, whereas a friend is an incoming edge. In the previous graph, for example, account <span class="strong1"><strong class="calibre12">382951</strong></span> has two followers: accounts <span class="strong1"><strong class="calibre12">35432131</strong></span> and <span class="strong1"><strong class="calibre12">100873813</strong></span>.</p><p class="calibre11">There are now two edges between nodes <span class="strong1"><strong class="calibre12">27475761</strong></span> and <span class="strong1"><strong class="calibre12">35432131</strong></span>. This means that it's possible to get from one node back to the other. We call this a cycle. The technical term for a graph such as the earlier one is a directed, <span class="strong1"><strong class="calibre12">cyclic</strong></span> graph.</p><div class="sidebar" title="Note"><div class="inner"><h3 class="title6"><a id="note74" class="pcalibre pcalibre3 pcalibre1 calibre8 pcalibre2"/>Note</h3><p class="calibre22">A cycle in a <a id="id1064" class="calibre4 pcalibre3 pcalibre pcalibre1 pcalibre2"/>graph means that it's possible to get back to a node by moving only in the direction of edges. If a graph contains no such loops, then the graph is said to be acyclic. A <span class="strong1"><strong class="calibre12">Directed </strong></span><a id="id1065" class="calibre4 pcalibre3 pcalibre pcalibre1 pcalibre2"/><span class="strong1"><strong class="calibre12">Acyclic Graph</strong></span> (<span class="strong1"><strong class="calibre12">DAG</strong></span>), is a model for a huge variety of hierarchical or ordered phenomena such as dependency graphs, family trees, and file system hierarchies.</p></div></div><p class="calibre11">We've seen that graphs <a id="id1066" class="calibre4 pcalibre3 pcalibre pcalibre1 pcalibre2"/>can be directed or undirected. The third <a id="id1067" class="calibre4 pcalibre3 pcalibre pcalibre1 pcalibre2"/>main type of graph is the <span class="strong1"><strong class="calibre12">weighted</strong></span> graph. A weight may be usefully associated with an edge to represent the strength of a connection between two nodes. For example, if the graph represents a social network, the weight between two <a id="id1068" class="calibre4 pcalibre3 pcalibre pcalibre1 pcalibre2"/>accounts might be the strength of their connection (for example, their frequency of communication).</p><p class="calibre11">We can load a weighted graph in <code class="literal">loom</code> with either the <code class="literal">loom/weighted-graph</code> or <code class="literal">loom/weighted-digraph</code> functions:</p><div class="calibre2"><pre class="programlisting">(defn ex-8-4 []
  (-&gt;&gt; (load-edges "twitter/98801140.edges")
       (apply loom/weighted-digraph)
       (lio/view)))</pre></div><p class="calibre11">Our input graph doesn't actually specify the weight of the edges. Loom's default weight for all the edges is <span class="strong1"><strong class="calibre12">1</strong></span>.</p><div class="mediaobject"><img src="Images/7180OS_08_120.jpg" alt="Visualizing graphs with Loom" class="calibre326"/></div><p class="calibre11">Another aspect in which graphs can differ is whether its vertices and edges are typed, representing different entities or connections between them. For example, the Facebook graph contains many types of entities: notably "pages" and "people". People can "like" the pages, but they <a id="id1069" class="calibre4 pcalibre3 pcalibre pcalibre1 pcalibre2"/>can't "like" other people. In <a id="id1070" class="calibre4 pcalibre3 pcalibre pcalibre1 pcalibre2"/>heterogeneous graphs where nodes of type "A" are always connected to type "B" and vice versa (but never to each other), the graph is said to be <a id="id1071" class="calibre4 pcalibre3 pcalibre pcalibre1 pcalibre2"/><span class="strong1"><strong class="calibre12">bipartite</strong></span>. Bipartite graphs can be represented as two <a id="id1072" class="calibre4 pcalibre3 pcalibre pcalibre1 pcalibre2"/>disjoint sets, where nodes in one set only ever link to the nodes in the other set.</p></div></div></div></div>



  
<div id="sbo-rt-content" class="calibre1"><div class="calibre2" title="Graph traversal with Loom"><div class="titlepage"><div class="calibre2"><div class="calibre2"><h1 class="title2"><a id="ch08lvl1sec131" class="pcalibre pcalibre3 pcalibre1 calibre8 pcalibre2"/>Graph traversal with Loom</h1></div></div></div><p class="calibre11">Traversal <a id="id1073" class="calibre4 pcalibre3 pcalibre pcalibre1 pcalibre2"/>algorithms concern themselves with the ways of exploring the <a id="id1074" class="calibre4 pcalibre3 pcalibre pcalibre1 pcalibre2"/>graph in a systematic way. Given the huge variety of phenomena that can be modeled with graphs, such algorithms could have a huge variety of uses.</p><p class="calibre11">The algorithms we'll consider in the next few sections concern some of the most common tasks such as:</p><div class="calibre2"><ul class="itemizedlist"><li class="listitem">Determining whether a path exists that traces each edge exactly once</li><li class="listitem">Determining the shortest path between two vertices</li><li class="listitem">Determining the shortest tree that connects all the vertices</li></ul></div><p class="calibre11">If the graph in question represented the road network covered by a delivery driver's round, the vertices could represent intersections. Finding a path that traces each edge exactly once would be the way a delivery driver would travel all the roads without doubling back or passing the same addresses twice. The shortest path between the two vertices would be the most efficient way to navigate from one address to the next delivery. Finally, the shortest tree connecting all the vertices would be the most effective way to connect all of the <a id="id1075" class="calibre4 pcalibre3 pcalibre pcalibre1 pcalibre2"/>vertices: perhaps, to lay a roadside power line for the lights at each intersection.</p><div class="calibre2" title="The seven bridges of Königsberg"><div class="titlepage"><div class="calibre2"><div class="calibre2"><h2 class="title5"><a id="ch08lvl2sec173" class="pcalibre pcalibre3 pcalibre1 calibre8 pcalibre2"/>The seven bridges of Königsberg</h2></div></div></div><p class="calibre11">The city of <a id="id1076" class="calibre4 pcalibre3 pcalibre pcalibre1 pcalibre2"/>Königsberg in Prussia (now Kaliningrad, Russia) was set on both sides of the Pregel River, and included two large islands that were connected to each other and the mainland by seven bridges. The Seven bridges of Königsberg is a historically notable problem in mathematics that laid the foundation for graph theory and prefigured the idea of topology. The name Pregel will appear again later in this chapter.</p><div class="mediaobject"><img src="Images/7180OS_08_150.jpg" alt="The seven bridges of Königsberg" class="calibre327"/></div><p class="calibre11">The problem was to find a walk through the city that would cross each bridge once and only once. The islands could not be reached by any route other than the bridges and the bridges had to be crossed completely every time; one could not walk halfway onto the bridge and then turn around and later cross the other half from the other side (though the walk need not start and end at the same spot).</p><p class="calibre11">Euler realized that the problem has no solution: that there could be no non-retracing route via the bridges, and the difficulty led to the development of a technique that established this assertion with mathematical rigor. The only structure of the problem that mattered were the connections between the bridges and landmasses. The essence of the problem could be preserved by representing the bridges as edges in a graph.</p><div class="mediaobject"><img src="Images/7180OS_08_160.jpg" alt="The seven bridges of Königsberg" class="calibre328"/></div><p class="calibre11">Euler observed that (except at the endpoints of the walk) one enters a vertex by one edge and leaves the vertex by a different edge. If every edge has been traversed exactly once, it follows that the number of connecting edges for each node must be even (half of them will have been traversed "inwards" and the other half will have been traversed "outwards").</p><p class="calibre11">Therefore, for an Euler tour to exist in a graph, all the nodes (with the possible exception of the start and end <a id="id1077" class="calibre4 pcalibre3 pcalibre pcalibre1 pcalibre2"/>node) must have an even number of connecting edges. We refer to the number of connecting edges as the degree of the node. Determining whether or not an Euler tour exists in a graph therefore is simply a matter of counting the number of odd-degree vertices. If there are zero or two vertices, then an Euler tour can be constructed from the graph. The following function makes use of two utility functions provided by Loom, <code class="literal">out-degree</code> and <code class="literal">nodes</code>, to check for the presence of an Euler tour:</p><div class="calibre2"><pre class="programlisting">(defneuler-tour? [graph]
  (let [degree (partial loom/out-degree graph)]
    (-&gt;&gt; (loom/nodes graph)
         (filter (comp odd? degree))
         (count)
         (contains? #{0 2}))))</pre></div><p class="calibre11">In this code, we used Loom's <code class="literal">out-degree</code> function to calculate the degree of each node in the graph. We filter just the <code class="literal">odd</code> degree vertices and verify that the count is either <code class="literal">0</code> or <code class="literal">2</code>. If it is, an Euler tour exists.</p></div></div></div>



  
<div id="sbo-rt-content" class="calibre1"><div class="calibre2" title="Breadth-first and depth-first search"><div class="titlepage"><div class="calibre2"><div class="calibre2"><h1 class="title2"><a id="ch08lvl1sec132" class="pcalibre pcalibre3 pcalibre1 calibre8 pcalibre2"/>Breadth-first and depth-first search</h1></div></div></div><p class="calibre11">The previous <a id="id1078" class="calibre4 pcalibre3 pcalibre pcalibre1 pcalibre2"/>example is historically notable, but a more common <a id="id1079" class="calibre4 pcalibre3 pcalibre pcalibre1 pcalibre2"/>desire in graph traversal is to find a node within the graph starting from some other node. There are several ways of addressing this challenge. For unweighted graphs such as our Twitter follow graph, the most common are breadth first and depth first search.</p><p class="calibre11">Breadth first search starts with a particular vertex and then searches each of its neighbors for the target vertex. If the vertex isn't found, it searches each of the neighbor's neighbors in turn, until either the vertex is found or the entire graph has been traversed.</p><p class="calibre11">The following diagram shows the order in which the vertices are traversed, beginning at the top and working <a id="id1080" class="calibre4 pcalibre3 pcalibre pcalibre1 pcalibre2"/>down in tiers, from left to right:</p><div class="mediaobject"><img src="Images/7180OS_08_130.jpg" alt="Breadth-first and depth-first search" class="calibre256"/></div><p class="calibre11">Loom contains a variety of traversal algorithms in the <code class="literal">loom.alg</code> namespace. Let's perform breadth first <a id="id1081" class="calibre4 pcalibre3 pcalibre pcalibre1 pcalibre2"/>search on the same Twitter followers graph we have been studying, which is repeated for convenience:</p><div class="mediaobject"><img src="Images/7180OS_08_135.jpg" alt="Breadth-first and depth-first search" class="calibre326"/></div><p class="calibre11">Breadth-first traversal is provided as the <code class="literal">bf-traverse</code> function. This will return a sequence of vertices in the order that they were visited which will allow us to see how breadth-first search traverses the graph:</p><div class="calibre2"><pre class="programlisting">(defn ex-8-5 []
  (let [graph (-&gt;&gt; (load-edges "twitter/98801140.edges")
                   (apply loom/digraph))]
    (alg/bf-traverse graph 100742942)))

;;(100742942 35432131 27475761 3829151)</pre></div><p class="calibre11">We're using the <code class="literal">bf-traverse</code> function to perform a traversal of the graph, beginning at node <code class="literal">100742942</code>. Notice how the response does not contain the node <code class="literal">100873813</code>. There's no way of traversing the graph to this vertex, following only the direction of the edges. The only way to get to vertex <code class="literal">100742942</code> would be to start there.</p><p class="calibre11">Also, note that <code class="literal">35432131</code> <a id="id1082" class="calibre4 pcalibre3 pcalibre pcalibre1 pcalibre2"/>is only listed once, even though it's connected to both <code class="literal">27475761</code> and <code class="literal">3829151</code>. Loom's implementation of breadth first search maintains a set of the <a id="id1083" class="calibre4 pcalibre3 pcalibre pcalibre1 pcalibre2"/>visited vertices in memory. Once a vertex is visited, it need not be visited again.</p><p class="calibre11">An alternative approach to breadth-first search is depth-first search. This algorithm proceeds immediately to the bottom of the tree and visits the nodes in the order shown in the following diagram:</p><div class="mediaobject"><img src="Images/7180OS_08_140.jpg" alt="Breadth-first and depth-first search" class="calibre267"/></div><p class="calibre11">Loom includes a depth-first search as <code class="literal">pre-traverse</code>:</p><div class="calibre2"><pre class="programlisting">(defn ex-8-6 []
  (let [graph (-&gt;&gt; (load-edges "twitter/98801140.edges")
                   (apply loom/digraph))]
    (alg/pre-traverse graph 100742942)))

;;(100742942 35432131 3829151 27475761)</pre></div><p class="calibre11">The advantage of depth-first search is that it has a much lower memory requirement than breadth-first search, because it's not necessary to store all of the nodes at each tier. This may make it less memory-intensive for large graphs.</p><p class="calibre11">However, depending on the circumstances, either a depth-first or breadth-first search may be more convenient. For <a id="id1084" class="calibre4 pcalibre3 pcalibre pcalibre1 pcalibre2"/>example, if we were traversing a family tree, looking for a <a id="id1085" class="calibre4 pcalibre3 pcalibre pcalibre1 pcalibre2"/>living relative, we could assume that person would be near the bottom of the tree, so a depth-first search may reach the target more quickly. If we were looking for an ancient ancestor, then a depth first search might waste its time checking a large number of more recent relatives and take much longer to reach the target.</p></div></div>



  
<div id="sbo-rt-content" class="calibre1"><div class="calibre2" title="Finding the shortest path"><div class="titlepage"><div class="calibre2"><div class="calibre2"><h1 class="title2"><a id="ch08lvl1sec133" class="pcalibre pcalibre3 pcalibre1 calibre8 pcalibre2"/>Finding the shortest path</h1></div></div></div><p class="calibre11">The algorithms <a id="id1086" class="calibre4 pcalibre3 pcalibre pcalibre1 pcalibre2"/>presented earlier traversed the graph vertex by vertex and returned a lazy sequence of all the nodes in the graph. They were convenient for illustrating the two primary ways of navigating the graph structures. However, a more common task would be to find the shortest path from one vertex to another. This means that we'll be interested only in the sequence of nodes that lie between them.</p><p class="calibre11">If we have an unweighted graph, such as the previous graphs, we'll usually count the distance as the number of "hops": a hop being the step between two neighboring nodes. The shortest path will have the fewest number of hops. Breadth-first search is, in general, a more efficient algorithm to use in this case.</p><p class="calibre11">Loom implements the breadth-first shortest path as the <code class="literal">bf-path</code> function. To demonstrate it, let's load a more complex Twitter graph:</p><div class="calibre2"><pre class="programlisting">(defn ex-8-7 []
  (-&gt;&gt; (load-edges "twitter/396721965.edges")
       (apply loom/digraph)
       (lio/view)))</pre></div><p class="calibre11">This code generates the following graph:</p><div class="mediaobject"><img src="Images/7180OS_08_145.jpg" alt="Finding the shortest path" class="calibre329"/></div><p class="calibre11">Let's see if we can identify the shortest path between the top and bottom nodes: <span class="strong1"><strong class="calibre12">75914648</strong></span> and <span class="strong1"><strong class="calibre12">32122637</strong></span>. There are many paths that the algorithm could return, but we want to identify the path that goes <a id="id1087" class="calibre4 pcalibre3 pcalibre pcalibre1 pcalibre2"/>through points <span class="strong1"><strong class="calibre12">28719244</strong></span> and <span class="strong1"><strong class="calibre12">163629705</strong></span>. This is the one with the fewest hops.</p><div class="calibre2"><pre class="programlisting">(defn ex-8-8 []
  (let [graph (-&gt;&gt; (load-edges "twitter/396721965.edges")
                   (apply loom/digraph))]
    (alg/bf-path graph 75914648 32122637)))

;;(75914648 28719244 163629705 32122637)</pre></div><p class="calibre11">Indeed it does.</p><div class="sidebar" title="Note"><div class="inner"><h3 class="title4"><a id="note75" class="pcalibre pcalibre3 pcalibre1 calibre8 pcalibre2"/>Note</h3><p class="calibre22">Loom also implements a bidirectional breadth-first shortest path algorithm as <code class="literal">bf-path-bi</code>. This searches in parallel from both the source and the destination and may find the shortest path much faster on certain types of graphs.</p></div></div><p class="calibre11">What if the graph is weighted? In this case, the fewest hops might not correspond to the shortest path between two nodes, because this path might be associated with a large weight. In this case, Dijkstra's algorithm is a method to find the shortest cost path between two nodes. The path may take a larger number of hops, but the sum of the edge weights traversed would be the lowest:</p><div class="calibre2"><pre class="programlisting">(defn ex-8-9 []
  (let [graph (-&gt;&gt; (load-edges "twitter/396721965.edges")
                   (apply loom/weighted-digraph))]
    (-&gt; (loom/add-edges graph [28719244 163629705 100])
        (alg/dijkstra-path 75914648 32122637))))

;;(75914648 28719244 31477674 163629705 32122637)</pre></div><p class="calibre11">In this code, we loaded the graph as a weighted digraph and updated the edge between node <code class="literal">28719244</code> and <code class="literal">163629705</code> to have a weight of <code class="literal">100</code>. All the other edges have a default weight of 1. This has the effect of assigning a very high cost to the most direct path, and so an alternative path is found.</p><p class="calibre11">Dijkstra's algorithm is <a id="id1088" class="calibre4 pcalibre3 pcalibre pcalibre1 pcalibre2"/>particularly valuable for route finding. For example, if the graph models the road network, the best route may be the one that takes major roads, rather than the one which takes the fewest number of steps. Or, depending on the time of day and the amount of traffic on the roads, the cost associated with particular routes may change. In this case, Dijkstra's algorithm would be able to determine the best route at any time of the day.</p><div class="sidebar" title="Note"><div class="inner"><h3 class="title4"><a id="note76" class="pcalibre pcalibre3 pcalibre1 calibre8 pcalibre2"/>Note</h3><p class="calibre22">An algorithm called <span class="strong1"><strong class="calibre12">A*</strong></span> (pronounced A-star) optimizes Dijkstra's algorithm by allowing a heuristic function. It's implemented as <code class="literal">alg/astar-path</code> in Loom. The heuristic function returns an expected cost to the destination. Any function can be used as a heuristic as long as it does not over-estimate the true cost. The use of this heuristic allows the A* algorithm to avoid making an exhaustive search of the graph <a id="id1089" class="calibre4 pcalibre3 pcalibre pcalibre1 pcalibre2"/>and thus, it can be much quicker. For more information on A* algorithm, refer to <a class="calibre4 pcalibre3 pcalibre pcalibre1 pcalibre2" href="https://en.wikipedia.org/wiki/A*_search_algorithm">https://en.wikipedia.org/wiki/A*_search_algorithm</a>.</p></div></div><p class="calibre11">Let's continue to consider weighted graphs and ask how we could construct a tree that connects all the nodes with the shortest cost. Such a tree is referred to as the minimum spanning tree.</p><div class="calibre2" title="Minimum spanning trees"><div class="titlepage"><div class="calibre2"><div class="calibre2"><h2 class="title5"><a id="ch08lvl2sec174" class="pcalibre pcalibre3 pcalibre1 calibre8 pcalibre2"/>Minimum spanning trees</h2></div></div></div><p class="calibre11">With the help of the <a id="id1090" class="calibre4 pcalibre3 pcalibre pcalibre1 pcalibre2"/>previous algorithms, we considered how to traverse the graph between two points. However, what if we want to discover a route that connects all the nodes in the graph? In this case, we could use a minimum spanning tree. We can think of a minimum spanning tree as a hybrid of the full-graph traversal algorithms we have considered and the shortest path algorithm we saw recently.</p><p class="calibre11">Minimum spanning trees are particularly useful for weighted graphs. If the weight represents the cost of connecting two vertices, the minimum spanning tree finds the minimum cost of connecting the whole graph. They occur in problems such as network design. If the nodes represent offices, for example, and the edge weights represent the cost of phone lines between offices, the minimum spanning tree will provide the set of phone lines that connect all the offices with the lowest total cost.</p><p class="calibre11">Loom's implementation <a id="id1091" class="calibre4 pcalibre3 pcalibre pcalibre1 pcalibre2"/>of minimum spanning trees makes use of Prim's algorithm and is available as the <code class="literal">prim-mst</code> function:</p><div class="calibre2"><pre class="programlisting">(defn ex-8-10 []
  (let [graph (-&gt;&gt; (load-edges "twitter/396721965.edges")
                   (apply loom/weighted-graph))]
    (-&gt; (alg/prim-mst graph)
        (lio/view))))</pre></div><p class="calibre11">This will return the following graph:</p><div class="mediaobject"><img src="Images/7180OS_08_180.jpg" alt="Minimum spanning trees" class="calibre330"/></div><p class="calibre11">If, once again, we update the edge between vertices <span class="strong1"><strong class="calibre12">28719244</strong></span> and <span class="strong1"><strong class="calibre12">163629705</strong></span> to be 100, we will be able to observe the difference it makes to the minimum spanning tree:</p><div class="calibre2"><pre class="programlisting">(defn ex-8-11 []
  (let [graph (-&gt;&gt; (load-edges "twitter/396721965.edges")
                   (apply loom/weighted-graph))]
    (-&gt; (loom/add-edges graph [28719244 163629705 100])
        (alg/prim-mst)
        (lio/view))))</pre></div><p class="calibre11">This code returns the following chart:</p><div class="mediaobject"><img src="Images/7180OS_08_185.jpg" alt="Minimum spanning trees" class="calibre331"/></div><p class="calibre11">The tree has been <a id="id1092" class="calibre4 pcalibre3 pcalibre pcalibre1 pcalibre2"/>reconfigured to bypass the edge with the highest cost.</p></div><div class="calibre2" title="Subgraphs and connected components"><div class="titlepage"><div class="calibre2"><div class="calibre2"><h2 class="title5"><a id="ch08lvl2sec175" class="pcalibre pcalibre3 pcalibre1 calibre8 pcalibre2"/>Subgraphs and connected components</h2></div></div></div><p class="calibre11">A minimum <a id="id1093" class="calibre4 pcalibre3 pcalibre pcalibre1 pcalibre2"/>spanning tree can only be specified for <a id="id1094" class="calibre4 pcalibre3 pcalibre pcalibre1 pcalibre2"/><span class="strong1"><em class="calibre13">connected</em></span> graphs, where all the nodes are connected to all the others by at least one path. Where the graphs are not connected, we're clearly unable to construct a minimum spanning tree (although we could construct a minimum spanning forest instead).</p><div class="mediaobject"><img src="Images/7180OS_08_190.jpg" alt="Subgraphs and connected components" class="calibre332"/></div><p class="calibre11">If a graph contains a set of subgraphs that are internally connected but are not connected to each other, then the subgraphs are referred to as connected components. We can observe the connected components if we load a still more complicated network:</p><div class="calibre2"><pre class="programlisting">(defn ex-8-12 []
  (-&gt;&gt; (load-edges "twitter/15053535.edges")
       (apply loom/graph)
       (lio/view)))</pre></div><p class="calibre11">This example <a id="id1095" class="calibre4 pcalibre3 pcalibre pcalibre1 pcalibre2"/>generates the following image:</p><div class="mediaobject"><img src="Images/7180OS_08_200.jpg" alt="Subgraphs and connected components" class="calibre333"/></div><p class="calibre11">Thanks to the layout of the graph, we can easily see that there are three connected components and Loom <a id="id1096" class="calibre4 pcalibre3 pcalibre pcalibre1 pcalibre2"/>will calculate these for us with the <code class="literal">connected-components</code> function. We'll see later in this chapter how we can implement an algorithm to calculate this for ourselves:</p><div class="calibre2"><pre class="programlisting">(defn ex-8-13 []
  (-&gt;&gt; (load-edges "twitter/15053535.edges")
       (apply loom/graph)
       (alg/connected-components)))

;;[[30705196 58166411] [25521487 34173635 14230524 52831025 30973
;; 55137311 50201146 19039286 20978103 19562228 46186400
;;14838506 14596164 14927205] [270535212 334927007]]</pre></div><p class="calibre11">A directed graph is strongly connected if there is a path from every node to every other node. A directed graph is weakly connected if, only treating all the edges as being undirected, there is a path from every node to every other node.</p><div class="mediaobject"><img src="Images/7180OS_08_210.jpg" alt="Subgraphs and connected components" class="calibre322"/></div><p class="calibre11">Let's load the <a id="id1097" class="calibre4 pcalibre3 pcalibre pcalibre1 pcalibre2"/>same graph as a directed graph to see if there are any strongly connected components:</p><div class="calibre2"><pre class="programlisting">(defn ex-8-14 []
  (-&gt;&gt; (load-edges "twitter/15053535.edges")
       (apply loom/digraph)
       (lio/view)))</pre></div><p class="calibre11">This example <a id="id1098" class="calibre4 pcalibre3 pcalibre pcalibre1 pcalibre2"/>generates the following image:</p><div class="mediaobject"><img src="Images/7180OS_08_220.jpg" alt="Subgraphs and connected components" class="calibre334"/></div><p class="calibre11">There are three weakly connected components as before. It's quite difficult to visually determine how many strongly connected components there are by just looking at the graph. Kosaraju's algorithm will calculate the number of strongly connected components in a graph. It's implemented by Loom as the <code class="literal">alg/scc</code> function:</p><div class="calibre2"><pre class="programlisting">(defn ex-8-15 []
  (-&gt;&gt; (load-edges "twitter/15053535.edges")
       (apply loom/digraph)
       (alg/scc)
       (count)))

;; 13</pre></div><p class="calibre11">Kosaraju's algorithm <a id="id1099" class="calibre4 pcalibre3 pcalibre pcalibre1 pcalibre2"/>makes use of the interesting property <a id="id1100" class="calibre4 pcalibre3 pcalibre pcalibre1 pcalibre2"/>that the transpose graph—one with all the edges reversed—has exactly the same number of connected components as the input graph. The response contains all the strongly connected components (even the degenerate cases containing only one node) as sequence vectors. If we sort by length in descending order the first component will be the largest:</p><div class="calibre2"><pre class="programlisting">(defn ex-8-16 []
  (-&gt;&gt; (load-edges "twitter/15053535.edges")
       (apply loom/digraph)
       (alg/scc)
       (sort-by count &gt;)
       (first)))

;;[14927205 14596164 14838506]</pre></div><p class="calibre11">The largest strongly connected component is merely three nodes.</p></div><div class="calibre2" title="SCC and the bow-tie structure of the web"><div class="titlepage"><div class="calibre2"><div class="calibre2"><h2 class="title5"><a id="ch08lvl2sec176" class="pcalibre pcalibre3 pcalibre1 calibre8 pcalibre2"/>SCC and the bow-tie structure of the web</h2></div></div></div><p class="calibre11">Weakly and <a id="id1101" class="calibre4 pcalibre3 pcalibre pcalibre1 pcalibre2"/>strongly connected components can provide an <a id="id1102" class="calibre4 pcalibre3 pcalibre pcalibre1 pcalibre2"/>informative way of understanding the structure of a directed graph. For example, research performed on the link structure of the internet has shown that strongly connected components can grow very large indeed.</p><div class="sidebar" title="Note"><div class="inner"><h3 class="title6"><a id="note77" class="pcalibre pcalibre3 pcalibre1 calibre8 pcalibre2"/>Note</h3><p class="calibre22">The paper from which the following numbers are quoted is available online at <a class="calibre4 pcalibre3 pcalibre pcalibre1 pcalibre2" href="http://www9.org/w9cdrom/160/160.html">http://www9.org/w9cdrom/160/160.html</a>.</p></div></div><p class="calibre11">Although the following numbers are from a study undertaken in 1999 and so they are therefore very out of date, we can see that at the center of the web was one large strongly connected component consisting of 56 million pages. This meant that from any page within the strongly connected component, you could reach any other within the strongly connected component only by following the outbound hyperlinks.</p><div class="mediaobject"><img src="Images/7180OS_08_230.jpg" alt="SCC and the bow-tie structure of the web" class="calibre245"/></div><p class="calibre11">44 million pages <a id="id1103" class="calibre4 pcalibre3 pcalibre pcalibre1 pcalibre2"/>linked into the SCC, but were not linked from it, and 44 million pages were linked from the SCC, but did not link back. Only very <a id="id1104" class="calibre4 pcalibre3 pcalibre pcalibre1 pcalibre2"/>few links bypassed the SCC entirely (the "tubes" in the preceding illustration).</p></div></div></div>



  
<div id="sbo-rt-content" class="calibre1"><div class="calibre2" title="Whole-graph analysis"><div class="titlepage"><div class="calibre2"><div class="calibre2"><h1 class="title2"><a id="ch08lvl1sec134" class="pcalibre pcalibre3 pcalibre1 calibre8 pcalibre2"/>Whole-graph analysis</h1></div></div></div><p class="calibre11">Let's turn our attention <a id="id1105" class="calibre4 pcalibre3 pcalibre pcalibre1 pcalibre2"/>away from the smaller graphs we've been working with towards the larger graph of followers provided by the <code class="literal">twitter_combined.txt</code> file. This contains over 2.4 million edges and will provide a more interesting sample to work with.</p><p class="calibre11">One of the simplest metrics to determine about a whole graph is its density. For directed graphs, this is defined as the number of edges <span class="strong1"><em class="calibre13">|E|</em></span>, over the number of vertices <span class="strong1"><em class="calibre13">|V|</em></span> multiplied by one less than itself.</p><div class="mediaobject"><img src="Images/7180OS_08_01.jpg" alt="Whole-graph analysis" class="calibre335"/></div><p class="calibre11">For a connected graph (one where every vertex is connected to every other vertex by an edge), the density would be 1. By contrast, a disconnected graph (one with no edges) would have a density of 0. Loom implements graph density as the <code class="literal">alg/density</code> function. Let's calculate the density of the larger Twitter graph:</p><div class="calibre2"><pre class="programlisting">(defn ex-8-17 []
  (-&gt;&gt; (load-edges "twitter_combined.txt")
       (apply loom/digraph)
       (alg/density)
       (double)))

;; 2.675E-4</pre></div><p class="calibre11">This seems very sparse, but bear in mind that a value of 1 would correspond to every account <a id="id1106" class="calibre4 pcalibre3 pcalibre pcalibre1 pcalibre2"/>following every other account, which is clearly not the case on social networks. Some accounts may have many connections, while others may have none at all.</p><p class="calibre11">Let's see how the edges are distributed among nodes. We can re-use Loom's <code class="literal">out-degree</code> function to count the number of outgoing edges from each node and plot a histogram of the distribution using the following code:</p><div class="calibre2"><pre class="programlisting">(defn ex-8-18 []
  (let [graph (-&gt;&gt; (load-edges "twitter_combined.txt")
                   (apply loom/digraph))
        out-degrees (map #(loom/out-degree graph %)
                         (loom/nodes graph))]
    (-&gt; (c/histogram out-degrees :nbins 50
                     :x-label "Twitter Out Degrees")
        (i/view))))</pre></div><p class="calibre11">This generates the following histogram:</p><div class="mediaobject"><img src="Images/7180OS_08_240.jpg" alt="Whole-graph analysis" class="calibre45"/></div><p class="calibre11">The distribution of out-degrees looks a lot like the exponential distribution we first encountered in <a class="calibre4 pcalibre3 pcalibre pcalibre1 pcalibre2" href="ch02.xhtml" title="Chapter 2. Inference">Chapter 2</a>, <span class="strong1"><em class="calibre13">Inference</em></span>. Notice how most people have very few out-degrees, but a handful have over a thousand.</p><p class="calibre11">Let's also plot the <a id="id1107" class="calibre4 pcalibre3 pcalibre pcalibre1 pcalibre2"/>histogram of in-degrees. On Twitter, the in-degree corresponds to the number of followers an account has.</p><div class="mediaobject"><img src="Images/7180OS_08_250.jpg" alt="Whole-graph analysis" class="calibre45"/></div><p class="calibre11">The distribution of in-degrees is even more extreme: the tail extends further to the right than the previous histogram and the first bar is even taller than before. This corresponds to most accounts having very few followers but a handful having several thousand.</p><p class="calibre11">Contrast the previous <a id="id1108" class="calibre4 pcalibre3 pcalibre pcalibre1 pcalibre2"/>histograms to the degree distribution we get when we generate a random graph of edges and nodes. Next, we use Loom's <code class="literal">gen-rand</code> function to generate a random graph with 10,000 nodes and 1,000,000 edges:</p><div class="calibre2"><pre class="programlisting">(defn ex-8-20 []
  (let [graph (generate/gen-rand (loom/graph) 10000 1000000)
        out-degrees (map #(loom/out-degree graph %)
                         (loom/nodes graph))]
    (-&gt; (c/histogram out-degrees :nbins 50
                     :x-label "Random out degrees")
        (i/view))))</pre></div><p class="calibre11">This generates the following histogram:</p><div class="mediaobject"><img src="Images/7180OS_08_260.jpg" alt="Whole-graph analysis" class="calibre45"/></div><p class="calibre11">The random graph <a id="id1109" class="calibre4 pcalibre3 pcalibre pcalibre1 pcalibre2"/>shows that the mean number of out-degrees for a graph of ten thousand vertices connected by a million edges is around 200. The distribution of the degrees is approximately normal. It's very apparent that the Twitter graph hasn't been generated by a random process.</p></div></div>



  
<div id="sbo-rt-content" class="calibre1"><div class="calibre2" title="Scale-free networks"><div class="titlepage"><div class="calibre2"><div class="calibre2"><h1 class="title2"><a id="ch08lvl1sec135" class="pcalibre pcalibre3 pcalibre1 calibre8 pcalibre2"/>Scale-free networks</h1></div></div></div><p class="calibre11">The Twitter degree <a id="id1110" class="calibre4 pcalibre3 pcalibre pcalibre1 pcalibre2"/>histograms are a characteristic of power-law degree distributions. Unlike the normally distributed, randomly generated graph, the Twitter histograms show that a few vertices are connected to a large majority of the edges.</p><div class="sidebar" title="Note"><div class="inner"><h3 class="title4"><a id="note78" class="pcalibre pcalibre3 pcalibre1 calibre8 pcalibre2"/>Note</h3><p class="calibre22">The term "scale-free network" was coined by researchers at the University of Notre Dame in 1999 to describe the structure they observed on the World Wide Web.</p></div></div><p class="calibre11">In the graphs that model human interactions, we'll often observe a power law of connectedness. This is also <a id="id1111" class="calibre4 pcalibre3 pcalibre pcalibre1 pcalibre2"/>called the <span class="strong1"><strong class="calibre12">Zipf</strong></span> scale and it indicates the so-called "law of preferential attachment", where a popular vertex is more likely to develop additional connections. Social media sites are prime examples of this sort of a process, where new users tend to follow already popular users.</p><p class="calibre11">In <a class="calibre4 pcalibre3 pcalibre pcalibre1 pcalibre2" href="ch02.xhtml" title="Chapter 2. Inference">Chapter 2</a>, <span class="strong1"><em class="calibre13">Inference</em></span>, we identified the exponential distribution by looking for a straight line when the <a id="id1112" class="calibre4 pcalibre3 pcalibre pcalibre1 pcalibre2"/>data was plotted on log-linear axes. We can most easily determine a power-law relationship by looking for a straight line on log-log axes:</p><div class="calibre2"><pre class="programlisting">(defn ex-8-21 []
  (let [graph (-&gt;&gt; (load-edges "twitter_combined.txt")
                   (apply loom/digraph))
        out-degrees (map #(loom/out-degree graph %)
                         (loom/nodes graph))
        points (frequencies out-degrees)]
    (-&gt; (c/scatter-plot (keys points) (vals points))
        (c/set-axis :x (c/log-axis :label "log(out-degree)"))
        (c/set-axis :y (c/log-axis :label "log(frequency)"))
        (i/view))))</pre></div><p class="calibre11">This code returns the following plot:</p><div class="mediaobject"><img src="Images/7180OS_08_270.jpg" alt="Scale-free networks" class="calibre45"/></div><p class="calibre11">Although not perfectly linear, the earlier chart is enough to show that a power law distribution is at work in the Twitter graph. If we visualize the connections between the nodes and edges in the <a id="id1113" class="calibre4 pcalibre3 pcalibre pcalibre1 pcalibre2"/>graph, scale-free networks will be recognizable because of their characteristic "clustered" shape. Popular vertices tend to have a halo of other vertices around them.</p><div class="mediaobject"><img src="Images/7180OS_08_280.jpg" alt="Scale-free networks" class="calibre336"/></div><p class="calibre11">Scaling up to the full Twitter combined dataset has caused the previous examples to run much more slowly, even though this graph is tiny in comparison to many social networks. The rest of this chapter will <a id="id1114" class="calibre4 pcalibre3 pcalibre pcalibre1 pcalibre2"/>be devoted to a graph library that runs on top of the Spark <a id="id1115" class="calibre4 pcalibre3 pcalibre pcalibre1 pcalibre2"/>framework called <span class="strong1"><strong class="calibre12">GraphX</strong></span>. GraphX expresses many of the algorithms we've covered already this chapter, but can take advantage of the Spark distributed computation model to process much larger graphs.</p></div></div>



  
<div id="sbo-rt-content" class="calibre1"><div class="calibre2" title="Distributed graph computation with GraphX"><div class="titlepage"><div class="calibre2"><div class="calibre2"><h1 class="title2"><a id="ch08lvl1sec136" class="pcalibre pcalibre3 pcalibre1 calibre8 pcalibre2"/>Distributed graph computation with GraphX</h1></div></div></div><p class="calibre11">GraphX (<a class="calibre4 pcalibre3 pcalibre pcalibre1 pcalibre2" href="https://spark.apache.org/graphx/">https://spark.apache.org/graphx/</a>) is a distributed graph processing library that is designed to work with Spark. Like the MLlib library we used in the <a id="id1116" class="calibre4 pcalibre3 pcalibre pcalibre1 pcalibre2"/>previous chapter, GraphX provides a set of abstractions that are built on top of Spark's RDDs. By representing the vertices and edges of a graph as RDDs, GraphX is able to process very large graphs in a scalable way.</p><p class="calibre11">We've seen in previous chapters how to process a large dataset using MapReduce and Hadoop. Hadoop is an example of a data-parallel system: the dataset is divided into groups that are processed in parallel. Spark is also a data-parallel system: RDDs are distributed across the cluster and processed in parallel.</p><div class="mediaobject"><img src="Images/7180OS_08_300.jpg" alt="Distributed graph computation with GraphX" class="calibre337"/></div><p class="calibre11">Data-parallel systems are appropriate ways of scaling data processing when your data closely resembles a table. Graphs, which may have complex internal structure, are not most efficiently represented as tables. Although graphs can be represented as edge lists, as we've seen, processing a graph stored in this way may involve complex joins and excessive data movement around the cluster because of how interconnected the data is.</p><p class="calibre11">The growing scale and significance of graph data has driven the development of numerous new <a id="id1117" class="calibre4 pcalibre3 pcalibre pcalibre1 pcalibre2"/>graph-parallel systems. By restricting the types of computation that can be expressed and introducing techniques to partition and distribute graphs, these systems can efficiently execute sophisticated graph algorithms orders of a magnitude faster than general data-parallel systems.</p><div class="sidebar" title="Note"><div class="inner"><h3 class="title4"><a id="note79" class="pcalibre pcalibre3 pcalibre1 calibre8 pcalibre2"/>Note</h3><p class="calibre22">Several libraries <a id="id1118" class="calibre4 pcalibre3 pcalibre pcalibre1 pcalibre2"/>bring graph-parallel computation to Hadoop, including <a id="id1119" class="calibre4 pcalibre3 pcalibre pcalibre1 pcalibre2"/>Hama, (<a class="calibre4 pcalibre3 pcalibre pcalibre1 pcalibre2" href="https://hama.apache.org/">https://hama.apache.org/</a>) and Giraph (<a class="calibre4 pcalibre3 pcalibre pcalibre1 pcalibre2" href="http://giraph.apache.org/">http://giraph.apache.org/</a>).</p></div></div><p class="calibre11">The GraphX library brings graph-parallel computation to Spark. One of the advantages of using Spark as the engine for graph processing is that its in-memory computation model is well-suited to the iterative nature of many graph algorithms.</p><div class="mediaobject"><img src="Images/7180OS_08_310.jpg" alt="Distributed graph computation with GraphX" class="calibre338"/></div><p class="calibre11">This diagram illustrates the challenge of processing graphs in parallel where the nodes may be interconnected. By processing the data within the graph topology, GraphX avoids excessive data movement and duplication. GraphX extends Spark's RDD abstraction by introducing the <a id="id1120" class="calibre4 pcalibre3 pcalibre pcalibre1 pcalibre2"/>Resilient Distributed Graph, or RDG, and a set of functions to query and transform the graph in a structurally-aware way.</p><div class="calibre2" title="Creating RDGs with Glittering"><div class="titlepage"><div class="calibre2"><div class="calibre2"><h2 class="title5"><a id="ch08lvl2sec177" class="pcalibre pcalibre3 pcalibre1 calibre8 pcalibre2"/>Creating RDGs with Glittering</h2></div></div></div><p class="calibre11">Spark and <a id="id1121" class="calibre4 pcalibre3 pcalibre pcalibre1 pcalibre2"/>GraphX are libraries that are predominantly written in Scala. In this chapter, we'll be using the Clojure library Glittering (<a class="calibre4 pcalibre3 pcalibre pcalibre1 pcalibre2" href="https://github.com/henrygarner/glittering">https://github.com/henrygarner/glittering</a>) to interact with GraphX. In much <a id="id1122" class="calibre4 pcalibre3 pcalibre pcalibre1 pcalibre2"/>the same way that Sparkling provides a thin Clojure wrapper around Spark, Glittering provides a thin Clojure wrapper around GraphX.</p><p class="calibre11">Our first task <a id="id1123" class="calibre4 pcalibre3 pcalibre pcalibre1 pcalibre2"/>will be to create a graph. Graphs can be instantiated in two ways: either by supplying two RDD representations (one containing the edges and the other the vertices), or simply by supplying an RDD of edges. If only the edges are supplied, then we will supply a default value for each node. We'll see how to do this next.</p><p class="calibre11">Since GraphX leverages Spark, every job requires an associated Spark context. In the previous chapter, we used Sparkling's <code class="literal">sparkling.conf/conf</code> default configuration. However, in this chapter, we'll use the default configuration provided by Glittering. Glittering extends Sparkling's defaults with the configuration necessary to serialize and deserialize GraphX types. In the following code, we'll include <code class="literal">glittering.core</code> as <code class="literal">g</code> and create a small graph of only three edges using Glittering's graph constructor:</p><div class="calibre2"><pre class="programlisting"> (defn ex-8-22 []
  (spark/with-context sc (-&gt; (g/conf)
                             (conf/master "local")
                             (conf/app-name "ch8"))
    (let [vertices [[1 "A"] [2 "B"] [3 "C"]]
          edges [(g/edge 1 2 0.5)
                 (g/edge 2 1 0.5)
                 (g/edge 3 1 1.0)]]
      (g/graph (spark/parallelize sc vertices)
               (spark/parallelize sc edges)))))

;; #&lt;GraphImpl org.apache.spark.graphx.impl.GraphImpl@adb2324&gt;</pre></div><p class="calibre11">The result is a GraphX graph object. Note that edges are provided as an RDD of <code class="literal">g/edges</code>: the <code class="literal">g/edge </code>function will create an edge type given a source ID, destination ID, and an optional edge attribute. Edge attributes can be any object that Spark can serialize. Note that vertices can have attributes too ("A", "B", and "C" in the previous example).</p><p class="calibre11">An alternative <a id="id1124" class="calibre4 pcalibre3 pcalibre pcalibre1 pcalibre2"/>way of constructing a graph is to use the <code class="literal">g/graph-from-edges</code> constructor. This will return a graph based solely on the RDD <a id="id1125" class="calibre4 pcalibre3 pcalibre pcalibre1 pcalibre2"/>of edges. The Twitter data is supplied in the edge list format, so this is the function we'll use to load it. In the next code, we'll load the full <code class="literal">twitter_combined.txt</code> as a text file and create an edge list from it by mapping over the lines of the file. From each line, we'll create an edge of weight 1.0:</p><div class="calibre2"><pre class="programlisting">(defn line-&gt;edge [line]
  (let [[from to] (map to-long (str/split line #" "))]
    (g/edge from to 1.0)))

(defn load-edgelist [sc path]
  (let [edges (-&gt;&gt; (spark/text-file sc path)
                   (spark/map line-&gt;edge))]
    (g/graph-from-edges edges 1.0)))

(defn ex-8-23 []
  (spark/with-context sc (-&gt; (g/conf)
                             (conf/master "local")
                             (conf/app-name "ch8"))
    (load-edgelist sc "data/twitter_combined.txt")))

;;#&lt;GraphImpl org.apache.spark.graphx.impl.GraphImpl@c63044d&gt;</pre></div><p class="calibre11">The second argument to the <code class="literal">graph-from-edges</code> function is a default value to use as each vertex's <a id="id1126" class="calibre4 pcalibre3 pcalibre pcalibre1 pcalibre2"/>attribute: the vertex attributes can't be provided in an edge list.</p></div><div class="calibre2" title="Measuring graph density with triangle counting"><div class="titlepage"><div class="calibre2"><div class="calibre2"><h2 class="title5"><a id="ch08lvl2sec178" class="pcalibre pcalibre3 pcalibre1 calibre8 pcalibre2"/>Measuring graph density with triangle counting</h2></div></div></div><p class="calibre11">GraphX <a id="id1127" class="calibre4 pcalibre3 pcalibre pcalibre1 pcalibre2"/>comes with a small selection <a id="id1128" class="calibre4 pcalibre3 pcalibre pcalibre1 pcalibre2"/>of built-in graph algorithms, which Glittering makes available in the <code class="literal">glittering.algorithms</code> namespace. Before covering Glittering's API in more detail, let's run one of these on the Twitter follows graph. We'll show how to use Glittering to create a simple graph processing job, and then show how to use more of Glittering's API to implement the algorithm ourselves using GraphX's graph-parallel primitives.</p><p class="calibre11">Triangle counting is an algorithm to measure the density of the graph in the vicinity of each node. It's similar in principle to counting degrees, but also accounts for how well our neighbors are connected to each other. We can picture the process using this very simple graph:</p><div class="mediaobject"><img src="Images/7180OS_08_330.jpg" alt="Measuring graph density with triangle counting" class="calibre339"/></div><p class="calibre11">In this example, we can see that vertices A, B, and C all participate in one triangle, and vertex D participates in none. Both B and C follow A, but C also follows B. In the context of social network analysis, triangle counting is a measure of how many friends of friends also know each other. In tight-knit communities, we would expect the number of triangles to be high.</p><p class="calibre11">Triangle counting is already implemented by GraphX and is accessible as the <code class="literal">triangle-count</code> function in the <code class="literal">glittering.algorithms</code> namespace. Before we use this particular algorithm, GraphX requires us to do two things:</p><div class="calibre2"><ol class="orderedlist1"><li class="listitem2">Point the edges in the "canonical" direction.</li><li class="listitem2">Ensure the graph is partitioned.</li></ol></div><p class="calibre11">Both of these steps are the artifacts of the way triangle counting is implemented in GraphX. GraphX allows there to be multiple edges between two vertices, but triangle counting seeks only to count the distinct edges. The previous two steps ensure that GraphX is able to efficiently calculate the distinct edges before performing the algorithm.</p><p class="calibre11">The canonical direction of an edge always points from a smaller node ID to a larger node ID. We can achieve this by ensuring all the edges are created in this direction when we first construct our edge RDD:</p><div class="calibre2"><pre class="programlisting">(defn line-&gt;canonical-edge [line]
  (let [[from to] (sort (map to-long (str/split line #" ")))]
    (glitter/edge from to 1.0)))

(defn load-canonical-edgelist [sc path]
  (let [edges (-&gt;&gt; (spark/text-file sc path)
                   (spark/map line-&gt;canonical-edge))]
    (glitter/graph-from-edges edges 1.0)))</pre></div><p class="calibre11">By sorting the <a id="id1129" class="calibre4 pcalibre3 pcalibre pcalibre1 pcalibre2"/><code class="literal">from</code> and <code class="literal">to</code> IDs before we <a id="id1130" class="calibre4 pcalibre3 pcalibre pcalibre1 pcalibre2"/>create the edge, we ensure that the <code class="literal">from</code> ID is always lower than the <code class="literal">to</code> ID. This is the first step towards making duplicate edge removal more efficient. The second is to choose a partitioning strategy for the graph. The next section describes our options.</p><div class="calibre2" title="GraphX partitioning strategies"><div class="titlepage"><div class="calibre2"><div class="calibre2"><h3 class="title7"><a id="ch08lvl3sec29" class="pcalibre pcalibre3 pcalibre1 calibre8 pcalibre2"/>GraphX partitioning strategies</h3></div></div></div><p class="calibre11">GraphX is built <a id="id1131" class="calibre4 pcalibre3 pcalibre pcalibre1 pcalibre2"/>for distributed computation and so it must partition graphs across multiple machines. In general, there are two approaches that you could take while partitioning graphs: the 'edge cut' and 'vertex cut' approach. Each makes a different trade-off.</p><div class="mediaobject"><img src="Images/7180OS_08_340.jpg" alt="GraphX partitioning strategies" class="calibre340"/></div><p class="calibre11">The edge cut strategy may seem the most "natural" way to partition a graph. By splitting the graph along the edges, it ensures that each vertex is assigned to exactly one partition indicated by the shade of gray. This presents an issue for the representation of edges that span partitions though. Any computation along the edge will necessarily need to be sent from one partition to another, and minimizing network communication is key to the implementation of efficient graph algorithms.</p><p class="calibre11">GraphX implements <a id="id1132" class="calibre4 pcalibre3 pcalibre pcalibre1 pcalibre2"/>the "vertex cut" approach, which ensures that the edges are assigned to partitions and that the vertices may be shared across partitions. This appears to simply move the network communication to a different part of the graph—from the edges to the vertices—but GraphX provides a number of strategies that allow us to ensure that vertices are partitioned in the most appropriate way for the algorithm we wish to apply.</p><p class="calibre11">Glittering provides the <code class="literal">partition-by</code> function, which accepts a keyword representing the strategy to partition the graph. Accepted values are <code class="literal">:edge-partition-1d</code>, <code class="literal">:edge-partition-2d</code>, <code class="literal">:canonical-random-vertex-cut</code>, and <code class="literal">:random-vertex-cut</code>.</p><p class="calibre11">Your choice about which partitioning strategy to use is based on the structure of the graph and the algorithm you will apply. The <code class="literal">:edge-partition-1d</code> strategy ensures that all the edges with the same source are partitioned together. This means that operations that aggregate edges by the source (for example, counting outgoing edges) have all the data they require on an individual machine. Although this minimizes network traffic, it also means that with power-law graphs a few partitions may receive a significant proportion of the overall number of edges.</p><p class="calibre11">The <code class="literal">:random-vertex-cut</code> partitioning strategy splits a graph into edges based on both the source and destination vertices. This can help to create more balanced partitions at the cost of run-time performance, as a single source or destination node may be spread across many machines in the cluster. Even the edges that connect the same pair of nodes may be spread across two machines depending on the direction of the edge. To group edges regardless of direction, we can use <code class="literal">:canonical-random-vertex-cut</code>.</p><p class="calibre11">Finally, <code class="literal">:edge-partition-2d</code> partitions edges by both their source and destination vertex using a more <a id="id1133" class="calibre4 pcalibre3 pcalibre pcalibre1 pcalibre2"/>sophisticated partitioning strategy. As with the <code class="literal">:canonical-random-vertex-cut</code>, nodes sharing both a source and a destination will be partitioned together. In addition, the strategy places an upper limit on the number of partitions that each node will be spread across. Where an algorithm aggregates information about edges sharing both a source and a destination node, and also by source or destination independently, this may be the most efficient strategy to use.</p></div></div><div class="calibre2" title="Running the built-in triangle counting algorithm"><div class="titlepage"><div class="calibre2"><div class="calibre2"><h2 class="title5"><a id="ch08lvl2sec179" class="pcalibre pcalibre3 pcalibre1 calibre8 pcalibre2"/>Running the built-in triangle counting algorithm</h2></div></div></div><p class="calibre11">We've <a id="id1134" class="calibre4 pcalibre3 pcalibre pcalibre1 pcalibre2"/>already seen how to load <a id="id1135" class="calibre4 pcalibre3 pcalibre pcalibre1 pcalibre2"/>our edges in the canonical direction. The next step is to choose a partitioning strategy, and we'll go for <code class="literal">:random-vertex-cut</code>. The following example shows the full sequence of loading and partitioning the graph, performing triangle counting and visualizing the results using Incanter:</p><div class="calibre2"><pre class="programlisting">(defn ex-8-24 []
  (spark/with-context sc (-&gt; (g/conf)
                             (conf/master "local")
                             (conf/app-name "ch8"))
    (let [triangles (-&gt;&gt; (load-canonical-edgelist
                          sc "data/twitter_combined.txt")
                         (g/partition-by :random-vertex-cut)
                         (ga/triangle-count)
                         (g/vertices)
                         (to-java-pair-rdd)
                         (spark/values)
                         (spark/collect)
                         (into []))
          data (frequencies triangles)]
      (-&gt; (c/scatter-plot (keys data) (vals data))
          (c/set-axis :x (c/log-axis :label "# Triangles"))
          (c/set-axis :y (c/log-axis :label "# Vertices"))
          (i/view)))))</pre></div><p class="calibre11">The output <a id="id1136" class="calibre4 pcalibre3 pcalibre pcalibre1 pcalibre2"/>of <code class="literal">triangle-count</code> is a new graph where the attribute of each vertex is a count of the number of triangles that the vertex participates in. The ID of the vertex is unchanged. We're only interested in the triangle counts themselves—the vertex attributes of the returned graph—so we extract <code class="literal">values</code> from the vertices. The <code class="literal">spark/collect</code> function gathers all the values into a single Clojure sequence, so it's not something we'd want to do on a very large graph.</p><p class="calibre11">Having gathered the count of triangles, we calculate the frequency of each count and visualize the <a id="id1137" class="calibre4 pcalibre3 pcalibre pcalibre1 pcalibre2"/>result on a log-log scatter plot using Incanter. The output is shown next:</p><div class="mediaobject"><img src="Images/7180OS_08_350.jpg" alt="Running the built-in triangle counting algorithm" class="calibre45"/></div><p class="calibre11">Once <a id="id1138" class="calibre4 pcalibre3 pcalibre pcalibre1 pcalibre2"/>again, we see the effect of a power law distribution. A few nodes connect a very large number of triangles.</p><p class="calibre11">Running a built-in algorithm has allowed us to see how to create and manipulate a graph, but the real power of GraphX is the way it allows us to express this sort of computation efficiently for ourselves. In the next section, we'll see how to accomplish triangle counting <a id="id1139" class="calibre4 pcalibre3 pcalibre pcalibre1 pcalibre2"/>using lower-level functions.</p></div><div class="calibre2" title="Implement triangle counting with Glittering"><div class="titlepage"><div class="calibre2"><div class="calibre2"><h2 class="title5"><a id="ch08lvl2sec180" class="pcalibre pcalibre3 pcalibre1 calibre8 pcalibre2"/>Implement triangle counting with Glittering</h2></div></div></div><p class="calibre11">There <a id="id1140" class="calibre4 pcalibre3 pcalibre pcalibre1 pcalibre2"/>are many ways to count the <a id="id1141" class="calibre4 pcalibre3 pcalibre pcalibre1 pcalibre2"/>number of triangles in a graph, but GraphX implements the algorithm in the following way:</p><div class="calibre2"><ol class="orderedlist1"><li class="listitem2">Compute the set of neighbors for each vertex.</li><li class="listitem2">For each edge, compute the intersection of the vertices at either end.</li><li class="listitem2">Send the count of the intersection to both vertices.</li><li class="listitem2">Compute the sum of the counts for each vertex.</li><li class="listitem2">Divide by two, since each triangle is counted twice.</li></ol></div><p class="calibre11">The following <a id="id1142" class="calibre4 pcalibre3 pcalibre pcalibre1 pcalibre2"/>diagram shows the steps <a id="id1143" class="calibre4 pcalibre3 pcalibre pcalibre1 pcalibre2"/>on our simple graph consisting of only one triangle:</p><div class="mediaobject"><img src="Images/7180OS_08_355.jpg" alt="Implement triangle counting with Glittering" class="calibre341"/></div><p class="calibre11">The algorithm ignores the direction of the edges and, as mentioned previously, expects the edges between any two nodes to be distinct. We'll therefore continue to work on the partitioned graph with the canonical edges we defined in the previous section.</p><p class="calibre11">The full code to perform triangle counting isn't very long, so it's presented in full next. It's representative of most of the algorithms we'll cover for the rest of the chapter so, once we've presented the code, we'll walk through each of the steps one at a time:</p><div class="calibre2"><pre class="programlisting">(defn triangle-m [{:keys [src-id src-attr dst-id dst-attr]}]
  (let [c (count (set/intersection src-attr dst-attr))]
    {:src c :dst c}))

(defn triangle-count [graph]
  (let [graph (-&gt;&gt; (g/partition-by :random-vertex-cut graph)
                   (g/group-edges (fn [a b] a)))
        adjacent (-&gt;&gt; (g/collect-neighbor-ids :either graph)
                      (to-java-pair-rdd)
                      (spark/map-values set))
        graph (g/outer-join-vertices
               (fn [vid attr adj] adj) adjacent graph)
        counters (g/aggregate-messages triangle-m + graph)]
    (-&gt;&gt; (g/outer-join-vertices (fn  [vid vattr counter]
                                  (/ counter 2))
                                counters graph)
         (g/vertices))))</pre></div><p class="calibre11">For the <a id="id1144" class="calibre4 pcalibre3 pcalibre pcalibre1 pcalibre2"/>algorithm to work, the input graph needs to have distinct edges. Once the canonical graph has been partitioned, we make sure the edges are distinct by calling <code class="literal">(g/group-edges (fn [a b] a) graph)</code> on the <a id="id1145" class="calibre4 pcalibre3 pcalibre pcalibre1 pcalibre2"/>graph. The <code class="literal">group-edges</code> function is similar to <code class="literal">reduce</code> and it reduces over the collection of edges that share the same start and end node. We're simply choosing to keep the first edge. The attributes of the edge don't factor into triangle counting, only the fact that there is one.</p><div class="calibre2" title="Step one – collecting neighbor IDs"><div class="titlepage"><div class="calibre2"><div class="calibre2"><h3 class="title7"><a id="ch08lvl3sec30" class="pcalibre pcalibre3 pcalibre1 calibre8 pcalibre2"/>Step one – collecting neighbor IDs</h3></div></div></div><p class="calibre11">At step one, we <a id="id1146" class="calibre4 pcalibre3 pcalibre pcalibre1 pcalibre2"/>want to collect the neighbor IDs for each vertex. Glittering makes this operation available as the <code class="literal">g/collect-neighbor-ids</code> function. We can choose to collect only the incoming or outgoing edges with <code class="literal">:in</code> or <code class="literal">:out</code>, respectively, or the edges in either direction with <code class="literal">:either</code>.</p><p class="calibre11">The<code class="literal"> g/collect-neighbor-ids</code> function returns a pair RDD with the key being the vertex ID in question and the value being the sequence of neighbor IDs. Like MLlib in the previous chapter, the RDD is not the <code class="literal">JavaRDD</code> class that Sparkling expects, and so we must convert it accordingly. Once we've done so, converting the sequence of neighbor IDs into a set is as simple as calling <code class="literal">set</code> on each of the values in the pair RDD. The result of step one is a PairRDD containing the of node ID and set of neighbor IDs, so we've flattened the graph to a series of sets stored as the value of <code class="literal">adjacent</code>.</p><div class="sidebar" title="Note"><div class="inner"><h3 class="title8"><a id="note80" class="pcalibre pcalibre3 pcalibre1 calibre8 pcalibre2"/>Note</h3><p class="calibre22">This graph representation, as a sequence of sets of connected vertices, is commonly known as an adjacency list. Along with the edge list, it's one of the two primary means of representing graphs.</p></div></div><p class="calibre11">Step two requires us to assign values to the graph edges though, so we'll want to preserve the graph structure. We use the <code class="literal">g/outer-join-vertices</code> function to combine <code class="literal">adjacent</code> and the original graph. Given a graph and a pair RDD indexed by vertex ID, <code class="literal">outer-join-vertices</code> allows us to supply a function whose return value will be assigned as the attribute of each vertex in the graph. The function receives three arguments: the vertex ID, the current vertex attribute, and the value associated with the vertex ID in the pair RDD being outer joined to the graph. In the earlier code, we <a id="id1147" class="calibre4 pcalibre3 pcalibre pcalibre1 pcalibre2"/>return the set of adjacent vertices as the new vertex attribute.</p></div><div class="calibre2" title="Steps two, three, and four – aggregate messages"><div class="titlepage"><div class="calibre2"><div class="calibre2"><h3 class="title7"><a id="ch08lvl3sec31" class="pcalibre pcalibre3 pcalibre1 calibre8 pcalibre2"/>Steps two, three, and four – aggregate messages</h3></div></div></div><p class="calibre11">The next several <a id="id1148" class="calibre4 pcalibre3 pcalibre pcalibre1 pcalibre2"/>steps are handled by one function, <code class="literal">g/aggregate-messages</code>, the workhorse function of GraphX's graph-parallel implementation. It requires two arguments: a message sending function and a message combining function. In the way they work together, these two functions are like map and reduce adapted for the vertex-centric view of graph-parallel computation.</p><div class="mediaobject"><img src="Images/7180OS_08_360.jpg" alt="Steps two, three, and four – aggregate messages" class="calibre270"/></div><p class="calibre11">The send message function is responsible for sending messages along edges. The function is called once for each edge, but it can send multiple messages to either the source or destination vertex. The input to the function is a triplet (an edge with two connected vertices) and it responds with a sequence of messages. A message is a key/value pair where the key is one of <code class="literal">:src</code> or <code class="literal">:dst</code> and the value is the message to be sent. In the previous example, this is implemented as a map with the <code class="literal">:src</code> and <code class="literal">:dst</code> keys.</p><p class="calibre11">The merge message function is responsible for combining all the messages for a particular vertex. In the earlier code, each message is a number and therefore the merge function has a sequence of numbers to merge. We can achieve this simply by passing <code class="literal">+</code> as the merge function.</p></div><div class="calibre2" title="Step five – dividing the counts"><div class="titlepage"><div class="calibre2"><div class="calibre2"><h3 class="title7"><a id="ch08lvl3sec32" class="pcalibre pcalibre3 pcalibre1 calibre8 pcalibre2"/>Step five – dividing the counts</h3></div></div></div><p class="calibre11">The final step of <a id="id1149" class="calibre4 pcalibre3 pcalibre pcalibre1 pcalibre2"/>triangle counting is to divide the counts we have calculated for each vertex ID by two, since each triangle is counted twice. In the earlier code, we do this while simultaneously updating the vertex attributes with the triangle count using <code class="literal">outer-join-vertices</code>.<a id="id1150" class="calibre4 pcalibre3 pcalibre pcalibre1 pcalibre2"/>
</p></div></div><div class="calibre2" title="Running the custom triangle counting algorithm"><div class="titlepage"><div class="calibre2"><div class="calibre2"><h2 class="title5"><a id="ch08lvl2sec181" class="pcalibre pcalibre3 pcalibre1 calibre8 pcalibre2"/>Running the custom triangle counting algorithm</h2></div></div></div><p class="calibre11">With all <a id="id1151" class="calibre4 pcalibre3 pcalibre pcalibre1 pcalibre2"/>of the earlier steps in place, we can run our custom triangle counting algorithm using Glittering. Let's first run it <a id="id1152" class="calibre4 pcalibre3 pcalibre pcalibre1 pcalibre2"/>on one of our Twitter follow graphs from the beginning of the chapter to see the result we get:</p><div class="calibre2"><pre class="programlisting">(defn ex-8-25 []
  (spark/with-context sc (-&gt; (g/conf)
                             (conf/master "local")
                             (conf/app-name "triangle-count"))
    (-&gt;&gt; (load-canonical-edgelist
          sc "data/twitter/396721965.edges")
         (triangle-count)
         (spark/collect)
         (into []))))

;; #sparkling/tuple [21938120 1] #sparkling/tuple [31477674 3]
;; #sparkling/tuple [32122637 0] ...]</pre></div><p class="calibre11">The result is a series of tuples with the vertex ID as the key and number of connected triangles as the value.</p><p class="calibre11">If we want to see how many triangles were there in the entire Twitter dataset, we could extract the values from the resulting graph (the values), add them up, and then divide them by three. Let's do this now:</p><div class="calibre2"><pre class="programlisting">(defn ex-8-26 []
  (spark/with-context sc (-&gt; (g/conf)
                             (conf/master "local")
                             (conf/app-name "triangle-count"))
    (let [triangles (-&gt;&gt; (load-canonical-edgelist
                          sc "data/twitter_combined.txt")
                         (triangle-count)
                         (to-java-pair-rdd)
                         (spark/values)
                         (spark/reduce +))]
      (/ triangles 3))))</pre></div><p class="calibre11">The algorithm shouldn't take too long to run. Our custom triangle counting code will be performant enough to run on the entire combined Twitter dataset.</p><p class="calibre11">If <code class="literal">aggregate-messages </code>is like a single step of MapReduce programming, we'll often end up performing it iteratively. Many graph algorithms will want to run to convergence. In fact, GraphX provides an alternative function that we will be able to use in this case called the <a id="id1153" class="calibre4 pcalibre3 pcalibre pcalibre1 pcalibre2"/><span class="strong1"><strong class="calibre12">Pregel API</strong></span>. We'll discuss it in detail in the next section.</p></div><div class="calibre2" title="The Pregel API"><div class="titlepage"><div class="calibre2"><div class="calibre2"><h2 class="title5"><a id="ch08lvl2sec182" class="pcalibre pcalibre3 pcalibre1 calibre8 pcalibre2"/>The Pregel API</h2></div></div></div><p class="calibre11">The Pregel API is <a id="id1154" class="calibre4 pcalibre3 pcalibre pcalibre1 pcalibre2"/>GraphX's main abstraction to express custom, iterative, graph-parallel computation. It's named after Google's internal system for running large-scale graph processing, about which they published a paper in 2010. You may remember that it was also the river upon which the town of Königsberg was built.</p><p class="calibre11">Google's Pregel <a id="id1155" class="calibre4 pcalibre3 pcalibre pcalibre1 pcalibre2"/>paper popularized the "think like a vertex" approach to graph parallel computation. Pregel's model fundamentally uses the message passing between the vertices in the graph organized into a series of steps called <span class="strong1"><strong class="calibre12">supersteps</strong></span>. At the <a id="id1156" class="calibre4 pcalibre3 pcalibre pcalibre1 pcalibre2"/>beginning of each superstep, Pregel runs a user-specified function on each vertex, passing all the messages sent to it in the previous superstep. The vertex function has the opportunity to process each of these messages and send messages to other vertices in turn. Vertices can also "vote to halt" the computation and, when all the vertices have voted to halt, the computation will terminate.</p><p class="calibre11">The <code class="literal">pregel</code> function implemented by Glittering implements a very similar approach to graph processing. The primary difference is that the vertices don't vote to halt: the computation terminates either when there are no more messages being sent or when a specified number of iterations has been exceeded.</p><p class="calibre11">While the aggregate-messages function introduced in the previous section makes use of two symbiotic functions to express its intent, the <code class="literal">pregel</code> function makes use of three related functions, applied iteratively, to implement graph algorithms. The first two are the message function and the message combiner we encountered before, the third is the "vertex program": a function that processes the incoming messages for each vertex. The return value of this function is assigned as the vertex attribute for the next superstep.</p><p class="calibre11">Let's see how the <code class="literal">pregel</code> function works in practice by implementing an algorithm we've already covered in this chapter: connected components.</p></div><div class="calibre2" title="Connected components with the Pregel API"><div class="titlepage"><div class="calibre2"><div class="calibre2"><h2 class="title5"><a id="ch08lvl2sec183" class="pcalibre pcalibre3 pcalibre1 calibre8 pcalibre2"/>Connected components with the Pregel API</h2></div></div></div><p class="calibre11">Connected <a id="id1157" class="calibre4 pcalibre3 pcalibre pcalibre1 pcalibre2"/>components can be expressed as <a id="id1158" class="calibre4 pcalibre3 pcalibre pcalibre1 pcalibre2"/>an iterative algorithm in the following way:</p><div class="calibre2"><ol class="orderedlist1"><li class="listitem2">Initialize all <a id="id1159" class="calibre4 pcalibre3 pcalibre pcalibre1 pcalibre2"/>vertex attributes to the vertex ID.</li><li class="listitem2">For each edge, determine whether the source or destination vertex attribute is the lowest.</li><li class="listitem2">Down each edge, send the lower of the two attributes to the opposite vertex.</li><li class="listitem2">For each vertex, update attribute to be the lowest of the incoming messages.</li><li class="listitem2">Repeat until the node attributes no longer change.</li></ol></div><p class="calibre11">As before, we <a id="id1160" class="calibre4 pcalibre3 pcalibre pcalibre1 pcalibre2"/>can visualize the process on a simple graph of four nodes.</p><div class="mediaobject"><img src="Images/7180OS_08_370.jpg" alt="Connected components with the Pregel API" class="calibre342"/></div><p class="calibre11">We can see how in six steps the graph has converged to a state where all the nodes have the lowest connected vertex ID as their attribute. Since the messages only travel along the edges, any nodes <a id="id1161" class="calibre4 pcalibre3 pcalibre pcalibre1 pcalibre2"/>that don't share any edges will <a id="id1162" class="calibre4 pcalibre3 pcalibre pcalibre1 pcalibre2"/>converge to different values. All the vertices that share the same attribute once the algorithm has converged will therefore be a part of the same connected component. Let's see the finished code first and we'll walk through the code in steps immediately afterwards:</p><div class="calibre2"><pre class="programlisting">(defn connected-component-m [{:keys [src-attr dst-attr]}]
  (cond
    (&lt; src-attr dst-attr) {:dst src-attr}
    (&gt; src-attr dst-attr) {:src dst-attr}))

(defn connected-components [graph]
  (-&gt;&gt; (glitter/map-vertices (fn [id attr] id) graph)
       (p/pregel {:vertex-fn (fn [id attr msg]
                               (min attr msg))
                  :message-fn connected-component-m
                  :combiner min})))</pre></div><p class="calibre11">Using the <code class="literal">g/pregel</code> <a id="id1163" class="calibre4 pcalibre3 pcalibre pcalibre1 pcalibre2"/>function is all that's required to implement <a id="id1164" class="calibre4 pcalibre3 pcalibre pcalibre1 pcalibre2"/>an iterative connected components algorithm.</p><div class="calibre2" title="Step one – map vertices"><div class="titlepage"><div class="calibre2"><div class="calibre2"><h3 class="title7"><a id="ch08lvl3sec33" class="pcalibre pcalibre3 pcalibre1 calibre8 pcalibre2"/>Step one – map vertices</h3></div></div></div><p class="calibre11">Initializing all the <a id="id1165" class="calibre4 pcalibre3 pcalibre pcalibre1 pcalibre2"/>vertex attributes to the vertex ID is handled outside of the <code class="literal">pregel </code>function by the <code class="literal">g/map-vertices</code> function. We pass it a function of two arguments, the vertex ID and vertex attribute, and it returns the vertex ID to be assigned as the vertex attribute.</p></div><div class="calibre2" title="Steps two and three – the message function"><div class="titlepage"><div class="calibre2"><div class="calibre2"><h3 class="title7"><a id="ch08lvl3sec34" class="pcalibre pcalibre3 pcalibre1 calibre8 pcalibre2"/>Steps two and three – the message function</h3></div></div></div><p class="calibre11">Glittering's <a id="id1166" class="calibre4 pcalibre3 pcalibre pcalibre1 pcalibre2"/><code class="literal">pregel</code> function expects to receive a map specifying at least three functions: a message function, a combiner function, and a vertex function. We'll discuss the last of these in more detail shortly. However, the first of these is responsible for steps two and three: for each edge, determining which connected node has the lower attribute and sending this value to the opposing node.</p><p class="calibre11">We introduced the message function along with the custom triangle counting function earlier in the chapter. This function receives the edge as a map and returns a map in return describing the messages to be sent. This time, only one message is sent: the <code class="literal">src-attr</code> attribute to the destination node if the source attribute is lower or the <code class="literal">dst-attr</code> attribute to the source node if the destination attribute is lower.</p><p class="calibre11">The combiner function aggregates all the incoming messages for a vertex. The combiner function for the connected components is simply the <code class="literal">min</code> function: we're only interested in the minimum value sent to each vertex.</p></div><div class="calibre2" title="Step four – update the attributes"><div class="titlepage"><div class="calibre2"><div class="calibre2"><h3 class="title7"><a id="ch08lvl3sec35" class="pcalibre pcalibre3 pcalibre1 calibre8 pcalibre2"/>Step four – update the attributes</h3></div></div></div><p class="calibre11">In step four, each <a id="id1167" class="calibre4 pcalibre3 pcalibre pcalibre1 pcalibre2"/>vertex updates its attribute to equal the lowest of its current attribute and the value of all the received messages. If any of its incoming messages is lower than its current attribute, it will update its attribute to equal the lowest. This step is handled by the vertex program, the third of Pregel's three symbiotic functions.</p><p class="calibre11">The vertex function for connected components is also trivial: for each vertex, we want to return the lower of the current vertex attribute and the lowest incoming message (as determined by the combiner function in the previous step). The return value will be used as the vertex <a id="id1168" class="calibre4 pcalibre3 pcalibre pcalibre1 pcalibre2"/>attribute for the next superstep.</p></div><div class="calibre2" title="Step five – iterate to convergence"><div class="titlepage"><div class="calibre2"><div class="calibre2"><h3 class="title7"><a id="ch08lvl3sec36" class="pcalibre pcalibre3 pcalibre1 calibre8 pcalibre2"/>Step five – iterate to convergence</h3></div></div></div><p class="calibre11">Step five is <a id="id1169" class="calibre4 pcalibre3 pcalibre pcalibre1 pcalibre2"/>something we get "for free" with the <code class="literal">pregel</code> function. We didn't specify the maximum number of iterations, so the three functions just described will be run repeatedly until there are no more messages to be sent. For this reason (and for reasons of efficiency), it's important that our message function only sends messages when it needs to. This is why our <code class="literal">cond</code> value in the earlier message function ensures we don't send a message if the source and destination attributes are already equal.</p></div></div><div class="calibre2" title="Running connected components"><div class="titlepage"><div class="calibre2"><div class="calibre2"><h2 class="title5"><a id="ch08lvl2sec184" class="pcalibre pcalibre3 pcalibre1 calibre8 pcalibre2"/>Running connected components</h2></div></div></div><p class="calibre11">Having <a id="id1170" class="calibre4 pcalibre3 pcalibre pcalibre1 pcalibre2"/>implemented the previous connected <a id="id1171" class="calibre4 pcalibre3 pcalibre pcalibre1 pcalibre2"/>components function, we use it in the following example:</p><div class="calibre2"><pre class="programlisting"> (defn ex-8-27 []
  (spark/with-context sc (-&gt; (g/conf)
                             (conf/master "local")
                             (conf/app-name "cljds.ch8"))
    (-&gt;&gt; (load-edgelist sc "data/twitter/396721965.edges")
         (connected-components)
         (g/vertices)
         (spark/collect)
         (into []))))

;; [#sparkling/tuple [163629705 21938120] #sparkling/tuple
;; [88491375 21938120] #sparkling/tuple [142960504 21938120] ...</pre></div><p class="calibre11">By converting the <a id="id1172" class="calibre4 pcalibre3 pcalibre pcalibre1 pcalibre2"/>graph back into an RDD, we can perform analysis in a data-parallel way. For example, we could determine the size of all of the connected components by counting the number of nodes that share the same attribute.</p></div><div class="calibre2" title="Calculating the size of the largest connected component"><div class="titlepage"><div class="calibre2"><div class="calibre2"><h2 class="title5"><a id="ch08lvl2sec185" class="pcalibre pcalibre3 pcalibre1 calibre8 pcalibre2"/>Calculating the size of the largest connected component</h2></div></div></div><p class="calibre11">In the next <a id="id1173" class="calibre4 pcalibre3 pcalibre pcalibre1 pcalibre2"/>example, we'll use the <a id="id1174" class="calibre4 pcalibre3 pcalibre pcalibre1 pcalibre2"/>same connected components function, but count the size of each connected component. We'll achieve this with Sparkling's <code class="literal">count-by-value</code> function:</p><div class="calibre2"><pre class="programlisting">(defn ex-8-28 []
  (spark/with-context sc (-&gt; (g/conf)
                             (conf/master "local")
                             (conf/app-name "ch8"))
    (-&gt;&gt; (load-canonical-edgelist
          sc "data/twitter_combined.txt")
         (connected-components)
         (g/vertices)
         (to-java-pair-rdd)
         (spark/values)
         (spark/count-by-value)
         (into []))))

;; [[12 81306]]</pre></div><p class="calibre11">Code such as the previous example is one of the great benefits of using GraphX and Glittering. We can take flat data represented as an edge list, convert it into a graph structure to perform an iterative graph algorithm, and then convert the results back into a flat structure to calculate aggregates: all in a single pipeline.</p><p class="calibre11">The example's response indicates that all of our vertices—81,306 of them—are in one large connected component. This shows that everyone in the graph is connected to everyone else, either as a friend or a follower.</p><p class="calibre11">While it's <a id="id1175" class="calibre4 pcalibre3 pcalibre pcalibre1 pcalibre2"/>useful to know that there are <a id="id1176" class="calibre4 pcalibre3 pcalibre pcalibre1 pcalibre2"/>no isolated groups of users, it would be more interesting to understand how the users are organized within the connected component. If certain groups of users tend to be more densely connected to each other, then we could think of these users as forming a community.</p></div><div class="calibre2" title="Detecting communities with label propagation"><div class="titlepage"><div class="calibre2"><div class="calibre2"><h2 class="title5"><a id="ch08lvl2sec186" class="pcalibre pcalibre3 pcalibre1 calibre8 pcalibre2"/>Detecting communities with label propagation</h2></div></div></div><p class="calibre11">A community <a id="id1177" class="calibre4 pcalibre3 pcalibre pcalibre1 pcalibre2"/>can be defined <a id="id1178" class="calibre4 pcalibre3 pcalibre pcalibre1 pcalibre2"/>informally as a group of vertices that are more strongly connected to each other than they are to the vertices outside the community.</p><div class="sidebar" title="Note"><div class="inner"><h3 class="title6"><a id="note81" class="pcalibre pcalibre3 pcalibre1 calibre8 pcalibre2"/>Note</h3><p class="calibre22">If every vertex is connected to every other vertex within the community, then we would call the community a clique.</p></div></div><p class="calibre11">Communities therefore correspond to increased density in the graph. We could think of communities within the Twitter network as groups of followers who tend to also follow each other's followers. Smaller communities might correspond to friendship groups, while larger communities are more likely to correspond to shared interest groups.</p><p class="calibre11">Community detection is a general technique and there are many algorithms that are capable of identifying communities. Depending on the algorithm, communities may overlap so that a user could be associated with more than one community. The algorithm we'll be looking at next is <a id="id1179" class="calibre4 pcalibre3 pcalibre pcalibre1 pcalibre2"/>called <span class="strong1"><strong class="calibre12">label propagation</strong></span> and it assigns each user to a maximum of one community.</p><p class="calibre11">Label propagation <a id="id1180" class="calibre4 pcalibre3 pcalibre pcalibre1 pcalibre2"/>can be implemented iteratively with the following steps:</p><div class="calibre2"><ol class="orderedlist1"><li class="listitem2">Initialize all the vertex attributes to equal the vertex ID.</li><li class="listitem2">For each edge, send the source and destination attributes to the opposing node.</li><li class="listitem2">For each vertex, calculate the frequency of each incoming attribute.</li><li class="listitem2">For each vertex, update the attribute to be the most frequent of the incoming attributes.</li><li class="listitem2">Repeat until convergence or until maximum iteration count is reached.</li></ol></div><p class="calibre11">The steps of the algorithm are shown next on a graph with two communities. Each community is also a clique, but this is not a requirement for label propagation to work in general.</p><div class="mediaobject"><img src="Images/7180OS_08_380.jpg" alt="Detecting communities with label propagation" class="calibre343"/></div><p class="calibre11">The code <a id="id1181" class="calibre4 pcalibre3 pcalibre pcalibre1 pcalibre2"/>for label propagation <a id="id1182" class="calibre4 pcalibre3 pcalibre pcalibre1 pcalibre2"/>using the <code class="literal">pregel</code> function is as follows:</p><div class="calibre2"><pre class="programlisting">(defn label-propagation-v [id attr msg]
  (key (apply max-key val msg)))

(defn label-propagation-m [{:keys [src-attr dst-attr]}]
  {:src {dst-attr 1}
   :dst {src-attr 1}})

(defn label-propagation [graph]
  (-&gt;&gt; (glitter/map-vertices (fn [vid attr] vid) graph)
       (p/pregel {:message-fn label-propagation-m
                  :combiner (partial merge-with +)
                  :vertex-fn label-propagation-v
                  :max-iterations 10})))</pre></div><p class="calibre11">As before, let's <a id="id1183" class="calibre4 pcalibre3 pcalibre pcalibre1 pcalibre2"/>walk through the <a id="id1184" class="calibre4 pcalibre3 pcalibre pcalibre1 pcalibre2"/>code step by step.</p><div class="calibre2" title="Step one – map vertices"><div class="titlepage"><div class="calibre2"><div class="calibre2"><h3 class="title7"><a id="ch08lvl3sec37" class="pcalibre pcalibre3 pcalibre1 calibre8 pcalibre2"/>Step one – map vertices</h3></div></div></div><p class="calibre11">Step one for label <a id="id1185" class="calibre4 pcalibre3 pcalibre pcalibre1 pcalibre2"/>propagation is identical to step one for the connected components algorithm we defined earlier. We use the <code class="literal">g/map-vertices</code> function to update each vertex attribute to equal the vertex ID.</p></div><div class="calibre2" title="Step two – send the vertex attribute"><div class="titlepage"><div class="calibre2"><div class="calibre2"><h3 class="title7"><a id="ch08lvl3sec38" class="pcalibre pcalibre3 pcalibre1 calibre8 pcalibre2"/>Step two – send the vertex attribute</h3></div></div></div><p class="calibre11">In step two, we <a id="id1186" class="calibre4 pcalibre3 pcalibre pcalibre1 pcalibre2"/>send the opposing vertex attribute along each edge. Step three will require us to count the most frequent of the incoming attributes, so each message is a map of attribute to the value "1".</p></div><div class="calibre2" title="Step three – aggregate value"><div class="titlepage"><div class="calibre2"><div class="calibre2"><h3 class="title7"><a id="ch08lvl3sec39" class="pcalibre pcalibre3 pcalibre1 calibre8 pcalibre2"/>Step three – aggregate value</h3></div></div></div><p class="calibre11">The combiner <a id="id1187" class="calibre4 pcalibre3 pcalibre pcalibre1 pcalibre2"/>function receives all the messages for a vertex and produces an aggregate value. Since the messages are maps of attribute value to the number "1", we can use Clojure's <code class="literal">merge-with</code> function to combine the messages together with <code class="literal">+</code>. The result will be a map of attribute to frequency.</p></div><div class="calibre2" title="Step four – vertex function"><div class="titlepage"><div class="calibre2"><div class="calibre2"><h3 class="title7"><a id="ch08lvl3sec40" class="pcalibre pcalibre3 pcalibre1 calibre8 pcalibre2"/>Step four – vertex function</h3></div></div></div><p class="calibre11">Step four is <a id="id1188" class="calibre4 pcalibre3 pcalibre pcalibre1 pcalibre2"/>handled by the vertex function. Given the frequency counts of all the incoming attributes, we want to pick the most frequent one. The <code class="literal">(apply max-key val msg)</code> expression returns the key/value pair from the map associated with the greatest value (the highest frequency). We pass this value to <code class="literal">key</code> to return the attribute associated with this value.</p></div><div class="calibre2" title="Step five – set the maximum iterations count"><div class="titlepage"><div class="calibre2"><div class="calibre2"><h3 class="title7"><a id="ch08lvl3sec41" class="pcalibre pcalibre3 pcalibre1 calibre8 pcalibre2"/>Step five – set the maximum iterations count</h3></div></div></div><p class="calibre11">As with the <a id="id1189" class="calibre4 pcalibre3 pcalibre pcalibre1 pcalibre2"/>connected components algorithm, iteration is the default behavior of the <code class="literal">pregel</code> function while there are messages to be sent. Unlike the connected components algorithm, we don't have a conditional clause in the earlier <code class="literal">message</code> function. In order to avoid an infinite loop, we pass <code class="literal">:max-iterations</code> of 10 in the map of options to <code class="literal">pregel</code>.</p></div></div><div class="calibre2" title="Running label propagation"><div class="titlepage"><div class="calibre2"><div class="calibre2"><h2 class="title5"><a id="ch08lvl2sec187" class="pcalibre pcalibre3 pcalibre1 calibre8 pcalibre2"/>Running label propagation</h2></div></div></div><p class="calibre11">The following <a id="id1190" class="calibre4 pcalibre3 pcalibre pcalibre1 pcalibre2"/>example makes use of the previous code to <a id="id1191" class="calibre4 pcalibre3 pcalibre pcalibre1 pcalibre2"/>perform label propagation on the full Twitter dataset. We calculate the size of each community with Sparkling's <code class="literal">count-by-value</code> function and calculate the frequencies of the counts. The resulting histogram is then visualized on a log-log scatterplot using Incanter to show the distribution of community sizes:</p><div class="calibre2"><pre class="programlisting"> (defn ex-8-29 []
  (spark/with-context sc (-&gt; (g/conf)
                             (conf/master "local")
                             (conf/app-name "ch8"))
    (let [xs (-&gt;&gt; (load-canonical-edgelist
                   sc "data/twitter_combined.txt")
                  (label-propagation)
                  (g/vertices)
                  (to-java-pair-rdd)
                  (spark/values)
                  (spark/count-by-value)
                  (vals)
                  (frequencies))]
      (-&gt; (c/scatter-plot (keys xs) (vals xs))
          (c/set-axis :x (c/log-axis :label "Community Size"))
          (c/set-axis :y (c/log-axis :label "# Communities"))
          (i/view)))))</pre></div><p class="calibre11">This code <a id="id1192" class="calibre4 pcalibre3 pcalibre pcalibre1 pcalibre2"/>generates the following chart:</p><div class="mediaobject"><img src="Images/7180OS_08_390.jpg" alt="Running label propagation" class="calibre45"/></div><p class="calibre11">As we may have come to expect, the distribution of community sizes is also a power law: small communities are much more common than larger communities. The largest communities have around 10,000 members, while the smallest consist of just one member. We're <a id="id1193" class="calibre4 pcalibre3 pcalibre pcalibre1 pcalibre2"/>beginning to tease apart the structure of the Twitter graph: we have a sense of how users are distributed into groups and we can hypothesize that the larger communities are likely to represent groups united by a shared interest.</p><p class="calibre11">In the final pages of this chapter, let's see whether we can establish what unites the largest of these communities. There are numerous ways we could go about this. If we had access to the tweets themselves, we could perform text analysis of the kind we performed in <a class="calibre4 pcalibre3 pcalibre pcalibre1 pcalibre2" href="ch06.xhtml" title="Chapter 6. Clustering">Chapter 6</a>, <span class="strong1"><em class="calibre13">Clustering</em></span> to see whether there were particular words—or particular languages—more frequently used among these groups.</p><p class="calibre11">This chapter is about network analysis though, so let's just use the structure of the graph to identify the most <a id="id1194" class="calibre4 pcalibre3 pcalibre pcalibre1 pcalibre2"/>influential accounts in each community. The list of the top ten most influential accounts might give us some indication of what resonates with their followers.</p></div><div class="calibre2" title="Measuring community influence using PageRank"><div class="titlepage"><div class="calibre2"><div class="calibre2"><h2 class="title5"><a id="ch08lvl2sec188" class="pcalibre pcalibre3 pcalibre1 calibre8 pcalibre2"/>Measuring community influence using PageRank</h2></div></div></div><p class="calibre11">One <a id="id1195" class="calibre4 pcalibre3 pcalibre pcalibre1 pcalibre2"/>simplistic way of measuring influence within a community is to calculate how many incoming edges a particular vertex has. On Twitter, this would correspond to an account with a large number of followers. Such accounts represent the most "popular" within the network.</p><p class="calibre11">Counting incoming edges is a simplistic way to measure influence because it treats all the incoming edges as being equal. In social graphs, this is often not the case, as certain followers will themselves be popular accounts and therefore their follow carries more importance than a follower who has no followers themselves.</p><div class="sidebar" title="Note"><div class="inner"><h3 class="title6"><a id="note82" class="pcalibre pcalibre3 pcalibre1 calibre8 pcalibre2"/>Note</h3><p class="calibre22">PageRank was developed at Stanford University in 1996 by Larry Page and Sergey Brin as part of the research project that ultimately became Google. PageRank works by counting both the number and quality of links to a page to determine a rough estimate of how important the website is.</p></div></div><p class="calibre11">The importance of an account is therefore based on two things: the number of followers and the importance of each of those followers. The importance of each follower is calculated in the same way. PageRank therefore has a recursive definition: it appears that we must calculate the importance of the followers before we can calculate the importance of the account, and so on.</p></div><div class="calibre2" title="The flow formulation"><div class="titlepage"><div class="calibre2"><div class="calibre2"><h2 class="title5"><a id="ch08lvl2sec189" class="pcalibre pcalibre3 pcalibre1 calibre8 pcalibre2"/>The flow formulation</h2></div></div></div><p class="calibre11">Fortunately, it's <a id="id1196" class="calibre4 pcalibre3 pcalibre pcalibre1 pcalibre2"/>possible to calculate PageRank iteratively. First, we initialize all the vertices to have the same weight. This could be a weight of one; in which case, the sum of all the weights equals the number of vertices <span class="strong1"><em class="calibre13">N</em></span>. Or, it could be a weight of <span class="inlinemediaobject"><img src="Images/7180OS_08_02.jpg" alt="The flow formulation" class="calibre185"/></span>; in which case, the sum of all the weights will equal one. Although it doesn't change the fundamental algorithm, the latter is often preferred, as it means the results of PageRank can be interpreted as probabilities. We'll be implementing the former.</p><p class="calibre11">This initial weight is the PageRank <span class="strong1"><em class="calibre13">r</em></span> of each account at the start of the algorithm. At iteration one, each account sends an equal proportion of its own rank to all the pages it follows. After this step, the rank of account <span class="strong1"><em class="calibre13">j</em></span> and <span class="strong1"><em class="calibre13">r</em></span>j is defined as the sum of all the incoming ranks. We can express this with the following equation:</p><div class="mediaobject"><img src="Images/7180OS_08_03.jpg" alt="The flow formulation" class="calibre344"/></div><p class="calibre11">Here, <span class="strong1"><em class="calibre13">r</em></span><sub class="calibre25">i</sub> is the rank of a follower and <span class="strong1"><em class="calibre13">ni</em></span> is the count of accounts they follow. Account <span class="strong1"><em class="calibre13">j</em></span> receives a proportion of the rank, <span class="inlinemediaobject"><img src="Images/7180OS_08_04.jpg" alt="The flow formulation" class="calibre345"/></span>, from all of their followers.</p><p class="calibre11">If this were all there was to PageRank, then the accounts with no followers would already have zero rank and, at every iteration, the most popular pages would just get more and more popular. PageRank therefore also includes a damping factor. This factor ensures that even the least <a id="id1197" class="calibre4 pcalibre3 pcalibre pcalibre1 pcalibre2"/>popular accounts retain some weight and that the algorithm can converge to stable values. This can be expressed by modifying the previous equation:</p><div class="mediaobject"><img src="Images/7180OS_08_05.jpg" alt="The flow formulation" class="calibre41"/></div><p class="calibre11">Here, <span class="strong1"><em class="calibre13">d</em></span> is the damping factor. A common damping factor to use is 85 percent.</p><p class="calibre11">The effect of the damping factor for a group of eleven accounts is visualized in the following diagram:</p><div class="mediaobject"><img src="Images/7180OS_08_400.jpg" alt="The flow formulation" class="calibre346"/></div><p class="calibre11">Without the damping factor, all the weight would eventually accrue on accounts <span class="strong1"><strong class="calibre12">A</strong></span>, <span class="strong1"><strong class="calibre12">B</strong></span>, and <span class="strong1"><strong class="calibre12">C</strong></span>. With the damping factor, even the small accounts with no follows continue to receive a small percentage of the overall weight. Even though account <span class="strong1"><strong class="calibre12">E</strong></span> has more followers, account <span class="strong1"><strong class="calibre12">C</strong></span> has a higher rank, because it is followed by high-ranking account.</p><div class="calibre2" title="Implementing PageRank with Glittering"><div class="titlepage"><div class="calibre2"><div class="calibre2"><h3 class="title7"><a id="ch08lvl3sec42" class="pcalibre pcalibre3 pcalibre1 calibre8 pcalibre2"/>Implementing PageRank with Glittering</h3></div></div></div><p class="calibre11">We <a id="id1198" class="calibre4 pcalibre3 pcalibre pcalibre1 pcalibre2"/>implement PageRank with the <code class="literal">pregel</code> function in the following example code. The structure of the code should be familiar to <a id="id1199" class="calibre4 pcalibre3 pcalibre pcalibre1 pcalibre2"/>you by now, although we will be making use of several new Glittering functions:</p><div class="calibre2"><pre class="programlisting">(def damping-factor 0.85)

(defn page-rank-v [id prev msgsum]
  (let [[rank delta] prev
        new-rank (+ rank (* damping-factor msgsum))]
    [new-rank (- new-rank rank)]))

(defn page-rank-m [{:keys [src-attr attr]}]
  (let [delta (second src-attr)]
    (when (&gt; delta 0.1)
      {:dst (* delta attr)})))

(defn page-rank [graph]
  (-&gt;&gt; (glitter/outer-join-vertices (fn [id attr deg] (or deg 0))
                                    (glitter/out-degrees graph)
                                    graph)
       (glitter/map-triplets (fn [edge]
                               (/ 1.0 (glitter/src-attr edge))))
       (glitter/map-vertices (fn [id attr] (vector 0 0)))
       (p/pregel {:initial-message (/ (- 1 damping-factor)
                                      damping-factor)
                  :direction :out
                  :vertex-fn page-rank-v
                  :message-fn page-rank-m
                  :combiner +
                  :max-iterations 20})
       (glitter/map-vertices (fn [id attr] (first attr)))))</pre></div><p class="calibre11">We begin in the usual way, using <code class="literal">outer-join-vertices</code> to join <code class="literal">out-degrees</code> of every node to itself. After this step, every node's attribute is equal to its number of outgoing links. Then, we use <code class="literal">map-triplets</code> to set all the <code class="literal">edge</code> attributes to be the inverse of their source vertex's attribute. The net effect is that each vertex's rank is split equally among all of its outgoing edges.</p><p class="calibre11">After this <a id="id1200" class="calibre4 pcalibre3 pcalibre pcalibre1 pcalibre2"/>initialization step, we use <code class="literal">map-edges</code> to set the attribute of each node to the default value: a vector of two zeros. The vector <a id="id1201" class="calibre4 pcalibre3 pcalibre pcalibre1 pcalibre2"/>contains the current page rank and the difference between this iteration's rank and the previous iteration's rank. Based on the size of the difference, our <code class="literal">message</code> function is able to decide whether or not to keep iterating.</p></div><div class="calibre2" title="Sort by highest influence"><div class="titlepage"><div class="calibre2"><div class="calibre2"><h3 class="title7"><a id="ch08lvl3sec43" class="pcalibre pcalibre3 pcalibre1 calibre8 pcalibre2"/>Sort by highest influence</h3></div></div></div><p class="calibre11">Before we run <a id="id1202" class="calibre4 pcalibre3 pcalibre pcalibre1 pcalibre2"/>PageRank on the communities identified by label propagation, we'll implement a utility function to list just the top 10 accounts in descending order of their ranks. The <code class="literal">top-n-by-pagerank</code> function will allow us to only show the accounts with the largest rank:</p><div class="calibre2"><pre class="programlisting">(defn top-n-by-pagerank [n graph]
  (-&gt;&gt; (page-rank graph)
       (g/vertices)
       (to-java-pair-rdd)
       (spark/map-to-pair
        (s-de/key-value-fn
         (fn [k v]
           (spark/tuple v k))))
       (spark/sort-by-key false)
       (spark/take n)
       (into [])))</pre></div><p class="calibre11">Once again, the fact that we can easily convert between graph and table representations of our data to enable this sort of data manipulation is one of the major benefits of using Glittering and Sparkling together for the graph analysis.</p><p class="calibre11">Finally, it will also be useful to have a function that returns the most frequently occurring node attributes <a id="id1203" class="calibre4 pcalibre3 pcalibre pcalibre1 pcalibre2"/>appearing in the first line:</p><div class="calibre2"><pre class="programlisting">(defn most-frequent-attributes [graph]
  (-&gt;&gt; (g/vertices graph)
       (to-java-pair-rdd)
       (spark/values)
       (spark/count-by-value)
       (sort-by second &gt;)
       (map first)))</pre></div><p class="calibre11">Given the output of label propagation, this function will return the community IDs as a sequence in the order of descending sizes.</p></div></div><div class="calibre2" title="Running PageRank to determine community influencers"><div class="titlepage"><div class="calibre2"><div class="calibre2"><h2 class="title5"><a id="ch08lvl2sec190" class="pcalibre pcalibre3 pcalibre1 calibre8 pcalibre2"/>Running PageRank to determine community influencers</h2></div></div></div><p class="calibre11">At last, we <a id="id1204" class="calibre4 pcalibre3 pcalibre pcalibre1 pcalibre2"/>can bring <a id="id1205" class="calibre4 pcalibre3 pcalibre pcalibre1 pcalibre2"/>together all the earlier code to identify the most resonant interests of the communities identified by label propagation. Unlike the other algorithms we've implemented with Glittering so far, we're sending our messages in the direction of follow rather than in the canonical direction. Therefore in the next example, we'll load the graph with <code class="literal">load-edgelist</code>, which preserves the follow direction:</p><div class="calibre2"><pre class="programlisting"> (defn ex-8-30 []
  (spark/with-context sc (-&gt; (g/conf)
                             (conf/master "local")
                             (conf/app-name "ch8"))
    (let [communities (-&gt;&gt; (load-edgelist
                            sc "data/twitter_combined.txt")
                           (label-propagation))
          by-popularity (most-frequent-attributes 2 communities)]
      (doseq [community (take 10 by-popularity)]
        (println
         (pagerank-for-community community communities))))))</pre></div><p class="calibre11">This code will take a little while to run, but will eventually return a sequence of the most important nodes in each of the ten most popular community graphs as shown in the following example:</p><div class="calibre2"><pre class="programlisting">;;[#sparkling/tuple [132.8254006818738 115485051]
;;#sparkling/tuple [62.13049747055527 62581962]
;;#sparkling/tuple [49.80716333905785 65357070]
;;#sparkling/tuple [46.248688749879875 90420314] ...]</pre></div><p class="calibre11">The first element of each tuple is the PageRank we've calculated for the vertex and the second element of each tuple is the node ID. The Twitter vertex IDs correspond to Twitter's own IDs. The accounts haven't been anonymized, so we can look up the Twitter accounts they correspond to.</p><div class="sidebar" title="Note"><div class="inner"><h3 class="title6"><a id="note83" class="pcalibre pcalibre3 pcalibre1 calibre8 pcalibre2"/>Note</h3><p class="calibre22">At the time of <a id="id1206" class="calibre4 pcalibre3 pcalibre pcalibre1 pcalibre2"/>writing, we can look up a Twitter account by ID using Twitter's Intent API available at <code class="literal">https://twitter.com/intent/user?user_id={$USER_ID}</code>. Substituting <code class="literal">{$USER_ID}</code> for Twitter's numeric ID will return the basic profile information.</p></div></div><p class="calibre11">The accounts with the highest PageRank in community one are American comic and talk show host Conan O'Brien with Barack Obama, Felicia Day, and Neil Patrick Harris. We could broadly categorize these people as American celebrities. It's not entirely surprising that on Twitter, the largest community is gathered around some of the largest accounts with the broadest general appeal.</p><p class="calibre11">Moving <a id="id1207" class="calibre4 pcalibre3 pcalibre pcalibre1 pcalibre2"/>down the list, the <a id="id1208" class="calibre4 pcalibre3 pcalibre pcalibre1 pcalibre2"/>second-largest community features among its top influencers the band Paramore, its members Hayley and Taylor, as well as Lady Gaga. This community clearly has a very specific set of musical interests.</p><p class="calibre11">Communities three and four both appear to have a strong gaming bias featuring X-Box, PlayStation, Steam, and Markus Persson (the creator of Minecraft) as their top influencers.</p><p class="calibre11">Bear in mind that we've already established that the whole graph is a part of one connected component, so we're not looking at disjoint sets of users. Using a combination of label propagation and PageRank, we are able to determine the groups of Twitter users with related interests.</p></div></div></div>



  
<div id="sbo-rt-content" class="calibre1"><div class="calibre2" title="Summary"><div class="titlepage"><div class="calibre2"><div class="calibre2"><h1 class="title2"><a id="ch08lvl1sec137" class="pcalibre pcalibre3 pcalibre1 calibre8 pcalibre2"/>Summary</h1></div></div></div><p class="calibre11">In this chapter, we've learned about graphs: a useful abstraction to model a huge variety of phenomena. We started the chapter using the Clojure library Loom to visualize and traverse small graphs of Twitter followers. We learned about two different methods of graph traversal, depth-first and breadth-first search, and the effect of changing edge weights on the paths discovered by Dijkstra's algorithm and Prim's algorithm. We also looked at the density of the whole graph and plotted the degree distributions to observe the difference between random and scale-free graphs.</p><p class="calibre11">We introduced GraphX and the Clojure library Glittering as a means of processing large graphs in a scalable way using Spark. In addition to providing several built-in graph algorithms, Glittering also exposes GraphX's Pregel API: a set of three symbiotic functions to express graph algorithms in a vertex-centric way. We showed that this alternative model of computation could be used to express triangle counting, connected components, label propagation, and finally PageRank algorithms, and chained our label propagation and PageRank steps together to determine the top influencers for a set of Twitter communities.</p><p class="calibre11">This was our last chapter using parallel computing techniques. In the next chapter, we'll focus on local data processing, but we'll continue the thread of recursive analysis. We'll cover methods to deal with time series data—ordered sequences of observations in time—and demonstrate how recursive functions can be used to produce forecasts.</p></div></div>



  </body></html>