["```py\nzcat amazon_reviews_us_Digital_Ebook_Purchase_v1_01.tsv.gz | cut -d$'\\t' -f2,8 | head\n```", "```py\nzcat amazon_reviews_us_Digital_Ebook_Purchase_v1_01.tsv.gz | cut -d$'\\t' -f2,8 | tail -n +2 | head\n```", "```py\nzcat amazon_reviews_us_Digital_Ebook_Purchase_v1_01.tsv.gz | cut -d$'\\t' -f15 | cut -d$'-' -f2,3,1 | head\n```", "```py\nzcat amazon_reviews_us_Digital_Ebook_Purchase_v1_01.tsv.gz | cut -c1-12 | head\n```", "```py\nzcat amazon_reviews_us_Digital_Ebook_Purchase_v1_01.tsv.gz | cut -d$'\\t' -f2,8 | tail -n +2 | grep \"^3\" | head \n```", "```py\njoin -j2 <(zcat amazon_reviews_us_Digital_Ebook_Purchase_v1_01.tsv.gz | cut -d$'\\t' -f2 | sort | uniq -c) <(zcat amazon_reviews_us_Digital_Ebook_Purchase_v1_00.tsv.gz | cut -d$'\\t' -f2 | sort | uniq -c) | head\n```", "```py\nzcat amazon_reviews_us_Digital_Ebook_Purchase_v1_01.tsv.gz | cut -d$'\\t' -f 2 | sort | uniq -c | head\n```", "```py\nzcat amazon_reviews_us_Digital_Ebook_Purchase_v1_01.tsv.gz | cut -d$'\\t' -f2,8 | awk '{sum[$1]+=$2;count[$1]+=1} END {for (i in sum) {print i,sum[i],count[i],sum[i]/count[i]}}' | head \n```", "```py\nzcat amazon_reviews_us_Digital_Ebook_Purchase_v1_01.tsv.gz | cut -d$'\\t' -f2,8 | awk '{sum[$1]+=$2;count[$1]+=1} END {for (i in sum) {print i,sum[i],count[i],sum[i]/count[i]}}' | sort -k3 -r -n | head\n```", "```py\nzcat amazon_reviews_us_Digital_Ebook_Purchase_v1_01.tsv.gz | cut -d$'\\t' -f2,8 | awk '{sum[$1]+=$2;count[$1]+=1} END {for (i in sum) {print i,sum[i],count[i],sum[i]/count[i]}}' | sort -k3 -r -n | awk '$3 >= 100 && $3 <=200' | head \n```", "```py\nhead -n21 amazon_reviews_us_Digital_Ebook_Purchase_v1_00.tsv > test.csv \nsqlite3 test.sq3 <<EOF\n.mode csv\n.separator \"\\t\"\n.import test.csv test_reviews\nEOF\n```", "```py\nCOLS=`head  amazon_reviews_us_Digital_Ebook_Purchase_v1_00.tsv | head -n1 | sed -e 's:^\\|$:\":g; s:\\t:\", \":g'`\n\nVALUES=`head  amazon_reviews_us_Digital_Ebook_Purchase_v1_00.tsv | tail -n1 | sed -e 's:^\\|$:\":g; s:\\t:\", \":g'` sqlite3 reviews.sq3 \"create table ‘aws-reviews' ( $COLS) ;\" \n```", "```py\nsqlite3 reviews.sq3 \".tables\"\n```", "```py\n sqlite3 reviews.sq3 \".schema aws-reviews\"\n```", "```py\nhead -n21 amazon_reviews_us_Digital_Ebook_Purchase_v1_00.tsv | sed '1d; s/\"/\"\"/g ; s/\\t/\", \"/g;' | while read LINE ; do VALUES=\"\\\"${LINE}\\\"\" ; sqlite3 reviews.sq3 \"insert into aws_reviews ($COLS) VALUES ($VALUES) ;\"; done  \n```", "```py\nsqlite3 reviews.sq3 “select * from aws_reviews”\n```", "```py\n$ let x=1\n $ echo $x\n 1\n $ let x=$x+1\n $ echo $x\n2\n```", "```py\nexpr 1 + 2\n3\nexpr 3 \\* 10\n30\n```", "```py\na=$((1 + 2))\necho $a \n((a++))\necho $a\n\n3\n4\n```", "```py\nscale = 2;\n(10.0*2+2)/7;\n```", "```py\ncat test.bc | bc\n3.14\n```", "```py\nscale=5; \ndefine harmonic(x,y){ return 2.0/((1.0/x) + (1.0/y)); }\n```", "```py\nawk '{s+=$2 ; f+=$4}END{print \"scale=5;\\n define harmonic(x,y){ return 2.0/((1.0/x) + (1.0/y)); } \\n harmonic(\",s/NR,\",\",f,\")\"}' data.txt | bc\n```", "```py\npattern {action}\npattern {action}\npattern {action}\n…\n```", "```py\n$0: The text of the entire record.\n$1, $2, … : The text of the 1st, 2nd, etc fields in the record.\nNF: The number of fields in the current record.\nNR: The current count of records (equal to the total number of records in the END step)\n```", "```py\nzcat amazon_reviews_us_Digital_Ebook_Purchase_v1_01.tsv.gz | tail -n +2 | head -n 10000 | cut -f14 | awk 'BEGIN {FS=\"[^a-zA-Z]+\"}; {for (i=1;i<NF;i++) words[$i] ++}; END {for (i in words) print words[i], i}' | head\n```", "```py\nzcat amazon_reviews_us_Digital_Ebook_Purchase_v1_01.tsv.gz | tail -n +2 | cut -f8 | awk '{star[$0]++}; END {for (i in star) print i,star[i]}'\n```", "```py\nimport sys\nimport pandas as pd\n\ndf = pd.read_csv(sys.stdin,sep='\\t')\nprint 'star rating mean',df['star_rating'].mean()\nprint 'helpful votes mean', df['helpful_votes'].mean()\n```", "```py\nzcat amazon_reviews_us_Digital_Ebook_Purchase_v1_01.tsv.gz | head -n 100 | python average.py\n```", "```py\ncurl -s \"https://api.weather.gov/points/42.5,-71.5\"\n```", "```py\n{\n \"@context\": [\n \"https://raw.githubusercontent.com/geojson/geojson-ld/master/contexts/geojson-base.jsonld\",\n\n {\n \"wx\": \"https://api.weather.gov/ontology#\",\n \"s\": \"https://schema.org/\",\n \"geo\": \"http://www.opengis.net/ont/geosparql#\",\n \"unit\": \"http://codes.wmo.int/common/unit/\",\n \"@vocab\": \"https://api.weather.gov/ontology#\",\n \"geometry\": {\n \"@id\": \"s:GeoCoordinates\",\n \"@type\": \"geo:wktLiteral\"\n }\n [......]\n}\n```", "```py\ncurl -s \"https://api.weather.gov/points/42.5,-71.5\" | jq -r '.| \"\\(.properties.cwa) \\(.properties.gridX) \\(.properties.gridY)\"'\n```", "```py\ncurl -s \"https://api.weather.gov/points/42.5,-71.5\" | jq -r '.| \"\\(.properties.forecastGridData)\"' \n```", "```py\nhttps://api.weather.gov/gridpoints/BOX/55,80\n```", "```py\ncurl -s \"https://api.weather.gov/gridpoints/BOX/55,80\" |  jq -r '[.properties.maxTemperature.values[1].validTime[0:10],.properties.maxTemperature.values[1].value] | @csv'\n```", "```py\n\"2018-06-22\",23.88888888888897\n```", "```py\n$ chmod 700 forecast.sh \n```", "```py\n$ cat forecast.sh \n#!/bin/bash\ncurl -s \"https://api.weather.gov/gridpoints/BOX/55,80\" | jq -r '[.properties.maxTemperature.values[1].validTime[0:10],.properties.maxTemperature.values[1].value] | @csv'\n```", "```py\n<minutes to run> <hours to run> <day of month to run> <month to run> <day of week to run>\n```", "```py\n0 12 * * *\n```", "```py\ncrontab -e\n```", "```py\n0 12 * * * sh <script location>/forecast.sh >> <data dir>forecast.csv\n```", "```py\ncurl -s \"https://api.weather.gov/gridpoints/BOX/55,80/stations\" | jq -r '.observationStations[0]'\n```", "```py\nhttps://api.weather.gov/stations/KBED\n```", "```py\nhttps://api.weather.gov/stations/KBED/observations/current\n```", "```py\ncurl -s \"https://api.weather.gov/stations/KBED/observations/current\" | jq -r '[.properties.timestamp[0:10],.properties.temperature.value]| @csv'\"2018-06-21\",20.600000000000023\n```", "```py\n0 * * * * sh <script location>/actual.sh >> <data location>/actual.csv\n```", "```py\ngawk  'BEGIN { FPAT = \"([^,]+)|(\\\"[^\\\"]+\\\")\" } {count[$1]++ ; max[$1] = (count[$1]==1||max[$1]<$2)?$2:max[$1]} END{ for (i in max) print $i,max[$i]}' actual.csv \n\"2018-06-22\",18.900000000000034\n```", "```py\n join -t',' <(gawk  'BEGIN { FPAT = \"([^,]+)|(\\\"[^\\\"]+\\\")\" } {count[$1]++ ; max[$1] = (count[$1]==1||max[$1]<$2)?$2:max[$1]} END{ for (i in max) print $i,max[$i]}' actual.csv ) forecast.csv\n```", "```py\n\"2018-06-22\",18.900000000000034 ,23.88888888888897\n...\n```", "```py\n> join -t',' <(gawk  'BEGIN { FPAT = \"([^,]+)|(\\\"[^\\\"]+\\\")\" } {count[$1]++ ; max[$1] = (count[$1]==1||max[$1]<$2)?$2:max[$1]} END{ for (i in max) print $i,max[$i]}' actual.csv ) forecast.csv | gawk 'BEGIN { FPAT = \"([^,]+)|(\\\"[^\\\"]+\\\")\" } {print $1,$2-$3}'\n```", "```py\n\"2018-06-22\" -4.98889\n```"]