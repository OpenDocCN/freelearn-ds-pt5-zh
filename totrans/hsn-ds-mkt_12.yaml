- en: Predicting the Likelihood of Marketing Engagement
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this chapter, we are going to expand the knowledge we gained from the previous
    chapter and the customer analytics exercise we conducted in [Chapter 7](72e8f4ee-7f95-4acc-928d-d33c9fc31bd6.xhtml),
    *Exploratory Analysis for Customer Behavior*. For successful and more intelligent
    marketing strategies, we cannot stop at analyzing customer data. With the advanced
    technology in data science and machine learning, we can now make intelligent guesses
    and estimates on customers' future behaviors, such as what types of customers
    are more likely to engage with marketing efforts, the amount of purchases that
    customers are likely to make, or which customers are likely to churn. These predictions
    or intelligent guesses that are built based on historical customer data can help
    you improve your marketing performance and further tailor your marketing strategies
    for different target audiences. In this chapter, we are going to learn how we
    can utilize data science and machine learning to predict future outcomes and how
    this can help your future marketing efforts.
  prefs: []
  type: TYPE_NORMAL
- en: 'In this chapter, we will cover the following topics:'
  prefs: []
  type: TYPE_NORMAL
- en: Predictive analytics in marketing
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Evaluating classification models
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Predicting the likelihood of marketing engagement with Python
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Predicting the likelihood of marketing engagement with R
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Predictive analytics in marketing
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: '**Predictive analytics** is a process of analyzing and extracting information
    from historical data to identify patterns and make predictions about future outcomes.
    Numerous statistical and machine learning models are typically used to find the
    relationship between the attributes or features in the dataset and the target
    variable or behavior that you would like to predict. Predictive analytics can
    be utilized and applied in many different industries.'
  prefs: []
  type: TYPE_NORMAL
- en: For example, it is often used in the financial industry for fraud detection,
    where machine learning models are trained to detect and prevent potential fraudulent
    transactions. The healthcare industry can also benefit from predictive analytics
    to help physicians in their decision-making processes. Furthermore, there are
    various parts of marketing that can also benefit from predictive analytics, such
    as customer acquisition, customer retention, and up-selling and cross-selling,
    to name a few.
  prefs: []
  type: TYPE_NORMAL
- en: 'In predictive analytics, broadly speaking, there are two types of problems:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Classification problems**: A classification problem is where there is a set
    of categories an observation can belong to. For example, predicting whether a
    customer is going to open a marketing email or not is a classification problem.
    There are only two possible outcomes—opening the marketing email or not opening
    the email.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Regression problems**: A regression problem, on the other hand, is where
    the outcome can take on any range of real numbers. For example, predicting customer
    lifetime value is a regression problem. One customer can have a lifetime value
    of $0 and another customer can have a lifetime value of $10,000\. This type of
    problem, where the outcome can take continuous values, is called a regression
    problem.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: In this chapter, we are going to focus on one of the common classification problems
    in the marketing industry—predicting the likelihood of customer engagement. In
    the following chapter, [Chapter 9](9b3d36ba-d690-491c-9a6f-b8c00f59cfb4.xhtml),
    *Customer Lifetime Value*, we are going to tackle one of the frequently appearing
    regression problems within the marketing industry.
  prefs: []
  type: TYPE_NORMAL
- en: Applications of predictive analytics in marketing
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'As briefly mentioned previously, there are numerous ways of applying and utilizing
    predictive analytics in marketing. In this section, we are going to discuss four
    popular use cases of predictive analytics in marketing:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Likelihood of engagement**: Predictive analytics can help marketers forecast
    the likelihood of customer engagements with their marketing strategies. For example,
    if your marketing happens a lot in the email space, you can utilize predictive
    analytics to forecast which customers have a high likelihood of opening your marketing
    emails and custom-tailor your marketing strategies to those high-likelihood customers
    to maximize your marketing results. For another example, if you are displaying
    advertisements on social media, predictive analytics can help you identify certain
    types of customers that are likely to click on the ads.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Customer lifetime value**: Predictive analytics can help you forecast the
    expected lifetime values of your customers. Using historical transactional data,
    predictive analytics can help you identify high-value customers within your customer
    base. With these predictions, you and your firm can focus more on building healthy
    relationships with those high-value customers. We are going to discuss in more detail
    how to build predictive models for customer lifetime value forecasts in the following
    chapter.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Recommending the right products and contents**: As we have already discussed
    in [Chapter 6](d3ba7047-2873-4b03-9a44-4c1d55b84178.xhtml), *Recommending the
    Right Products*, we can use data science and machine learning to predict which
    customers are likely to purchase products or view contents. Using these predictions,
    you can improve customer conversion rates by recommending the right products and
    contents for individual customers.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Customer acquisition and retention**: Predictive analytics has also been
    heavily used for customer acquisition and retention. Based on the profile data
    you gathered about your prospects or leads and the historical data of your existing
    customers, you can apply predictive analytics to identify high-quality leads or
    rank the leads by their likelihood of being converted into active customers. On
    the other hand, you can use the customer churn data and the historical data of
    your existing customers to develop predictive models to forecast which customers
    are likely to leave or unsubscribe from your products. We are going to discuss
    in more detail applying predictive analytics for customer retention in [Chapter
    11](3d5c7798-6874-40e9-b7e9-6fe39592cc2a.xhtml), *Retaining Customers*.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: On top of these four common use cases of predictive analytics in marketing,
    there are many other ways you can utilize predictive analytics for your marketing
    strategies. You should get creative on how and where to use predictive analytics
    for your future marketing strategies.
  prefs: []
  type: TYPE_NORMAL
- en: Evaluating classification models
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'When developing predictive models, it is important to know how to evaluate
    those models. In this section, we are going to discuss five different ways to
    evaluate the performance of classification models. The first metric that can be
    used to measure prediction performance is **accuracy**. Accuracy is simply the
    percentage of correct predictions out of all predictions, as shown in the following
    formula:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/84ed1d1c-4cfa-42b1-bbc9-378337f43d0a.png)'
  prefs: []
  type: TYPE_IMG
- en: 'The second metric that is commonly used for classification problems is **precision**.
    Precision is defined as the number of true positives divided by the total number
    of true positives and false positives. True positives are cases where the model
    correctly predicted as positive, while false positives are cases where the model
    was predicted as positive, but the true label was negative. The formula looks
    as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/ae4af65b-cc35-401a-938e-d5da51b56c4d.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Along with precision, **recall** is also commonly used to evaluate the performances
    of classification models. Recall is defined as the number of true positives divided
    by the number of true positives plus false negatives. False negatives are cases
    where the model was predicted as negative, but the true label was positive. Recall
    can be thought of as a measure of how much of the positive cases are retrieved
    or found by the model. The formula looks as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/7aef9390-c65f-4cf2-91f2-2c2f5a1d4a58.png)'
  prefs: []
  type: TYPE_IMG
- en: 'The final two metrics we are going to discuss are the **receiver operating
    characteristic** (**ROC**) curve and the **area under the curve** (**AUC**). The
    ROC curve shows how true positive rates and false positive rates change at different
    thresholds. The AUC is simply the total area under the ROC curve. The AUC ranges
    from 0 to 1 and a higher AUC number suggests better model performance. A random
    classifier has an AUC of 0.5, so any classifier with an AUC higher than 0.5 suggests
    that the model performs better than random predictions. A typical ROC curve looks
    as in the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/8b7e03bd-8eec-49a7-8c05-138ca8798c0a.png)'
  prefs: []
  type: TYPE_IMG
- en: In the following programming exercise, we are going to use these five metrics
    that we have just discussed to evaluate the performance of the model we build
    in Python and R. Let's now dive into building machine learning models to predict
    the likelihood of marketing engagement!
  prefs: []
  type: TYPE_NORMAL
- en: Predicting the likelihood of marketing engagement with Python
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this section, we are going to discuss how to build predictive models using
    machine learning algorithms in Python. More specifically, we will learn how to
    build a predictive model using the random forest algorithm, as well as how to
    tune the random forest model and evaluate the performance of the model. We will
    be mainly using the `pandas`, `matplotlib`, and `scikit-learn` packages to analyze,
    visualize, and build machine learning models that predict the likelihood of customer
    marketing engagement. For those readers who would like to use R instead of Python
    for this exercise, you can skip to the next section.
  prefs: []
  type: TYPE_NORMAL
- en: 'For this exercise, we will be using one of the publicly available datasets
    from IBM, which can be found at this link: [https://www.ibm.com/communities/analytics/watson-analytics-blog/marketing-customer-value-analysis/](https://www.ibm.com/communities/analytics/watson-analytics-blog/marketing-customer-value-analysis/).
    You can follow this link and download the data that is available in CSV format,
    named `WA_Fn UseC_ Marketing Customer Value Analysis.csv`. Once you have downloaded
    this data, you can load it into your Jupyter notebook by running the following
    command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: 'The `df` DataFrame looks as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/63a2f76d-29f3-443a-a327-34ab8b596ffd.png)'
  prefs: []
  type: TYPE_IMG
- en: As you might have noticed, this is the same dataset that we used in the previous
    chapter, where we conducted customer analytics. With the knowledge we gained about
    this dataset from the previous chapter, we are going to first prepare our data
    by encoding the target variable and other categorical variables that we are going
    to use as features for our machine learning models.
  prefs: []
  type: TYPE_NORMAL
- en: Variable encoding
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In order to build machine learning models using the `scikit-learn` package in
    Python, all the features in the dataset need to have numerical values. However,
    in the dataset, we have numerous columns that have non-numerical values. For example,
    the target variable, `Response`, which is what we are going to try to predict
    with machine learning models, is non-numeric. It contains two string values—`Yes`
    and `No`. We will need to encode this `Response` target variable with numerical
    values in order to be able to build machine learning models. For another example,
    the column `Gender`, which we can use as one of the features for our predictive
    model, also does not have numerical values. It contains two string values—`F`
    for female and `M` for male. In this section, we are going to discuss how we can
    encode these non-numeric columns so that we can use them as features for machine
    learning models.
  prefs: []
  type: TYPE_NORMAL
- en: Response variable encoding
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'The first thing we are going to do is encode the response variable `Response`.
    We are going to encode `Yes` values with `1`s and `No` values with `0`s. Take
    a look at the following code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: 'As you can see from this code, we are using the `apply` function of the `pandas`
    `DataFrame` to apply our `lambda` function on the `Response` column, so that it
    encodes `Yes` values with `1` and `No` values with `0`. We then store these encoded
    values in a newly-created column, `Engaged`. In order to get the overall response
    or engagement rate using this newly-created column, you can use the following
    code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: 'The overall engagement rate looks as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/90aabaf8-3052-4f9f-a47f-57daf049fbe0.png)'
  prefs: []
  type: TYPE_IMG
- en: Categorical variable encoding
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'If you look closely at the data, the following variables are categorical variables:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: These variables have a set of different values they can take and those values
    do not necessarily have orders that differentiate one from another.
  prefs: []
  type: TYPE_NORMAL
- en: 'If you recall from [Chapter 4](a9f09970-4826-46d0-8bfd-5796702c5629.xhtml),
    *From Engagement to Conversion*, there is more than one way to encode categorical
    variables. In this chapter, the method we are going to use is to create dummy
    variables for each category of individual categorical variables, using the `get_dummies`
    function in the `pandas` package. Take a look at the following code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: 'As you can see from this code snippet, we are iterating through the list of
    column names of categorical variables, defined in `columns_to_encode`. Then, for
    each column, we are using the `get_dummies` function in the `pandas` package to
    build dummy variables. In order to make things clear and cause less confusion,
    we are renaming the columns of the newly-created and encoded `DataFrame` `encoded_df`,
    where each column contains information about the original column name and the
    category it represents. As an example, for the  `Sale Channel` column, the newly-created
    DataFrame `encoded_df` will look as in the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/cea74d25-63a1-4b68-b9be-1041261dea91.png)'
  prefs: []
  type: TYPE_IMG
- en: As you can see from this example, each column of this new `DataFrame` represents
    each category in the original `Sales Channel` column and the values are one-hot
    encoded, meaning it assigns a value of `1` if the given record belongs to the
    given category, and `0` otherwise.
  prefs: []
  type: TYPE_NORMAL
- en: Once we have created dummy variables for the given column, we then store the
    newly-created columns into a variable named `categorical_features`. Lastly, we
    concatenate this newly-created `DataFrame` to the original `DataFrame`, by using
    the `concat` function of the `pandas` package. One of the parameters in the concat
    function, `axis=1`, tells `pandas` to concatenate the two `DataFrames` by the
    column.
  prefs: []
  type: TYPE_NORMAL
- en: 'By now, we have successfully encoded all the categorical variables except `Gender`.
    Since we do not need to create two dummy variables for the `Gender` column, as
    there can only be two genders, we are going to create one variable that contains
    information about the gender of a given record. Take a look at the following code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: As you can see from this code, we are creating a new column named `Is.Female`.
    We are using the apply function of the `pandas` `DataFrame` and encoding all females
    with the value of `1` and all males with the value of `0`.
  prefs: []
  type: TYPE_NORMAL
- en: Building predictive models
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'We are almost ready to start building and training machine learning models
    to predict customer responses or engagements. There are a few things to clean
    up in our data. Take a look at the following code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: 'As you can see from this code, we are creating a new `DataFrame` `sample_df`,
    which contains all the features, `all_features`, and the response variable, `response`.
    Then, we are cleaning up the column and feature names by replacing all the spaces
    in the names with dots. After these cleanups, DataFrame `sample_df` now looks
    as in the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/eb370c76-2e57-4457-a963-d7d7e9995c9f.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Now that we have a sample set that we can train and test our machine learning
    models with, let''s split this sample set into two subsets—one for training the
    models and another for testing and evaluating the trained models. The Python machine
    learning package, `scikit-learn`, has a function that splits a given sample set
    into train and test sets. Take a look at the following code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: 'In the `model_selection` module of the `scikit-learn` package, there is a function
    named `train_test_split`. This function takes the sample set and the desired breakdown
    between train and test set sizes as input parameters and returns train and test
    sets that are randomly split. As you can see from this code snippet, we are using
    `70%` of the sample set for training and the remaining `30%` for testing. The
    following shows the breakdowns of train and test sets from the sample set:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/b4bae11b-4c12-4301-a00b-a4d6616a5795.png)'
  prefs: []
  type: TYPE_IMG
- en: As you can see here, there are a total of `9,134` records in `sample_df`, `6,393`
    records in `x_train`, and `2,741` records in `x_test`, meaning that roughly `70%`
    of the sample set went into the train set and the remaining `30%` of the sample
    set went into the test set. We will be using these train and test sets for building
    and evaluating models in the following sections.
  prefs: []
  type: TYPE_NORMAL
- en: Random forest model
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'With the data that we have prepared so far, we are going to build a predictive
    model, using a random forest algorithm, which predicts whether a customer is going
    to respond or engage with the marketing campaign. In Python''s `scikit-learn`
    package, the random forest algorithm is implemented in the `ensemble` module and
    you can import the random forest class using the following code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs: []
  type: TYPE_PRE
- en: 'You can create a random forest classifier using the following code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs: []
  type: TYPE_PRE
- en: However, there are many hyperparameters you can tune for random forest models.
    Hyperparameters are the parameters you define before you train a machine learning
    model. For example, in the case of a random forest algorithm, you can define the
    number of trees you want in your random forest model. As another example, you
    can define the maximum depth of each tree in the forest, so that you can limit
    how big each tree in the forest can grow.
  prefs: []
  type: TYPE_NORMAL
- en: 'There are numerous hyperparameters you can define in `scikit-learn`''s `RandomForestClassifier`
    class. We will take a look at the following few examples of hyperparameters:'
  prefs: []
  type: TYPE_NORMAL
- en: '`n_estimators`: This defines the number of trees you want to build in the forest.
    Generally speaking, more trees mean better performance results. However, the amount
    of performance gain for each additional tree decreases as the number of trees
    in the forest increases. Since having more trees in a forest means higher cost
    in computations for training additional trees, you should try to find the balance
    and stop adding trees when the computational cost from training additional trees
    outweighs the performance gain.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`max_depth`: This parameter defines the maximum depth of individual trees.
    The larger the depth is, the more information your tree can capture from the train
    set, meaning larger trees learn the train set better than smaller trees. However,
    the larger the tree grows, the more likely it is going to overfit the train set.
    This means that the trained tree performs and predicts well within the train set,
    but predicts poorly in the dataset that it has not seen before. In order to avoid
    overfitting, we would want to limit the depth of the tree to a point where it
    does not overfit to the train set, but predicts the outcomes well enough.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`min_samples_split`: This defines the minimum number of data points required
    to split a node of the tree. For example, if you defined `min_samples_split` to
    be `50`, but the node only has `40` records, then it will not split the node any
    further. On the other hand, if the node has more than the predefined minimum number
    of samples, then it will split the node into child nodes. Similar to the `max_depth`
    hyperparameter, this helps you manage the amount of overfitting happening in the
    tree.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`max_features`: This defines the maximum number of features to be considered
    for splitting a node. This parameter creates the *randomness* in random forest
    models. Given the maximum number of features to be considered for a split, the
    random forest algorithm randomly chooses a subset of the features up to the maximum
    number and decides how to split a given node of a tree. This helps each tree of
    a random forest model to learn different information from the train set. When
    these trees that have learned the train set with slightly different set of features
    are bagged or ensembled all together, then the resulting forest will become more
    accurate and robust in its predictions.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: For a more detailed description and information on other hyperparameters, you
    can refer to their official documentation, which can be found at the following
    link: [https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html).
  prefs: []
  type: TYPE_NORMAL
- en: Training a random forest model
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Training a random forest model using `scikit-learn` is simple. Take a look
    at the following code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE10]'
  prefs: []
  type: TYPE_PRE
- en: Using the `RandomforestClasifier` class in the `scikit-learn` package's `ensemble`
    module, you first need to create a `RandomforestClasifier` object with the hyperparameters.
    For illustration purposes, we are instructing the model to build `200` trees,
    where each tree can only grow up to the depth of `5`. Then, you can train this
    model with the `fit` function, which takes two parameters, `X` and `y`, where
    `X` is for the training samples and `y` is for the training labels or target values.
  prefs: []
  type: TYPE_NORMAL
- en: 'When you run this code, you will see an output that looks as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/eb29841c-0a3c-423b-8568-410014d5215e.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Once a random forest model is trained or fitted, the model object contains
    a lot of useful information. One of the useful attributes you can extract from
    a trained `scikit-learn` random forest model is the information about individual
    trees in the forest. Using the `estimators_` attribute, you can retrieve the individual
    trees that are built within the forest. Take a look at the following output:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/08d11a03-fa14-417c-aa6e-c7f2b7750427.png)'
  prefs: []
  type: TYPE_IMG
- en: 'As you can see from this output, the `estimators_` attribute returns a list
    of sub-estimators, which are decision trees. With this information, you can simulate
    what each of these sub-estimators predicts for each input. For example, the following
    code shows how you can get the predictions from the first sub-estimator in the
    forest:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE11]'
  prefs: []
  type: TYPE_PRE
- en: 'The following output shows some of the predictions from the first five sub-estimators:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/db72f840-2ef0-4e2f-a4c0-8526c150a6c1.png)'
  prefs: []
  type: TYPE_IMG
- en: As you can see from this output, different trees predict differently for each
    record of the test set. This is because each tree is trained with different subsets
    of features that are randomly selected. Let's take a quick look at the predictions
    of these individual sub-estimators. The first tree predicts the `6th` record in
    the test set to be a class of `1` and the rest to be a class of `0`. On the other
    hand, the second tree predicts that the first 10 records of the test set to be
    a class of `0`. Using this information, you can see how the final predictions
    from the random forest model are formed from these individual sub-estimators or
    trees.
  prefs: []
  type: TYPE_NORMAL
- en: 'Other useful information that we can gain from the trained `RandomForestClassifier`
    object is the feature importances, with which we can understand the importance
    or the impact of each feature on the final predictions. You can get the feature
    importances for each feature using the following code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE12]'
  prefs: []
  type: TYPE_PRE
- en: 'The output of this code looks as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/1b9b3774-34bf-4bb3-8431-5be4b5e0c88f.png)'
  prefs: []
  type: TYPE_IMG
- en: 'In order to associate these feature importances with the corresponding features,
    you can use the following code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE13]'
  prefs: []
  type: TYPE_PRE
- en: 'The result looks as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/9482caaa-0e7e-418d-a0fc-eaa2ca7edc89.png)'
  prefs: []
  type: TYPE_IMG
- en: As you can see from this output, the `EmploymentStatus.Retired` feature seems
    to be the most important factor in making the final prediction and the `Income`,
    `Total.Claim.Amount`, and `Customer.Lifetime.Value` features follow as the second,
    third, and fourth most important features.
  prefs: []
  type: TYPE_NORMAL
- en: Evaluating a classification model
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Earlier in this chapter, we have discussed five different ways to look at the
    performance of a classification model. In this section, we are going to learn
    how we can compute and visualize the metrics for evaluating a classification model
    in Python using the random forest model we have just built.
  prefs: []
  type: TYPE_NORMAL
- en: 'The first three metrics that we are going to look at are accuracy, precision,
    and recall. Python''s `scikit-learn` package has implemented functions for these
    three metrics. You can import these functions using the following line of code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE14]'
  prefs: []
  type: TYPE_PRE
- en: As you can see from this code snippet, the `metrics` module of the `scikit-learn`
    package has an `accuracy_score` function for calculating the accuracy of a model,
    a `precision_score` function for the precision, and a `recall_score` function
    for the recall.
  prefs: []
  type: TYPE_NORMAL
- en: 'Before we go ahead and evaluate the model performance, we will need the model
    prediction results. In order to have the random forest model we have built in
    the previous section to make predictions on a dataset, we can simply use the `predict`
    function of the model. Take a look at the following code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE15]'
  prefs: []
  type: TYPE_PRE
- en: 'With these prediction results, we are going to evaluate how well our random
    forest model performs in the train and test sets. The following code shows how
    we can use the `accuracy_score`, `precision_score`, and `recall_score` functions
    in the `scikit-learn` package:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE16]'
  prefs: []
  type: TYPE_PRE
- en: 'As you can see from this code, the `accuracy_score`, `precision_score`, and
    `recall_score` functions all take two parameters—truth labels and predicted labels.
    Take a look at the following output:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/d6d2fa84-f2c8-4adc-95d2-47d878b3792f.png)'
  prefs: []
  type: TYPE_IMG
- en: This output gives us a brief overview of how well our model performs at predicting
    the responses. For the train set, the accuracy of the overall prediction was `0.8724`,
    meaning the model prediction was correct for about `87%` of the time. For the
    test set, the accuracy of the overall prediction was `0.8818`, which is roughly
    on the same line with the prediction accuracy within the train set. You can also
    see that the precision for in-sample and out-of-sample predictions were `0.9919`
    and `0.9423` respectively, and the recalls were `0.1311` and `0.1324`. Due to
    the randomness and the different hyperparameters you might have used, you can
    get different results.
  prefs: []
  type: TYPE_NORMAL
- en: 'The next set of metrics we are going to look at are the ROC curve and the AUC. The
    `metrics` module in the `scikit-learn` package has handy functions for the ROC
    curve and the AUC. Take a look at the following line of code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE17]'
  prefs: []
  type: TYPE_PRE
- en: 'The `roc_curve` function in the metrics module of the `scikit-learn` package
    computes the ROC, and the `auc` function computes the AUC. In order to compute
    the ROC and AUC using these functions, we need to first get the prediction probabilities
    from our random forest model. The following code shows how we can get the random
    forest model''s prediction probabilities for both the train and test sets:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE18]'
  prefs: []
  type: TYPE_PRE
- en: As you can see from this code, we are using the `predict_proba` function of
    the random forest model, `rf_model`. This function outputs the predicted probabilities
    of the given record belonging to each class. Since we only have two possible classes
    in our case, `0` for no responses and `1` for responses, the output of the `predict_proba`
    function has two columns, where the first column represents the predicted probability
    of a negative class, meaning no response for each record, and the second column
    represents the predicted probability of a positive class, meaning a response for
    each record. Since we are only interested in the likelihood of responding to the
    marketing effort, we can take the second column for the predicted probabilities
    of the positive class.
  prefs: []
  type: TYPE_NORMAL
- en: 'With these predicted probabilities of the positive class for both the train
    and test sets, we can now compute the ROC curve and AUC. Let''s first take a look
    at how we can compute the ROC curve using the `roc_curve` function in the following
    code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE19]'
  prefs: []
  type: TYPE_PRE
- en: As you can see from this code snippet, the `roc_curve` function takes two parameters—observed
    labels and predicted probabilities. This function returns three variables, `fpr`,
    `tpr`, and `thresholds`. The `fpr` values represent the false positive rates for
    each given threshold and the `tpr` values represent the true positive rates for
    each given threshold. The `thresholds` values represent the actual thresholds
    at which `fpr` and `tpr` are measured.
  prefs: []
  type: TYPE_NORMAL
- en: 'Next, with these `fpr` and `tpr` values, we can compute the AUC using the following
    code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE20]'
  prefs: []
  type: TYPE_PRE
- en: 'As you can see from this code, the `auc` function takes two parameters—`fpr`
    and `tpr`. Using the previously calculated `fpr` and `tpr` values from the `roc_curve`
    function, we can easily compute the AUC numbers for both the train and test sets.
    The output looks as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/0bd94f4b-6d28-4250-a692-262db25c71ae.png)'
  prefs: []
  type: TYPE_IMG
- en: Depending on the hyperparameters and the randomness within the random forest
    algorithm, your AUC numbers can look different from these examples. However, in
    our case, the in-sample train set AUC was `0.8745` and the out-of-sample test
    set AUC was `0.8425`. If you see a big gap between these two numbers, it is a
    sign of overfitting and you should try to address it by pruning the trees in the
    forest by tuning the hyperparameters, such as the maximum depth and minimum number
    of samples to split.
  prefs: []
  type: TYPE_NORMAL
- en: 'The last thing we are going to look at for evaluating machine learning models
    is the actual ROC curve. With the output of the `roc_curve` function, we can plot
    the actual ROC curves using the `matplotlib` package. Take a look at the following
    code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE21]'
  prefs: []
  type: TYPE_PRE
- en: 'As you can see from this code, we are plotting three line plots—one for the
    out-of-sample test set ROC curve, another for the in-sample train set ROC curve,
    and lastly one for a straight line for the benchmark. The result looks as in the
    following:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/0a2dedf6-0a8c-4f20-909b-6d231c502508.png)'
  prefs: []
  type: TYPE_IMG
- en: As you can see from this plot, it is easier to see and compare the overall performance
    of the model between the train and test sets with ROC curves. The larger the gap
    between the in-sample ROC curve and the out-of-sample ROC curve, the more the
    model is overfitting to the train set and fails to generalize the findings for
    unforeseen data.
  prefs: []
  type: TYPE_NORMAL
- en: The full code for this Python exercise can be found at the following link: [https://github.com/yoonhwang/hands-on-data-science-for-marketing/blob/master/ch.8/python/PredictingEngagement.ipynb](https://github.com/yoonhwang/hands-on-data-science-for-marketing/blob/master/ch.8/python/PredictingEngagement.ipynb)
  prefs: []
  type: TYPE_NORMAL
- en: Predicting the likelihood of marketing engagement with R
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this section, we are going to discuss how to build predictive models using
    machine learning algorithms in R. More specifically, we will learn how to build
    a predictive model using a random forest algorithm, as well as how to tune the
    random forest model, and evaluate the performance of the model. We will be mainly
    using the `caTools`, `ROCR`, and `randomForest` packages to evaluate, visualize,
    and build machine learning models that predict the likelihood of customer marketing
    engagement. For those readers who would like to use Python instead of R for this
    exercise, you can refer to the previous section.
  prefs: []
  type: TYPE_NORMAL
- en: 'For this exercise, we will be using one of the publicly available datasets
    from **IBM**, which can be found at this link: [https://www.ibm.com/communities/analytics/watson-analytics-blog/marketing-customer-value-analysis/](https://www.ibm.com/communities/analytics/watson-analytics-blog/marketing-customer-value-analysis/).
    You can follow this link and download the data that is available in CSV format,
    named `WA_Fn UseC_ Marketing Customer Value Analysis.csv`. Once you have downloaded
    this data, you can load it into your RStudio by running the following command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE22]'
  prefs: []
  type: TYPE_PRE
- en: '`df` looks as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/5ae79a64-9bbd-424d-9259-21bdec131954.png)'
  prefs: []
  type: TYPE_IMG
- en: As you might have noticed, this is the same dataset that we used in the previous
    chapter, where we conducted customer analytics. With the knowledge we gained about
    this dataset from the previous chapter, we are going to first prepare our data
    by encoding the target variable and other categorical variables that we are going
    to use as features for our machine learning models.
  prefs: []
  type: TYPE_NORMAL
- en: Variable encoding
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In order to build machine learning models in R, all the features in the dataset
    need to have numerical values. However, in the dataset we have numerous columns
    that have non-numerical values. For example, the target variable, `Response`,
    which is what we are going to try to predict with our machine learning models,
    is non-numeric. It contains two string values—`Yes` or `No`. We will need to encode
    this `Response` target variable with numerical values in order to be able to build
    machine learning models. For another example, the `Gender` column, which we can
    use as one of the features for our predictive model, also does not have numerical
    values. It contains two string values—`F` for female and `M` for male. In this
    section, we are going to discuss how we can encode these non-numeric columns,
    so that we can use them as features in machine learning models.
  prefs: []
  type: TYPE_NORMAL
- en: Response variable encoding
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'The first thing we are going to do is encode the response variable, `Response`.
    We are going to encode `Yes` values with `1`s and `No` values with `0`s. Take
    a look at the following code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE23]'
  prefs: []
  type: TYPE_PRE
- en: 'As you can see from this code, we are simply casting the values of the `Response`
    column to integer values using the `as.integer` function. The reason why we are
    subtracting by `1` is because it encodes values into `1` for `No` and `2` for
    `Yes`, instead of `0` for `No` and `1` for `Yes`, as we wanted. We then store
    these encoded values in a newly-created column, `Engaged`. In order to get the
    overall response or engagement rate using this newly-created column, you can use
    the following code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE24]'
  prefs: []
  type: TYPE_PRE
- en: 'The overall engagement rate looks as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/aa44411e-2bd6-4206-938f-11a79d3908ec.png)'
  prefs: []
  type: TYPE_IMG
- en: Categorical variable encoding
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'If you look closely at the data, the following columns are categorical variables
    in our dataset:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE25]'
  prefs: []
  type: TYPE_PRE
- en: These variables have a set of different values they can take and these values
    do not necessarily have orders that differentiate one from another.
  prefs: []
  type: TYPE_NORMAL
- en: 'If you recall from [Chapter 4](a9f09970-4826-46d0-8bfd-5796702c5629.xhtml),
    *From Engagement to Conversion*, we discussed how we can create factor variables
    for such categorical variables in R. In this chapter, the method we are going
    to use is to create dummy variables for each category of individual categorical
    variables, using the `model.matrix` function in R. Take a look at the following
    code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE26]'
  prefs: []
  type: TYPE_PRE
- en: 'As you can see from this code, it is simple to create dummy variables for categorical
    variables in R. All you need to do is to apply the `model.matrix` function on
    the R `DataFrame`''s categorical variable columns. If you look closely at the
    code, you will notice the `~.-1` formula that we are using here. Without this
    formula, the `model.matrix` function will create an unnecessary column named `Intercept` in
    the output matrix. In order to avoid having this unnecessary column, we can use
    the formula in this code example. The first few columns of the newly-created `DataFrame` `encodedDf` now
    look as in the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/b03f57a2-e6e4-43cd-9918-6b10293bf4b2.png)'
  prefs: []
  type: TYPE_IMG
- en: As you can see from this output, each column of this new `DataFrame` represents
    each category in the original column. For example, the first column, `Sales.ChannelAgent`,
    is encoded with `1` if the given record or customer was reached out by a sales
    agent and `0` otherwise. For another example, the fifth column, `Vehicle.SizeMedsize`,
    is encoded with `1` if the given record or customer has medium-size vehicles and
    `0` otherwise.
  prefs: []
  type: TYPE_NORMAL
- en: 'Now that we have successfully encoded all the categorical variables with numerical
    values, we need to append the continuous variables to this newly-created `DataFrame`,
    `encodedDF`. Take a look at the following code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE27]'
  prefs: []
  type: TYPE_PRE
- en: As you can see from this code, we are using the `cbind` R function, which combines
    two DataFrames by columns. We are combining the previously-created DataFrame `encodedDF`,
    which contains all the encoded categorical variables with the DataFrame with continuous
    variables. Then, we are storing this combined `DataFrame` back to the `encodedDF` variable.
  prefs: []
  type: TYPE_NORMAL
- en: Building predictive models
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'We are almost ready to start building and training machine learning models
    to predict customer responses or engagements. There is one thing we need to do
    before we start training a random forest model. We need to split the sample set,
    the `encodedDF` variable, into two subsets—one for training the models and another
    for testing and evaluating the trained models. The `caTools` R package has a handy
    function that splits a given sample set into train and test sets. If you do not
    have this library installed in your R environment, you can install it using the
    following command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE28]'
  prefs: []
  type: TYPE_PRE
- en: 'Now, take a look at the following code on how to split the sample set into
    training and testing:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE29]'
  prefs: []
  type: TYPE_PRE
- en: Let's take a closer look at this code. The `sample.split` function in the `caTools`
    package lets us split the dataset into a proportion we would like. As you can
    see from this code, we defined `SplitRatio` to be `0.7`, which means we are taking
    `70%` of the sample set as a training set and the remaining `30%` of the `sample`
    set as a test set. The resulting variable, sample, now has an array of Boolean
    values, `TRUE` or `FALSE`, where `70%` of the arrays are `TRUE` and the remaining `30%`
    are `FALSE`.
  prefs: []
  type: TYPE_NORMAL
- en: 'With this data, we can create train and test sets. As you can see from the
    code, we are using the `subset` function in R to create train and test sets. First,
    we take those records that correspond to `TRUE` values in the `sample` variable as
    the train set. Then, we take those records whose indexes correspond to `FALSE`
    values in the `sample` variable as the test set. The following shows the breakdown
    of train and test sets from the sample set:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/9b3580ee-87ad-4281-9f57-cc83a7323b88.png)'
  prefs: []
  type: TYPE_IMG
- en: As you can see here, there are a total of `9,134` records in `encodedDF`, `6,393` records
    in `trainX`, and `2,741` records in `testX`, meaning that roughly `70%` of the
    sample set went into the the train set and the remaining `30%` of the sample set
    went into the test set. We will be using these train and test sets for building
    and evaluating models in the following sections.
  prefs: []
  type: TYPE_NORMAL
- en: Random forest model
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'With the data that we have prepared so far, we are going to build a predictive
    model using a random forest algorithm, which predicts whether a customer is going
    to respond or engage with the marketing campaign. We are going to use the `randomForest` R
    library. If you do not have this library installed in your R environment, you
    can install it using the following command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE30]'
  prefs: []
  type: TYPE_PRE
- en: 'Once you have this package installed, you can use the following code to build
    a random forest model:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE31]'
  prefs: []
  type: TYPE_PRE
- en: However, there are many hyperparameters you can tune for random forest models.
    Hyperparameters are the parameters you define before you train a machine learning
    model. For example, in the case of a random forest algorithm, you can define the
    number of trees you want in your random forest model. As another example, you
    can define the maximum number of terminal nodes for each tree in the forest, so
    that you can limit how big each tree in the forest can grow.
  prefs: []
  type: TYPE_NORMAL
- en: 'There are numerous hyperparameters you can define and fine-tune. We will take
    a look at a few of these hyperparameters:'
  prefs: []
  type: TYPE_NORMAL
- en: '**ntree:** This defines the number of trees you want to build in the forest.
    Generally speaking, more trees mean better performance results. However, the amount
    of performance gain for each additional tree decreases as the number of trees
    in the forest increases. Since having more trees in a forest means higher cost
    in computations for training additional trees, you should try to find the balance
    and stop adding trees when the computational cost from training additional trees
    outweighs the performance gain.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**sampsize**: This parameter defines the size of the sample to draw for training
    each tree. This introduces randomness in the forest, while training a random forest
    model. Having a high sample size results in a less random forest and has a higher
    chance of overfitting. This means that the trained tree performs and predicts
    well within the train set, but predicts poorly in the dataset that it has not
    seen before. Decreasing the sample size can help you avoid overfitting, but the
    performance of your model usually decreases as you decrease the sample size.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**nodesize**: This parameter defines the minimum size of the terminal nodes,
    which means how many samples each terminal node needs to have at the very least.
    The larger this number is, the smaller the tree can grow. As you increase this
    number, you can mitigate the overfitting issues, but at the expense of the model
    performance.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**maxnodes**: This parameter defines the maximum number of terminal nodes each
    tree in the forest can have. If you do not set this number, the algorithm is going
    to grow the tree to the fullest. This can result in overfitting the train set.
    Reducing the maximum number of terminal nodes can help you overcome overfitting
    issues.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'For a more detailed description and information on other hyperparameters, you
    can refer to the official documentation that can be found at the following link:
    [https://www.rdocumentation.org/packages/randomForest/versions/4.6-14/topics/randomForest](https://www.rdocumentation.org/packages/randomForest/versions/4.6-14/topics/randomForest).'
  prefs: []
  type: TYPE_NORMAL
- en: Training a random forest model
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Training a random forest model using the `randomForest` package is simple.
    Take a look at the following code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE32]'
  prefs: []
  type: TYPE_PRE
- en: Using the `randomForest` function in the `randomForest` package, you can easily
    train a random forest model. You just need to supply the train set to the function.
    For illustration purposes, we are instructing the model to build `200` trees,
    where each tree can only grow up to `24` terminal nodes.
  prefs: []
  type: TYPE_NORMAL
- en: 'When you run this code, your model object will look as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/9c563e81-5c46-48cd-a297-3f7600443bca.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Once a random forest model is trained or fitted, the model object contains
    a lot of useful information. One of the useful attributes you can extract from
    a trained random forest model is the information about individual trees in the
    forest. Using the `getTree` function, you can retrieve how the individual trees
    are built within the forest. Take a look at the following example:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/d829463f-5d3e-40ad-9886-e52700eec057.png)'
  prefs: []
  type: TYPE_IMG
- en: Here we are looking at the information about the first tree in the forest. This
    gives us some information about the structure of the tree. The `left daughter`
    and `right daughter` columns tell us the location of this node in the given tree.
    The `status` column tells us whether the node is terminal (`-1`) or not (`1`).
    The `prediction` column tells us the prediction from this node.
  prefs: []
  type: TYPE_NORMAL
- en: 'Other information we can get from the fitted random forest model is the prediction
    from each tree in the forest. Take a look at the following code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE33]'
  prefs: []
  type: TYPE_PRE
- en: 'By using the `predict.all=TRUE` flag, the `prediction` function returns the
    predictions from each tree in the forest. Take a look at the following output:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/09bc2153-ddd4-4d9c-bcd7-64668f852017.png)'
  prefs: []
  type: TYPE_IMG
- en: This output is showing the first 20 trees' predictions for the first five records
    in the train set. As you can see from this output, the `10^(th)` tree in the forest
    predicted the `5^(th)` record in the train set to be a class of `1`, but all the
    other 19 trees predicted the `5^(th)` record in the train set to be a class of
    `0`. As you can see from this output, different trees predict differently for
    each record of the test set. This is because each tree is trained with different
    subsets of features that are randomly selected. Using this information, you can
    see how the final predictions from the random forest model are formed from these
    individual sub-estimators or trees.
  prefs: []
  type: TYPE_NORMAL
- en: 'Other useful information that we can gain from a trained `randomForest` object
    is the feature importances, with which we can understand the importance or the
    impact of each feature on the final predictions. You can get the feature importances
    for each feature using the following code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE34]'
  prefs: []
  type: TYPE_PRE
- en: 'Part of the output of this code looks as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/14bab6a6-f5a2-4ff3-9c5c-b40bb0a74b48.png)'
  prefs: []
  type: TYPE_IMG
- en: As you can see from this output, the `EmploymentStatusRetired` feature seems
    to be the most important factor in making the final prediction and the `Income`, `Total.Claim.Amount`,
    and `Customer.Lifetime.Value` features follow as the second, third, and fourth
    most important features.
  prefs: []
  type: TYPE_NORMAL
- en: Evaluating a classification model
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Earlier in this chapter, we discussed five different ways to look at the performance
    of a classification model. In this section, we are going to learn how we can compute
    and visualize the metrics for evaluating a classification model in R using the
    random forest model we have just built.
  prefs: []
  type: TYPE_NORMAL
- en: 'The first three metrics that we are going to look at are accuracy, precision,
    and recall. Before we go ahead and evaluate the model performance, we will need
    the model prediction results. In order to have the random forest model we have
    built in the previous section make predictions on a dataset, we can simply use
    the `predict` function. Take a look at the following code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE35]'
  prefs: []
  type: TYPE_PRE
- en: 'With these prediction results, we are going to evaluate how well our random
    forest model performs in the train and test sets. The following code shows how
    we can compute accuracy, precision, and recall in R:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE36]'
  prefs: []
  type: TYPE_PRE
- en: 'Using this method, we can compare the in-sample train set `accuracy`, `precision`,
    and `recall` against the out-of-sample test set''s `accuracy`, `precision`, and
    `recall`. Take a look at the following output:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/cc2daec3-a359-482b-b2d6-c4f83f2803b4.png)'
  prefs: []
  type: TYPE_IMG
- en: This output gives us a brief overview of how well our model performs at predicting
    the responses. For the train set, the accuracy of the overall prediction was `0.8756`,
    meaning the model prediction was correct for about `88%` of the time. For the
    test set, the accuracy of the overall prediction was `0.8636`. You can also find
    that the precisions for in-sample and out-of-sample predictions were `0.9717` and `0.8980` respectively,
    and the recalls were `0.1151` and `0.1065`. Due to the randomness and the different
    hyperparameters you might have used, you might get different results.
  prefs: []
  type: TYPE_NORMAL
- en: 'The next set of metrics we are going to look at are the ROC curve and the AUC. We
    are going to use the `ROCR` R package. If you do not have this package installed
    in your R environment, you can install it using the following command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE37]'
  prefs: []
  type: TYPE_PRE
- en: 'Take a look at the following code for the ROC curve and the AUC number first:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE38]'
  prefs: []
  type: TYPE_PRE
- en: The first thing we need to do is to get the predicted probabilities from the
    model we have built. Using the `predict` function and the `type='prob'` flag,
    we can get the predicted probabilities from the random forest model. Then, we
    are using the `prediction` function in the `ROCR` package. This function computes
    the number of true positives and false positives at different probability cutoffs
    that we need for the ROC curve. Using the output of the `prediction` function,
    we can then get the true positive rates and false positive rates at different
    probability cutoffs with the `performance` function in the `ROCR` package. Lastly,
    in order to get the AUC number, we can use the same `performance` function with
    a different flag, `measure='auc'`.
  prefs: []
  type: TYPE_NORMAL
- en: 'With this data, we can now plot the ROC curve. Using the `plot` function and
    the `perf` variable, which is the output of the `performance` function, we can
    plot the ROC curve. The plot looks as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/6e8169d1-ce56-4e05-b2af-e80266d6f90a.png)'
  prefs: []
  type: TYPE_IMG
- en: As you can see from this plot, the AUC of our random forest model was `0.76`.
    Compared to the benchmark straight line, which represents the random line, the
    model performs much better, and this shows that the model predictions are much
    better than random predictions.
  prefs: []
  type: TYPE_NORMAL
- en: 'The full code for this R exercise can be found at the following link: [https://github.com/yoonhwang/hands-on-data-science-for-marketing/blob/master/ch.8/R/PredictingEngagement.R](https://github.com/yoonhwang/hands-on-data-science-for-marketing/blob/master/ch.8/R/PredictingEngagement.R).'
  prefs: []
  type: TYPE_NORMAL
- en: Summary
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this chapter, we discussed predictive analytics and its applications in marketing.
    We first discussed what predictive analytics is and how it is used in various
    other industries, such as in the financial and healthcare industries. Then we
    discussed four common use cases of predictive analytics in marketing—likelihood
    of engagement, customer lifetime value, recommending the right products and contents,
    and customer acquisition and retention. There can be numerous other use cases
    of predictive analytics in marketing, so we recommend you keep up with the latest
    news on how predictive analytics can be used in marketing industries. We then
    discussed five different ways to evaluate the performances of predictive models—accuracy,
    precision, recall, the ROC curve, and the AUC.
  prefs: []
  type: TYPE_NORMAL
- en: In the following chapter, we are going to expand our knowledge of predictive
    analytics. We are going to discuss the concept and importance of measuring customer
    lifetime value, as well as building machine learning models for customer lifetime
    value predictions.
  prefs: []
  type: TYPE_NORMAL
