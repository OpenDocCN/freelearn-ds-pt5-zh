<html><head></head><body><div><h1 class="header-title">Statistical Modeling in Anaconda</h1>
                
            
            
                
<p>In this chapter, we will first present the simplest statistical model: the one-factor linear model. To make the learning process more interesting, we will discuss an application of such a model: the famous financial model called the <strong>Capital Asset Pricing Model</strong> (<strong>CAPM</strong>). In terms of processing data, we will show you how to detect and remove missing values, and how to replace missing values with means or other values in R, Python, or Julia. Also, <strong>outliers</strong> would distort our statistical results. Thus, we need to know how to detect and deal with them. After that, we talk about multi-factor linear models. Again, to make our discussion more meaningful, we will discuss the famous <strong>Fama-French</strong> 3-factor and 5-factor linear models, and the <strong>Fama-French-Carhart</strong> 4-factor linear model. Then, we will discuss how to rank those different models, that is, how to measure the performance of different models. In this chapter, the following topics will be covered:</p>
<ul>
<li>Introduction to linear models</li>
<li>Running a linear regression in R, Python, Julia, and Octave</li>
<li>Critical value and the decision rule</li>
<li>F-test, critical value, and the decision rule</li>
<li>Dealing with missing data</li>
<li>Detecting outliers and treatments</li>
<li>Several multivariate linear models</li>
<li>Collinearity and its solution</li>
<li>A model's performance measure</li>
</ul>


            

            
        
    </div>
<div><h1 class="header-title">Introduction to linear models</h1>
                
            
            
                
<p>The one-factor linear model is the simplest way to show a relationship between two variables: <em>y</em> and <em>x</em>. In other words, we try to use <em>x</em> to explain <em>y</em>. The general form for a one-factor linear model is given here, where <em>y<sub>t</sub></em> is the dependent variable at time <em>t</em>, <em>α</em> is the intercept, β is the slope, <em>x<sub>t</sub></em> is the value of an independent variable at time <em>t</em>, and <em>ε<sub>t</sub></em> is a random term:</p>
<div><img class="fm-editor-equation" src="img/f297f98b-bbf1-4ffd-9c98-ae239138099c.png" style="width:22.92em;height:1.83em;" width="2750" height="220"/></div>
<p>To run a linear regression, we intend to estimate the intercept (<em>α</em>) and the slope (<em>β</em>). One-factor means that the model has just one explanatory variable, that is, one independent variable of <kbd>x</kbd>, and linear means that when drawing a graph based on the equation (1), we would have a straight line. With the following R program, we could get a linear line:</p>
<pre>&gt; x&lt;--10:10<br/>&gt; y&lt;-2+1.5*x<br/>&gt; title&lt;-"A straight line"<br/>&gt; plot(x,y,type='l',main=title)</pre>
<p>The related graph is shown here:</p>
<div><img class="alignnone size-full wp-image-709 image-border" src="img/331f78ac-5e43-44cb-a036-eb3166523eed.png" style="width:22.92em;height:24.25em;" width="457" height="481"/></div>
<p>Another explanation for a linear model is that the power of the independent variable of <kbd>x</kbd> is <kbd>1</kbd>. There are many applications for such a simple one-factor linear model. Later in the chapter, we present the famous CAPM, which is a one-factor linear model.</p>


            

            
        
    </div>
<div><h1 class="header-title">Running a linear regression in R, Python, Julia, and Octave</h1>
                
            
            
                
<p>The following code block shows how to run such a one-factor linear regression in R:</p>
<pre>&gt; set.seed(12345)<br/>&gt; x&lt;-1:100<br/>&gt; a&lt;-4<br/>&gt; beta&lt;-5<br/>&gt; errorTerm&lt;-rnorm(100)<br/>&gt; y&lt;-a+beta*x+errorTerm<br/>&gt; lm(y~x)</pre>
<p>The first line of <kbd>set.seed(12345)</kbd> guarantees that different users will get the same random numbers when the same <kbd>seed()</kbd> is applied, that is, <kbd>12345</kbd> in this case. The R function <kbd>rnorm(n)</kbd> is used to generate <em>n</em> random numbers from a standard normal distribution. Also, the two letters of the <kbd>lm()</kbd> function stand for linear model. The result is shown here:</p>
<pre class="mce-root"><strong>Call: lm(formula = y ~ x)</strong><br/><strong>Coefficients: <br/>(Intercept) x <br/>4.114 5.003</strong></pre>
<p class="mce-root">The estimated intercept is <kbd>4.11</kbd>, while the estimated slope is <kbd>5.00</kbd>. To get more information about the function, we can use the <kbd>summary()</kbd> function, shown in the following code:</p>
<pre>&gt; summary(lm(y~x))<br/><strong>Call:</strong><br/><strong>lm(formula = y ~ x)</strong><br/><br/><strong>Residuals:</strong><br/><strong>    Min 1Q Median 3Q Max </strong><br/><strong>-2.6168 -0.8699 0.2071 0.6326 2.1451 </strong>
<strong>Coefficients:</strong><br/><strong>            Estimate Std. Error t value Pr(&gt;|t|) </strong><br/><strong>(Intercept) 4.114297 0.225258 18.27 &lt;2e-16 ***</strong><br/><strong>x 5.002592 0.003873 1291.81 &lt;2e-16 ***</strong><br/><strong>---</strong><br/><strong>Signif. codes: 0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1</strong><br/><br/><strong>Residual standard error: 1.118 on 98 degrees of freedom</strong><br/><strong>Multiple R-squared: 0.9999, Adjusted R-squared: 0.9999 </strong><br/><strong>F-statistic: 1.669e+06 on 1 and 98 DF, p-value: &lt; 2.2e-16</strong></pre>
<p class="mce-root">The alpha, that is, the intercept, is <kbd>4.11</kbd> and it is statistically significant. The reason is that its T-value is <kbd>18.27</kbd>, which is higher than <kbd>2</kbd> if we choose a 5% significance value. However, it is also significant at any significance level, indicated by the three stars: <kbd>***</kbd>. Alternatively, we could look at its P-value to determine significance. With the same logic, the slope value is <kbd>5</kbd>, which is statistically significant. Usually, we have the following two critical values for the T-value:</p>
<div><img class="fm-editor-equation" src="img/46d5ad70-5beb-4521-bf68-71f6b2cdaf79.png" style="width:23.75em;height:2.67em;" width="4450" height="500"/>                              </div>
<p class="mce-root">Alternatively, we have the following decision rule for <em>pValue</em>:</p>
<div><img class="fm-editor-equation" src="img/1ea7a5bc-ebed-41aa-86ee-9199a2a9311e.png" style="width:23.00em;height:2.42em;" width="4570" height="480"/>                              </div>
<p class="mce-root">The following Python code would run a linear regression:</p>
<pre>from scipy import stats <br/>import scipy as sp<br/>sp.random.seed(31233)<br/>alpha=2.0<br/>beta=3.8<br/>n=1000<br/>x=sp.arange(n)<br/>y=alpha+beta*x+sp.random.rand(n)<br/>(beta, alpha, r_value, p_value, std_err) = stats.linregress(y,x) 
print("Alpha , Beta")<br/>print(alpha,beta) <br/>print("R-squared=", r_value**2)<br/>print("p-value =", p_value)</pre>
<p class="mce-root">Similarly, in the following code, for a set of <em>x</em> and <em>y</em> values, we could run a linear regression in Julia:</p>
<pre>using GLM, DataFrames<br/>data = DataFrame(X=[1,2,3], Y=[2,4,7])<br/>OLS = glm(@formula(Y ~ X), data, Normal(), IdentityLink())</pre>
<p class="mce-root">The related output is shown here:</p>
<div><img class="alignnone size-full wp-image-710 image-border" src="img/b6a1c1d9-eb98-4d12-889e-6082f063bf22.png" style="width:54.33em;height:24.58em;" width="652" height="295"/></div>
<p class="mce-root">Note that there is no meaning in <kbd>X</kbd> and <kbd>Y</kbd> since their values are arbitrarily chosen. Based on the z values for both intercept and <em>β</em>, we can conclude that the intercept is statistically the same as zero since its <kbd>z value</kbd> is <kbd>-1.09</kbd> and the slope is statistically different from zero since its <kbd>z value</kbd> if <kbd>8.66</kbd>. In the previous Julia program, we assume that the <kbd>GLM</kbd> package is installed. If not, see the following screenshot to install the package:</p>
<div><img class="alignnone size-full wp-image-711 image-border" src="img/f0b74a26-0d21-4ef8-acf0-79d384ebcfde.png" style="width:49.67em;height:20.50em;" width="596" height="246"/></div>
<p>In other words, if the <kbd>DataFrames</kbd> Julia package is not installed, we need to issue a command of <kbd>Pkg.add("DataFrames")</kbd>. For more information on handling various packages for R, Python, and Julia, see <a href="c812a40e-eb24-4bb8-8af5-1cfe1834ec77.xhtml">Chapter 6</a>, <em>Managing Packages</em>. To run a linear regression for Octave, we generate <kbd>x</kbd> and <kbd>y</kbd> first:</p>
<pre>rand('seed',123) 
n = 50; 
x = sort(rand(n,1)*5-1); 
y = 2+1.5*x + randn(size(x)); 
figure % open a new figure window 
plot(x, y, 'o');</pre>
<p>The related graph is shown here:</p>
<div><img class="alignnone size-full wp-image-712 image-border" src="img/d0a55b69-6dec-4280-8b27-5ca391e2e651.png" style="width:40.08em;height:31.42em;" width="481" height="377"/></div>
<p>Based on the previously generated <kbd>x</kbd> and <kbd>y</kbd> values, we have the following Octave program to run a linear regression:</p>
<pre>n = length(y);  
x2= [ones(n, 1), x];  % Add a column of ones to x 
b = inv(x2'*x2)*x2'*y; 
R = y - (x2 * b);        # residuals 
v = (R'*R)/(4 - 3);      # residual variance 
sigma = v * inv(x2'*x2); # variance covariance matrix 
se = sqrt(diag(sigma));  # std errors of parameters  
The related estimated parameters are shown below.  
&gt;&gt; b 
<strong>b = 
 
   2.5259 
   1.3585 
</strong> 
&gt;&gt; sigma 
<strong>sigma = 
 
   1.01374  -0.37919 
  -0.37919   0.29591 
</strong> 
&gt;&gt; se 
<strong>se = 
 
   1.00685 
   0.54398 
</strong> 
&gt;&gt; </pre>


            

            
        
    </div>
<div><h1 class="header-title">Critical value and the decision rule</h1>
                
            
            
                
<p>A T-test is any statistical hypothesis test in which the test statistic follows a student's T-distribution under the null hypothesis. It can be used to determine whether two sets of data are significantly different from each other. For a one-sample <em>T</em>-test and for the null hypothesis that the mean is equal to a specified value <em>μ<sub>0</sub></em>, we use the following statistic, where <em>t</em> is the T-value, <img class="fm-editor-equation" src="img/98cefac5-8dc6-4f27-ad6c-f9d66caf3882.png" style="width:1.25em;height:1.83em;" width="150" height="220"/> is the sample mean, <em>μ<sub>0</sub></em> is the our assumed return mean, <em>σ</em> is the sample standard deviation of the sample, <em>n</em> is the sample size, and <em>S.E.</em> is the standard error:</p>
<div><img class="fm-editor-equation" src="img/adc69a2d-b42c-40bc-93dc-8a4db2806f62.png" style="width:17.42em;height:5.08em;" width="2400" height="700"/>                         </div>
<p>The degrees of freedom used in this test are <em>n - 1</em>. The critical <em>T</em>-value is used to accept or reject the null hypothesis. The decision rule is given here:</p>
<div><img class="fm-editor-equation" src="img/c70c67be-bbcc-499c-a644-45093038d010.png" style="width:26.58em;height:3.42em;" width="3740" height="480"/></div>
<p>In the previous section, we mentioned two critical values: <kbd>2</kbd> for a T-value and <kbd>0.05</kbd> for a P-value. Actually, those two critical values are correlated. For a 5% critical P-value, its related critical T-value will be about <kbd>2</kbd>. The following function, <kbd>qt()</kbd>, shows this relationship:</p>
<pre>&gt; qt(0.05/2,50)<br/><strong>[1] -2.008559</strong><br/>&gt; qt(1-0.05/2,50)<br/><strong>[1] 2.008559</strong></pre>
<p class="mce-root">The general function will be:</p>
<div><img class="fm-editor-equation" src="img/5b3af1cd-1922-4397-98fa-aa85f8917347.png" style="width:23.42em;height:1.58em;" width="3540" height="240"/></div>
<p class="mce-root">where <kbd>qt()</kbd> is the student's T-distribution, α is the significance level, such as 1%, 5%, or 10%, <em>degree_freedom</em> is the degree of freedom (<em>n-p</em>) where <em>n</em> is the number of data points, and <em>p</em> is the number of repressors, that is, the number of independent variables. When we want a much stronger result, we can choose <kbd>0.01</kbd> as our <em>α</em>. Assume that from the code that follows, our degree of freedom is <kbd>50</kbd>; the corresponding critical T-value will be <kbd>2.68</kbd>:</p>
<pre class="mce-root">&gt; alpha&lt;-0.01<br/>&gt; degreeFreedom&lt;-50<br/>&gt; qt(1-alpha/2,degreeFreedom)<br/><strong>[1] 2.677793</strong></pre>
<p class="mce-root">The following Python code would give us the critical value for a two-sided test:</p>
<pre>&gt; from scipy import stats<br/>&gt; alpha=0.05<br/>&gt; print(stats.t.ppf(1-alpha/2, 100))<br/><strong>1.98397151845</strong></pre>


            

            
        
    </div>
<div><h1 class="header-title">F-test, critical value, and the decision rule</h1>
                
            
            
                
<p>In the previous examples, we saw the F-value for the performance of the whole model. Now, let's look at the F-distribution. Assume that <em>x<sub>1</sub></em> and <em>x<sub>2</sub></em> are two independent random variables with the <a href="http://www.r-tutor.com/node/60">Chi-Square distribution</a> with <em>df<sub>1</sub></em> and <em>df<sub>2</sub></em> degrees of freedom, respectively. The ratio of <em>x<sub>1</sub>/df<sub>1</sub></em> divided by <em>x<sub>2</sub>/df<sub>2</sub></em> would follow an F-distribution:</p>
<div><img class="fm-editor-equation" src="img/6aa00651-92ca-4301-8aa6-1a9f3e271d57.png" style="width:10.92em;height:2.50em;" width="1470" height="350"/>    </div>
<p>An R program to draw a graph for the F distribution with (10, 2) degrees of freedom is shown here:</p>
<pre>&gt; d1&lt;-4 
&gt; d2&lt;-2 
&gt; n&lt;-100 
&gt; x = seq(0, 5, length = n) 
&gt; plot(x, df(x = x, df1 = d1, df2 = d2),type='l') </pre>
<p>The related plot is shown here:</p>
<div><img class="alignnone size-full wp-image-713 image-border" src="img/113bf502-a271-4cd5-9bce-3d652065a80b.png" style="width:21.33em;height:20.17em;" width="499" height="470"/></div>
<p>The following R program shows the critical value for a given α of <kbd>0.1</kbd> and (1, 2) degrees of freedom:</p>
<pre>&gt; alpha&lt;-0.1<br/>&gt; d1&lt;-1<br/>&gt; d2&lt;-1<br/>&gt; qf(1-alpha,df1=d1,df2=d2)<br/><strong>[1] 39.86346</strong></pre>
<p class="mce-root">The following Python program estimates the critical F-value:</p>
<pre>import scipy as sp<br/>alpha=0.10<br/>d1=1<br/>d2=1<br/>critical=sp.stats.f.ppf(q=1-alpha, dfn=d1, dfd=d2)<br/>prob=sp.stats.f.cdf(critical, dfn=d1, dfd=d2)<br/>print("alpha, d1, d2, critical value, prob")<br/>print(alpha, d1, d2, critical, prob)<br/><strong>alpha, d1, d2, critical value, prob</strong><br/><strong>(0.1, 1, 1, 39.86345818906144, 0.90000000000000002)</strong></pre>
<p>The related decision rule is that if our F-value is higher than the critical value, we would conclude that our overall model is significant.</p>


            

            
        
    </div>
<div><h1 class="header-title">An application of a linear regression in finance</h1>
                
            
            
                
<p>In finance, a famous application of a one-factor linear model is associated with CAPM, which was developed in the 1960s; see <em>Sharpe</em> (1964), <em>Litner</em> (1965), and <em>Mossin</em> (1966). Up until today, CAPM has been discussed in almost all finance textbooks because of its simplicity and usefulness. Its general formula is shown here:</p>
<div><img class="fm-editor-equation" src="img/fc6e90ba-1bda-45c6-ad7f-7eb7ee26fd87.png" style="width:20.25em;height:1.17em;" width="4000" height="230"/></div>
<p>where <kbd>E()</kbd> is the expectation, <em>R<sub>i</sub></em> is return for stock <em>i</em>, R<sub>f</sub> is the risk-free interest rate, and <em>E(R<sub>mkt</sub>)</em> is the expected market return. Usually, we could use the S&amp;P500 index as our market index. The slope of the equation, that is <em>β</em>, is a measure of the market risk. For individual stock, β represents the sensitivity of a stock's expected returns in response to the market risk premium, that is, E(R<sub>mkt</sub>)-R<sub>f</sub>. A risk premium represents the required extra return for bearing extra risk when compared with the risk-free rate. The following formula could be used to estimate <em>β</em>, where <em>β<sub>i</sub></em> is the beta for stock <em>i</em>, <em>cov(R<sub>i</sub>,R<sub>m</sub>)</em> is the covariance between the returns of stock i, and the returns of a market index, <em>ρ,</em> is the correlation between stock <em>i</em> and the market index. <em>σ<sub>i</sub></em> is the standard deviation of stock <em>i</em> and <em>σ<sub>m</sub></em> is the standard deviation of the market index:</p>
<div><img class="fm-editor-equation" src="img/a17e8178-c7c3-4ea6-8ceb-83a647a27827.png" style="width:20.75em;height:2.50em;" width="3320" height="400"/>   </div>
<p>For the beta value, we could run a linear regression for CAPM by using historical data. There is another variable of the previous formula shown next, where <em>R<sub>i,t</sub></em> is stock i's return at time <em>t</em>, <em>R<sub>f,t</sub></em> is the risk-free interest rate at time t, and R<sub>mkt,t</sub> is the market return at time t while <img class="fm-editor-equation" src="img/4436b8c9-48f4-4ffe-82f0-591a062c4f95.png" style="width:1.17em;height:1.17em;" width="140" height="140"/> is a random factor:</p>
<div><img class="fm-editor-equation" src="img/461d54bd-94ba-4d06-b3d9-75a5df45d38a.png" style="width:28.25em;height:1.42em;" width="4580" height="230"/></div>
<p>The previous equation associated with CAPM can be applied to estimate the expected cost of equity, that is, the expected stock return, after we estimate the beta successfully. In the preceding variation, one added advantage is that the logic of CAPM is much clearer. On the left-hand side, we have an individual stock's risk premium while on the right-hand side, we have the market risk premium, shown in the following:</p>
<div><img class="fm-editor-equation" src="img/99c63600-13e7-4f4e-8bf7-67482c21140e.png" style="width:39.92em;height:4.67em;" width="5900" height="690"/></div>
<p>Later in the chapter, we will show you how to run CAPM by using historical monthly stock data and the <em>S&amp;P500</em> data as the market index; programs written in R, Python, and Julia will be available. Using R, we could estimate a stock's market risk, that is, the beta value. First, let's write a function called <kbd>ret_f()</kbd> to estimate returns for a given input price dataset:</p>
<pre>ret_f&lt;-function(data){<br/>   ddate&lt;-as.Date(data[,1])<br/>   n&lt;-nrow(data)<br/>   p&lt;-data[,6]<br/>   ret&lt;-p[2:n]/p[1:(n-1)]-1<br/>   final&lt;-data.frame(ddate[2:n],ret,stringsAsFactors=F)<br/>   colnames(final)&lt;-c("DATE","RET")<br/>   return(final)<br/>}<br/>#<br/>x&lt;-read.csv("http://canisius.edu/~yany/data/ibmMonthly.csv")<br/>stock&lt;-ret_f(x)<br/>y&lt;-read.csv("http://canisius.edu/~yany/data/^gspcMonthly.csv")<br/>mkt&lt;-ret_f(y)<br/>colnames(mkt)&lt;-c("DATE","MKTRET")<br/>final&lt;-merge(stock,mkt)</pre>
<p class="mce-root">In the previous R program, we define a function called <kbd>ret_f()</kbd>. Then, we call this function twice to estimate returns for the download IBM's price data and S&amp;P500 monthly data. Again, these two time series can be manually downloaded from Yahoo!Finance at <a href="http://finance.yahoo.com">http://finance.yahoo.com</a>. The first several lines of the final dataset are shown here:</p>
<pre>&gt; head(final)<br/><strong>        DATE RET MKTRET</strong><br/><strong>1 1962-02-01 -0.009225374 0.016269655</strong><br/><strong>2 1962-03-01 -0.007779475 -0.005860435</strong><br/><strong>3 1962-04-01 -0.147816831 -0.061969875</strong><br/><strong>4 1962-05-01 -0.135463769 -0.085990147</strong><br/><strong>5 1962-06-01 -0.135531661 -0.081838016</strong><br/><strong>6 1962-07-01 0.140751225 0.063561644</strong></pre>
<p class="mce-root">Now, we can apply the <kbd>lm()</kbd> function, shown as follows, with the corresponding output:</p>
<div><img class="alignnone size-full wp-image-714 image-border" src="img/e85e6273-de2b-444d-bbf5-c3418169187b.png" style="width:33.50em;height:21.17em;" width="501" height="316"/></div>
<p class="mce-root">Based on the result, the intercept is <kbd>0.00277</kbd> and it is not statistically significant. The slope (or the beta value) is <kbd>0.96</kbd>, which is statically significant. R2 is 35%, which means that the model could explain 35% of the variation in the dependent variable. The F-statistic is a measure of goodness of fit of the whole model, which is statistically significant since its P-value is extremely small. Note that for the previous beta estimation, we use the whole input data set, that is, all years, while in real-world market risk (<em>β</em>) estimation, researchers or professionals working on Wall Street usually use only a few years' data, such as a 3-year window. Before writing a Python program to estimate a stock's beta, first we have to retrieve stock data from <kbd>quandl</kbd>, shown in the program here:</p>
<pre>import quandl as qd<br/>x=qd.get("WIKI/ibm")<br/>print(x.head(2))<br/>print(x.tail(2))</pre>
<p class="mce-root">The related output is shown in the following screenshot:</p>
<div><img class="alignnone size-full wp-image-715 image-border" src="img/b6d0497f-2d3f-438f-98e1-cf27becafca2.png" style="width:37.33em;height:23.50em;" width="617" height="387"/></div>
<p class="mce-root">From the previous output, we know that the frequency of data is daily. For monthly data, we have the following Python code:</p>
<pre>import quandl as qd<br/>x=qd.get("WIKI/ibm",collapse='monthly')</pre>
<p class="mce-root"><kbd>quandl</kbd> is a data delivery platform which includes many free datasets, but users might need to register to get specific datasets (for a more detailed discussion, see <a href="b40472e2-4998-4d7c-ac22-b77f4ad21a22.xhtml" target="_blank">Chapter 3</a>, <em>Data Basics</em>). The following Python program downloads IBM's monthly data from <kbd>quandl</kbd> and the monthly S&amp;P500 market index data from the author's website, and runs a linear regression to get the market risk, that is, β for IBM:</p>
<pre>import quandl as qd<br/>import pandas as pd<br/>from scipy import stats<br/>x=qd.get("WIKI/ibm",collapse='monthly')<br/>#<br/>p=x[['Adj. Close']]<br/>ret=p.diff()/p.shift(1)<br/>stockRet=ret.dropna()<br/>stockRet.columns=['stockRet']<br/>#stockRet.assign(yyyymm=stockRet.index.strftime("%Y%m"))<br/>#<br/>inFile="http://canisius.edu/~yany/data/sp500monthlyEndOfMonthDate.csv"<br/>y=pd.read_csv(inFile,index_col=0)<br/>d=y[['Adj.Close']]<br/>ret2=d.diff()/d.shift(1)<br/>mktRet=ret2.dropna()<br/>mktRet.columns=['mktRet']<br/>df= stockRet.merge(mktRet, how='inner', left_index=True, right_index=True)<br/>(beta,alpha,r_value,p_value,std_err)=stats.linregress(df.stockRet,df.mktRet)<br/>alpha=round(alpha,8)<br/>beta=round(beta,3)<br/>r_value=round(r_value,3)<br/>p_vaue=round(p_value,3)<br/>print("alpha, beta, R2 and P-value")<br/>print(alpha,beta,r_value,p_value)</pre>
<p class="mce-root">The related output is shown here:</p>
<pre><strong>alpha, beta, R2 and P-value</strong><br/><strong>(0.00408539, 0.322, 0.561, 3.8213963635856179e-38)</strong></pre>
<p>By using daily data, the next Python program estimates the annual betas for Walmart, with a ticker symbol of WMT using <kbd>quandl</kbd> to download data:</p>
<pre>import scipy as sp<br/>import pandas as pd<br/>import quandl as qd<br/>from scipy import stats<br/>#<br/>ticker="wmt"<br/>x=qd.get("WIKI/"+ticker)<br/>p=x[['Adj. Close']]<br/>ret=p.diff()/p.shift(1)<br/>stockRet=ret.dropna()<br/>stockRet.columns=['stockRet']<br/>#<br/>inFile="http://canisius.edu/~yany/data/^gspcDaily.csv"<br/>y=pd.read_csv(inFile,index_col=0)<br/>d=y[['Adj Close']]<br/>ret2=d.diff()/d.shift(1)<br/>mktRet=ret2.dropna()<br/>mktRet.columns=['mktRet']<br/><br/>final= stockRet.merge(mktRet, how='inner', left_index=True, right_index=True)<br/>years=pd.unique(final.index.strftime("%Y"))<br/>print(" year, alpha, beta,R_value, P_value")<br/>for i in sp.arange(0,5):<br/>#for i in sp.arange(1,len(years)):<br/>    #print(years[i])<br/>    d=final[final.index.strftime("%Y")==years[i]]                        (beta,alpha,r_value,p_value,std_err)=stats.linregress(d.stockRet,d.mktRet)<br/>    alpha=round(alpha,8)<br/>    beta=round(beta,3)<br/>    r_value=round(r_value,3)<br/>    p_vaue=round(p_value,3)<br/>    print(years[i],alpha,beta,r_value,p_value)</pre>
<p class="mce-root">The related output is shown here:</p>
<div><img class="alignnone size-full wp-image-716 image-border" src="img/11262017-2fb0-4a63-a536-5dfdba3a6d0c.png" style="width:31.08em;height:6.42em;" width="486" height="101"/></div>
<p class="mce-root">In the following Julia program, we assume that two files are downloaded from Yahoo!Finance at <a href="http://finance.yahoo.com">http://finance.yahoo.com</a>. Those input files are <kbd>ibmMonthly5years.csv</kbd> and <kbd>sp500Monthly5years.csv</kbd>, and they are the latest 5-year monthly historical data. The Julia program is given here:</p>
<pre>using DataFrames,StatsBase,StatsModels,GLM<br/>x = readtable("c:/temp/ibmMonthly5years.txt")<br/>#x = CSV.read("c:/temp/ibmMonthly5years.csv")<br/>p=x[:Adj_Close]<br/>n=length(p)<br/>stockRet=p[2:n]./p[1:(n-1)]-1<br/>y = readtable("c:/temp/sp500Monthly5years.txt")<br/>#y = CSV.read("c:/temp/sp500Monthly5years.csv")<br/>p2=y[:Adj_Close]<br/>n2=length(p2)<br/>mktRet=p2[2:n2]./p2[1:(n2-1)]-1<br/>n3=min(length(stockRet),length(mktRet))<br/>data = DataFrame(X=mktRet[1:n3], Y=stockRet[1:n3])<br/>OLS = glm(@formula(Y ~ X), data, Normal(), IdentityLink())</pre>
<p class="mce-root">Note that we manually removed the first observation since it contained a non-numerical value. The related output is shown here:</p>
<div><img class="alignnone size-full wp-image-717 image-border" src="img/f47d91af-ea7c-4b98-9aab-b3a6e2ef0ac9.png" style="width:53.42em;height:12.17em;" width="641" height="146"/></div>


            

            
        
    </div>
<div><h1 class="header-title">Dealing with missing data</h1>
                
            
            
                
<p>There are many ways to deal with missing records. The simplest one is to delete them. This is especially true when we have a relative large dataset. One potential issue is that our final dataset should not be changed in any fundamental way after we delete the missing data. In other words, if the missing records happened in a random way, then simply deleting them would not generate a biased result.</p>


            

            
        
    </div>
<div><h1 class="header-title">Removing missing data</h1>
                
            
            
                
<p>The following R program uses the <kbd>na.omit()</kbd> function:</p>
<pre>&gt; x&lt;-c(NA,1,2,50,NA) 
&gt; y&lt;-na.omit(x) 
&gt; mean(x) 
<strong>[1] NA</strong> 
&gt; mean(y) 
<strong>[1] 17.66667</strong> </pre>
<p>Another R function called <kbd>na.exclude()</kbd> could be used as well. The following Python program removes all <kbd>sp.na</kbd> code:</p>
<pre>import scipy as sp 
x={2,4,3,sp.nan,6,sp.nan,7} 
print(x) 
x.remove(sp.nan) 
print(x)</pre>
<p>For brevity, we omitted the output.</p>


            

            
        
    </div>
<div><h1 class="header-title">Replacing missing data with another value</h1>
                
            
            
                
<p>In the following dataset, we have three valid values: <kbd><em>2</em></kbd>, <kbd><em>3</em></kbd>, and <kbd><em>4</em></kbd>. Obviously, their mean is <kbd>3</kbd>. Since there are two NAs, we plan to replace them with the mean, that is, <em>3</em> in this case. The following R code achieves this:</p>
<pre>&gt; x&lt;-c(NA,2,3,4,NA) 
&gt; y&lt;-na.omit(x) 
&gt; m&lt;-mean(y) 
&gt; m 
[1] 3 
<strong>&gt; x[is.na(x)]&lt;-m</strong> 
&gt; x 
<strong>[1] 3 2 3 4 3</strong> 
&gt; </pre>
<p>For Python, see the following program:</p>
<pre>import scipy as sp 
import pandas as pd 
df = pd.DataFrame({'A' : [2,sp.nan,3,4]}) 
print(df) 
df.fillna(df.mean(), inplace=True) 
print(df) </pre>
<p>The related output is:</p>
<pre><strong>     A 
0  2.0 
1  NaN 
2  3.0 
3  4.0 
     A 
0  2.0 
1  3.0 
2  3.0 
3  4.0</strong></pre>


            

            
        
    </div>
<div><h1 class="header-title">Detecting outliers and treatments</h1>
                
            
            
                
<p>First, a word of caution: one person's waste might be another person's treasure, and this is true for outliers. For example, for the week of 2/5/2018 to 2/15/2018, the <strong>Dow Jones Industrial Average</strong> (<strong>DJIA</strong>) suffers a huge loss. Cheng and Hum (2018) show that the index travels more than 22,000 points, as shown in the following table:</p>
<table style="border-collapse: collapse;width: 100%" class="MsoTableGrid" border="1">
<tbody>
<tr>
<td style="width: 331px">
<div><strong>Weekday</strong></div>
</td>
<td style="width: 355px">
<div><strong>Points</strong></div>
</td>
</tr>
<tr>
<td style="width: 331px">
<p>Monday</p>
</td>
<td style="width: 355px">
<p>5,113</p>
</td>
</tr>
<tr>
<td style="width: 331px">
<p>Tuesday</p>
</td>
<td style="width: 355px">
<p>5,460</p>
</td>
</tr>
<tr>
<td style="width: 331px">
<p>Wednesday</p>
</td>
<td style="width: 355px">
<p>2,886</p>
</td>
</tr>
<tr>
<td style="width: 331px">
<p>Thursday</p>
</td>
<td style="width: 355px">
<p>3,369</p>
</td>
</tr>
<tr>
<td style="width: 331px">
<p>Friday</p>
</td>
<td style="width: 355px">
<p>5,425</p>
</td>
</tr>
<tr>
<td style="width: 331px">
<p>Total</p>
</td>
<td style="width: 355px">
<p>22,253</p>
</td>
</tr>
</tbody>
</table>
<p>Table 5.1 Dow Jones industrial average points traveled</p>
<p>If we want to study the relationship between a stock and the DJIA index, the observations might be treated as outliers. However, when studying the topic related to the impact of the market on individual stocks, we should pay special attention to those observations. In other words, those observations should not be treated as outliers.</p>
<p>There are many different definitions of an outlier:</p>
<ul>
<li>First, for a given dataset, an outlier is a data point, or an observation, that is located an abnormal distance from other observations</li>
<li>Second, if removing an observation results in a metrical change for a regression, then this observation will be an outliner</li>
<li>Third, the distance between an outlier and the mean is at least three standard deviations</li>
</ul>
<p>Assume that we have download the weekly S&amp;P500 historical data from Yahoo!Finance at <a href="https://finance.yahoo.com/">https://finance.yahoo.com/</a>. The ticker symbol for the S&amp;P500 market index is <kbd>^GSPC</kbd>. Assume further that the dataset is saved under <kbd>c:/temp</kbd> with a name of <kbd>^GSPCweekly.csv</kbd>. The following R program shows the number of cases satisfying the following condition: <em>n</em> standard deviations from their mean. In the program, we assign <kbd>n</kbd> a value of <kbd>3</kbd>:</p>
<pre>&gt;  distance&lt;-3 
&gt;  x&lt;-read.csv("c:/temp/^GSPCweekly.csv") 
&gt;  p&lt;-x$Adj.Close 
&gt;  ret&lt;-p[2:n]/p[1:(n-1)]-1 
&gt;  m&lt;-mean(ret) 
&gt;  std&lt;-sd(ret) 
&gt;  ret2&lt;-subset(ret,((ret-m)/std)&gt;distance) 
&gt;  n2&lt;-length(ret2)</pre>
<p>It is a good idea to show a few output results:</p>
<pre>&gt; head(x,2)<br/><strong>        Date Open High Low Close Adj.Close Volume</strong><br/><strong>1 1950-01-02 16.66 17.09 16.66 17.09 17.09 9040000</strong><br/><strong>2 1950-01-09 17.08 17.09 16.65 16.65 16.65 14790000</strong><br/>&gt; m<br/><strong>[1] 0.001628357</strong><br/>&gt; std<br/><strong>[1] 0.02051384</strong><br/>&gt; length(ret)<br/><strong>[1] 3554</strong><br/>&gt; n2<br/><strong>[1] 15</strong></pre>
<p class="mce-root">Among <kbd>3554</kbd> weekly returns, <kbd>15</kbd> of them could be treated as outliers if defined as at least three standard deviations from the mean. Of course, users could use other ways to define an outlier. How to treat those outliers depends on the research topic. One way is to delete them, but the most important reminder is that researchers should detail their methods of treating outliers.</p>


            

            
        
    </div>
<div><h1 class="header-title">Several multivariate linear models</h1>
                
            
            
                
<p>As we mentioned at the beginning of the chapter, we could show several applications of multivariable linear models. The first one is a three-factor linear model. The general formula is quite similar to the one-factor linear model, shown here:</p>
<div><img class="fm-editor-equation" src="img/590f701a-5550-4ec0-90a6-e61d96de449e.png" style="width:26.92em;height:1.33em;" width="4440" height="220"/></div>
<p>The definitions are the same as before. The only difference is that we have three independent variables instead of one. Our objective is to estimate four parameters, one intercept plus three coefficients:</p>
<div><img class="fm-editor-equation" src="img/92a1dee0-b7a2-4925-8ab0-720a95711e27.png" style="width:34.00em;height:1.25em;" width="6260" height="230"/></div>
<p>For example, the equation of the famous Fama-French 3-factor model is given, where <em>R<sub>i</sub></em> is the stock i's return and R<sub>m</sub> is the market return. SMB (Small Minus Big) is defined as the returns of the small portfolios minus the returns of the big portfolios and HML (High Minus Low) is the difference of returns of high book-to-market portfolios minus the returns of low book-to-market portfolios. (See the Ken French data library at <a href="http://mba.tuck.dartmouth.edu/pages/faculty/ken.french/data_library.html">http://mba.tuck.dartmouth.edu/pages/faculty/ken.french/data_library.html</a> for more detailed definitions.) To download these three factors, we could go to Prof. French's data library to download them, as shown in the following steps:</p>
<ol>
<li>Go to the previous link.</li>
<li>Choose CSV for the monthly data (the first line in the following screenshot):</li>
</ol>
<div><img class="alignnone size-full wp-image-718 image-border" src="img/5c583731-0785-4977-a66d-2064f2c2c8b2.png" style="width:22.08em;height:4.25em;" width="303" height="58"/></div>
<p>The first several lines of the unzipped <kbd>csv</kbd> file are shown here:</p>
<pre>This file was created by CMPT_ME_BEME_RETS using the 201712 CRSP database.<br/>The 1-month TBill return is from Ibbotson and Associates, Inc.<br/><br/>,Mkt-RF,SMB,HML,RF<br/>192607, 2.96, -2.30, -2.87, 0.22<br/>192608, 2.64, -1.40, 4.19, 0.25<br/>192609, 0.36, -1.32, 0.01, 0.23<br/>192610, -3.24, 0.04, 0.51, 0.32<br/>192611, 2.53, -0.20, -0.35, 0.31<br/>192612, 2.62, -0.04, -0.02, 0.28<br/>192701, -0.06, -0.56, 4.83, 0.25<br/>192702, 4.18, -0.10, 3.17, 0.26<br/>192703, 0.13, -1.60, -2.67, 0.30<br/>192704, 0.46, 0.43, 0.60, 0.25</pre>
<p>This file was created by <kbd>CMPT_ME_BEME_RETS</kbd> using the 201712 CRSP database:</p>
<pre>The 1-month TBill return is from Ibbotson and Associates, Inc.<br/><br/>,Mkt-RF,SMB,HML,RF<br/>192607, 2.96, -2.30, -2.87, 0.22<br/>192608, 2.64, -1.40, 4.19, 0.25<br/>192609, 0.36, -1.32, 0.01, 0.23<br/>192610, -3.24, 0.04, 0.51, 0.32<br/>192611, 2.53, -0.20, -0.35, 0.31<br/>192612, 2.62, -0.04, -0.02, 0.28<br/>192701, -0.06, -0.56, 4.83, 0.25<br/>192702, 4.18, -0.10, 3.17, 0.26<br/>192703, 0.13, -1.60, -2.67, 0.30<br/>192704, 0.46, 0.43, 0.60, 0.25</pre>
<p>In R, we could issue the following code to download it from the author's website:</p>
<pre>&gt; con&lt;-url("http://canisius.edu/~yany/RData/ff3monthly.RData")<br/>&gt; load(con)<br/>&gt; head(.ff3monthly)<br/><strong>        DATE MKT_RF SMB HML RF</strong><br/><strong>1 1926-07-01 0.0296 -0.0230 -0.0287 0.0022</strong><br/><strong>2 1926-08-01 0.0264 -0.0140 0.0419 0.0025</strong><br/><strong>3 1926-09-01 0.0036 -0.0132 0.0001 0.0023</strong><br/><strong>4 1926-10-01 -0.0324 0.0004 0.0051 0.0032</strong><br/><strong>5 1926-11-01 0.0253 -0.0020 -0.0035 0.0031</strong><br/><strong>6 1926-12-01 0.0262 -0.0004 -0.0002 0.0028</strong></pre>
<p class="mce-root">For the following R program, we can run the Fama-French 3-factor model for IBM:</p>
<pre>con&lt;-url("http://canisius.edu/~yany/RData/ff3monthly.RData")<br/>load(con)<br/>head(.ff3monthly)<br/>x&lt;-read.csv("http://canisius.edu/~yany/data/ibmMonthly.csv")<br/>stock&lt;-ret_f(x)<br/>final&lt;-merge(stock,.ff3monthly)<br/>y&lt;-final$RET<br/>x&lt;-as.matrix(data.frame(final[,3:5]))<br/>summary(lm(y~x))</pre>
<p>In the previous code, we assume that the function called <kbd>ret_f()</kbd> is available (see the previous discussion about this function). The output is shown here:</p>
<div><img class="alignnone size-full wp-image-719 image-border" src="img/879ce7f4-bbda-4a08-9879-3b999c299adb.png" style="width:36.42em;height:24.25em;" width="516" height="343"/></div>
<p>Here is the Fama-French-Carhart's 4-factor model:</p>
<div><img class="fm-editor-equation" src="img/d01e2160-0af8-4e60-81db-d831227f1d8b.png" style="width:41.33em;height:1.25em;" width="7690" height="230"/>  </div>
<p>To download these four factors (Market, SMB, HML, and Momentum), we go to Professor Ken French's data library to download two zipped files:</p>
<pre>con&lt;-url("http://canisius.edu/~yany/RData/ffc4monthly.RData") 
load(con) 
head(.ffc4monthly) </pre>
<p>The related output is shown here:</p>
<pre><strong>  DATE       MKT_RF  SMB      HML     MOM    RF 
1 1927-01-31 -0.0006 -0.0056  0.0483  0.0044 0.0025 
2 1927-02-28  0.0418 -0.0010  0.0317 -0.0201 0.0026 
3 1927-03-31  0.0013 -0.0160 -0.0267  0.0359 0.0030 
4 1927-04-30  0.0046  0.0043  0.0060  0.0419 0.0025 
5 1927-05-31  0.0544  0.0141  0.0493  0.0301 0.0030 
6 1927-06-30 -0.0234  0.0047 -0.0153  0.0051 0.0026</strong></pre>
<p>To save space, we would not run a Fama-French-Carhart 4-factor model since it is quite similar to running the CAPM and Fama-French 3-factor model.</p>
<p>In 2014, Fama and French developed their 5-factor model, which has the following form:</p>
<div><img class="fm-editor-equation" src="img/206f05ba-4c88-4285-85b2-427d4a2c6b19.png" style="width:43.25em;height:1.25em;" width="7930" height="230"/></div>
<p>In the equation, RMW<sub>t</sub> is the return difference between portfolios of stocks with robust and weak profitability, and CMA<sub>t</sub> is the return difference between portfolios of low and high investment stocks. Fama and French call the low and high investment stocks conservative and aggressive, respectively. If the sensitivities to the five factors, βi (i=1,2,...,5), capture all the variations in the expected returns, the intercept α<sub>i</sub> will be zero for all securities and portfolios <em>i</em>. The following R program downloads the <kbd>ff5Monthly.RData</kbd> set from the author's website:</p>
<pre>&gt; con&lt;-url("http://canisius.edu/~yany/RData/ff5Monthly.RData") 
&gt; load(con) 
&gt; head(.ff5Monthly) </pre>
<p>The related output is shown here:</p>
<pre><strong>        DATE MKT_RF SMB HML RMW CMA                     RF</strong><br/><strong>1 1963-07-01 -0.0039 -0.0046 -0.0082 0.0072 -0.0116 0.0027</strong><br/><strong>2 1963-08-01 0.0507 -0.0081 0.0163 0.0042 -0.0040   0.0025</strong><br/><strong>3 1963-09-01 -0.0157 -0.0048 0.0019 -0.0080 0.0023  0.0027</strong><br/><strong>4 1963-10-01 0.0253 -0.0129 -0.0011 0.0275 -0.0226  0.0029</strong><br/><strong>5 1963-11-01 -0.0085 -0.0084 0.0166 -0.0034 0.0222  0.0027</strong><br/><strong>6 1963-12-01 0.0183 -0.0187 -0.0011 0.0018 -0.0031  0.0029</strong></pre>


            

            
        
    </div>
<div><h1 class="header-title">Collinearity and its solution</h1>
                
            
            
                
<p>In statistics, multicollinearity, or collinearity, is a phenomenon in which one independent variable (predictor variable) in a multiple regression model can be linearly predicted from the others with a substantial degree of accuracy. Collinearity tends to inflate the variance of at least one estimated regression coefficient. This could cause some regression coefficients to have the wrong sign. Those issues would make our regression results unreliable. Therefore, how can we detect the potential problem? One way is that we could simply look at the correlation between each pair of independent variables. If their correlation is close to ±1, then we might have such an issue:</p>
<pre>&gt;con&lt;-url("http://canisius.edu/~yany/RData/ff3monthly.RData") 
&gt;load(con) 
&gt; head(.ff3monthly) 
<strong>        DATE  MKT_RF     SMB     HML     RF 
1 1926-07-01  0.0296 -0.0230 -0.0287 0.0022 
2 1926-08-01  0.0264 -0.0140  0.0419 0.0025 
3 1926-09-01  0.0036 -0.0132  0.0001 0.0023 
4 1926-10-01 -0.0324  0.0004  0.0051 0.0032 
5 1926-11-01  0.0253 -0.0020 -0.0035 0.0031 
6 1926-12-01  0.0262 -0.0004 -0.0002 0.0028</strong> </pre>
<p>To find out the correlation between each pair of portfolios, we could use the R function called <kbd>cor()</kbd> to generate a correlation matrix, shown here:</p>
<pre>&gt; cor(.ff3monthly[,2:5]) 
<strong>            MKT_RF         SMB        HML          RF 
MKT_RF  1.00000000  0.31850074 0.23995229 -0.06543067 
SMB     0.31850074  1.00000000 0.12240744 -0.05063652 
HML     0.23995229  0.12240744 1.00000000  0.02117111 
RF     -0.06543067 -0.05063652 0.02117111  1.00000000</strong> </pre>
<p>According to <em>Martz</em> (2013), we have the following warning signs for a collinearity problem:</p>
<table style="border-collapse: collapse;width: 100%" class="MsoTableGrid" border="1">
<tbody>
<tr>
<td style="width: 40px">
<div><strong>#</strong></div>
</td>
<td style="width: 662px">
<div><strong>Description</strong></div>
</td>
</tr>
<tr>
<td style="width: 40px">
<p>1</p>
</td>
<td style="width: 662px">
<p>A coefficient is not significant, even though it should be</p>
</td>
</tr>
<tr>
<td style="width: 40px">
<p>2</p>
</td>
<td style="width: 662px">
<p>After adding/deleting an <kbd>X</kbd> variable, the regression coefficients change dramatically</p>
</td>
</tr>
<tr>
<td style="width: 40px">
<p>3</p>
</td>
<td style="width: 662px">
<p>A negative coefficient when the opposite should be true</p>
</td>
</tr>
<tr>
<td style="width: 40px">
<p>4</p>
</td>
<td style="width: 662px">
<p>A positive coefficient when the opposite should be true</p>
</td>
</tr>
<tr>
<td style="width: 40px">
<p>5</p>
</td>
<td style="width: 662px">
<p>Input variables have high pairwise correlations</p>
</td>
</tr>
</tbody>
</table>
<p>Table 5.2 Warning signs of collinearity</p>
<p class="mce-root">There are many ways to treat the issue. The simplest one is to delete one of the input variables that is highly correlated with another input variable. For example, if two input variables are strongly correlated, we could drop one of them. The second way is to use the residuals after running two variables against each other.</p>


            

            
        
    </div>
<div><h1 class="header-title">A model's performance measure</h1>
                
            
            
                
<p>In this chapter, we looked at several applications of linear models, including CAPM, the Fama-French 3-factor linear model, the Fama-French-Carhart 4-factor linear model, and the Fama-French 5-factor linear model. Obviously, CAPM is the simplest one since it only involves a market index as the explanatory variable. One question remains though: which model is the best? In other words, how do we rank these models and how is their performance measured? When running linear regressions, the output will show both the R<sup>2</sup> and adjusted R<sup>2</sup>. When comparing models with different numbers of independent variables, the adjusted R<sup>2</sup> is a better measure since it is adjusted by the number of input variables. However, note we should not depend only on the adjusted R<sup>2</sup> since this is in the sample measure. In other words, a higher adjusted R<sup>2</sup> simply means that based on this sample dataset, model A is better than model B. Hence, a much better measure is to use the performance of the out-of-sample prediction.</p>


            

            
        
    </div>
<div><h1 class="header-title">Summary</h1>
                
            
            
                
<p>In this chapter, we have explained many important issues related to statistics, such as T-distribution, F-distribution, T-tests, F-tests, and other hypothesis tests. We have also discussed linear regression, how to deal with missing data, how to treat outliers, collinearity and its treatments, and how to run a multi-variable linear regression.</p>
<p>In <a href="c812a40e-eb24-4bb8-8af5-1cfe1834ec77.xhtml">Chapter 6</a>, Ma<em>naging Packages</em>, we will discuss the importance of managing package; how to find out about all packages available for R, Python, and Julia; and how to find the manual for each package. In addition, we will discuss the issue of package dependency and how to make our programming a little easier when dealing with packages.</p>


            

            
        
    </div>
<div><h1 class="header-title">Review questions and exercises</h1>
                
            
            
                
<ol>
<li>What is the definition of a single-factor linear model?</li>
<li>How many independent variables are there in a single-factor model?</li>
<li>What does it mean for something to be statically different from zero?</li>
<li>What are the critical T-values and P-values to tell whether an estimate is statistically significant?</li>
<li>When the significant level is 1%, what is the critical T-value when there are 30 degrees of freedom?</li>
</ol>
<p> </p>
<ol start="6">
<li>What is the difference between a one-sided test and a two-sided test?</li>
<li>What are the corresponding missing codes for missing data items in R, Python, and Julia?</li>
<li>How do we treat missing variables if our sample is big? How about if our sample is small?</li>
<li>How do we generally detect outliners and deal with them?</li>
<li>How do we generate a correlated return series? For example, write an R program to generate 5-year monthly returns for two stocks with a fixed correlation of 0.5.</li>
<li>In terms of the critical T-value, is this the same for a one-sided test and a two-sided test when the significance level is fixed?</li>
<li>What is collinearity? What might be damaged if our dependents variables are strongly correlated?</li>
<li>How do we detect the multicollinearity? What are the functions to estimate the correlation matrix in R, Python, and Julia?</li>
<li>Write an R program to estimate Microsoft's annual βs over the last 10 years by using daily data. (Source of data: <a href="http://finance.yahoo.com">http://finance.yahoo.com</a>.)</li>
<li>Based on the following code, we could download monthly data. Find out whether the last day of each week is a trading day or not (hint: you could use an R dataset downloadable at <a href="http://canisius.edu/~yany/RData/tradingDaysM.RData">http://canisius.edu/~yany/RData/tradingDaysM.RData</a>):</li>
</ol>
<pre style="padding-left: 90px">import quandl as qd 
x=qd.get("WIKI/ibm",collapse='monthly')  </pre>
<ol start="16">
<li>Download the monthly price data for Walmart from the Quandl platform and S&amp;P500 data from Yahoo!Finance. Estimate Walmart's <em>β</em> by using monthly data from the last 5 years. A few lines of sample code are given here:</li>
</ol>
<pre style="padding-left: 90px">import pandas as pd 
import quandl as qd 
x=qd.get("WIKI/ibm",collapse='monthly') 
inFile="http://canisius.edu/~yany/data/^gspcMonthly.csv.csv" 
y=pd.read_csv(inFile,index_col=0) </pre>
<ol start="17">
<li>Write an R program by using the monthly data over the last 10 years for IBM and run a Fama-French-Carhart 4-factor model. Then, compare it with CAPM. Which model is better?</li>
</ol>
<p> </p>
<ol start="18">
<li>Generate a pickle dataset similar to the following R dataset:</li>
</ol>
<pre style="padding-left: 90px">&gt;con&lt;-url("http://canisius.edu/~yany/RData/ff3monthly.RData") 
&gt;load(con) 
&gt; head(.ff3monthly) 
<strong>        DATE  MKT_RF     SMB     HML     RF 
1 1926-07-01  0.0296 -0.0230 -0.0287 0.0022 
2 1926-08-01  0.0264 -0.0140  0.0419 0.0025 
3 1926-09-01  0.0036 -0.0132  0.0001 0.0023 
4 1926-10-01 -0.0324  0.0004  0.0051 0.0032 
5 1926-11-01  0.0253 -0.0020 -0.0035 0.0031 
6 1926-12-01  0.0262 -0.0004 -0.0002 0.0028</strong> </pre>
<ol start="19">
<li>When estimating <em>β</em>, we could have the following formula, where <em>βi</em> is the beta for stock <em>i</em>, <em>Ri</em> is the return for stock <em>i</em>, <em>Rm</em> is the return for a market index, and <img class="fm-editor-equation" src="img/0ae88abb-5d23-424f-b85d-f5d7d24e9411.png" style="width:2.00em;height:1.75em;" width="240" height="210"/> is the variance for the market:</li>
</ol>
<div><img class="fm-editor-equation" src="img/cc2d06e5-cab4-4967-8e4e-d22eb575f1e4.png" style="width:9.08em;height:3.00em;" width="1450" height="480"/></div>
<ol start="20">
<li>Write an R program to estimate the correlation matrix for the following five stocks:</li>
</ol>
<table style="border-collapse: collapse;width: 100%" class="MsoTableGrid" border="1">
<tbody>
<tr>
<td style="width: 118px">
<div><strong>#</strong></div>
</td>
<td style="width: 293px">
<div><strong>Name</strong></div>
</td>
<td style="width: 308px">
<div><strong>Ticker</strong></div>
</td>
</tr>
<tr>
<td style="width: 118px">
<p>1</p>
</td>
<td style="width: 293px">
<p>International Business Machines</p>
</td>
<td style="width: 308px">
<p>IBM</p>
</td>
</tr>
<tr>
<td style="width: 118px">
<p>2</p>
</td>
<td style="width: 293px">
<p>Walmart</p>
</td>
<td style="width: 308px">
<p>WMT</p>
</td>
</tr>
<tr>
<td style="width: 118px">
<p>3</p>
</td>
<td style="width: 293px">
<p>Citigroup</p>
</td>
<td style="width: 308px">
<p>CG</p>
</td>
</tr>
<tr>
<td style="width: 118px">
<p>4</p>
</td>
<td style="width: 293px">
<p>Microsoft</p>
</td>
<td style="width: 308px">
<p>MSFT</p>
</td>
</tr>
<tr>
<td style="width: 118px">
<p>5</p>
</td>
<td style="width: 293px">
<p>Johnson and Johnson</p>
</td>
<td style="width: 308px">
<p>JNJ</p>
</td>
</tr>
</tbody>
</table>
<ol start="21">
<li>Use the 10-year monthly price data to estimate the correlation matrix based on the previous five stocks (assume the returns of those five stocks follow a normal distribution).</li>
<li>Based on the correlation matrix, generate a return matrix to simulate their future monthly returns over the next 10 years.</li>
<li> Write programs in R or Python to generate similar F-tables (see the link at <a href="http://www.socr.ucla.edu/applets.dir/f_table.html">http://www.socr.ucla.edu/applets.dir/f_table.html</a>).</li>
</ol>
<p> </p>
<ol start="24">
<li>In this chapter, we have the following Julia program to run CAPM (one-factor linear model). Simplify the program by writing a subroutine to estimate a return:</li>
</ol>
<pre style="padding-left: 90px">using DataFrames; 
using GLM, StatsModels 
# 
x = readtable("c:/temp/ibmMonthly5years.csv") 
p=x[:Adj_Close] 
n=length(p) 
stockRet=p[2:n]./p[1:(n-1)]-1 
# 
y = readtable("c:/temp/sp500Monthly5years.csv") 
p2=y[:Adj_Close] 
n2=length(p2) 
mktRet=p2[2:n2]./p2[1:(n2-1)]-1 
# 
n3=min(length(stockRet),length(mktRet)) 
data = DataFrame(X=mktRet[1:n3], Y=stockRet[1:n3]) 
OLS = glm(@formula(Y ~ X), data, Normal(), IdentityLink()) </pre>


            

            
        
    </div></body></html>