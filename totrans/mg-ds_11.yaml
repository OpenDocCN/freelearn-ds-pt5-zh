- en: Managing Data Science Projects
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In the previous chapter, we looked at innovation management. We developed recipes
    that can help find ideas for data science projects and matched them with their
    market demand. In this chapter, we will cover the non-technical side of data science
    project management by looking at how data science projects stand out from general
    software development projects. We'll look at common reasons for their failure
    and develop an approach that will lower the risks of data science projects. We
    will conclude this chapter by diving into the art and science of project estimates.
  prefs: []
  type: TYPE_NORMAL
- en: 'In this chapter, we will look at how we can manage projects from start to end
    by covering the following topics:'
  prefs: []
  type: TYPE_NORMAL
- en: Understanding data science project failure
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Exploring the data science project life cycle
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Choosing a project management methodology
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Choosing a methodology that suits your project
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Estimating data science projects
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Discovering the goals of the estimation process
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Understanding data science project failure
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Every data science project ends up being a software system that generates scheduled
    reports or operates online. The world of software engineering already provides
    us with a multitude of software project management methodologies, so why do we
    need to reinvent a special approach for data science projects? The answer is that
    data science projects require much more experimentation and have to tolerate far
    more failures than software engineering projects.
  prefs: []
  type: TYPE_NORMAL
- en: 'To see the difference between a traditional software system and a system with
    predictive algorithms, let''s look at the common causes of failure for data science
    projects:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Dependence on data**: A robust **customer relationship management** (**CRM**)
    system that organizes the sales process will work well in many organizations,
    independent of their business. A system that predicts the outcome of a sales process
    may work well in one organization, but will require a partial rewrite for another
    organization and may not work at all in another. The reason for this is that machine
    learning algorithms depend on data, and every organization will have its own data
    model of its customers and its own sales process.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Changing requirements**: While software development projects often suffer
    from changing requirements, the changes mostly flow from the customer to the implementation
    team. In data science projects, new insights and research results from the implementation
    team can create a feedback loop. Project stakeholders can generate new requirements
    and change the course of the project based on the new information that''s discovered
    by data scientists.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Changing data**: In software development projects, the data model is mostly
    fixed or can be changed in a controlled manner. Data science projects often need
    to be integrated with new data sources for research purposes. Data is always changing
    and transforming, creating multiple intermediate representations inside the system.
    People and software components use these representations for reporting, data processing,
    and modeling. Software engineering projects use fixed or slowly changing data
    models, while data science projects use constantly evolving data pipelines.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Experimentation and research**: Data science projects involve completing
    many experiments. Typically, the number ranges from hundreds to thousands. Software
    engineering projects limit research by designing a system architecture and evolving
    it in a controlled manner. In data science projects, the next experiment may turn
    the project in a new direction, and you never know when this will happen.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Understanding data science management approaches
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The traditional management approach to software engineering projects was not
    built with these problems in mind. The key problem that most modern software project
    management methodologies need to solve is the issue of changing requirements.
    Agile methodologies focus on planning and executing fast iterations. Each iteration
    aims to deliver functionality to the client as fast as possible. External feedback
    is the primary source of changes in the project.
  prefs: []
  type: TYPE_NORMAL
- en: In data science projects, changes come from every direction. They spread internally
    from the project's team and externally from the business' customers. Metrics should
    always confirm progress. Getting one step closer to your goal may take tens or
    even hundreds of failed experiments, which makes fast iterations a must.
  prefs: []
  type: TYPE_NORMAL
- en: The typical iteration length of an Agile project can stretch from 2 weeks to
    1 month. The project team fixes the iteration scope for this duration and delivers
    it under a strict timeline. In a data science project, an experiment's result
    in the middle of the sprint can affect the sprint's goals and make working on
    other planned tasks less important due to the new discovery.
  prefs: []
  type: TYPE_NORMAL
- en: Management must provide a safety net for common issues and problems. Methodologies
    that come from the software engineering domain can give you a solid foundation
    here, but they do not provide any tools that we can use to manage research and
    govern data.
  prefs: []
  type: TYPE_NORMAL
- en: 'If you develop systems that use machine learning under the hood, it is necessary
    to take care of the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Requirements for validation and alignment**: You need to detect and manage
    requirement changes from external (customers) and internal (research team) sources.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Data governance**: Your project will need data governance standards, which
    should be rigorously applied to each piece of code that works with data. Ideally,
    each row of data going through your pipeline should be tracked back to its data
    source. All incoming and outgoing datasets, including intermediate reports, should
    be tracked and documented.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Research processes**: Each data science project will need to be researched
    extensively. Without control, research can quickly eat away at your budget without
    project completion being in sight. The essential components for managing a research
    project include the following:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Research planning**: The project team should plan and prioritize all of their
    research.'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Experimentation methodology**: Each experiment should conform to a set of
    standards such as tracking, documentation, and reproducibility.'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Fail fast and recover early**: Experiments often fail. Your management approach
    should make experiments fast so that your team can iterate and learn as quickly
    as possible.'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Software engineering processes**: Much of your work will be in creating software.
    Software project management already offers great tools for this, but they need
    to be tightly integrated with all the other components of the management methodology.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Next, we will look at common stages that arise in data science projects. We
    will tie those stages into a process that's comprised of the project life cycle
    so that we can see the whole picture behind data science projects.
  prefs: []
  type: TYPE_NORMAL
- en: Exploring the data science project life cycle
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Each data science project has several distinct states. We can structure projects
    in different domains and different technologies into stages that comprise the
    data science project life cycle, as shown in the following diagram:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/3911e318-2ed0-4e02-bec3-55e08f0d9d71.png)'
  prefs: []
  type: TYPE_IMG
- en: Let's explore each stage of the life cycle in more detail.
  prefs: []
  type: TYPE_NORMAL
- en: Business understanding
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: During this stage, you apply your domain expertise and research the business
    side of the project. You define the business requirements and confirm that their
    implementation would make the lives of your customers better. You should also
    define and document all the relevant business metrics that will allow you to measure
    and report on results in a way that is understandable by the business side. The
    output of this stage should be a business requirements specification that has
    been viewed, redacted, and agreed upon by the project stakeholders.
  prefs: []
  type: TYPE_NORMAL
- en: Data understanding
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: During this stage, you research the data architecture of the organization you
    are working with. You document data sources, their owners, and the technologies
    they use. You should not document every available data source unless you want
    to mine project ideas from data (see [Chapter 7](e5f57688-4506-40ea-858e-84169c97c6ad.xhtml),
    *Managing Innovation*). Focus on data that's useful for the project.
  prefs: []
  type: TYPE_NORMAL
- en: After finding this data, perform an **exploratory data analysis** (**EDA**)
    and research the data thoroughly. Look at any anomalies and unusual artifacts
    in the data. Study the reasons behind their occurrence and document ways to handle
    them. For example, if the dataset has a lot of empty values, you should have a
    plan for how to deal with them, and your actions should not distort the data in
    an undesirable way.
  prefs: []
  type: TYPE_NORMAL
- en: You should also look at ideas regarding feature engineering during the EDA stage.
    Perform statistical analysis on the data and try to find causal relationships
    that will help to solve the task at hand.
  prefs: []
  type: TYPE_NORMAL
- en: 'The data understanding stage should have the following outputs:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Data source dictionary**: This document briefly describes all the data sources
    that are relevant to your project.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**An EDA report that shows the conclusions of your data analysis**: This document
    should describe the approach that you will use to solve the task at hand and the
    strategies for handling errors that you have found in the data. You should include
    facts that may interest your customer.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Data preparation
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: This stage is where we start working with data. The data preparation stage involves
    taking raw data and changing it into a useful format. You read data from its sources
    and prepare it so that you can use the data to reach the project's goal. If you
    are solving a task based on structured data and plan to use machine learning,
    you will need to perform feature engineering. The previous stage should give you
    insights into the quirks of the data that you can fix during the data preparation
    stage. This stage's output is one or more reproducible data preparation jobs and
    a dataset that you can use to build and test models.
  prefs: []
  type: TYPE_NORMAL
- en: Optimizing data preparation
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Data preparation and data understanding are surprisingly time-consuming. These
    stages can take up to 80% of the project's time, so don't forget to plan in advance.
    Since this stage is time-consuming, optimizing the team's performance is important.
    Open source tools for automated EDA and feature engineering can save you a lot
    of time at the start of the project, so don't hesitate to use them. In the *Creating
    the Development Infrastructure* section of this book, we will look at several
    libraries that you can use to speed up the data preparation and data understanding
    stages.
  prefs: []
  type: TYPE_NORMAL
- en: To make this process less error-prone and easier to monitor, you should care
    about data provenance and versioning. Every dataset should be able to be traced
    back to its source. Take care to save all the data files, regardless of whether
    they're intermediate and raw. Log the inputs and outputs of every data transformation
    job in your code. Data processing bugs are notoriously hard to spot unless you
    have complete control of your data streams.
  prefs: []
  type: TYPE_NORMAL
- en: Another important point to make is reusability. Code your data processing jobs
    well. It is tempting to create a large pile of tangled code lines in a single
    file and let them do their job. Doing this will increase your technical debt.
    The code will work for a while, and then it will fail without notice. Over time,
    you may also want to add additional features to the code. If it is badly written,
    you will spend an unexpectedly large amount of time making fixes and debugging.
  prefs: []
  type: TYPE_NORMAL
- en: 'To ensure that you have robust data processing code, use the following checklist
    during the code review:'
  prefs: []
  type: TYPE_NORMAL
- en: All the repeated code is encapsulated into functions
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The logically connected functions are encapsulated in classes and modules
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Your code has extensive logging
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: All the configuration parameters can be changed via the config file or command-line
    arguments
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The inputs and outputs of your data job are saved somewhere
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The code is reproducible and has documentation
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Modeling
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'This topic was covered in the *What is Data Science?* section of this book.
    In this stage, we apply our knowledge of data science, machine learning, and deep
    learning to solve the task at hand. This is done in the following stages:'
  prefs: []
  type: TYPE_NORMAL
- en: First, we determine the task type, that is, supervised (classification and regression),
    unsupervised (clustering and document topic modeling), or reinforcement learning.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Then, prepare a list of algorithms that are suitable for solving the task.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Next, come up with a model validation and testing approach.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Finally, optimize the parameters of the model and select the best model.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Evaluation
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: While not being separate from the modeling and deployment steps, this stage
    deserves to stand on its own. You must test technical and business metrics, as
    well as checking the individual predictions of the model at this stage. Look at
    the biggest errors the model made on the test set and think about the changes
    that you can make to your data, features, or models that can fix those errors.
    This is also a good way to spot data processing bugs.
  prefs: []
  type: TYPE_NORMAL
- en: 'Your project should have two evaluation strategies: online and offline. Online
    evaluation takes care of tracking all the metrics for the already deployed model,
    while offline evaluation is used to decide which model will make it to the deployment
    stage.'
  prefs: []
  type: TYPE_NORMAL
- en: Typical data science projects contain hundreds of experiments with different
    models, data, and parameters. Each experiment generates new data in the form of
    metrics, code parameters, and notes. Use a specialized experiment tracking tool
    to decide on the success or failure of a particular experiment. These tools can
    automatically collect all the logs, metrics, and artifacts of the experiment to
    ensure their reproducibility and to ease searching the experiment results. If
    you don't want to or can't use a special tool, a spreadsheet can be a good substitute,
    although you will need to spend more time working on it. Having a complete log
    of all the experiments and decisions you've made regarding modeling and data preprocessing
    will help you compare different experiments and make conclusions about their results.
  prefs: []
  type: TYPE_NORMAL
- en: If you need to know about the technical details of model testing, please refer
    to [Chapter 2](20c52af6-9bb7-4578-9db2-6d74ac656248.xhtml), *Testing Your Models.*
  prefs: []
  type: TYPE_NORMAL
- en: The modeling and evaluation stages are closely related and are often repeated
    several times in successive iterations before the final stage is reached.
  prefs: []
  type: TYPE_NORMAL
- en: Deployment
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'At the deployment stage, you publish your best model for your end users and
    examine the results. At this stage, complexities are often overlooked. Production
    code has a separate set of strict requirements and **service level agreements**
    (**SLAs**) that your model needs to meet. We can separate those requirements into
    two categories: functional and nonfunctional. Functional requirements define your
    service''s features, while nonfunctional requirements define your SLAs.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Some examples of the functional requirements for your model service are as
    follows:'
  prefs: []
  type: TYPE_NORMAL
- en: Request/response format
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Capability for model versioning
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: A UI for tracking deployments and request statistics
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Nonfunctional requirements define the quality of service and availability of
    your service, and some of them are as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: Desired request throughput (1,000 requests per second)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Availability schedule (24/7 and 5/8)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Secure communication
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Elastic scalability so that the system will stay available when the user load
    peaks
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The requirements for model deployment are similar for different projects, so
    this part of the process is subject to reusability. Instead of repeating the same
    work for each project, you can develop your own model-serving framework or use
    an existing one.
  prefs: []
  type: TYPE_NORMAL
- en: Another important point to remember at the deployment stage is evaluation. This
    does not end at the previous stage; you should evaluate all of the model's metrics
    online. Your system may trigger alerts or compensative actions such as model retraining
    if the online metrics drop below a certain threshold. A/B testing and multi-armed
    bandits are also a part of the deployment process and can be supported as features
    of your model server.
  prefs: []
  type: TYPE_NORMAL
- en: Now, you should be familiar with the common stages of each data science project.
    Let's see how we can execute each stage with a proper management approach.
  prefs: []
  type: TYPE_NORMAL
- en: Choosing a project management methodology
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Project management methodologies provide a set of rules and processes that can
    distinguish chaotic projects from coherent ones. They provide a framework where
    everyone can act toward a greater goal. Laws do the same for our society. However,
    laws are not perfect and they often fail. There is no silver bullet in the world
    of software management either. Some management practices are better suited to
    one type of project and will let you down in another. In the following sections,
    we will explore the most popular ways of managing software projects and learn
    how to adapt them to a data science environment so that we can draw conclusions
    and choose the one that suits our project the best.
  prefs: []
  type: TYPE_NORMAL
- en: Waterfall
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'The most intuitive way to manage a project is to approach it like you''re building
    a house. The steps for this are as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: Prepare the building site
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Lay a foundation
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Create a framework
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Build a roof
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Build walls
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Connect the electricity and water
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Finish the exterior and interior
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'To build a software system, you do the following:'
  prefs: []
  type: TYPE_NORMAL
- en: Prepare the development environment
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Analyze and document the requirements
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Analyze and document the architecture and software specification
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Build the system
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Test that everything is working according to the requirements
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Finish the project
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: This management methodology is called a **waterfall**. It is logical on paper,
    but real-world applications rarely end up being very successful. The reason behind
    this is that all the steps are laid out sequentially and are only repeated once.
    If you make a single mistake, the project plan will fall apart. A single undocumented
    requirement, such as the one at *step 2*, can result in a disaster at *step 6*.
    Clients do not have a complete view of the end result and they can make mistakes
    too. Requirements can change after customers see the actual implementation of
    their requests.
  prefs: []
  type: TYPE_NORMAL
- en: Software project managers know that a single waterfall won't solve their issues,
    so they compose many smaller waterfalls into sequential iterations. This stage
    of evolution is called iterative and incremental software development. The iterative
    project is comprised of several phases that are managed in a waterfall fashion.
    The length of a single iteration is measured in months. At the end of each phase,
    the development team shows intermediate results to the end user for the purpose
    of collecting feedback. This feedback is used to jumpstart the next iteration.
    With each cycle, the understanding of the desired result evolves until it satisfies
    the customer's needs.
  prefs: []
  type: TYPE_NORMAL
- en: Agile
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'The iterative approach is still too heavy for most software projects. They
    suffer from changes that pile up in a mountain of technical requirements. In 2001,
    some of the brightest heads of the software development world created an Agile
    manifesto ([https://agilemanifesto.org](https://agilemanifesto.org)), which described
    a new management approach in four simple points:'
  prefs: []
  type: TYPE_NORMAL
- en: Individuals and interactions take precedence over processes and tools
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Working software takes precedence over comprehensive documentation
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Customer collaboration takes precedence over contract negotiation
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Responding to change takes precedence over following a plan
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: That is, while there is value in the latter of each point, we value the former
    of each point more.
  prefs: []
  type: TYPE_NORMAL
- en: Today, we associate agile with Kanban and Scrum. These methodologies take somewhere
    between 50 and 500 pages to explain. Nonetheless, at its core, Agile is simple.
    Any project can go astray with the agile manifesto, and many did. If you leave
    out the last sentence in the manifesto, you may end up creating a project without
    a plan or specification, which will inevitably end in an uncontrollable mess.
    People needed a more direct guide when it comes to managing software projects.
    This is why Kanban and Scrum were invented.
  prefs: []
  type: TYPE_NORMAL
- en: Kanban
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: First, let's cover Kanban. The best metaphor for explaining Kanban is a conveyor
    belt. Imagine that all of your tasks go through a fixed number of stages before
    they're finished. The concrete definition of those stages is up to you.
  prefs: []
  type: TYPE_NORMAL
- en: 'In software projects, you may want to use the following process:'
  prefs: []
  type: TYPE_NORMAL
- en: Backlog (a buffer where all incoming tasks are collected before they're processed)
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Requirements specification
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Development
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Code review
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Testing
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Deployment
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Kanban visualizes each task on a board, as shown in the following diagram:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/7d0fe435-1d6b-4ecf-94dd-6c7d89222cf9.png)'
  prefs: []
  type: TYPE_IMG
- en: Each stage should have a limit regarding the tasks that can be done in parallel.
    Kanban purposefully limits the number of simultaneous tasks to increase throughput.
    If the team becomes blocked because there are too many tasks sitting in the deployment stage,
    then all the team members who are capable of making shipments of the end product
    to production should stop doing their tasks and switch to getting rid of the bottleneck.
    Once the problem has been resolved, the team may decide to work on other tasks
    according to their priority. Because of this, Kanban favors cross-functional teams
    where everyone can help push tasks through each stage. Kanban does not remove
    the concept of roles, but it states that no matter the role, each team member
    should be able to help in dealing with a bottleneck.
  prefs: []
  type: TYPE_NORMAL
- en: 'Kanban focuses on completing a single task from start to finish as fast as
    possible. The main metrics that we can use to measure the effectiveness of Kanban
    projects are as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Lead time**: The time it takes for a task to move from the backlog to being
    completed on average.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Cycle tile**: The time it takes for a task to move from the starting stage
    to being completed on average. In our example, the cycle time would be between
    the requirements specification and deployment.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Throughput**: The average number of tasks you can get done during a time
    interval, that is, a day, a week, or a month.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: In general, you don't create a fixed project plan with fixed deadlines when
    using Kanban. Also, you don't have to estimate each task individually since the
    metrics will take care of that. Measure your team's throughput for several weeks
    so that you have an idea of how much you will be able to deliver in the near future.
  prefs: []
  type: TYPE_NORMAL
- en: 'Kanban''s powers are also its limitations, some of which are as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: Kanban works best when the amount of work in each of your tasks is the same.
    If some tasks are taking significantly longer than the others, your metrics will
    stop being useful.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: If you don't want to work as a cross-functional team, your throughput will suffer
    from bottlenecks, which makes using Kanban worthless.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Kanban does not give you the tools you need to manage deadlines, project scope,
    and budgets. The single thing it takes care of is optimizing throughput.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Kanban is a great software management approach for projects with repetitive
    tasks. It can also be partially applied to parts of your project where it makes
    sense to use it. Here are some examples of projects where using Kanban is a good
    idea:'
  prefs: []
  type: TYPE_NORMAL
- en: In a software support project, where you should take care of deployment and
    fixing frequent issues.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: If your data science project has a dedicated team that performs experiments
    with machine learning models, using Kanban will help increase their throughput.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Projects where you need to create lots of similar things, such as hundreds of
    web forms, data mappings, or identical machine learning models.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The surprising thing about ![](img/8bde82b7-182f-46db-b1ff-c07bd4e276b7.png) (Kanban)
    is that it was originally developed to make the car manufacturing process more
    efficient. Toyota invented Kanban in 1959 and integrated it into their production
    environment in 1962\. You can see that all of Kanban's pros and cons make sense
    in terms of a manufacturing environment, where car parts go through different
    stages on a conveyor belt.
  prefs: []
  type: TYPE_NORMAL
- en: Scrum
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Another popular management methodology from the agile family is Scrum. The main
    idea behind Scrum is the sprint. The sprint is a set of tasks with a fixed deadline
    and duration. Typical sprint durations are one week, two weeks, and one month.
    Explaining the entirety of Scrum would take another book, so we will only present
    the basics here.
  prefs: []
  type: TYPE_NORMAL
- en: 'The Scrum process includes the following steps:'
  prefs: []
  type: TYPE_NORMAL
- en: Backlog grooming
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Sprint planning
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Sprint execution
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Retrospective
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Akin to other agile methodologies, all the tasks go into the project backlog.
    The project backlog needs periodic grooming: all of the obsolete tasks should
    be deleted; the rest of the tasks need to be ordered by priority.'
  prefs: []
  type: TYPE_NORMAL
- en: The main component of Scrum is the sprint. A sprint is an iteration with a fixed
    deadline and a defined goal. The typical length of a sprint is 2 weeks. It always
    starts with a sprint planning meeting, where team members observe the project
    backlog and take tasks into a sprint. Each task is estimated in abstract story
    points. The goal of estimating in story points rather than hours is to make estimations
    relative rather than absolute. For example, we can consider a task with one story
    point trivial and a task with two story points as being slightly harder but still
    easy to complete. Four to six story points would indicate a normal task. Another
    system of story point estimates suggests using powers of 2 to 128 as task estimates.
    On the first sprint, the estimations are fairly approximate. On the second sprint,
    you compare the new tasks with the previous ones and see how many story points
    the task is worth. After four sprints, you can see how many story points your
    team can complete on average. You can also calculate an approximate hour equivalent
    of a single story point, although this should only be used as a reference and
    not as a substitute for story points during the sprint planning process.
  prefs: []
  type: TYPE_NORMAL
- en: During planning, each team member estimates the task on their own, and then
    their estimations are compared. This helps ensure everyone understands the task
    definition in the same way. Differences in estimates signify that the task needs
    a clearer explanation and evaluation in terms of the SMART criteria.
  prefs: []
  type: TYPE_NORMAL
- en: The sprint starts after the planning phase. When you start working on the sprint,
    it will be locked. You cannot change the scope you defined during the planning
    phase. The primary focus of the team is to complete all the tasks in the sprint
    before it ends. This strategy allows you to achieve your planned goals while being
    robust to changes. The main strength of Scrum is also its main weakness. If your
    customer comes into work in the middle of the week with an *extremely important
    task that needs to be done ASAP*, you should do your best to convince them that
    the team will deliver this during the next sprint. Scope locking is an essential
    mechanism that makes sprints work. If you depart from this rule often, Scrum will
    become an obstacle rather than a beneficial and effective management approach.
  prefs: []
  type: TYPE_NORMAL
- en: 'In practice, scope locking can cause problems, especially if you are working
    in a B2B environment. For situations where you have no options and are forced
    to change sprint scope, you have two options:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Trade tasks**: You can remove a task from the sprint and add a new one.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Start a new sprint**: You can stop the current sprint and plan a new one.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Using these options frequently makes Scrum ineffective. Try to negotiate a fixed
    sprint scope with your customers and show them that it brings benefits such as
    planned delivery while leaving space for requirement changes.
  prefs: []
  type: TYPE_NORMAL
- en: A good strategy you can use to avoid unexpected scope changes is to ask your
    customers to take part in backlog grooming and sprint planning. Scrum experts
    suggest that you should assign a special product owner role for this task. The
    product owner should decide on task priorities, sprint goals, and negotiate all
    the conflicting requirements with project stakeholders.
  prefs: []
  type: TYPE_NORMAL
- en: 'Scrum came directly from the software development world, so it has fewer limitations
    than Kanban. The price lies in its complexity: Scrum is not an easy methodology,
    and it will create management overhead. Each team member should understand Scrum
    if you want it to work. In complex projects, you may need to give someone the dedicated
    role of Scrum master. This is someone who will take care of applying the methodology
    to one or several of your projects.'
  prefs: []
  type: TYPE_NORMAL
- en: In the next section, we will look at choosing a methodology according to the
    needs of your project.
  prefs: []
  type: TYPE_NORMAL
- en: Choosing a methodology that suits your project
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Choosing a project management methodology can become a captivating and complex
    task. You can spend a lot of time thinking about how one approach will support
    your processes better than another, and what limitations it will have. Try not
    to spend much of your time on methodological considerations. It is much more important
    to choose something and stick with it unless it is clearly harming your project.
    To simplify this process, we will explore some simple guidelines when it comes
    to choosing a management approach.
  prefs: []
  type: TYPE_NORMAL
- en: Creating disruptive innovation
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: If you create a solution that should disrupt the market, the only thing that
    matters is the efficiency of your methodology. You won't have many customers at
    the start of the project, so you should be able to collect feedback and perform
    focused work to iterate on the next version of your product. Scrum works best
    in such situations. You can implement new features regarding the sprint and collect
    feedback at the end of each sprint to start a new iteration. Kanban will work
    too, but it will provide fewer benefits in terms of disruptive innovation.
  prefs: []
  type: TYPE_NORMAL
- en: Providing a tested solution
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: If you implement a system that resembles some of your past projects, it will
    presumably require much less research than in previous iterations. This is also
    the case for system integration projects, where you provide services that can
    integrate your product into the customer's IT environment. In those projects,
    you can define many customer-focused tasks that can be divided into three to five
    groups depending on the total amount of work that needs to be done. In this setting,
    Kanban will provide the most benefit. Using Kanban will allow you to focus on
    delivering more results to the customer in less time.
  prefs: []
  type: TYPE_NORMAL
- en: Developing a custom project for a customer
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Using Agile methodologies can be extremely tricky when you''re working on a
    project for a customer. Your clients will want to have the best of both worlds:
    fixed deadlines with constantly changing requirements. Your job is to decide on
    the best approach for this project and explain its pros and cons. Many teams settle
    for something between Scrum and waterfall: you develop the initial scope of the
    project, estimate it, and show it to the client. Next, you implement the project
    scope piece by piece using sprints. The requirements will inevitably change during
    the implementation stage, so it is important that you manage these changes and
    keep the customer involved in sprint planning.'
  prefs: []
  type: TYPE_NORMAL
- en: Choosing a project methodology goes hand in hand with estimating data science
    projects. In the next section, we will define the goals of the estimation process
    and learn how to make estimates.
  prefs: []
  type: TYPE_NORMAL
- en: Estimating data science projects
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'If you need to explain the basic principles of forecasting to someone, ask
    them if they have ever worked on a software project. If so, they already know
    the basics of forecasting: everyone who has worked on one has estimated tasks.
    Everyone needs estimates. Your customers need them to plan and control when they
    will start to use the results of your project. The project manager needs estimates
    to understand the scope, amount of work, and approximate costs for individual
    tasks or an entire project.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Estimation is beneficial in several areas, such as the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Understanding work structure**: Break down a task into multiple subtasks
    to view the main steps that you need to complete.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Understanding complexity**: While it is hard to estimate a complex task by
    itself, estimating each individual part of the work structure is simpler. It allows
    you to get an idea of how complex the task is and how long it will take to finish
    it.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Understanding costs**: In most businesses, you won''t be able to start working
    on a project if you don''t explain and defend its costs and required resources
    first.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The largest problem with estimations is that they fail. Our plans are inaccurate,
    incomplete, and often irrelevant to how the real work will be done. Even experienced
    software developers struggle to estimate the total amount of hours that it will
    take to do a single task unless they have done it multiple times already.
  prefs: []
  type: TYPE_NORMAL
- en: Research shows that humans are bad at absolute estimates. Our brains are simply
    not suited to making accurate mental models of complex multilayered projects.
    For example, if we were to ask a bunch of strangers about the height of the nearest
    building, the majority would fail to give you the correct answer. However, if
    you told them the height of several buildings, their estimates would be much more
    accurate. This is true not only for building height estimates but for all kinds
    of estimation.
  prefs: []
  type: TYPE_NORMAL
- en: 'To use relative estimates in data science projects, you need two things: relevant
    samples and a good estimation process. We can think of relevant estimates as simple
    statistical estimators that average the length of all previous relevant tasks.
    To create such an estimator, we first need to collect a dataset. If you follow
    a waterfall process, then to get one new data point in your estimation dataset, you
    need to complete a whole project from start to end. You may need to fail estimates
    in many projects before you get good at estimating one particular type of project.'
  prefs: []
  type: TYPE_NORMAL
- en: The trick is to get down to the individual task levels. Scrum suggests that
    you use relative story points instead of absolute hours for this reason. First,
    your estimates become relative at the task level, then at the sprint level, and
    finally at the project level. If you have no prior experience that will help you
    to make relative estimates, the only absolute estimate you should make is one
    for the first sprint of the project. From here, you should use the previous tasks
    as a basis for making new estimations.
  prefs: []
  type: TYPE_NORMAL
- en: You don't have to use Scrum to benefit from relative estimations. Scrum provides
    one way to make them work, but it may not be ideal for your circumstances. If
    that is the case, you can adapt any management methodology for relative estimation.
  prefs: []
  type: TYPE_NORMAL
- en: '**Differentiating between business and implementation estimates:**'
  prefs: []
  type: TYPE_NORMAL
- en: 'We can look at estimates from two perspectives. The first one will be familiar
    to project managers and team leaders who are mostly concerned with project delivery:
    the implementation perspective. The main goal of estimates in this example is
    to provide correct expectations regarding how much time and money will be required
    to build the solution.'
  prefs: []
  type: TYPE_NORMAL
- en: Another perspective is closely related to the business goals of the project
    and is often unseen by the implementation team. Every project is generally backed
    up by a business model that fixes expectations on revenue increases, customer
    satisfaction, reduced costs, and so on.
  prefs: []
  type: TYPE_NORMAL
- en: This business model should always be considered when you're creating implementation
    estimates. In data science projects, business estimations can be included in the
    project by deriving budget constraints from a business model and creating a set
    of business metrics that will evaluate the project's performance.
  prefs: []
  type: TYPE_NORMAL
- en: Learning to make time and cost estimates
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Using relative estimates is an effective strategy, but it becomes useless if
    someone asks you, *When exactly will you be able to finish this?* Scrum and Kanban
    do not give you project estimation tools. In fact, both methodologies argue that
    making such estimates is unnecessary. This line of thought is true if your goal
    is to efficiently complete a project with known deadlines and known budget constraints.
    However, there are situations where you may need to set budgeting and time constraints
    yourself.
  prefs: []
  type: TYPE_NORMAL
- en: Let's take a consulting environment as an example. We need to build a custom
    analytics system for a client. The main task is to estimate the probability of
    buying a certain product based on the user's profile. This customer needs an entirely
    new solution that will meet the requirements of various stakeholders from several
    departments. They also ask you to integrate the solution with various IT systems.
    They have invited several companies to compete for the project. The first thing
    they ask each candidate company is, *How much will this cost and how fast will
    you be able to build it?* *How can we approach this if we know the limitations
    of absolute estimations?*
  prefs: []
  type: TYPE_NORMAL
- en: 'Let''s start with the outline. The outline is a hierarchical list of high-level
    tasks that you will need to complete. The simplest outline for a waterfall project
    may look like this:'
  prefs: []
  type: TYPE_NORMAL
- en: Collect the requirements
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Implement the requirements
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Test the system
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Deploy the system
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Using a waterfall project is risky, so we will split the system into several
    stages, with each going through several successive steps. Depending on the complexity
    of the stage, you will need to make one or several iterations of the same stage
    to complete it. In theory, you could try to create an outline for every two-week
    sprint, but this is unrealistic because of the ever-changing nature of data science
    projects.
  prefs: []
  type: TYPE_NORMAL
- en: 'For example, let''s look at the outline for requirements collection:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Collect the requirements:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Software architecture:'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: Nonfunctional requirements specification
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: Nonfunctional requirements implementation strategy
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: Component diagram
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: Integration diagram
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Functional requirements specification:'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: 'UI:'
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: UI requirements
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: UI mockups
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: Backend services
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Data analysis and modeling:'
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: EDA
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: Creating an experimentation backlog
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: You should start by defining the rough steps and then detail them. If you have
    created similar projects before, you can look at their outlines so that you know
    where to start. Collecting and using data from other projects can serve as a primary
    source of relative estimates, so do not underestimate your prior experience.
  prefs: []
  type: TYPE_NORMAL
- en: You will have difficulty decomposing some tasks. Being unsure about an approach
    to a task is a red flag signaling that you need to communicate with your customers
    and figure this out. If you do not how many systems you will need to integrate
    with, you will have a hard time decomposing all the stages and tasks related to
    integration. In this case, we need to call the customer and quickly discover the
    necessary information. However, you may have hundreds of such questions during
    the estimation process, and tracking new information will quickly become ineffective.
    It is a good idea to prepare a numbered list of questions first. Answers can change
    during the estimation process, so each question should be assigned a date. Ideally,
    those questions should be shared in a format that makes collaboration easy.
  prefs: []
  type: TYPE_NORMAL
- en: When your outline is detailed enough, it is time to design a software architecture
    proposal. This is a crucial step because matching outlines with customer requirements
    is not always economically viable or even possible from a technological standpoint.
    You should have at least a rough idea of what technologies you will use, how they
    will integrate with the rest of the customer's system, and how your solution should
    be deployed. If there are any crucial nonfunctional requirements, such as 24/7
    availability, the software architect should also think about how to implement
    them in terms of technology and system design. Drafting a high-level architecture
    vision will help explain this outline. Do not hesitate to change the outline if
    you think that's necessary. Software design is a complex task an experienced engineer
    should do, so if you do not have deep expertise in designing software solutions,
    ask for help from someone on your team, or even better, make software design a
    collaborative effort.
  prefs: []
  type: TYPE_NORMAL
- en: After you've completed the outline and have a software architecture vision,
    you can start estimating the project. I recommend using simple statistical estimation
    procedures such as the **program evaluation and review technique** (**PERT**).
  prefs: []
  type: TYPE_NORMAL
- en: 'In PERT, you give each task a three-point estimate:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Optimistic estimate**: The time you plan to spend on the task if everything
    goes well; minor technical problems and requirements issues may arise.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Most likely estimate**: The most realistic estimate you can give for the
    task.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Pessimistic estimate**: The time that''s required to finish the task if problems
    arise. This includes additional risks for dealing with experiments that have gone
    wrong, complex debugging sessions, and having long debates with the customer.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Then, you can calculate a simple weighted average to get the final estimate:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/5b8ed5ce-4b32-43f4-baec-969771483465.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Calculating the standard deviation is also useful when it comes to making confidence
    intervals:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/d0a5302f-0c0f-43db-b6cd-50d57bc1856b.png)'
  prefs: []
  type: TYPE_IMG
- en: '![](img/ffe349f6-61eb-4b27-9f13-7af82bfc0f42.png) will give you a 99.7% confidence
    interval, meaning that the task will end up somewhere between these numbers with
    a 99.7% probability. If this range is too wide for you, you can use ![](img/db37e54f-236b-4e22-8614-7a4fd948247d.png),
    which will give you a 95.5% confidence interval.'
  prefs: []
  type: TYPE_NORMAL
- en: Use data from any finished projects as a base for relative estimation. The more
    external resources you use for estimation, the more accurate and risk-averse your
    estimates will become.
  prefs: []
  type: TYPE_NORMAL
- en: Since we are ineluctably bad at estimation, all of the estimates are only a
    rough idea of your current view of the project implementation plan. Project outlines
    and estimates should constantly change and be adapted to the current situation.
    You should periodically check whether the original plan should be changed and
    updated. If so, convey this to the customer and work through the necessity of
    the changes. It may be that the customer added several new features to your backlog,
    thinking that they were present in the original scope. If this is not the case,
    negotiate a scope expansion, followed by a budget and deadline extension. If these
    features are not critical enough, advise the customer to remove them from the
    backlog. With each completed task on a particular type of project, your experience
    will grow. As a result, you will be able to anticipate more of the customer's
    needs and include them in the base plan, which will make estimates more accurate.
    Store all of the versions of the project estimations so that you can track all
    scope changes effortlessly.
  prefs: []
  type: TYPE_NORMAL
- en: Project architecture vision should also be robust in terms of changes. The more
    customized your solution is, the less likely it is that it will create an ideal
    architecture vision that will survive all scope changes. Plan ahead and include
    several variation points in the parts of your solution that are the most likely
    to change. A vacation point is a software component (or a set of software components)
    that was going to change from the start. A plugin architecture and microservices
    with fixed contracts are examples of variation points that allow for easy extension
    or substitution.
  prefs: []
  type: TYPE_NORMAL
- en: Discovering the goals of the estimation process
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: It is important to keep the end goal in mind while making estimations. You can
    build a data science system without making a grand plan. Creating estimates and
    keeping them up to date requires a lot of effort and time. Data science projects
    are complex and unpredictable, so the more you and your customers believe in your
    estimates, the more likely they're going to fail. Estimates become more uncertain
    if your team has no prior experience in building solutions for a new business
    domain or if you are trying to apply new types of algorithms or use new technologies.
  prefs: []
  type: TYPE_NORMAL
- en: Having a fine-grained view of how to achieve the end goal is useful. In contrast,
    relying on the exact calculations of how long it will take you, or using extremely
    detailed outlines, is not. Use estimates wisely; they will help you align your
    implementation plans with customer demands.
  prefs: []
  type: TYPE_NORMAL
- en: Summary
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this chapter, we looked at how to manage data science projects. We explored
    how analytical projects differ from software engineering projects and studied
    the data science project life cycle. We looked at how we can choose a project
    management methodology that suits our needs and uncovered practical guidelines
    for estimating data science projects, and also discussed the limitations of long-term
    plans. No matter how good your plans and estimates are, data science projects
    have many inherent risks that can become the failing points of your projects.
  prefs: []
  type: TYPE_NORMAL
- en: In the next chapter, we will look at common pitfalls of data science projects.
  prefs: []
  type: TYPE_NORMAL
