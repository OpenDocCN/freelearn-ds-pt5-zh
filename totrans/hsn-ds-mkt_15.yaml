- en: Retaining Customers
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: As customers have more options for similar content to consume or similar products
    and services to shop for, it has become more difficult for many businesses to
    retain their customers and not lose them to other competitors. As the cost of
    acquiring new customers is typically higher than that of retaining and keeping
    existing customers, customer churn is becoming more and more of a concern than
    ever before. In order to retain existing customers and not lose them to competitors,
    businesses should not only try to understand their customers and their customers'
    needs and interests, but they should also be able to identify which customers
    are highly likely to churn and how to retain these customers at churn risk.
  prefs: []
  type: TYPE_NORMAL
- en: In this chapter, we are going to dive deeper into customer churn and how it
    hurts businesses, as well as how to retain existing customers. We will discuss
    some of the common reasons for customers leaving businesses and look at how data
    science can help reduce the risk of losing customers. As a way of predicting customer
    churn, we will learn about what an artificial neural network model is and its
    applications in different areas, as well as how we can build one using Python
    and R.
  prefs: []
  type: TYPE_NORMAL
- en: 'In this chapter, we will cover the following topics:'
  prefs: []
  type: TYPE_NORMAL
- en: Customer churn and retention
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Artificial neural networks
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Predicting customer churn with Python
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Predicting customer churn with R
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Customer churn and retention
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: '**Customer churn** is when a customer decides to stop using services, content,
    or products from a company. As we have briefly discussed in [Chapter 7](72e8f4ee-7f95-4acc-928d-d33c9fc31bd6.xhtml), *Exploratory
    Analysis for Customer Behavior*, when we discussed customer analytics, it is much
    less expensive to retain existing customers than to acquire new customers, and
    the revenue from repeat customers is typically higher than that form new customers.
    In competitive industries, where a business faces many competitors, the cost of
    new customer acquisition is even higher, and retaining existing customers becomes
    more important for such businesses.'
  prefs: []
  type: TYPE_NORMAL
- en: There are many reasons behind customers leaving a business. Some of the common
    reasons why customers churn are poor customer service, not finding enough value
    in the products or services, lack of communications, and lack of customer loyalty.
    The first step to retaining these customers is to monitor customer churn rates
    over time. If the churn rate is generally high or is increasing over time, then
    it will be a good idea to dedicate some resources to improving customer retention.
  prefs: []
  type: TYPE_NORMAL
- en: In order to improve the customer retention rate, the top priority should be
    to understand the customer better. You can survey customers who have already churned
    to understand why they left. You can also survey existing customers to understand
    what their needs are and what their pain points are. A data science and data analytics
    approach would be to look into the data. For example, you can look at customers'
    web activity data and understand where they spend the most time, whether there
    were errors on the pages that they were looking at, or whether their search results
    did not return good content. You can also look into the customer service call
    logs to understand how long their wait time was, what their complaints were, and
    how their issues were handled. Conducting deep analyses on these data points can
    reveal the problems that a business is facing in retaining its existing customers.
  prefs: []
  type: TYPE_NORMAL
- en: When analyzing for customer churn, you can also utilize some of the topics we
    have discussed in this book. You can apply what we have learned from [Chapter
    5](73a716c6-6a84-4785-b04e-87651d0a29d1.xhtml), *Product Analytics*, and [Chapter 6](d3ba7047-2873-4b03-9a44-4c1d55b84178.xhtml),
    *Recommending the Right Products*, to understand which products serve the customer
    needs and interests the best, and recommend the right products so that you can
    deliver more personalized content. You can also use what we have learned from
    [Chapter 7](72e8f4ee-7f95-4acc-928d-d33c9fc31bd6.xhtml), *Exploratory Analysis
    for Customer Behavior*, and [Chapter 10](5955002d-2a75-4d5a-aa6a-86710a3bf00e.xhtml),*Data-Driven
    Customer Segmentation*, to understand the customer behavior better and the different
    segments of customers. Another way is to build a machine learning model that can
    predict which customers are likely to churn and target and retain these specific
    customers that are at higher risk of churn. In the following sections, we will
    discuss how to build a neural network model to identify those customers with higher
    risk of churn for customer retention.
  prefs: []
  type: TYPE_NORMAL
- en: Artificial neural networks
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'The** artificial neural network** (**ANN**) model is a machine learning model
    that is inspired by how a human brain functions. Recent successful applications
    of ANN models in image recognition, voice recognition, and robotics have proven
    their predictive power and usefulness in various industries. You might have heard
    the term **deep learning**. This is a type of ANN model where the number of layers
    between the input and output layers is large. It is best explained with the following
    diagram:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/94952b7d-1e29-44d5-9886-ebc15f2b8781.png)'
  prefs: []
  type: TYPE_IMG
- en: This diagram shows a simple case of an ANN model with one hidden layer. The
    circles in this diagram represent artificial neurons or nodes, which model those
    neurons in human brains. The arrows represent how signals are transmitted from
    one neuron to another. As this diagram suggests, an ANN model learns by finding
    the patterns or the weights of signals from each input neuron to the neuron in
    the next layer, which best predicts the output.
  prefs: []
  type: TYPE_NORMAL
- en: The specific type of an ANN model that we will be experimenting with in the
    following programming exercises is a **multilayer perceptron** (**MLP**) model.
    Simply put, an MLP model is a neural network model that has at least one or more
    hidden layers of nodes. Including one layer for the input and another layer for
    the output, the MLP model consists of at least three or more layers of nodes.
    The diagram we just looked at is the simplest case of an MLP model, where there
    is only one hidden layer.
  prefs: []
  type: TYPE_NORMAL
- en: ANN models can be utilized in many areas of marketing. Using neural network
    models by BrainMaker, Microsoft increased its direct mail response rate from 4.9%
    to 8.2%. This helped Microsoft to bring in the same amount of revenue for 35%
    less cost. Similarly, for the marketing engagement prediction problems we discussed
    in [Chapter 8](4f5163a1-c34a-495f-bc5f-e02f9b2a2052.xhtml), *Predicting the Likelihood
    of Marketing Engagement*, we could have used neural network models, instead of
    random forest models. We can also use neural network models for the customer segmentation
    problems that we discussed in [Chapter 10](5955002d-2a75-4d5a-aa6a-86710a3bf00e.xhtml),
    *Data-Driven Customer Segmentation*. In the following programming exercises, we
    will discuss how we can use ANN models to predict which customers are likely to
    churn.
  prefs: []
  type: TYPE_NORMAL
- en: Predicting customer churn with Python
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this section, we are going to discuss how to use an ANN model to predict
    the customers at the risk of leaving, or customers who are highly likely to churn.
    By the end of this section, we will have built a customer churn prediction model
    using an ANN model. We will be mainly using the `pandas`, `matplotlib`, and `keras` packages
    to analyze, visualize, and build machine learning models. For those readers who
    would like to use R, instead of Python, for this exercise, you can skip to the
    next section.
  prefs: []
  type: TYPE_NORMAL
- en: 'For this exercise, we will be using one of the publicly available datasets
    from the IBM Watson Analytics community, which can be found at this link: [https://www.ibm.com/communities/analytics/watson-analytics-blog/predictive-insights-in-the-telco-customer-churn-data-set/](https://www.ibm.com/communities/analytics/watson-analytics-blog/predictive-insights-in-the-telco-customer-churn-data-set/).
    You can follow this link and download the data, which is available in XLSX format,
    named `WA_Fn-UseC_-Telco-Customer-Churn.xlsx`. Once you have downloaded this data,
    you can load it into your Jupyter Notebook by running the following command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: 'The DataFrame, `df`, is shown in the following screenshot:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/82ebeb7f-fa1b-4fb8-9cb8-3c1e3f1f5048.png)'
  prefs: []
  type: TYPE_IMG
- en: There are 21 variables in this dataset, where our goal is to predict the target
    variable, `Churn`.
  prefs: []
  type: TYPE_NORMAL
- en: Data analysis and preparation
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'As you may notice by looking at the data, there are a few things we need to
    do before we can start building machine learning models. In this section, we are
    going to transform continuous variables that have monetary values and encode the
    target variable, `Churn`, as well as other categorical variables. To do so, perform
    the following steps:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Target variable encoding**: As you may have noticed from the data, the target
    variable, `Churn`, has two values: `Yes` and `No`. We are going to encode these
    values as `1` for `Yes` and `0` for `No`. The code to encode the target variable
    looks like the following:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: 'To get the overall churn rate, you can simply run the following code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: The output of this code is around 0.27, which suggests that about 27% of customers
    have churned. A 27% churn rate is not a small number; rather, it is high enough
    for a business to worry about the overall customer churn and come up with a solution
    to retain these customers. In the following modeling section, we will discuss
    how to predict customers who are likely to churn with this data and use these
    predictions to retain customers.
  prefs: []
  type: TYPE_NORMAL
- en: '**Handling missing values in the TotalCharges column**: If you looked through
    the `TotalCharges` column in the dataset, you may have noticed that there are
    some records with no `TotalCharges` values. Since there are only `11` records
    with missing `TotalCharges` values, we are going to simply ignore and drop those
    records with missing values. Take a look at the following code:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: As you may notice from this code, we are simply replacing the blank space values
    with `nan` values. Then, we are dropping all the records with `nan` values by
    using the `dropna` function.
  prefs: []
  type: TYPE_NORMAL
- en: '**Transforming continuous variables**: The next step is to scale the continuous
    variables. Take a look at the following summary statistics for continuous variables:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![](img/9b23f08b-ff28-4ecd-93d4-1605191cfbe0.png)'
  prefs: []
  type: TYPE_IMG
- en: 'You can get these summary statistics using the following code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: 'As you can see from the summary statistics, the three `tenure`, `MonthlyCharges`,
    and `TotalCharges` continuous variables all have different scales. The `tenure` variable,
    ranges from `1` to `72`, while the `TotalCharges` variable , ranges from `18.8`
    to `8684.8`. ANN models typically perform better with scaled or normalized features.
    Take a look at the following code for normalizing these three features:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: 'As you can see from this code, we apply log-transform first and then normalize
    the continuous variables by subtracting by the mean and dividing the values by
    standard deviations. The results look like the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/c3feef9a-26f3-4d7f-b6af-3c1fd1bbd9ce.png)'
  prefs: []
  type: TYPE_IMG
- en: As you see from this output, all the variables now have a mean of `0` and a
    standard deviation of `1`. We are going to use these normalized variables for
    future model building.
  prefs: []
  type: TYPE_NORMAL
- en: '**One-hot encoding categorical variables**: As you can see from the data, there
    are many categorical variables. Let''s first take a look at the number of unique
    values each column has. Take a look at the following code:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: 'You can use the `nunique` function to count the number of unique values in
    each column. The output of this code looks like the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/8607d3f9-078b-46c8-8795-36677f850605.png)'
  prefs: []
  type: TYPE_IMG
- en: As this output suggests, there are `7032` unique customer IDs, `2` unique genders,
    `3` unique values for `MultipleLines`, and `6530` unique values for `TotalCharges`.
    We have handled the `tenure`, `MonthlyCharges`, and `TotalCharges` variables,
    in the previous step, so we are going to focus on those variables with `2` to
    `4` unique values.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let''s take a look at the distributions of some of these categorical variables.
    First, to view the distribution of the data between males and females, you can
    use the following code for visualization:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: 'The plot looks like the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/d45a82ef-8941-4a1e-b045-603f6a250358.png)'
  prefs: []
  type: TYPE_IMG
- en: 'As you can see from this bar plot, the distribution of the data across different
    genders is roughly equally distributed. You can use the same code to view the
    distribution of the data across different values of `InternetService` and `PaymentMethod`.
    Take a look at the following plots:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/c9f241ba-b160-4d32-9ed5-6d5a3f4789cb.png)'
  prefs: []
  type: TYPE_IMG
- en: '![](img/02f7e148-eae1-433d-839d-846866528189.png)'
  prefs: []
  type: TYPE_IMG
- en: The first plot shows the distribution of the data across three different categories
    of the `InternetService` variable, and the second plot shows the distribution
    of the data across four different categories of the `PaymentMethod` variable.
    As you can see from these plots, we can easily visualize and understand what the
    distributions of categorical variables look like using bar plots. We recommend
    that you draw bar plots for other categorical variables to get a better understanding
    of the data distribution.
  prefs: []
  type: TYPE_NORMAL
- en: 'Now, we are going to apply one-hot encoding for these categorical variables.
    Take a look at the following code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs: []
  type: TYPE_PRE
- en: 'As you can see from this code, we are using the `get_dummies` function in the
    `pandas` package to create dummy variables for each categorical variable. Then,
    we concatenate these newly created dummy variables back to the `sample_set` variable,
    which will be used for training models in the following section. The results are
    shown in the following output:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/e0661e37-7736-4081-a012-d09060d67881.png)'
  prefs: []
  type: TYPE_IMG
- en: Once you have completed these four steps, it is time to start building ANN models
    for customer churn predictions. Move onto the next section for ANN modeling!
  prefs: []
  type: TYPE_NORMAL
- en: ANN with Keras
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'For building ANN models in Python, we are going to use `keras` package, which
    is a high-level neural networks library. For more details, we recommend you visit
    their official documentation at the following link: [https://keras.io/](https://keras.io/).
    Before we can use this package for building ANN models, we need to install two
    packages: `tensorflow` and `keras`. The `keras` package uses `tensorflow` as a
    backend for building neural network models, so we need to install `tensorflow`
    first. You can install these two packages using the following `pip` commands in
    your Terminal:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs: []
  type: TYPE_PRE
- en: 'Once you have installed these two packages, we can finally start building our
    first neural network models. In this exercise, we are going to build a neural
    network model with one hidden layer. Take a look at the following code first:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE10]'
  prefs: []
  type: TYPE_PRE
- en: Let's take a closer look at this code. First, we are using a `Sequential` model
    here, which is the type of model where the layers are stacked linearly and looks
    similar to the diagram we saw in the earlier section about the MLP model. The
    first layer is an input layer, where `input_dim` is simply the number of features
    or columns in the sample set and the number of output units is `16`. We are using
    the `relu` activation function for this input layer. Then, in the hidden layer,
    the number of output units is `8` and the activation function to be used is `relu`.
    Lastly, the output layer has one output unit, which is the probability of customer
    churn, and we use the `sigmoid` activation function in this layer. You can experiment
    with different numbers of output units and activation functions for your exercise.
  prefs: []
  type: TYPE_NORMAL
- en: 'The final step to build a neural network model with the `keras` package is
    to compile this model. Take a look at the following code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE11]'
  prefs: []
  type: TYPE_PRE
- en: Here, we are using the `adam` optimizer, which is one of the most commonly and
    frequently used optimization algorithms. Since our target variable is binary,
    we are using `binary_crossentropy` as the loss function. Lastly, this model will
    use the `accuracy` metric to evaluate model performance during training.
  prefs: []
  type: TYPE_NORMAL
- en: 'Before we start training this neural network model, we will need to split our
    sample set into train and test sets. Take a look at the following code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE12]'
  prefs: []
  type: TYPE_PRE
- en: 'As you can see from this code, we are using the `train_test_split` function
    of the `scikit-learn` package. For our exercise, we will use 70% of the sample
    set for training and 30% for testing. Now we can train our neural network model
    using the following code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE13]'
  prefs: []
  type: TYPE_PRE
- en: 'Here, we are using `100` samples as `batch_size`, from which the model is going
    to learn to predict each time, and `50` as the number of `epochs`, which is the
    number of complete passes through the entire training set. Once you run this code,
    you will see output that looks like the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/c3546491-4c7b-410c-80d6-47b584305a45.png)'
  prefs: []
  type: TYPE_IMG
- en: As you can see from this output, `loss` typically decreases and the accuracy
    (`acc`) improves in each epoch. However, the rate of model performance improvement
    decreases over time. As you can see from this output, there are big improvements
    in the loss and accuracy measures in the first few epochs and the amount of performance
    gain decreases over time. You can monitor this process and decide to stop when
    the amount of performance gain is minimal.
  prefs: []
  type: TYPE_NORMAL
- en: Model evaluations
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Now that we have built our first neural network model, let''s evaluate its
    performance. We are going to look at the overall accuracy, precision, and recall,
    as well as the **receiver operating characteristic** (**ROC**) curve and area
    under the curve (AUC). First, take a look at the following code for computing
    accuracy, precision, and recall:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE14]'
  prefs: []
  type: TYPE_PRE
- en: 'You should be familiar with this code, as we used the same evaluation metrics
    in [Chapter 8](4f5163a1-c34a-495f-bc5f-e02f9b2a2052.xhtml), *Predicting the Likelihood
    of Marketing Engagement*. The output of this code in our case looks like the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/7494f39e-a14f-4eda-8c43-7f86d4fca089.png)'
  prefs: []
  type: TYPE_IMG
- en: Due to some randomness in the model, your results might differ from these numbers.
    As you can see from this output, the accuracy of predicting whether a customer
    will churn or not in the test set is about `0.79`, suggesting the model is correct
    roughly about 80% of the time. The out-of-sample precision suggests that the model
    is correct about 66% of the time that it predicts that the customer is going to
    churn, and the out-of-sample recall suggests that the model captures roughly 52%
    of the churn cases.
  prefs: []
  type: TYPE_NORMAL
- en: 'Next, we can compute the AUC numbers, using the following code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE15]'
  prefs: []
  type: TYPE_PRE
- en: 'The output of this code looks like this:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/0ec3005a-e8e1-48e0-a8ec-293c4ffff915.png)'
  prefs: []
  type: TYPE_IMG
- en: 'To visualize this data in the ROC curve, you can use the following code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE16]'
  prefs: []
  type: TYPE_PRE
- en: 'And the output looks like this:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/99716b1c-5a70-4197-b28d-3a7297340dac.png)'
  prefs: []
  type: TYPE_IMG
- en: Along with the accuracy, precision, and recall measures that we looked at previously,
    the AUC and the ROC curve also suggest that the model captures and predicts those
    customers at churn risk pretty well. As you can see from these evaluation outputs,
    it is better to use the output of this model for identifying the customers who
    are likely to churn than simply guessing who they will be. By focusing on those
    customers with high churn probabilities from this model in your marketing strategies,
    you can try to retain those customers at churn risks in a more cost-effective
    way.
  prefs: []
  type: TYPE_NORMAL
- en: 'The full code for this exercise can be found in this repository: [https://github.com/yoonhwang/hands-on-data-science-for-marketing/blob/master/ch.11/python/CustomerRetention.ipynb](https://github.com/yoonhwang/hands-on-data-science-for-marketing/blob/master/ch.11/python/CustomerRetention.ipynb).'
  prefs: []
  type: TYPE_NORMAL
- en: Predicting customer churn with R
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this section, we are going to discuss how to use an ANN model to predict
    the customers at risk of leaving or customers who are highly likely to churn.
    By the end of this section, we will have built a customer churn prediction model
    using the ANN model. We will be mainly using the `dplyr`, `ggplot2`, and `keras` libraries
    to analyze, visualize, and build machine learning models. For those readers who
    would like to use Python, instead of R, for this exercise, see the previous section.
  prefs: []
  type: TYPE_NORMAL
- en: 'For this exercise, we will be using one of the publicly available datasets
    from the IBM Watson Analytics community, which can be found at this link: [https://www.ibm.com/communities/analytics/watson-analytics-blog/predictive-insights-in-the-telco-customer-churn-data-set/](https://www.ibm.com/communities/analytics/watson-analytics-blog/predictive-insights-in-the-telco-customer-churn-data-set/).
    You can follow this link and download the data, which is available in XLSX format,
    named `WA_Fn-UseC_-Telco-Customer-Churn.xlsx`. Once you have downloaded this data,
    you can load it into your RStudio environment by running the following command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE17]'
  prefs: []
  type: TYPE_PRE
- en: 'The DataFrame, `df`, should look as in the following screenshot:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/d24ceede-a86b-41b1-bbd9-7666d58b0ced.png)'
  prefs: []
  type: TYPE_IMG
- en: There are 21 variables in this dataset, where our goal is to predict the target
    variable, `Churn`.
  prefs: []
  type: TYPE_NORMAL
- en: Data analysis and preparation
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'As you may have noticed by looking at the data, there are a few things we need
    to do before we start building machine learning models. In this section, we are
    going to transform continuous variables that have monetary values and encode the
    target variable, `Churn`, as well as other categorical variables. To do so, perform
    the following steps:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Handling missing values in the data**: If you looked through the `TotalCharges` column
    in the dataset, you may have noticed that there are some records with no `TotalCharges` values.
    Since there are only `11` records with missing `TotalCharges` values, we are going
    to simply ignore and drop those records with missing values. Take a look at the
    following code:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE18]'
  prefs: []
  type: TYPE_PRE
- en: As you may notice from this code, we are using the `drop_na` function in the `tidyr`
    package, which drops all records with `NA` values.
  prefs: []
  type: TYPE_NORMAL
- en: '**Categorical variables**: As you can see from the data, there are many categorical
    variables. Let''s first take a look at the number of unique values each column
    has. Take a look at the following code:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE19]'
  prefs: []
  type: TYPE_PRE
- en: 'You can use the `unique` function to get the unique values in each column.
    By applying this function across all the columns in `df`, the output of this code
    looks like the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/1f273b2e-a384-444f-8f1f-7db9920dd7b9.png)'
  prefs: []
  type: TYPE_IMG
- en: As this output suggests, there are `7032` unique customer IDs, `2` unique genders,
    `3` unique values for `MultipleLines`, and `6530` unique values for `TotalCharges`.
    The `tenure`, `MonthlyCharges`, and `TotalCharges` variables, are continuous variables,
    where each variable can take any value and the rest are the categorical variables.
  prefs: []
  type: TYPE_NORMAL
- en: 'We are going to take a look at the distributions of some of these categorical
    variables. First, to view the distribution of the data between male and female,
    you can use the following code for visualization:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE20]'
  prefs: []
  type: TYPE_PRE
- en: 'The plot looks like this:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/6260b535-4c47-4c74-80b2-af0ba8d0fafe.png)'
  prefs: []
  type: TYPE_IMG
- en: 'As you can see from this bar plot, the distribution of the data across the
    two genders is roughly equally distributed. You can use the same code to view
    the distribution of the data across different values of `InternetService` and `PaymentMethod`.
    Take a look at the following plots:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/680a8c86-bc81-438c-aef3-ba25bb90aee9.png)'
  prefs: []
  type: TYPE_IMG
- en: '![](img/37b195d5-6b3d-4733-b792-c19443bf1187.png)'
  prefs: []
  type: TYPE_IMG
- en: The first plot shows the distribution of the data across three different categories
    of the `InternetService` variable and the second plot shows the distribution of
    the data across four different categories of the `PaymentMethod` variable. As
    you can see from these plots, we can easily visualize and understand what the
    distributions of categorical variables look like using bar plots. We recommend
    that you draw bar plots for other categorical variables to get a better understanding
    of the data distribution.
  prefs: []
  type: TYPE_NORMAL
- en: '**Transforming and encoding variables**: The next step is to transform the
    continuous variables and encode the binary-class categorical variables. Take a
    look at the following code:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE21]'
  prefs: []
  type: TYPE_PRE
- en: 'As you can see from this code, we are simply encoding those variables with
    only two categories, `gender`, `Partner`, `Dependents`, `PhoneService`, `PaperlessBilling`,
    and `Churn`, with `0`s and `1`s. Then, we apply log transformations to the two
    continuous variables that have monetary values, `MonthlyCharges` and `TotalCharges`.
    Also, we standardize all three continuous variables, `tenure`, `MonthlyCharges`,
    and `TotalCharges`, so that these variables center around `0` and have standard
    deviations of `1`. This is because ANN models typically perform better with scaled
    or normalized features. After transformations, the distributions of these three
    continuous variables look as in the following screenshot:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/b8f430c2-8ecb-4a6b-91cf-6ab156c6950c.png)'
  prefs: []
  type: TYPE_IMG
- en: 'As you can see, the means of these three transformed variables are `0` and
    the standard deviations are `1`. Whereas, before this transformation, the distributions
    looked like the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/5e6d440f-d902-48a1-a6d9-1c66d4ede730.png)'
  prefs: []
  type: TYPE_IMG
- en: '**One-hot encoding categorical variables**: There is one last set of variables
    we need to transform: multi-class categorical variables that have three or more
    categories. We are going to apply one-hot encoding and create dummy variables
    for these variables. Take a look at the following code:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE22]'
  prefs: []
  type: TYPE_PRE
- en: 'As you can see from this code, we are using the `dummies` library to create
    dummy variables. Using the `dummy` function of this package, we can apply one-hot
    encoding and create dummy variables for each multi-class categorical variable.
    Since the `dummy` function prepends `sampleDF` to the names of the newly created
    dummy variables, we can replace it with corresponding variable name by using the `gsub`
    function. We are going to apply the same logic to the rest of the categorical
    variables, as shown in the following code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE23]'
  prefs: []
  type: TYPE_PRE
- en: 'The results are shown in the following output:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/3f7333f7-b81f-4fae-8a53-06624b08ad67.png)'
  prefs: []
  type: TYPE_IMG
- en: Once you have completed these four steps, it is time to start building ANN models
    for customer churn predictions. Move onto the next section for ANN modeling!
  prefs: []
  type: TYPE_NORMAL
- en: ANN with Keras
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'For building ANN models in R, we are going to use the `keras` package, which
    is a high-level neural networks library. For more details, we recommend you visit
    their official documentation at the following link: [https://keras.io/](https://keras.io/).
    Before we can use this package for building ANN models, we need to install two
    libraries:`tensorflow` and `keras`. The `keras` package uses `tensorflow` as a
    backend for building neural network models, so we need to install `tensorflow` first.
    You can install these two packages using the following commands in your RStudio:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE24]'
  prefs: []
  type: TYPE_PRE
- en: 'Once you have installed these two libraries, we can finally start building
    our first neural network models. In this exercise, we are going to build a neural
    network model with one hidden layer. Take a look at the following code first:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE25]'
  prefs: []
  type: TYPE_PRE
- en: Let's take a closer look at this code. First, we are building a `Sequential` model
    here, `keras_model_sequential`, which is the type of model where the layers are
    stacked linearly and looks similar to the diagram we saw in the earlier section
    about the MLP model. The first layer, `layer_dense`, is an input layer, where `input_shape` is
    simply the number of features or columns in the sample set and the number of output
    units is `16`. We are using the `relu` activation function for this input layer.
    Then, in the hidden layer, the number of output units is `8` and the activation
    function to be used is `relu`. Lastly, the output layer has one output unit, which
    is the probability of customer churn, and we use the `sigmoid` activation function
    in this layer. You can experiment with different numbers of output units and activation
    functions for your exercise. Lastly, we need to compile this model, using the `compile`
    function. Here, we are using the `adam` optimizer, which is one of the most frequently
    used optimization algorithms. Since our target variable is binary, we are using `binary_crossentropy` as
    the `loss` function. Lastly, this model will use the `accuracy` metric to evaluate
    model performance during training.
  prefs: []
  type: TYPE_NORMAL
- en: 'Before we start training this neural network model, we will need to split our
    sample set into train and test sets. Take a look at the following code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE26]'
  prefs: []
  type: TYPE_PRE
- en: 'As you can see from this code, we are using the `sample.split` function of
    the `caTools` package. For our exercise, we will use 70% of the sample set for
    training and 30% for testing. Now we can train our neural network model using
    the following code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE27]'
  prefs: []
  type: TYPE_PRE
- en: 'Here, we are using `100` samples as `batch_size`, from which the model is going
    to learn to predict every time, and `50` as the number of `epochs`, which is the
    number of complete passes through the entire training set. Once you run this code,
    you will see the following output:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/35a5fae0-f1a2-42df-903e-c27aba09ef92.png)'
  prefs: []
  type: TYPE_IMG
- en: As you can see from this output, `loss` typically decreases and the accuracy
    (`acc`) improves in each epoch. However, the rate of model performance improvements
    decreases over time. As you can see from this output, there are big improvements
    in the loss and accuracy measures in the first few epochs and the amount of performance
    gain decreases over time. You can monitor this process and decide to stop when
    the amount of performance gain is minimal.
  prefs: []
  type: TYPE_NORMAL
- en: Model evaluations
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Now that we have built our first neural network model, let''s evaluate its
    performance. We are going to look at the overall accuracy, precision, and recall,
    as well as the ROC curve and AUC. First, take a look at the following code for
    computing accuracy, precision, and recall:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE28]'
  prefs: []
  type: TYPE_PRE
- en: 'You should be familiar with this code, as we used the same evaluation metrics
    in [Chapter 8](4f5163a1-c34a-495f-bc5f-e02f9b2a2052.xhtml), *Predicting the Likelihood
    of Marketing Engagement*. The output of this code in our case looks like the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/d902f785-3d48-4cf3-a2cf-ea30f0ec423c.png)'
  prefs: []
  type: TYPE_IMG
- en: Due to some randomness in the model, your results might differ from these numbers.
    As you can see from this output, the accuracy of predicting whether a customer
    will churn or not in the test set is about `0.83`, suggesting the model is correct
    roughly about 83% of the time. The out-of-sample precision suggests that the model
    is correct about 72% of the time it predicts that the customer is going to churn,
    and the out-of-sample recall suggests that the model captures roughly 58% of the
    churn cases.
  prefs: []
  type: TYPE_NORMAL
- en: 'Next, we can compute the AUC and plot the ROC curve, using the following code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE29]'
  prefs: []
  type: TYPE_PRE
- en: 'And the output looks like the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/9f54bb8f-6c32-4411-86f8-36fb52b697b3.png)'
  prefs: []
  type: TYPE_IMG
- en: Along with the accuracy, precision, and recall measures that we looked at previously,
    the AUC and the ROC curve also suggest that the model captures and predicts those
    customers at churn risk pretty well. As you can see from these evaluation outputs,
    it is better to use the output of this model for identifying the customers who
    are likely to churn than simply guessing who they will be. By focusing on those
    customers with high churn probabilities from this model in your marketing strategies,
    you can try to retain those customers at churn risk in a more cost-effective way.
  prefs: []
  type: TYPE_NORMAL
- en: The full code for this exercise can be found in this repository: [https://github.com/yoonhwang/hands-on-data-science-for-marketing/blob/master/ch.11/R/CustomerRetention.R](https://github.com/yoonhwang/hands-on-data-science-for-marketing/blob/master/ch.11/R/CustomerRetention.R).
  prefs: []
  type: TYPE_NORMAL
- en: Summary
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this chapter, we have learned about customer churn and retention. We have
    discussed the reasons why customer churn hurts businesses. More specifically,
    we have learned how retaining existing customers is much less expensive than acquiring
    new customers. We have shown some of the common reasons why customers leave a
    company, such as poor customer service, not finding enough value in products or
    services, lack of communications, and lack of customer loyalty. In order to understand
    why customers leave, we could conduct surveys or analyze customer data to understand
    their needs and pain points better. We have also discussed how we can train ANN models
    to identify those customers who are at risk of churning. Through programming exercises,
    we have learned how to use the `keras` library to build and train ANN models in
    Python and R.
  prefs: []
  type: TYPE_NORMAL
- en: In the following chapter, we are going to learn about A/B testing and how it
    can be used to determine the best marketing strategy among different options.
    We are going to discuss how to compute statistical significance in Python and
    R to help marketers decide which marketing strategy to choose among different
    ideas.
  prefs: []
  type: TYPE_NORMAL
