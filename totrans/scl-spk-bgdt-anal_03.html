<html><head></head><body>
        <section id="2OM4A1-21aec46d8593429cacea59dbdcd64e1c">

                            <header>
                    </header><h1 class="header-title" id="calibre_pb_0">Functional Programming Concepts</h1>
                
            
            <article>
                
<div class="book-info-bottom-author-body">"Object-oriented programming makes code understandable by encapsulating moving parts. Functional programming makes code understandable by minimizing moving parts."</div>
<p class="cdpalignright">- Michael Feathers</p>
<p class="mce-root">Using Scala and Spark is a very good combination for learning big data analytics. However, along with the OOP paradigm, we also need to know-how why functional concepts are important for writing Spark applications that eventually analyze your data. As mentioned in the previous chapters, Scala supports two programming paradigms: the Object-Oriented Programming paradigm and the Functional programming concepts. In <a href="part0058.html#1NA0K1-21aec46d8593429cacea59dbdcd64e1c" class="calibre10">Chapter 2</a>, <em class="calibre8">Object-Oriented Scala</em>, we explored the OOP paradigm in which we have seen how to represent real-world objects in blueprints (classes) and then instantiate them into objects having real memory representation.</p>
<p class="mce-root">In this chapter, we will focus on the second paradigm (i.e. functional programming). We will see what functional programming is and how Scala supports it, why it matters, and the related advantages of using this concept. More specifically, we will learn several topics, such as why Scala is an arsenal for the data scientist, why it is important to learn the Spark paradigm, pure functions, and <strong class="calibre1">higher-order functions</strong> (<strong class="calibre1">HOFs</strong>). A real-life use case using HOF will also be shown in this chapter. Then, we will see how to handle exceptions in the higher-order functions outside collections using the standard library of Scala. Finally, we will learn how functional Scala affects an object's mutability.</p>
<p class="mce-root">In a nutshell, the following topics will be covered in this chapter:</p>
<ul class="calibre9">
<li class="mce-root1">Introduction to functional programming</li>
<li class="mce-root1">Functional Scala for the data scientists</li>
<li class="mce-root1">Why functional programming and Scala are important for learning Spark?</li>
<li class="mce-root1">Pure functions and higher-order functions</li>
<li class="mce-root1">Using higher-order functions: A real-life use case</li>
<li class="mce-root1">Error handling in functional Scala</li>
<li class="mce-root1">Functional programming and data mutability</li>
</ul>


            </article>

            
        </section>
    

        <section id="2PKKS1-21aec46d8593429cacea59dbdcd64e1c">

                            <header>
                    </header><h1 class="header-title" id="calibre_pb_0">Introduction to functional programming</h1>
                
            
            <article>
                
<p class="mce-root"><span>In computer science, <kbd class="calibre11">functional programming</kbd> (FP) is a programming paradigm and a unique style of building the structure and elements of computer programs. This uniqueness helps treat the computation as the evaluation of mathematical functions and avoids changing-state and mutable data. Thus, by using the FP concept, you can learn to code in your own style that ensures the immutability of your data.</span> <span>In other words,</span> FP is about writing pure functions, about removing hidden inputs and outputs as far as we can, so that as much of our code as possible <em class="calibre8">just</em> describes a relationship between inputs and outputs.</p>
<p class="mce-root">This is not a new concept but the <kbd class="calibre11">Lambda Calculus</kbd>, which provides the basis of FP, was first introduced in the 1930s. However, in the realm of programming language, the term functional programming refers to a new style of declarative programming paradigm that means programming can be done with the help of control, declarations, or expressions instead of classical statements commonly used in an old programming language, such as C.</p>


            </article>

            
        </section>
    

        <section id="2QJ5E1-21aec46d8593429cacea59dbdcd64e1c">

                            <header>
                    </header><h1 class="header-title" id="calibre_pb_0">Advantages of functional programming</h1>
                
            
            <article>
                
<p class="mce-root">There are some exciting and cool features in FP paradigms such as <kbd class="calibre11">composition</kbd>, <kbd class="calibre11">pipelining</kbd>, and <kbd class="calibre11">higher order functions</kbd> that help to avoid writing unfunctional code. Alternatively, at least later on, this helps translate a unfunctional program into a functional style towards an imperative one. Finally, now let's see how we can define the term functional programming from the computer science perspective. Functional programming is a common computer science concept in which computations and the building structure of the program are treated as if you are evaluating mathematical functions that support immutable data and avoid state change. In functional programming, each function has the same mapping or output for the same input argument values.</p>
<p class="mce-root">With the need for a complex software comes the need for good structured programs and software that are not difficult to write and are debuggable. We also need to write extendable code that will save us programming costs in the future and can contribute to easy writing and debugging of the code; even more modular software that is easy to extend and requires less programming efforts. Due to the latter contribution of functional programming, modularity, functional programming is considered as a great advantage for software development.</p>
<p class="mce-root">In functional programming, there is a basic building block in its structure called functions without side effects (or at least very few) in most of your code. Without side effects, the order of evaluation really doesn't matter. When it comes to programming languages views, there are methods to force a particular order. In some FP languages (for example, eager languages such as Scheme), which have no evaluation order on arguments, you could nest these expressions in their own lambda forms as follows:</p>
<pre class="calibre19">
((lambda (val1) <br class="title-page-name"/>  ((lambda (val2) <br class="title-page-name"/>    ((lambda (val3) (/ (* val1 val2) val3)) <br class="title-page-name"/>      expression3)) ; evaluated third<br class="title-page-name"/>      expression2))   ; evaluated second<br class="title-page-name"/>    expression1)      ; evaluated first
</pre>
<p class="mce-root">In functional programming, writing mathematical functions in which the execution order doesn't matter usually makes your code more readable. Sometimes, one will argue that we need functions with side effects to be there as well. Actually, this is one of the major disadvantages of most functional programming languages since it's typically difficult to write functions that don't require any I/O; on the other hand, these function that requires I/O are difficult to implement in functional programming. From <em class="calibre8">Figure 1</em>, it can be seen that Scala is also a hybrid language that evolved by taking features from imperative languages such as Java and functional language such as Lisp.</p>
<p class="mce-root">But fortunately, here we are dealing with a mixed language in which object-oriented and functional programming paradigms are allowed and hence writing such functions that require I/O is quite easy. Functional programming also has major advantages over basic programming, such as comprehensions and caching.</p>
<p class="mce-root">One of the major advantages of functional programming is brevity because with functional programming you can write more compact and concise code. Also, concurrency is considered one of the major advantages, which is done more easily in functional programming. Therefore, functional languages such as Scala provide many other features and tools that encourage coders to make an entire paradigm shift to a more mathematical way of thinking.</p>
<div class="cdpaligncenter"><img class="image-border22" src="../images/00062.jpeg"/></div>
<div class="cdpaligncenter1"><strong class="calibre1">Figure 1:</strong> Shows a conceptual view of using functional programming concepts</div>
<p class="mce-root">By narrowing the focus to only a small number of composable abstract concepts, such as functions, function composition, and abstract algebra, FP concept provides several advantages over other paradigms. For example:</p>
<ul class="calibre9">
<li class="mce-root1"><strong class="calibre1">Closer alignment to mathematical thinking:</strong> You tend to spell out your ideas in a format close to mathematical definitions rather than iterative programs.</li>
<li class="mce-root1"><strong class="calibre1">No (or at least fewer) side effects:</strong> Your functions do not influence other functions, which is great for concurrency and parallelization, and also for debugging.</li>
<li class="mce-root1"><strong class="calibre1">Fewer lines of code without sacrificing conceptual clarity:</strong> Lisp is more powerful than non-functional languages. Although it's true that you need to spend a greater proportion of your project thinking than writing, you will probably find that you are more productive eventually.</li>
</ul>
<p class="mce-root">For these exciting features, functional programming achieves significant expressive power. For example, machine learning algorithms can take hundreds of lines of imperative code to implement yet they can be defined in just a handful of equations.</p>


            </article>

            
        </section>
    

        <section id="2RHM01-21aec46d8593429cacea59dbdcd64e1c">

                            <header>
                    </header><h1 class="header-title" id="calibre_pb_0">Functional Scala for the data scientists</h1>
                
            
            <article>
                
<p class="mce-root">For performing interactive data cleaning, processing, munging, and analysis, many data scientists use R or Python as their favorite tool. However, there are many data scientists who tend to get very attached to their favorite tool--that is, Python or R and try to solve all data analytics problems or jobs using that tool. Thus, introducing them to a new tool can be very challenging in most circumstances as the new tool has more syntax and a new set of patterns to learn before using the new tool to solve their purpose.</p>
<p class="mce-root">There are other APIs in Spark written in Python and R such as PySpark and SparkR respectively that allow you to use them from Python or R. However, most Spark books and online examples are written in Scala. Arguably, we think that learning how to work with Spark using the same language on which the Spark code has been written will give you many advantages over Java, Python, or R as a data scientist:</p>
<ul class="calibre9">
<li class="mce-root1">Better performance and removes the data processing overhead</li>
<li class="mce-root1">Provides access to the latest and greatest features of Spark</li>
<li class="mce-root1">Helps to understand the Spark philosophy in a transparent way</li>
</ul>
<p class="mce-root">Analyzing data means that you are writing Scala code to retrieve data from the cluster using Spark and its APIs (that is, SparkR, SparkSQL, Spark Streaming, Spark MLlib, and Spark GraphX). Alternatively, you're developing a Spark application using Scala to manipulate that data locally on your own machine. In both cases, Scala is your real friend and will pay you dividends in time.</p>


            </article>

            
        </section>
    

        <section id="2SG6I1-21aec46d8593429cacea59dbdcd64e1c">

                            <header>
                    </header><h1 class="header-title" id="calibre_pb_0">Why FP and Scala for learning Spark?</h1>
                
            
            <article>
                
<p class="mce-root">In this section, we will discuss why we will learn Spark to solve our data analytics problem. We will then discuss why the functional programming concepts in Scala are particularly important to make data analysis easier for the data scientists. We will also discuss the Spark programming model and its ecosystem to make them clearer.</p>


            </article>

            
        </section>
    

        <section id="2TEN41-21aec46d8593429cacea59dbdcd64e1c">

                            <header>
                    </header><h1 class="header-title" id="calibre_pb_0">Why Spark?</h1>
                
            
            <article>
                
<p class="mce-root">Spark is a lightning fast cluster computing framework and is mainly designed for fast computations. Spark is based on the Hadoop MapReduce model and uses MapReduce in more forms and types of computation, such as interactive queries and stream processing. One of the main features of Spark is in-memory processing, which helps increase the performance and processing speed of an application. Spark supports a wide range of applications and workloads, such as the following:</p>
<ul class="calibre9">
<li class="mce-root1">Batch-based applications</li>
<li class="mce-root1">Iterative algorithms that were not possible to run fast before</li>
<li class="mce-root1">Interactive query and streaming</li>
</ul>
<p class="mce-root">Also, it doesn't require much time for you to learn Spark and implement it in your applications without the need to understand the inner details of concurrency and distributed systems. Spark was implemented in 2009 at AMPLab of UC Berkeley. In 2010, they decided to make it open source. Then, Spark became an Apache release in 2013 and since then Spark has been considered as the most famous/used Apache-released software. Apache Spark became very famous because of its features:</p>
<ul class="calibre9">
<li class="mce-root1"><strong class="calibre1">Fast computations</strong>: Spark helps you to run applications that are faster than Hadoop because of its golden feature--in-memory processing.</li>
<li class="mce-root1"><strong class="calibre1">Support for multiple programming languages</strong>: Apache Spark provides wrappers and built-in APIs in different languages such as Scala, Java, Python, or even R.</li>
<li class="mce-root1"><strong class="calibre1">More analytics</strong>: As mentioned earlier, Spark supports MapReduce operations and it also supports more advanced analytics such as <strong class="calibre1">machine learning</strong> (<strong class="calibre1">MLlib</strong>), data streaming, and algorithms for graph processing.</li>
</ul>
<p class="mce-root">As mentioned earlier, Spark is built on top of the Hadoop software and you can deploy Spark in different ways:</p>
<ul class="calibre9">
<li class="mce-root1"><strong class="calibre1">Standalone cluster</strong>: This means that Spark will run on top of <strong class="calibre1">Hadoop Distributed File System</strong> (<strong class="calibre1">HDFS</strong>) and space will actually be allocated to HDFS. Spark and MapReduce will run side by side to serve all the Spark jobs.</li>
<li class="mce-root1"><strong class="calibre1">Hadoop YARN cluster</strong>: This means that Spark simply runs on YARN without any root privileges or pre-installations.</li>
<li class="mce-root1"><strong class="calibre1">Mesos cluster</strong>: When a driver program creates a Spark job and starts assigning related tasks for scheduling, Mesos determines which computing nodes will handle which tasks. We assume that you have already configured and installed Mesos on your machine.</li>
<li class="mce-root1"><strong class="calibre1">Deploy on pay-as-you-go cluster</strong>: You can deploy Spark jobs in real cluster mode on AWS EC2. To make your applications run on Spark cluster mode and for better scalability, you can consider <strong class="calibre1">Amazon Elastic Compute Cloud</strong> (<strong class="calibre1">EC2</strong>) services as <strong class="calibre1">Infrastructure as a Service</strong> (<strong class="calibre1">IaaS</strong>) or <strong class="calibre1">Platform as a Service</strong> (<strong class="calibre1">PaaS</strong>).</li>
</ul>
<div class="packt_tip">Refer to <a href="part0511.html#F7AFE1-21aec46d8593429cacea59dbdcd64e1c" class="calibre21">Chapter 17</a>, <em class="calibre25">Time to Go to ClusterLand - Deploying Spark on a Cluster</em> and <a href="part0550.html#GCGLC1-21aec46d8593429cacea59dbdcd64e1c" class="calibre21">Chapter 18</a>, <em class="calibre25">Testing and Debugging Spark</em> for how to deploy your data analytics application using Scala and Spark on a real cluster.</div>


            </article>

            
        </section>
    

        <section id="2UD7M1-21aec46d8593429cacea59dbdcd64e1c">

                            <header>
                    </header><h1 class="header-title" id="calibre_pb_0">Scala and the Spark programming model</h1>
                
            
            <article>
                
<p class="mce-root">Spark programming starts with a dataset or a few, usually residing in some form of distributed and persistent storage such as HDFS. A typical RDD programming model that Spark provides can be described as follows:</p>
<ul class="calibre9">
<li class="mce-root1">From an environment variable, Spark context (the Spark shell provides you with a Spark Context or you can make your own, this will be described later in this chapter) creates an initial data reference RDD object.</li>
<li class="mce-root1">Transform the initial RDD to create more RDD objects following the functional programming style (to be discussed later on).</li>
<li class="mce-root1">Send the code, algorithms, or applications from the driver program to the cluster manager nodes. Then, the cluster manager provides a copy to each computing node.</li>
<li class="mce-root1">Computing nodes hold a reference to the RDDs in their partition (again, the driver program also holds a data reference). However, computing nodes could have the input dataset provided by the cluster manager as well.</li>
<li class="mce-root1">After a transformation (via either narrow or wider transformation), the result to be generated is a brand new RDD, since the original one will not be mutated.</li>
<li class="mce-root1">Finally, the RDD object or more (specifically, data reference) is materialized through an action to dump the RDD into the storage.</li>
<li class="mce-root1">The driver program can ask the computing nodes for a chunk of results for the analysis or visualization of a program.</li>
</ul>
<p class="mce-root">Wait! So far we have moved smoothly. We suppose you will ship your application code to the computing nodes in the cluster. Still, you will have to upload or send the input datasets to the cluster to be distributed among the computing nodes. Even during the bulk upload, you will have to transfer the data across the network. We also argue that the size of the application code and results are negligible or trivial. Another obstacle is if you want Spark to process the data at scale computation, it might require data objects to be merged from multiple partitions first. This means we will need to shuffle data among the worker/computing nodes that is usually done by <kbd class="calibre11">partition()</kbd>, <kbd class="calibre11">intersection()</kbd>, and <kbd class="calibre11">join()</kbd> transformation operations.</p>


            </article>

            
        </section>
    

        <section id="2VBO81-21aec46d8593429cacea59dbdcd64e1c">

                            <header>
                    </header><h1 class="header-title" id="calibre_pb_0">Scala and the Spark ecosystem</h1>
                
            
            <article>
                
<p class="mce-root">To provide more enhancement and additional big data processing capabilities, Spark can be configured and run on top of existing Hadoop-based clusters. The core APIs in Spark, on the other hand, are written in Java, Scala, Python, and R. Compared to MapReduce, with the more general and powerful programming model, Spark also provides several libraries that are part of the Spark ecosystems for additional capabilities for general-purpose data processing and analytics, graph processing, large-scale structured SQL, and <strong class="calibre1">Machine Learning</strong> (<strong class="calibre1">ML</strong>) areas.</p>
<p class="mce-root">The Spark ecosystem consists of the following components as shown (for details please refer <a href="part0480.html#E9OE01-21aec46d8593429cacea59dbdcd64e1c" class="calibre10">Chapter 16﻿</a>, <em class="calibre8">Spark Tuning</em>):</p>
<ul class="calibre9">
<li class="mce-root1"><strong class="calibre1">Apache Spark core</strong>: This is the underlying engine for the Spark platform on which all the other functionalities are built. Also, it's the one that provides in-memory processing.</li>
<li class="mce-root1"><strong class="calibre1">Spark SQL</strong>: As mentioned Spark core is the underlying engine and all the other components or features are built upon it. Spark SQL is the Spark component that provides support for different data structures (structured and semi-structured data).</li>
<li class="mce-root1"><strong class="calibre1">Spark streaming</strong>: This component is responsible for streaming data for analytics and converts them into mini batches that can be used later on for analytics.</li>
<li class="mce-root1"><strong class="calibre1">MLlib (Machine Learning Library)</strong>: MLlib is a machine learning framework that supports lots of ML algorithms in a distributed fashion.</li>
<li class="mce-root1"><strong class="calibre1">GraphX</strong>: A distributed graph framework built on top of Spark to express user-defined graph components in a parallel fashion.</li>
</ul>
<p class="mce-root">As mentioned earlier, most functional programming languages allow the user to write nice, modular, and extensible code. Also, functional programming encourages safe ways of programming by writing functions that look like mathematical functions. Now, how did Spark make all the APIs work as a single unit? It was possible because of the advancement in the hardware and of course, the functional programming concepts. Since adding syntactic sugar to easily do lambda expressions is not sufficient to make a language functional, this is just the start.</p>
<p class="mce-root">Although the RDD concept in Spark works quite well, there are many use cases where it's a bit complicated due to its immutability. For the following example which is the classic example of calculating an average, make the source code robust and readable; of course, to reduce the overall cost, one does not want to first compute totals, then counts, even if the data is cached in the main memory.</p>
<pre class="calibre19">
val data: RDD[People] = ...<br class="title-page-name"/>data.map(person =&gt; (person.name, (person.age, 1)))<br class="title-page-name"/>.reduceByKey(_ |+| _)<br class="title-page-name"/>.mapValues { case (total, count) =&gt;<br class="title-page-name"/>  total.toDouble / count<br class="title-page-name"/>}.collect()
</pre>
<p class="mce-root">The DataFrames API (this will be discussed in the later chapters in detail) produces equally terse and readable code where the functional API fits well for most use cases and minimizes the MapReduce stages; there are many shuffles that can cost dramatically and the key reasons for this are as follows:</p>
<ul class="calibre9">
<li class="mce-root1">Large code bases require static typing to eliminate trivial mistakes, such as <em class="calibre8">aeg</em> instead of <em class="calibre8">age</em> instantly</li>
<li class="mce-root1">Complex code requires transparent APIs to communicate design clearly</li>
<li class="mce-root1">2x speed-ups in the DataFrames API via under-the-hood mutation can be equally achieved by encapsulating state via OOP and using mapPartitions and combineByKey</li>
<li class="mce-root1">Flexibility and Scala features are required to build functionality quickly</li>
</ul>
<p class="mce-root">The combination of OOP and FP with Spark can make a pretty hard problem easier in Barclays. For example, in Barclays, recently an application called Insights Engine has been developed to execute an arbitrary number N of near-arbitrary SQL-like queries. The application can execute them in a way that can scale with increasing N.</p>
<p class="mce-root">Now let's talk about pure functions, higher order functions, and anonymous functions, which are the three important concepts in the functional programming of Scala.</p>


            </article>

            
        </section>
    

        <section id="30A8Q1-21aec46d8593429cacea59dbdcd64e1c">

                            <header>
                    </header><h1 class="header-title" id="calibre_pb_0">Pure functions and higher-order functions</h1>
                
            
            <article>
                
<p class="mce-root">From the computer science perspective, functions can have many forms such as first order functions, higher-order functions, or pure functions. This is also true from the mathematics point of view. Using a higher-order function is a function one of the following can be performed:</p>
<ul class="calibre9">
<li class="mce-root1">Takes one or more functions as arguments to do some operations</li>
<li class="mce-root1">Returns a function as its result</li>
</ul>
<p class="mce-root">All other functions except the higher-order functions are first-order functions. However, from the mathematics point of view, higher-order functions are also called <strong class="calibre1">operators</strong> or <strong class="calibre1">functionals</strong>. On the other hand, if the return value of a function is only determined by its input and of course without observable side effects, it is called a <strong class="calibre1">pure function</strong>.</p>
<p class="mce-root">In this section, we will briefly discuss why and how to use different functional paradigms in Scala. Especially, pure functions, and higher-order functions will be discussed. At the end of this section, a brief overview of using anonymous functions will also be provided since this is used frequently while developing a Spark application using Scala.</p>


            </article>

            
        </section>
    

        <section id="318PC1-21aec46d8593429cacea59dbdcd64e1c">

                            <header>
                    </header><h1 class="header-title" id="calibre_pb_0">Pure functions</h1>
                
            
            <article>
                
<p class="mce-root">One of the most important principles of functional programming is pure functions. So what are pure functions and why do we care about them? In this section, we will address this important feature of functional programming. One of the best practices of functional programming is to implement your programs such that the core of your program/application is made from pure functions and all the I/O functions or side effects such as network overhead and exceptions are in an exposed external layer.</p>
<p class="mce-root">So what are the benefits of pure functions? Pure functions are normally smaller than normal functions (although it depends on other factors such as programming language) and even easier to interpret and understand for the human brain because it looks like a mathematical function.</p>
<p class="mce-root">Yet, you might argue against this since most developers still find imperative programming more understandable! Pure functions are much easier to implement and test. Let's demonstrate this by an example. Suppose we have the following two separate functions:</p>
<pre class="calibre19">
def pureFunc(cityName: String) = s"I live in $cityName"<br class="title-page-name"/>def notpureFunc(cityName: String) = println(s"I live in $cityName")
</pre>
<p class="mce-root">So in the previous two examples, if you want to test the <kbd class="calibre11">pureFunc</kbd> pure function, we just assert the return value that's coming from the pure function with what we are expecting based on our input such as:</p>
<pre class="calibre19">
assert(pureFunc("Dublin") == "I live in Dublin")
</pre>
<p class="mce-root">But on the other side, if we wanted to test our <kbd class="calibre11">notpureFunc</kbd> impure function then we need to redirect the standard output and then apply assertion on it. The next practical tip is that functional programming makes programmers more productive because, as mentioned earlier, pure functions are smaller and easier to write and you can easily compose them together. Also, the duplication of code is minimal and you can easily reuse your code. Now let's demonstrate this advantage with a better example. Consider these two functions:</p>
<pre class="calibre19">
<strong class="calibre1">scala&gt; def pureMul(x: Int, y: Int) = x * y</strong><br class="title-page-name"/><strong class="calibre1">pureMul: (x: Int, y: Int)Int<br class="title-page-name"/></strong><br class="title-page-name"/><strong class="calibre1">scala&gt; def notpureMul(x: Int, y: Int) = println(x * y)</strong><br class="title-page-name"/><strong class="calibre1">notpureMul: (x: Int, y: Int)Unit</strong>
</pre>
<p class="mce-root">However, there might be side effects of mutability; using a pure function (that is, without mutability) helps us reason about and test code:</p>
<pre class="calibre19">
def pureIncrease(x: Int) = x + 1
</pre>
<p class="mce-root">This one is advantageous and very easy to interpret and use. However, let's see another example:</p>
<pre class="calibre19">
varinc = 0<br class="title-page-name"/>def impureIncrease() = {<br class="title-page-name"/>  inc += 1<br class="title-page-name"/>  inc<br class="title-page-name"/>}
</pre>
<p class="mce-root">Now, consider how confusing this could be: what will be the output in a multithreaded environment? As you can see, we can easily use our pure function, <kbd class="calibre11">pureMul</kbd>, to multiply any sequence of numbers, unlike our <kbd class="calibre11">notpureMul</kbd> impure function. Let's demonstrate this by the following example:</p>
<pre class="calibre19">
<strong class="calibre1">scala&gt; Seq.range(1,10).reduce(pureMul)</strong><br class="title-page-name"/><strong class="calibre1">res0: Int = 362880</strong>
</pre>
<p class="mce-root">The complete code for the preceding examples can be shown as follows (methods were called using some real values):</p>
<pre class="calibre19">
package com.chapter3.ScalaFP<br class="title-page-name"/><br class="title-page-name"/>object PureAndNonPureFunction {<br class="title-page-name"/>  def pureFunc(cityName: String) = s"I live in $cityName"<br class="title-page-name"/>  def notpureFunc(cityName: String) = println(s"I live in $cityName")<br class="title-page-name"/>  def pureMul(x: Int, y: Int) = x * y<br class="title-page-name"/>  def notpureMul(x: Int, y: Int) = println(x * y)  <br class="title-page-name"/>  <br class="title-page-name"/>  def main(args: Array[String]) {<br class="title-page-name"/>    //Now call all the methods with some real values<br class="title-page-name"/>    pureFunc("Galway") //Does not print anything<br class="title-page-name"/>    notpureFunc("Dublin") //Prints I live in Dublin<br class="title-page-name"/>    pureMul(10, 25) //Again does not print anything<br class="title-page-name"/>    notpureMul(10, 25) // Prints the multiplicaiton -i.e. 250   <br class="title-page-name"/>  <br class="title-page-name"/>    //Now call pureMul method in a different way<br class="title-page-name"/>    val data = Seq.range(1,10).reduce(pureMul)<br class="title-page-name"/>    println(s"My sequence is: " + data)<br class="title-page-name"/>  }<br class="title-page-name"/>}
</pre>
<p class="mce-root">The output of the preceding code is as follows:</p>
<pre class="calibre19">
<strong class="calibre1">I live in Dublin 250 </strong><br class="title-page-name"/><strong class="calibre1">My sequence is: 362880</strong>
</pre>
<p class="mce-root">As discussed earlier, you can consider pure functions as one of the most important features of functional programming and as a best practice; you need to build the core of your application using pure functions.</p>
<div class="packt_infobox"><span class="field">Functions versus methods:</span><br class="calibre23"/>
In the programming realm, a <strong class="calibre27">function</strong> is a piece of code called by a name. Data (as an argument or as a parameter) can be passed to operate on and can return data (optionally). All data passed to a function is passed explicitly. A <strong class="calibre27">method,</strong> on the other hand, is also a piece of code that is called by a name too. However, a method is always associated with an object. Sounds similar? Well! In most cases, a method is identical to a function except for two key differences:<br class="calibre23"/>
1. A method is implicitly passed the object on which it was called.<br class="calibre23"/>
2. A method is able to operate on data that is contained within the class.<br class="calibre23"/>
<br class="calibre23"/>
It is already stated in the previous chapter that an object is an instance of a class--the class is the definition, the object is an instance of that data.</div>
<p class="mce-root">Now it's time to learn about higher-order functions. However, before that, we should learn one more important concept in functional Scala--<strong class="calibre1">anonymous functions</strong>. Through this, we will also learn how to use the lambda expression with functional Scala.</p>


            </article>

            
        </section>
    

        <section id="3279U1-21aec46d8593429cacea59dbdcd64e1c">

                            <header>
                    </header><h1 class="header-title" id="calibre_pb_0">Anonymous functions</h1>
                
            
            <article>
                
<p class="mce-root">Sometimes in your code, you don't want to define a function prior to its usage, maybe because you will use it in one place. In functional programming, there's a type of function that is very suitable to this situation. It's called an anonymous function. Let's demonstrate the use of anonymous functions using the previous example of transferring money:</p>
<pre class="calibre19">
def TransferMoney(money: Double, bankFee: Double =&gt; Double): Double = {<br class="title-page-name"/>  money + bankFee(money)<br class="title-page-name"/>}
</pre>
<p class="mce-root">Now, let's call the <kbd class="calibre11">TransferMoney()</kbd> method with some real value as follows:</p>
<pre class="calibre19">
 TransferMoney(100, (amount: Double) =&gt; amount * 0.05)
</pre>
<div class="packt_infobox"><span class="field">Lambda expression:</span><br class="calibre23"/>
As already stated, Scala supports first-class functions, which means functions can be expressed in function-literal syntax as well; functions can be represented by objects, called function values. Try the following expression, it creates a successor function for integers:<br class="calibre23"/>
<kbd class="calibre22">scala&gt; var apply = (x:Int) =&gt; x+1</kbd><br class="calibre23"/>
<kbd class="calibre22">apply: Int =&gt; Int = &lt;function1&gt;</kbd><br class="calibre23"/>
The apply variable is now a function that can be used in the usual way as follows:<br class="calibre23"/>
<kbd class="calibre22">scala&gt; var x = apply(7)</kbd><br class="calibre23"/>
<kbd class="calibre22">x: Int = 8</kbd><br class="calibre23"/>
What we have done here is simply use the core of a function: the argument list followed by the function arrow and the body of the function. This one is not black magic but a full-fledged function, only without a given name--that is, anonymous. If you define a function this way, there will be no way to refer to that function afterward and hence you couldn't call that function afterward because without a name it's an anonymous one. Also, we have a so-called <strong class="calibre27">lambda expression</strong>! It's just the pure, anonymous definition of a function.</div>
<p class="mce-root">The output of the preceding code is as follows:</p>
<pre class="calibre19">
<strong class="calibre1">105.0</strong>
</pre>
<p class="mce-root">So, in the previous example instead of declaring a separate <kbd class="calibre11">callback</kbd> function, we passed an anonymous function directly and it did the same job just like the <kbd class="calibre11">bankFee</kbd> function. You can also omit the type in the anonymous function and it will be directly inferred based on the passed argument like this:</p>
<pre class="calibre19">
TransferMoney(100, amount =&gt; amount * 0.05)
</pre>
<p class="mce-root">The output of the preceding code is as follows:</p>
<pre class="calibre19">
<strong class="calibre1">105.0</strong>
</pre>
<p class="mce-root">Let's demonstrate the previous example on the Scala shell as shown in the following screenshot:</p>
<div class="cdpaligncenter"><img class="image-border23" src="../images/00066.jpeg"/></div>
<div class="cdpaligncenter1"><strong class="calibre1">Figure 6:</strong> Use of the anonymous function in Scala</div>
<p class="mce-root">Some programming languages that have functional support use the name lambda function instead of anonymous function.</p>


            </article>

            
        </section>
    

        <section>

                            <header id="335QG2-21aec46d8593429cacea59dbdcd64e1c">
                    </header><h1 class="header-title" id="calibre_pb_0">Higher-order functions</h1>
                
            
            <article>
                
<p class="mce-root">In Scala's functional programming, you are allowed to pass functions as parameters and even return a function as a result from another function; this defines what are called higher-order functions.</p>
<p class="mce-root">Let's demonstrate this feature by an example. Consider the following function <kbd class="calibre11">testHOF</kbd> that takes another function <kbd class="calibre11">func</kbd> and then applies this function to its second argument value:</p>
<pre class="calibre19">
object Test {<br class="title-page-name"/>  def main(args: Array[String]) {<br class="title-page-name"/>    println( testHOF( paramFunc, 10) )<br class="title-page-name"/>  }<br class="title-page-name"/>  def testHOF(func: Int =&gt; String, value: Int) = func(value)<br class="title-page-name"/>  def paramFunc[A](x: A) = "[" + x.toString() + "]"<br class="title-page-name"/>}
</pre>
<p class="mce-root">After demonstrating the basics of Scala's functional programming, now we are ready to move to more complex cases of functional programming. As mentioned earlier, we can define a higher-order function as a function that accepts other functions as arguments and it returns them as a result. If you are coming from an object-oriented programming background, you will find it very a different approach, but it will become easier to understand as we go on.</p>
<p class="mce-root">Let's start by defining a simple function:</p>
<pre class="calibre19">
def quarterMaker(value: Int): Double = value.toDouble/4
</pre>
<p class="mce-root">The previous function is a very simple one. It's a function that accepts an Int value and then returns a quarter of this value in a <kbd class="calibre11">Double</kbd> type. Let's define another simple function:</p>
<pre class="calibre19">
def addTwo(value: Int): Int = value + 2
</pre>
<p class="mce-root">The second function <kbd class="calibre11">addTwo</kbd> is more trivial than the first one. It accepts an <kbd class="calibre11">Int</kbd> value and then adds 2 to it. As you can see, these two functions have something in common. Both of them accept <kbd class="calibre11">Int</kbd> and return another processed value that we can call <kbd class="calibre11">AnyVal</kbd>. Now, let's define a higher-order function that accepts another function among its parameters:</p>
<pre class="calibre19">
def applyFuncOnRange(begin: Int, end: Int, func: Int =&gt; AnyVal): Unit = {<br class="title-page-name"/>  for (i &lt;- begin to end)<br class="title-page-name"/>    println(func(i))<br class="title-page-name"/>}
</pre>
<p class="cdpalignleft1">As you can see, the preceding function <kbd class="calibre11">applyFuncOnRange</kbd> accepts two <kbd class="calibre11">Int</kbd> values that work as a beginning and end to a sequence and it accepts a function that has the <kbd class="calibre11">Int =&gt; AnyVal</kbd> signature just like the previously defined simple functions (<kbd class="calibre11">quarterMakder</kbd> and <kbd class="calibre11">addTwo</kbd>). Now let's demonstrate our previous higher-order function by passing one of the two simple functions to it as a third argument (if you want to pass your own function then make sure that it has the same signature <kbd class="calibre11">Int =&gt; AnyVal</kbd>).</p>
<div class="cdpalignleft2"><strong class="calibre27">Scala syntax for loop with ranges:</strong> The simplest syntax of using a for loop with ranges in Scala is:<br class="calibre23"/>
<kbd class="calibre22">for( var x &lt;- range ){</kbd><br class="calibre23"/>
<kbd class="calibre22">statement(s)</kbd><br class="calibre23"/>
<kbd class="calibre22">}</kbd><br class="calibre23"/>
Here, the <kbd class="calibre22">range</kbd> could be a range of numbers and is represented as <kbd class="calibre22">i</kbd> to <kbd class="calibre22">j</kbd> or sometimes like <kbd class="calibre22">i</kbd> until <kbd class="calibre22">j</kbd>. The left-arrow <kbd class="calibre22">←</kbd> operator is called a generator because it's generating individual values from a range. Let's see a concrete example of this feature:<br class="calibre23"/>
<kbd class="calibre22">object UsingRangeWithForLoop {</kbd><br class="calibre23"/>
<kbd class="calibre22">def main(args: Array[String]):Unit= {</kbd><br class="calibre23"/>
<kbd class="calibre22">var i = 0;</kbd><br class="calibre23"/>
<kbd class="calibre22">// for loop execution with a range</kbd><br class="calibre23"/>
<kbd class="calibre22">for( i &lt;- 1 to 10){</kbd><br class="calibre23"/>
<kbd class="calibre22">println( "Value of i: " + i )</kbd><br class="calibre23"/>
<kbd class="calibre22">}</kbd><br class="calibre23"/>
<kbd class="calibre22">}</kbd><br class="calibre23"/>
<kbd class="calibre22">}</kbd><br class="calibre23"/>
The output of the preceding code is as follows:<br class="calibre23"/>
<kbd class="calibre22">Value of i: 1</kbd><br class="calibre23"/>
<kbd class="calibre22">Value of i: 2</kbd><br class="calibre23"/>
<kbd class="calibre22">Value of i: 3</kbd><br class="calibre23"/>
<kbd class="calibre22">Value of i: 4</kbd><br class="calibre23"/>
<kbd class="calibre22">Value of i: 5</kbd><br class="calibre23"/>
<kbd class="calibre22">Value of i: 6</kbd><br class="calibre23"/>
<kbd class="calibre22">Value of i: 7</kbd><br class="calibre23"/>
<kbd class="calibre22">Value of i: 8</kbd><br class="calibre23"/>
<kbd class="calibre22">Value of i: 9</kbd><br class="calibre23"/>
<kbd class="calibre22">Value of i: 10</kbd></div>
<p class="cdpalignleft1">Let's first define our functions before starting to use them as shown in the following screenshot:</p>
<div class="cdpaligncenter"><img class="image-border24" src="../images/00070.jpeg"/></div>
<div class="cdpaligncenter1"><strong class="calibre1">Figure 2:</strong> An example of defining a higher-order function in Scala</div>
<p class="mce-root">Now, let's start by calling our higher-order function <kbd class="calibre11">applyFuncOnRange</kbd> and passing the <kbd class="calibre11">quarterMaker</kbd> function as a third argument:</p>
<div class="cdpaligncenter"><img class="image-border25" src="../images/00074.jpeg"/></div>
<div class="cdpaligncenter1"><strong class="calibre1">Figure 3:</strong> Calling a higher-order function</div>
<p class="mce-root">We can even apply the other function <kbd class="calibre11">addTwo</kbd> since it has the same signature as shown in the following screenshot:</p>
<div class="cdpaligncenter"><img class="image-border26" src="../images/00079.jpeg"/></div>
<div class="cdpaligncenter1"><strong class="calibre1">Figure 4:</strong> An alternative way of calling a higher-order function</div>
<p class="cdpalignleft1">Before going into more examples, let's define what's called a callback function. A callback function is a function that can be passed as an argument to another function. Other functions are simply normal functions. Let's demonstrate more examples of using different callback functions. Consider the following higher-order function, which is responsible for transferring a specific amount of money from your account:</p>
<pre class="calibre19">
def TransferMoney(money: Double, bankFee: Double =&gt; Double): Double = {<br class="title-page-name"/>  money + bankFee(money)<br class="title-page-name"/>}<br class="title-page-name"/>def bankFee(amount: Double) = amount * 0.05
</pre>
<p class="mce-root">After calling the <kbd class="calibre11">TransferMoney</kbd> function on 100:</p>
<pre class="calibre19">
TransferMoney(100, bankFee)
</pre>
<p class="mce-root">The output of the preceding code is as follows:</p>
<pre class="calibre19">
<strong class="calibre1">105.0</strong>
</pre>
<p class="mce-root">From a functional programming point of view, this code is not ready to be integrated into the banking system because you need to apply different validations on the money parameters, such as it has to be positive and greater than the specific amount specified by the bank. However, here we are just demonstrating the use of high-order functions and callback functions.</p>
<p class="mce-root">So, this example works as follows: you want to transfer a specific amount of money to another bank account or money agent. The bank has a specific fee to be applied depending on the amount that you are transferring and here comes the role of the callback function. It takes the amount of money to transfer and applies the bank fee to it in order to come up with the total amount.</p>
<p class="mce-root">The <kbd class="calibre11">TransferMoney</kbd> function takes two parameters: the first one is the money to be transferred and the second one is a callback function with the signature <kbd class="calibre11">Double =&gt; Double</kbd> that the function applies to the money argument to determine the bank fee over the transferred money.</p>
<div class="cdpaligncenter"><img class="image-border27" src="../images/00083.jpeg"/></div>
<div class="cdpaligncenter1"><strong class="calibre1">Figure 5:</strong> Calling and giving extra power to the higher-order function</div>
<p class="mce-root">The complete source code of the preceding examples can be seen as follows (we called the methods using some real values):</p>
<pre class="calibre19">
package com.chapter3.ScalaFP<br class="title-page-name"/>object HigherOrderFunction {<br class="title-page-name"/>  def quarterMaker(value: Int): Double = value.toDouble / 4<br class="title-page-name"/>  def testHOF(func: Int =&gt; String, value: Int) = func(value)<br class="title-page-name"/>  def paramFunc[A](x: A) = "[" + x.toString() + "]"<br class="title-page-name"/>  def addTwo(value: Int): Int = value + 2<br class="title-page-name"/>  def applyFuncOnRange(begin: Int, end: Int, func: Int =&gt; AnyVal): Unit = {<br class="title-page-name"/>    for (i &lt;- begin to end)<br class="title-page-name"/>      println(func(i))<br class="title-page-name"/>  }<br class="title-page-name"/>  def transferMoney(money: Double, bankFee: Double =&gt; Double): Double = {<br class="title-page-name"/>    money + bankFee(money)<br class="title-page-name"/>  }<br class="title-page-name"/>  def bankFee(amount: Double) = amount * 0.05<br class="title-page-name"/>  def main(args: Array[String]) {<br class="title-page-name"/>    //Now call all the methods with some real values<br class="title-page-name"/>    println(testHOF(paramFunc, 10)) // Prints [10]<br class="title-page-name"/>    println(quarterMaker(20)) // Prints 5.0<br class="title-page-name"/>    println(paramFunc(100)) //Prints [100]<br class="title-page-name"/>    println(addTwo(90)) // Prints 92<br class="title-page-name"/>    println(applyFuncOnRange(1, 20, addTwo)) // Prints 3 to 22 and ()<br class="title-page-name"/>    println(TransferMoney(105.0, bankFee)) //prints 110.25<br class="title-page-name"/>  }<br class="title-page-name"/>}
</pre>
<p class="mce-root">The output of the preceding code is as follows:</p>
<pre class="calibre19">
<strong class="calibre1">[10] </strong><br class="title-page-name"/><strong class="calibre1">5.0 </strong><br class="title-page-name"/><strong class="calibre1">[100] </strong><br class="title-page-name"/><strong class="calibre1">92 </strong><br class="title-page-name"/><strong class="calibre1">3 4 5 6 7 8 9 10 11 12 13 14 15 16 1718 19 20 21 22 () </strong><br class="title-page-name"/><strong class="calibre1">110.25</strong>
</pre>
<p class="mce-root">By using callback functions, you are giving extra power to the higher-order function; so, it's a very powerful mechanism to make your program more elegant, flexible, and efficient.</p>


            </article>

            
        </section>
    

        <section id="344B21-21aec46d8593429cacea59dbdcd64e1c">

                            <header>
                    </header><h1 class="header-title" id="calibre_pb_0">Function as a return value</h1>
                
            
            <article>
                
<p class="mce-root">As mentioned, higher-order functions also support returning a function as a result. Let's demonstrate this by an example:</p>
<pre class="calibre19">
def transferMoney(money: Double) = {<br class="title-page-name"/>  if (money &gt; 1000)<br class="title-page-name"/>    (money: Double) =&gt; "Dear customer we are going to add the following<br class="title-page-name"/>                        amount as Fee: "+money * 0.05<br class="title-page-name"/>  else<br class="title-page-name"/>    (money: Double) =&gt; "Dear customer we are going to add the following<br class="title-page-name"/>                        amount as Fee: "+money * 0.1<br class="title-page-name"/>} <br class="title-page-name"/>val returnedFunction = TransferMoney(1500)<br class="title-page-name"/>returnedFunction(1500)
</pre>
<p class="mce-root">The preceding code segment will produce the following output:</p>
<pre class="calibre19">
<strong class="calibre1">Dear customer, we are going to add the following amount as Fee: 75.0</strong>
</pre>
<p class="mce-root">Let's run the previous example as shown in the following screenshot; it shows how to use the function as a return value:</p>
<div class="cdpaligncenter"><img class="image-border28" src="../images/00087.jpeg"/></div>
<div class="cdpaligncenter1"><strong class="calibre1">Figure 7:</strong> Function as a return value</div>
<p class="cdpalignleft1">The complete code of the preceding example can be seen as follows:</p>
<pre class="calibre19">
package com.chapter3.ScalaFP<br class="title-page-name"/>object FunctionAsReturnValue {<br class="title-page-name"/>  def transferMoney(money: Double) = {<br class="title-page-name"/>    if (money &gt; 1000)<br class="title-page-name"/>      (money: Double) =&gt; "Dear customer, we are going to add following<br class="title-page-name"/>                          amount as Fee: " + money * 0.05<br class="title-page-name"/>    else<br class="title-page-name"/>      (money: Double) =&gt; "Dear customer, we are going to add following<br class="title-page-name"/>                          amount as Fee: " + money * 0.1<br class="title-page-name"/>  }  <br class="title-page-name"/>  def main(args: Array[String]) {<br class="title-page-name"/>    val returnedFunction = transferMoney(1500.0)<br class="title-page-name"/>    println(returnedFunction(1500)) //Prints Dear customer, we are <br class="title-page-name"/>                         going to add following amount as Fee: 75.0<br class="title-page-name"/>  }<br class="title-page-name"/>}
</pre>
<p class="cdpalignleft1">The output of the preceding code is as follows:</p>
<pre class="calibre19">
<strong class="calibre1">Dear customer, we are going to add following amount as Fee: 75.0</strong>
</pre>
<p class="cdpalignleft1">Now before stopping our discussion on HFO, let's see a real-life example, that is, currying using HFO.</p>


            </article>

            
        </section>
    

        <section id="352RK1-21aec46d8593429cacea59dbdcd64e1c">

                            <header>
                    </header><h1 class="header-title" id="calibre_pb_0">Using higher-order functions</h1>
                
            
            <article>
                
<p class="cdpalignleft1">Suppose you work in a restaurant as a chef and one of your colleagues ask you a question: Implement a <strong class="calibre1">HOF</strong> (<strong class="calibre1">higher-order function</strong>) that performs currying. Looking for clues? Suppose you have the following two signatures for your HOF:</p>
<pre class="cdpalignleft3">
def curry[X,Y,Z](f:(X,Y) =&gt; Z) : X =&gt; Y =&gt; Z
</pre>
<p class="cdpalignleft1">Similarly, implement a function that performs uncurrying as follows:</p>
<pre class="cdpalignleft3">
def uncurry[X,Y,Z](f:X =&gt; Y =&gt; Z): (X,Y) =&gt; Z
</pre>
<p class="cdpalignleft1">Now, how could you use HOFs to perform the currying operation? Well, you could create a trait that encapsulates the signatures of two HOFs (that is, curry and uncurry) as follows:</p>
<pre class="cdpalignleft3">
trait Curry {<br class="title-page-name"/>  def curry[A, B, C](f: (A, B) =&gt; C): A =&gt; B =&gt; C<br class="title-page-name"/>  def uncurry[A, B, C](f: A =&gt; B =&gt; C): (A, B) =&gt; C<br class="title-page-name"/>}
</pre>
<p class="cdpalignleft1">Now, you can implement and extend this trait as an object as follows:</p>
<pre class="cdpalignleft3">
<br class="title-page-name"/>object CurryImplement extends Curry {<br class="title-page-name"/>  def uncurry[X, Y, Z](f: X =&gt; Y =&gt; Z): (X, Y) =&gt; Z = { (a: X, b: Y) =&gt; f(a)(b) }<br class="title-page-name"/>  def curry[X, Y, Z](f: (X, Y) =&gt; Z): X =&gt; Y =&gt; Z = { (a: X) =&gt; { (b: Y) =&gt; f(a, b) } }<br class="title-page-name"/>}
</pre>
<p class="cdpalignleft1">Here I have implemented the uncurry first since it's easier. The two curly braces after the equals sign are an anonymous function literal for taking two arguments (that is, <kbd class="calibre11">a</kbd> and <kbd class="calibre11">b</kbd> of types <kbd class="calibre11">X</kbd> and <kbd class="calibre11">Y</kbd> respectively). Then, these two arguments can be used in a function that also returns a function. Then, it passes the second argument to the returned function. Finally, it returns the value of the second function. The second function literal takes one argument and returns a new function, that is, <kbd class="calibre11">curry()</kbd>. Eventually, it returns a function when called returns another function.</p>
<p class="cdpalignleft1">Now it comes: how to use the preceding object that extends the base trait in a real-life implementation. Here's an example:</p>
<pre class="cdpalignleft3">
object CurryingHigherOrderFunction {<br class="title-page-name"/>  def main(args: Array[String]): Unit = {<br class="title-page-name"/>    def add(x: Int, y: Long): Double = x.toDouble + y<br class="title-page-name"/>    val addSpicy = CurryImplement.curry(add) <br class="title-page-name"/>    println(addSpicy(3)(1L)) // prints "4.0"    <br class="title-page-name"/>    val increment = addSpicy(2) <br class="title-page-name"/>    println(increment(1L)) // prints "3.0"    <br class="title-page-name"/>    val unspicedAdd = CurryImplement.uncurry(addSpicy) <br class="title-page-name"/>    println(unspicedAdd(1, 6L)) // prints "7.0"<br class="title-page-name"/>  }<br class="title-page-name"/>}
</pre>
<p class="cdpalignleft1">In the preceding object and inside the main method:</p>
<ul class="calibre9">
<li class="mce-root1">The <kbd class="calibre11">addSpicy</kbd> holds a function that takes a long as a type and adds 1 to it and then prints 4.0.</li>
<li class="mce-root1">The <kbd class="calibre11">increment</kbd> holds a function which takes a long as a type and adds 2 to it and finally prints 3.0.</li>
<li class="mce-root1">The <kbd class="calibre11">unspicedAdd</kbd> holds a function which adds 1 and takes a long as type. Finally, it prints 7.0.</li>
</ul>
<p class="cdpalignleft1">The output of the preceding code is as follows:</p>
<pre class="cdpalignleft3">
<strong class="calibre1">4.0</strong><br class="title-page-name"/><strong class="calibre1">3.0</strong><br class="title-page-name"/><strong class="calibre1">7.0</strong><span><br class="title-page-name"/></span>
</pre>
<div class="cdpalignleft2">In mathematics and computer science, currying is the technique of translating the evaluation of a function that takes multiple arguments (or a tuple of arguments) into evaluating a sequence of functions, each with a a single argument. Currying is related to, but not the same as, partial application:<br class="calibre23"/>
<strong class="calibre27">Currying:</strong> Currying is useful in both practical and theoretical settings. In functional programming languages, and many others, it provides a way of automatically managing how arguments are passed to functions and exceptions. In theoretical computer science, it provides a way to study functions with multiple arguments in simpler theoretical models, which provide only one argument.<br class="calibre23"/>
<strong class="calibre27">Uncurrying:</strong> Uncurrying is the dual transformation to currying, and can be seen as a form of defunctionalization. It takes a function <kbd class="calibre22">f</kbd> whose return value is another function <kbd class="calibre22">g</kbd> and yields a new function <kbd class="calibre22">f′</kbd> that takes as parameters the arguments for both <kbd class="calibre22">f</kbd> and <kbd class="calibre22">g</kbd>, and returns, as a result, the application of <kbd class="calibre22">f</kbd> and subsequently, <kbd class="calibre22">g</kbd>, to those arguments. The process can be iterated.</div>
<p class="cdpalignleft1">So far, we have seen how to deal with pure, higher-order, and anonymous functions in Scala. Now, let's have a brief overview on how to extend the higher-order function using <kbd class="calibre11">Throw</kbd>, <kbd class="calibre11">Try</kbd>, <kbd class="calibre11">Either</kbd>, and <kbd class="calibre11">Future</kbd> in the following section.</p>


            </article>

            
        </section>
    

        <section id="361C61-21aec46d8593429cacea59dbdcd64e1c">

                            <header>
                    </header><h1 class="header-title" id="calibre_pb_0">Error handling in functional Scala</h1>
                
            
            <article>
                
<p class="mce-root">So far, we focused on ensuring that the body of a Scala function does what it's supposed to and doesn't do anything else (that is, an error or exception). Now, in order to make use of any programming and to avoid producing error-prone code then you need to know how to catch exceptions and handle errors in this language. We will see how to extend higher-order functions outside collections using some special features of Scala such as <kbd class="calibre11">Try</kbd>, <kbd class="calibre11">Either</kbd>, and <kbd class="calibre11">Future</kbd>.</p>


            </article>

            
        </section>
    

        <section id="36VSO1-21aec46d8593429cacea59dbdcd64e1c">

                            <header>
                    </header><h1 class="header-title" id="calibre_pb_0">Failure and exceptions in Scala</h1>
                
            
            <article>
                
<p class="mce-root">At first, let's define what we mean by failures in general (source: <a href="https://tersesystems.com/2012/12/27/error-handling-in-scala/" class="calibre10">https://tersesystems.com/2012/12/27/error-handling-in-scala/</a>):</p>
<ul class="calibre9">
<li class="mce-root1"><strong class="calibre1">Unexpected internal failure</strong>: The operation fails as the result of an unfulfilled expectation, such as a null pointer reference, violated assertions, or simply bad state</li>
<li class="mce-root1"><strong class="calibre1">Expected internal failure</strong>: The operation fails deliberately as a result of internal state, that is, a blacklist or circuit breaker</li>
<li class="mce-root1"><strong class="calibre1">Expected external failure</strong>: The operation fails because it is told to process some raw input, and will fail if the raw input cannot be processed</li>
<li class="mce-root1"><strong class="calibre1">Unexpected external failure</strong>: The operation fails because a resource that the system depends on is not there: there's a loose file handle, the database connection fails, or the network is down</li>
</ul>
<p class="mce-root">Unfortunately, there are no concrete ways of stopping failures unless the failures are due to some manageable exceptions. On the other hand, Scala makes <em class="calibre8">checked versus unchecked</em> very simple: it doesn't have checked exceptions. All exceptions are unchecked in Scala, even <kbd class="calibre11">SQLException</kbd> and <kbd class="calibre11">IOException</kbd>, and so on. Now let's see how to handle such exceptions at least.</p>


            </article>

            
        </section>
    

        <section id="37UDA1-21aec46d8593429cacea59dbdcd64e1c">

                            <header>
                    </header><h1 class="header-title" id="calibre_pb_0">Throwing exceptions</h1>
                
            
            <article>
                
<p class="mce-root">A Scala method can throw an exception because of the unexpected workflow. You create an exception object and then you throw it with the throw keyword as follows. For example:</p>
<pre class="calibre19">
//code something<br class="title-page-name"/>throw new IllegalArgumentException("arg 2 was wrong...");<br class="title-page-name"/>//nothing will be executed from here.
</pre>
<p class="mce-root">Note that the primary goal of using exception handling is not to produce friendly messages but to exit the normal flow of your Scala program.</p>


            </article>

            
        </section>
    

        <section id="38STS1-21aec46d8593429cacea59dbdcd64e1c">

                            <header>
                    </header><h1 class="header-title" id="calibre_pb_0">Catching exception using try and catch</h1>
                
            
            <article>
                
<p class="mce-root">Scala allows you to try/catch any exception in a single block and then perform pattern matching against it using case blocks. The basic syntax of using <kbd class="calibre11">try...catch</kbd> in Scala is as follows:</p>
<pre class="calibre19">
try<br class="title-page-name"/>{<br class="title-page-name"/>  // your scala code should go here<br class="title-page-name"/>} <br class="title-page-name"/>catch<br class="title-page-name"/>{<br class="title-page-name"/>  case foo: FooException =&gt; handleFooException(foo)<br class="title-page-name"/>  case bar: BarException =&gt; handleBarException(bar)<br class="title-page-name"/>  case _: Throwable =&gt; println("Got some other kind of exception")<br class="title-page-name"/>}<br class="title-page-name"/>finally<br class="title-page-name"/>{<br class="title-page-name"/>  // your scala code should go here, such as to close a database connection <br class="title-page-name"/>}
</pre>
<p class="mce-root">Thus, if you throw an exception, then you need to use the <kbd class="calibre11">try...catch</kbd> block in order to handle it nicely without crashing with an internal exception message:</p>
<pre class="calibre19">
package com.chapter3.ScalaFP<br class="title-page-name"/>import java.io.IOException<br class="title-page-name"/>import java.io.FileReader<br class="title-page-name"/>import java.io.FileNotFoundException<br class="title-page-name"/><br class="title-page-name"/>object TryCatch {<br class="title-page-name"/>  def main(args: Array[String]) {<br class="title-page-name"/>    try {<br class="title-page-name"/>      val f = new FileReader("data/data.txt")<br class="title-page-name"/>    } catch {<br class="title-page-name"/>      case ex: FileNotFoundException =&gt; println("File not found exception")<br class="title-page-name"/>      case ex: IOException =&gt; println("IO Exception") <br class="title-page-name"/>    } <br class="title-page-name"/>  }<br class="title-page-name"/>}
</pre>
<p class="mce-root">If there's no file named <kbd class="calibre11">data.txt</kbd>, in the path/data under your project tree, you will experience <kbd class="calibre11">FileNotFoundException</kbd> as follows:</p>
<p class="mce-root">The output of the preceding code is as follows:</p>
<pre class="calibre19">
<strong class="calibre1">File not found exception</strong>
</pre>
<p class="mce-root">Now, let's have a brief example of using the <kbd class="calibre11">finally</kbd> clause in Scala to make the <kbd class="calibre11">try...catch</kbd> block complete.</p>


            </article>

            
        </section>
    

        <section id="39REE1-21aec46d8593429cacea59dbdcd64e1c">

                            <header>
                    </header><h1 class="header-title" id="calibre_pb_0">Finally</h1>
                
            
            <article>
                
<p class="mce-root">Suppose you want to execute your code regardless of an exception being thrown or not, then you should use the <kbd class="calibre11">finally</kbd> clause. You can place it inside the <kbd class="calibre11">try block</kbd> as follows. Here is an example:</p>
<pre class="calibre19">
try {<br class="title-page-name"/>    val f = new FileReader("data/data.txt")<br class="title-page-name"/>  } catch {<br class="title-page-name"/>    case ex: FileNotFoundException =&gt; println("File not found exception")<br class="title-page-name"/>  } finally { println("Dude! this code always executes") }<br class="title-page-name"/>}
</pre>
<p class="mce-root">Now, here's the complete example of using <kbd class="calibre11">try...catch...finally</kbd>:</p>
<pre class="calibre19">
package com.chapter3.ScalaFP<br class="title-page-name"/>import java.io.IOException<br class="title-page-name"/>import java.io.FileReader<br class="title-page-name"/>import java.io.FileNotFoundException<br class="title-page-name"/><br class="title-page-name"/>object TryCatch {<br class="title-page-name"/>  def main(args: Array[String]) {<br class="title-page-name"/>    try {<br class="title-page-name"/>      val f = new FileReader("data/data.txt")<br class="title-page-name"/>    } catch {<br class="title-page-name"/>      case ex: FileNotFoundException =&gt; println("File not found <br class="title-page-name"/>                                                 exception")<br class="title-page-name"/>      case ex: IOException =&gt; println("IO Exception") <br class="title-page-name"/>    } finally {<br class="title-page-name"/>      println("Finally block always executes!")<br class="title-page-name"/>    }<br class="title-page-name"/>  }<br class="title-page-name"/>}
</pre>
<p class="mce-root">The output of the preceding code is as follows:</p>
<pre class="calibre19">
<strong class="calibre1">File not found exception </strong><br class="title-page-name"/><strong class="calibre1">Finally block always executes!</strong>
</pre>
<p class="mce-root">Next, we will discuss another powerful feature in Scala called <kbd class="calibre11">Either</kbd>.</p>


            </article>

            
        </section>
    

        <section id="3APV01-21aec46d8593429cacea59dbdcd64e1c">

                            <header>
                    </header><h1 class="header-title" id="calibre_pb_0">Creating an Either</h1>
                
            
            <article>
                
<p class="mce-root"><kbd class="calibre11">Either[X, Y]</kbd> is an instance that contains either an instance of <kbd class="calibre11">X</kbd> or an instance of <kbd class="calibre11">Y</kbd> but not both. We call these subtypes left and right of Either. Creating an Either is trivial. But it's very powerful sometimes to use it in your program:</p>
<pre class="calibre19">
package com.chapter3.ScalaFP<br class="title-page-name"/>import java.net.URL<br class="title-page-name"/>import scala.io.Source<br class="title-page-name"/>object Either {<br class="title-page-name"/>  def getData(dataURL: URL): Either[String, Source] =<br class="title-page-name"/>    if (dataURL.getHost.contains("xxx"))<br class="title-page-name"/>      Left("Requested URL is blocked or prohibited!")<br class="title-page-name"/>    else<br class="title-page-name"/>      Right(Source.fromURL(dataURL))      <br class="title-page-name"/>  def main(args: Array[String]) {<br class="title-page-name"/>      val either1 = getData(new URL("http://www.xxx.com"))    <br class="title-page-name"/>      println(either1)      <br class="title-page-name"/>      val either2 = getData(new URL("http://www.google.com"))    <br class="title-page-name"/>      println(either2)<br class="title-page-name"/>  }<br class="title-page-name"/>}
</pre>
<p class="mce-root">Now, if we pass any arbitrary URL that doesn't contain <kbd class="calibre11">xxx</kbd> then we will get a <kbd class="calibre11">Scala.io.Source</kbd> wrapped in a <kbd class="calibre11">Right</kbd> subtype. If the URL contains <kbd class="calibre11">xxx</kbd>, then we will get a <kbd class="calibre11">String</kbd> wrapped in a <kbd class="calibre11">Left</kbd> subtype. To make the preceding statement clearer, let's see the output of the preceding code segment:</p>
<pre class="calibre19">
<strong class="calibre1">Left(Requested URL is blocked or prohibited!) Right(non-empty iterator)</strong>
</pre>
<p class="mce-root">Next, we will explore another interesting feature of Scala called <kbd class="calibre11">Future</kbd> that is used to execute tasks in a non-blocking way. This is also a better way to handle the results when they finish.</p>


            </article>

            
        </section>
    

        <section id="3BOFI1-21aec46d8593429cacea59dbdcd64e1c">

                            <header>
                    </header><h1 class="header-title" id="calibre_pb_0">Future</h1>
                
            
            <article>
                
<p class="mce-root">If you simply want to run tasks in a non-blocking way and need a way to handle the results when they finish, Scala provides you with Futures, for example, if you want to make multiple web service calls in a parallel fashion and work with the results after the web service handles all these calls. An example of using Future is provided in the following section.</p>


            </article>

            
        </section>
    

        <section id="3CN041-21aec46d8593429cacea59dbdcd64e1c">

                            <header>
                    </header><h1 class="header-title" id="calibre_pb_0">Run one task, but block</h1>
                
            
            <article>
                
<p class="mce-root">The following example demonstrates how to create a Future and then block the sequence of execution in order to wait for its result. Creating Futures is trivial. You just need to pass it to the code that you want. The following example performs 2+2 in the future and then returns the results:</p>
<pre class="calibre19">
package com.chapter3.ScalaFP<br class="title-page-name"/>import scala.concurrent.ExecutionContext.Implicits.global<br class="title-page-name"/>import scala.concurrent.duration._<br class="title-page-name"/>import scala.concurrent.{Await, Future}<br class="title-page-name"/><br class="title-page-name"/>object RunOneTaskbutBlock {<br class="title-page-name"/>  def main(args: Array[String]) {<br class="title-page-name"/>    // Getting the current time in Milliseconds<br class="title-page-name"/>    implicit val baseTime = System.currentTimeMillis    <br class="title-page-name"/>    // Future creation<br class="title-page-name"/>    val testFuture = Future {<br class="title-page-name"/>      Thread.sleep(300)<br class="title-page-name"/>      2 + 2<br class="title-page-name"/>    }    <br class="title-page-name"/>    // this is the blocking part<br class="title-page-name"/>    val finalOutput = Await.result(testFuture, 2 second)<br class="title-page-name"/>    println(finalOutput)<br class="title-page-name"/>  }<br class="title-page-name"/>}
</pre>
<p class="mce-root">The <kbd class="calibre11">Await.result</kbd> method waits up to 2 seconds till the <kbd class="calibre11">Future</kbd> returns the result; if it doesn't return the result within 2 seconds, it throws the following exception you might want to handle or catch:</p>
<pre class="calibre19">
<strong class="calibre1">java.util.concurrent.TimeoutException</strong>
</pre>
<p class="mce-root">It's time to wrap up this chapter. However, I would like to take the chance to discuss an important view of mine about functional programming with Scala and object mutability.</p>


            </article>

            
        </section>
    

        <section id="3DLGM1-21aec46d8593429cacea59dbdcd64e1c">

                            <header>
                    </header><h1 class="header-title" id="calibre_pb_0">Functional programming and data mutability</h1>
                
            
            <article>
                
<p class="mce-root">Pure functional programming is one of the best practices in functional programming and you should stick to it. Writing pure functions will make your programming life easier and you will be able to write code that's easy to maintain and extend. Also, if you want to parallelize your code then it will be easier to do so if you write pure functions.</p>
<p class="mce-root">If you're an FP purist, one drawback of using functional programming in Scala is that Scala supports both OOP and FP (see <em class="calibre8">Figure 1</em>), and therefore it's possible to mix the two coding styles in the same code base. In this chapter, we have seen several examples showing that writing pure functions is easy. However, combining them into a complete application is difficult. You might agree that advanced topics such as monads make FP intimidating.</p>
<p class="mce-root">I talked to many people and they think that the recursion doesn't feel reasonably natural. When you use immutable objects, you can never mutate them with something else. There aren't times when you are allowed to do that. That's the whole point of immutable objects! Sometimes what I have experienced is that a pure function and data input or output really mixes up. However, when you need to mutate, you can create a copy of the object containing your mutated field. Thus, theoretically, there's no need to <em class="calibre8">mix up</em>. Lastly, using only immutable values and recursion can potentially lead to performance problems in terms of CPU usage and RAM.</p>


            </article>

            
        </section>
    

        <section id="3EK181-21aec46d8593429cacea59dbdcd64e1c">

                            <header>
                    </header><h1 class="header-title" id="calibre_pb_0">Summary</h1>
                
            
            <article>
                
<p class="mce-root">In this chapter, we have explored some functional programming concepts in Scala. We have seen what functional programming is and how Scala supports it, why it matters, and the advantages of using functional concepts. We have seen why learning FP concepts is important in learning the Spark paradigm. Pure functions, anonymous functions, and higher-order functions were discussed with suitable examples. Later in this chapter, we saw how to handle exceptions in the higher-order functions outside collections using the standard library of Scala. Finally, we discussed how functional Scala affects object mutability.</p>
<p class="mce-root">In the next chapter, we will provide an in-depth analysis on the Collections API, one of the most prominent features of the standard library.</p>


            </article>

            
        </section>
    </body></html>